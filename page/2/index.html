<!DOCTYPE html>
<html lang="zh">
<head><meta name="generator" content="Hexo 3.9.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    
    <title>曹文强</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="A note is preferable to the best memory">
<meta property="og:type" content="website">
<meta property="og:title" content="曹文强">
<meta property="og:url" content="atlantic8.github.io/page/2/index.html">
<meta property="og:site_name" content="曹文强">
<meta property="og:description" content="A note is preferable to the best memory">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="曹文强">
<meta name="twitter:description" content="A note is preferable to the best memory">
    

    

    
        <link rel="icon" href="/css/images/logo.png">
    

    <link rel="stylesheet" href="/libs/font-awesome5/css/fontawesome.min.css">
    <link rel="stylesheet" href="/libs/font-awesome5/css/fa-brands.min.css">
    <link rel="stylesheet" href="/libs/font-awesome5/css/fa-solid.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    
        <script>
var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?ff86ad40748d96af89d192e9b0a3ae62";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    


</head>
</html>
<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">曹文强</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/.">Home</a>
                
                    <a class="main-nav-link" href="/archives">Archives</a>
                
                    <a class="main-nav-link" href="/categories/OJ">OJ</a>
                
                    <a class="main-nav-link" href="/categories/Algorithm">Algorithm</a>
                
                    <a class="main-nav-link" href="/categories/Math">Math</a>
                
                    <a class="main-nav-link" href="/categories/Dev">Dev</a>
                
                    <a class="main-nav-link" href="/about">About</a>
                
            </nav>
            
                
                <nav id="sub-nav">
                    <div class="profile" id="profile-nav">
                        <a id="profile-anchor" href="javascript:;">
                            <img class="avatar" src="/css/images/me.png" />
                            <i class="fas fa-caret-down"></i>
                        </a>
                    </div>
                </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fas fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/.">Home</a></td>
                
                    <td><a class="main-nav-link" href="/archives">Archives</a></td>
                
                    <td><a class="main-nav-link" href="/categories/OJ">OJ</a></td>
                
                    <td><a class="main-nav-link" href="/categories/Algorithm">Algorithm</a></td>
                
                    <td><a class="main-nav-link" href="/categories/Math">Math</a></td>
                
                    <td><a class="main-nav-link" href="/categories/Dev">Dev</a></td>
                
                    <td><a class="main-nav-link" href="/about">About</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
                

<aside id="profile" class="profile-fixed">
    <div class="inner profile-inner">
        <div class="base-info profile-block">
            <img id="avatar" src="/css/images/me.png" />
            <h2 id="name">曹文强</h2>
            <h3 id="title">algorithm engineer</h3>
            <span id="location"><i class="fas fa-map-marker-alt" style="padding-right: 5px"></i>Beijing, China</span>
            <a id="follow" target="_blank" href="https://github.com/Atlantic8">关注我</a>
        </div>
        <div class="article-info profile-block">
            <div class="article-info-block">
                134
                <span>文章</span>
            </div>
            <div class="article-info-block">
                48
                <span>标签</span>
            </div>
        </div>
        
        <div class="profile-block social-links">
            <table>
                <tr>
                    
                    
                    <td>
                        <a href="https://github.com/Atlantic8" target="_blank" title="github" class=tooltip>
                            
                                <i class="fab fa-github"></i>
                            
                        </a>
                    </td>
                    
                    <td>
                        <a href="https://www.linkedin.com/in/wenqiang-cao-704236b8/" target="_blank" title="linkedin" class=tooltip>
                            
                                <i class="fab fa-linkedin"></i>
                            
                        </a>
                    </td>
                    
                    <td>
                        <a href="mailto:atlantic8@outlook.com" target="_blank" title="envelope" class=tooltip>
                            
                                <i class="fas fa-envelope"></i>
                            
                        </a>
                    </td>
                    
                    <td>
                        <a href="http://weibo.com/2614093607" target="_blank" title="weibo" class=tooltip>
                            
                                <i class="fab fa-weibo"></i>
                            
                        </a>
                    </td>
                    
                    <td>
                        <a href="/" target="_blank" title="facebook" class=tooltip>
                            
                                <i class="fab fa-facebook"></i>
                            
                        </a>
                    </td>
                    
                </tr>
            </table>
        </div>
        
    </div>
</aside>

            
            <section id="main">
    <article id="post-NLP-Pre-train-Models-after-Bert" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2020/08/30/NLP-Pre-train-Models-after-Bert/">NLP Pre-train Models after Bert</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fas fa-calendar-alt"></i>
        <a href="/2020/08/30/NLP-Pre-train-Models-after-Bert/">
            <time datetime="2020-08-30T05:16:49.000Z" itemprop="datePublished">2020-08-30</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fas fa-folder"></i>
        <a class="article-category-link" href="/categories/Algorithm/">Algorithm</a>
    </div>

                        
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/NLP/">NLP</a>, <a class="tag-link" href="/tags/deep-learning/">deep learning</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <p>BERT开启了NLP领域预训练模型的时代，BERT之后大量的改型出现，以下会介绍一些。</p>
<h3 id="ALBERT"><a href="#ALBERT" class="headerlink" title="ALBERT"></a>ALBERT</h3><p>ALBERT的设计目标是解决BERT参数量大的问题</p>
<p>其主要做了如下的修改</p>
<ul>
<li>embedding分解<ul>
<li>intuition是：transformer的输入词的embedding维度和隐层输出维度一样大，但是<strong>隐层除了词本身信息还包含了上下文信息</strong>，所以词的embedding维度可以小一点</li>
<li>降低维度的方法是<strong>对输入的onehot矩阵进行分解，映射到低维度空间E，然后再映射到H维</strong>，输入到Transformer中。将参数量由O(VH)降到O(VE+EH)，当E远小于H时，参数量会下降很多。（假设V为词的总数）</li>
</ul>
</li>
<li>参数贡献<ul>
<li>共享encoder内的所有参数，包含多头注意力和前向网络</li>
</ul>
</li>
<li>Sentence-Order Prediction<ul>
<li>BERT的next sentence prediction是个二分类任务，负样本是通过采用两个不同的文档的句子，后续的研究发现该任务效果并不好。NSP其实<strong>包含主题预测与句子关系一致性预测两个子任务</strong>，但是主题预测相比于关系一致性预测简单太多了，模型学习NSP任务的时候可能<strong>只学到了主题预测</strong>，而没学到句子关系一致性</li>
<li>SOP则在样本选取上去除了主题不同的因素，将<strong>正样本反过来当作负样本</strong></li>
</ul>
</li>
</ul>
<p>ALBERT论文表示在训练了100w步之后，模型依旧没有过拟合，于是乎作者移除了dropout，没想到对下游任务的效果竟然有一定的提升。这也是业界<strong>第一次发现dropout对大规模的预训练模型会造成负面影响</strong></p>
<h3 id="ERNIE"><a href="#ERNIE" class="headerlink" title="ERNIE"></a>ERNIE</h3><p>ERNIE是大百度的中文预训练模型，有两个版本</p>
<h5 id="1-0"><a href="#1-0" class="headerlink" title="1.0"></a>1.0</h5><p>ERNIE1.0在BERT的基础上做了如下事情</p>
<ul>
<li>在mask语言模型上，不再局限于mask单个token，而是考虑mask短语和实体</li>
<li><strong>直接对先验语义知识单元进行建模，增强了模型语义表示能力</strong></li>
<li>海量中文数据，Dialogue Language Model</li>
</ul>
<h5 id="2-0"><a href="#2-0" class="headerlink" title="2.0"></a>2.0</h5><p>ERNIE2.0的要点如下：</p>
<ul>
<li>多任务学习的引入，<strong>输入层加入了task embedding</strong></li>
<li>构建了词法级别，语法级别，语义级别的预训练任务<ul>
<li>词法<ul>
<li><strong>mask短语和实体</strong>，同1.0</li>
<li><strong>大写字母预测</strong>：大写的词一般会有特殊含义</li>
<li><strong>Token-Document关系预测</strong>：预测一个词在文中的A 段落出现，是否会在文中的B 段落出现</li>
</ul>
</li>
<li>语法<ul>
<li><strong>句子顺序预测</strong>：文本分段，所有shuffle的组合后模型预测正确顺序</li>
<li><strong>句子距离预测</strong>：三分类任务（0表示两个句子是同一个文章中相邻的句子，1表示两个句子是在同一个文章，但是不相邻，2表示两个句子是不同的文章）</li>
</ul>
</li>
<li>语义<ul>
<li>判断句子对之间的<strong>语义关系</strong>，比如修辞</li>
<li>搜索下<strong>query和title的相关性</strong></li>
</ul>
</li>
</ul>
</li>
<li>大量的百度生态语料<ul>
<li>搜索日志</li>
<li>贴吧对话</li>
<li>百科数据</li>
<li>新闻内容</li>
</ul>
</li>
</ul>
<h3 id="XLNET"><a href="#XLNET" class="headerlink" title="XLNET"></a>XLNET</h3><blockquote>
<p>XLNet: Generalized Autoregressive Pretraining<br>for Language Understanding</p>
</blockquote>
<p>Elmo、GPT这种单向语言模型属于<strong>自回归语言模型(<br>autoregressive)</strong>，模型在当前位置只能看到之前看到过的数据。Bert这类双向语言模型，属于自编码语言模型（autoencoder），可以<strong>对上下文进行完整建模</strong>，在BERT与GPT的对比数据中也可以看出来其优点。但是这种模型也存在问题：</p>
<ul>
<li>bert训练时用到了mask语言模型，引入了[MASK]标识，但是fine-tuning阶段没有，导致<strong>预训练阶段和fine-tuning阶段存在不一致的问题</strong></li>
<li>模型在预测一个被mask掉的单词，<strong>无法利用其他被mask掉的单词信息</strong></li>
</ul>
<p>xlnet就是想鱼和熊掌兼得，那么怎么能够在单词Ti的上文中Contenxt_before中揉入下文Context_after的内容呢?</p>
<h5 id="Permutation-Language-Model"><a href="#Permutation-Language-Model" class="headerlink" title="Permutation Language Model"></a>Permutation Language Model</h5><p>最naive的思想就是：在预测$x_k$时，固定$x_k$，将$x_{!= k}$打乱，这样当前单词就能看见原来在其之后的单词了。在随机排列组合后的各种可能里，再选择一部分作为模型预训练的输入。</p>
<p>但是这样会有问题，假设出现一个长度为n的序列，原序列为$x$，两个排列$z^{(1)},z^{(2)}$，第t个位置不一样(对应于之前的$x_i,x_j$)，之前的位置都一样，所以由自回归语言模型定义可知</p>
<script type="math/tex; mode=display">
p_{\theta}(z^{(1)}_t(x)=x_i)=p_{\theta}(z^{(2)}_t(x)=x_j)</script><p>即，<strong>对$x_i,x_j$的预测满足同一分布</strong>，这显然是不合理的</p>
<p>并且，<strong>fine-tuning时不可能也去排列组合原始输入</strong></p>
<h4 id="双流自注意力机制"><a href="#双流自注意力机制" class="headerlink" title="双流自注意力机制"></a>双流自注意力机制</h4><p>双流注意力机制就是为了解决上述问题的，分为<strong>query流</strong>和<strong>内容流</strong>，其实就是在两个层面表示当前输入（内容层面和位置层面），其中</p>
<ul>
<li>内容流self-attention<ul>
<li>内容编码信息$h_t$，计算方式和标准的self-attention一致</li>
<li>能看到自己</li>
<li>内容流输入是token的Embedding向量</li>
</ul>
</li>
<li>query流self-attention<ul>
<li>位置编码信息$g_t$，后一层的query向量不包含当前位置的查询向量</li>
<li>不能看到自己</li>
<li>在模型输入端对每个token都是统一的，是可学习的参数</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/xlnet-1.PNG" alt="xlnet-1"></p>
<p>上图中，预测下一层的内容向量时，用到当前层能看到的所有内容向量（<strong>包括自己</strong>）[a]；预测下一层的query向量时，用到当前层能看到的所有内容向量（<strong>不包括自己</strong>）[b]。</p>
<p>整体上来看，以序列$x=[x_1,x_2,x_3,x_4]$为例，通过<strong>attention mask矩阵</strong>来完成mask操作，决定排列顺序后即可得到mask矩阵。假如排列之后得到$[x_3,x_2,x_4,x_1]$，mask矩阵也有两个分为内容流（能看见自己）、query流（不能看见自己）两个，上图中，红色表示可见，白色表示不可见，第$k$行表示第$k$个位置能看到哪些位置的信息</p>
<h5 id="Transformer-XL"><a href="#Transformer-XL" class="headerlink" title="Transformer XL"></a>Transformer XL</h5><p>借助transformer xl，<strong>增强对长文本的友好程度</strong>，其主要思想就是分段然后引入recurrent连接结构</p>
<h5 id="pretrain-amp-finetune"><a href="#pretrain-amp-finetune" class="headerlink" title="pretrain &amp; finetune"></a>pretrain &amp; finetune</h5><ul>
<li>pretrain阶段<ul>
<li>在输出端<strong>对query流向量</strong>预测相应的token</li>
<li>只预测有足够长的依赖上下文的token，降低训练难度</li>
<li><strong>放弃了Next Sentence Prediction任务</strong></li>
<li>与BERT相比，加大增加了预训练阶段使用的数据规模</li>
</ul>
</li>
<li>finetune阶段<ul>
<li><strong>只需要内容流向量</strong>，不再需要query流向量</li>
<li>使用的时候，<strong>只需要内容流向量</strong></li>
</ul>
</li>
</ul>
<h3 id="RoBerta"><a href="#RoBerta" class="headerlink" title="RoBerta"></a>RoBerta</h3><blockquote>
<p>RoBERTa: A Robustly Optimized BERT Pretraining Approach</p>
</blockquote>
<p>较于BERT，其升级点如下</p>
<ul>
<li>训练模型时间更长，Batch Size更大，数据更多</li>
<li>放弃Next Sentence Prediction训练任务</li>
<li>对较长序列的训练</li>
<li>动态mask应用于训练数据的mask模式<ul>
<li>BERT静态mask：随机mask和替换在开始时只执行一次，后续保存</li>
<li>作者将训练数据重复10次，以便在40个epoch中以10种不同的方式对每个序列进行mask，<strong>避免在每个epoch中对每个训练实例使用相同的mask</strong></li>
</ul>
</li>
<li>新建数据集（CC-NEWS）</li>
<li>使用Sennrich[2]等人提出的Byte-Pair Encoding (BPE)字符编码<ul>
<li>避免出现较多的未登录词</li>
</ul>
</li>
</ul>
<h3 id="T5"><a href="#T5" class="headerlink" title="T5"></a>T5</h3><h3 id="ELECTRA"><a href="#ELECTRA" class="headerlink" title="ELECTRA"></a>ELECTRA</h3><blockquote>
<p>Efficiently Learning an Encoder that Classifies Token Replacements Accurately</p>
</blockquote>
<p>ELECTRA的特色如下</p>
<ul>
<li>放弃BERT随机选取token预测的方法，而是通过MLM过滤非常容易学到的token，加大学习难度</li>
<li>预测目标不是预测目标究竟是哪个token，而是预测这个句子中哪些词被替换过，也就是说<strong>模型需要看输入的每一个token，而不仅仅是被mask选取的那些，加速了学习过程</strong></li>
<li>解决BERT中MASK标志在train和finetune阶段的不一致问题</li>
</ul>
<h5 id="GAN视角"><a href="#GAN视角" class="headerlink" title="GAN视角"></a>GAN视角</h5><p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/electra-1.PNG" alt="GAN视角"></p>
<p>模型整体可以看成有两部分，一部分是Generator，一部分是Discriminator。模型依然需要随机地mask一部分token，但是用途不一样</p>
<p>流程</p>
<ul>
<li>对于输入文本序列，随机mask一部分token（15%）</li>
<li>带MASK标志的输入序列，G会<strong>预测每个被MASK掉的token具体是什么</strong>，这里其实就是MLM做的事情</li>
<li>D<strong>判别这个序列中哪些token是G生成的</strong><ul>
<li>二分类，</li>
</ul>
</li>
</ul>
<p>需要注意的是，G的训练方式与传统的GAN不一样，<strong>G的训练目标不是去糊弄Discriminator，而是通过极大似然估计训练</strong>。因为<strong>D的梯度不能直接流到G</strong>，原因是G输出的token在表示上是离散的</p>
<script type="math/tex; mode=display">
\mathcal{L}_{MLM}(x,\theta_G)=\mathbb{E}\left(\sum_{i}-\log p_G(x_i|x^{masked})\right)</script><p>其中，$i$是被选中mask的token序号。作者也尝试了用强化学习的训练思路做，但是效果没有直接使用MLE效果好</p>
<p>而Discriminator因为是要对每个token判断是否是原始token，所以可以看成一个二分类问题（序列上看也可以看成序列标注，只是tag之间没有直接关系），其损失函数为交叉熵形式</p>
<script type="math/tex; mode=display">
\mathcal{L}_{D}(x,\theta_G)=\mathbb{E}\left(-\sum_{t=1}^n\mathbf{I}(x_t^{G}=x_t)\log D(x^G,t) + \mathbf{I}(x_t^{G}\ne x_t)\log (1-D(x^G,t)) )\right)</script><p>这里可以看成是使用MLM的<strong>负采样</strong>方法，颇有word2vec的CBOW意味。类似地，把多分类换成二分类也可以有效降低参数数量。此外，D的目标也刚好消除了BERT中MASK标识导致的mismatch问题</p>
<p>所以，整体的目标就是</p>
<script type="math/tex; mode=display">
\min_{\theta_G,\theta_D}\sum_{x\in X}\mathcal{L}_{MLM}+\lambda\mathcal{L}_{D}(x,\theta_G)</script><p>其中，$X$是整体的数据集，$\lambda$是平衡系数，作者设为50，原因是D的任务较G简单，损失也小。</p>
<h5 id="其他点"><a href="#其他点" class="headerlink" title="其他点"></a>其他点</h5><ul>
<li>G和D共享token的embedding<ul>
<li>G会对embedding进行调整，但是D不会，所以需要参数共享</li>
</ul>
</li>
<li>建议G要小一点<ul>
<li>G太猛了，D学起来会比较费劲。D可能会将注意力更多放在对G的建模上而不是实际的数据分布</li>
<li>建议G的规模为D的1/4-1/2</li>
</ul>
</li>
</ul>
<hr>
<p>[1]. <a href="https://blog.csdn.net/u012526436/article/details/101924049" target="_blank" rel="noopener">一文揭开ALBERT的神秘面纱</a></p>
<p>[2]. <a href="https://blog.csdn.net/PaddlePaddle/article/details/102713947" target="_blank" rel="noopener">一文读懂最强中文NLP预训练模型ERNIE</a></p>
<p>[3]. <a href="https://zhuanlan.zhihu.com/p/70257427" target="_blank" rel="noopener">XLNet:运行机制及和Bert的异同比较</a></p>
<p>[4]. <a href="https://zhuanlan.zhihu.com/p/86845458" target="_blank" rel="noopener">自然语言处理之XLNet</a></p>
<p>[5]. <a href="https://arxiv.org/pdf/1906.08237.pdf" target="_blank" rel="noopener">XLNet: Generalized Autoregressive Pretraining<br>for Language Understanding</a></p>
<p>[6]. <a href="https://arxiv.org/pdf/1907.11692.pdf" target="_blank" rel="noopener">RoBERTa: A Robustly Optimized BERT Pretraining Approach</a></p>
<p>[7]. <a href="https://www.zhihu.com/question/337776337" target="_blank" rel="noopener">如何评价RoBERTa?</a></p>
<p>[8]. <a href="https://arxiv.org/pdf/1910.10683.pdf" target="_blank" rel="noopener">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a></p>
<p>[10]. <a href="https://openreview.net/pdf?id=r1xMH1BtvB" target="_blank" rel="noopener">ELECTRA: PRE-TRAINING TEXT ENCODERS AS DISCRIMINATORS RATHER THAN GENERATORS</a></p>
<p>[11]. <a href="https://www.zhihu.com/question/354070608/answer/885907890" target="_blank" rel="noopener">如何评价NLP算法ELECTRA的表现？</a></p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="atlantic8.github.io/2020/08/30/NLP-Pre-train-Models-after-Bert/" data-id="ckjflh7xf0087wophfdzyh9pd" class="article-share-link"><i class="fas fa-share"></i>分享到</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fab fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fab fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fab fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fab fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    

        </footer>
    </div>
    
</article>



    <article id="post-XGboost" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2020/08/30/XGboost/">XGboost</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fas fa-calendar-alt"></i>
        <a href="/2020/08/30/XGboost/">
            <time datetime="2020-08-30T05:00:24.000Z" itemprop="datePublished">2020-08-30</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fas fa-folder"></i>
        <a class="article-category-link" href="/categories/Algorithm/">Algorithm</a>
    </div>

                        
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/machine-learning/">machine learning</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <p>XGBoost是提升树的一种，是一种非常常用且效果很好的算法。</p>
<h4 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h4><p>提升树的基本思想就是将$K$个弱学习器以相加的方式集成到一起</p>
<script type="math/tex; mode=display">
\hat{y_i}=\sum_{k=1}^K f_k(x_i)</script><p>假设有数据集$D=\{(x_1,y_1),…,(x_n,y_n)\}$<br>对于树型弱学习器，结构化损失函数的形式如下：</p>
<script type="math/tex; mode=display">
L=\sum_il(y_i,\hat{y_i})+\sum_k\Omega(f_k) \\
\Omega(f)=\gamma T+\frac{1}{2}\lambda \Vert w\Vert^2</script><p>其中，正则项有两个部分，$T$表示叶子节点的数量，$w$是叶子节点的权值。</p>
<p>为了推导，我们假设第$t$次迭代的损失函数为</p>
<script type="math/tex; mode=display">
L^{(t)}=\sum_i^nl(y_i,\hat{y_i}^{(t-1)}+f_k(x_i))+\Omega(f_t)</script><p>做一次泰勒二次展开</p>
<script type="math/tex; mode=display">
L^{(t)}\gets\sum_i^n[l(y_i,\hat{y_i}^{(t-1)})+g_if_t(x)+\frac{1}{2}h_if_t^2(x_i)] + \Omega(f_t)</script><p>其中，$g_i=\partial_{\hat{y_i}^{(t-1)}}l(y_i,\hat{y_i}^{(t-1)})$是$l$对$\hat{y_i}^{(t-1)}$的一阶导数，$h_i=\partial^2_{\hat{y_i}^{(t-1)}}l(y_i,\hat{y_i}^{(t-1)})$是二阶导数。将常数项放在一起，我们有</p>
<script type="math/tex; mode=display">
\widetilde{L}^{(t)}=\sum_i^n[g_if_t(x)+\frac{1}{2}h_if_t^2(x_i)]+\gamma T+\frac{1}{2}\lambda \sum_j\Vert w_j\Vert^2+C</script><p>做一次转换，将上式中的<strong>样本求和转换到以叶子节点求和</strong>。<strong>令$q(x_i)$表示$x_i$属于的叶子节点（也就是表示了整课树了）</strong>，$I_j=\{i|q(x_i)=j\}$表示属于第$j$个叶子节点的样本序号集合。对于$\sum_i^ng_if_t(x)$，将其分散到各个叶子节点上，第$j$个叶子节点上的样本序号为$I_j$，整体有</p>
<script type="math/tex; mode=display">
\widetilde{L}^{(t)}=\sum_{j=1}^T[(\sum_{i\in I_j}g_i)w_j+\frac{1}{2}(\sum_{i\in I_j}h_i+\gamma)w_j^2]+\gamma T+C</script><p>对于$w$而言，上式是一个二次函数。最优值可以通过对$w_j$求导，有</p>
<script type="math/tex; mode=display">
w_j^*=-\frac{\sum_{i\in I_j}g_i}{\sum_{i\in I_j}h_i+\gamma}</script><p>带回损失函数有</p>
<script type="math/tex; mode=display">
\widetilde{L}^{(t)}_{optimal}=-\frac{1}{2}\sum_{j=1}^T\frac{(\sum_{i\in I_j}g_i)^2}{\sum_{i\in I_j}h_i+\gamma}+\gamma T</script><p>上式可以看成对树结构$q$函数的度量。有了上式，我们可以衡量分裂节点前后目标函数的变化。未分裂时，当前节点就是叶子节点，分裂后<strong>一个叶子节点($I$)变成了两个($I_L$和$L_R$)，树的其他部分不变化</strong>，所以我们只考虑在当前位置的目标函数变化</p>
<script type="math/tex; mode=display">
L_{split}=\frac{1}{2}[\frac{(\sum_{i\in I_L}g_i)^2}{\sum_{i\in I_L}h_i+\gamma}+\frac{(\sum_{i\in I_R}g_i)^2}{\sum_{i\in I_R}h_i+\gamma}-\frac{(\sum_{i\in I}g_i)^2}{\sum_{i\in I}h_i+\gamma}]-\gamma</script><p>分裂树节点可以使用贪婪的方法进行，从单个结点开始.</p>
<h4 id="收缩（shrinkage）与列采样"><a href="#收缩（shrinkage）与列采样" class="headerlink" title="收缩（shrinkage）与列采样"></a>收缩（shrinkage）与列采样</h4><p>除了上一节损失函数中加入正则项，XGBoost还有收缩（shrinkage）与列采样这两种减少过拟合的方法</p>
<ul>
<li>shrinkage在每迭代一棵树后为其加上一个收缩权值，减少当前树的作用，为后续的树留下空间</li>
<li>列采样的思想在随机森林中出现，就是在建树过程中选择一部分属性值作为可能分裂属性，而不是所有；除了减少过拟合，还可以降低计算复杂度</li>
</ul>
<h4 id="节点分裂"><a href="#节点分裂" class="headerlink" title="节点分裂"></a>节点分裂</h4><h6 id="贪婪算法"><a href="#贪婪算法" class="headerlink" title="贪婪算法"></a>贪婪算法</h6><ul>
<li>对于离散特征，枚举所有的分裂方法（所有特征、所有取值），根据目标函数选择分割方法</li>
<li>对于连续特征：一般会先排序，但是枚举带来的计算复杂度太高</li>
</ul>
<h6 id="近似算法"><a href="#近似算法" class="headerlink" title="近似算法"></a>近似算法</h6><p>主要思想是根据特征的分位数给出候选分割点，根据分割点将连续特征转换到bucket中，计算bucket中的聚合统计量。候选分割点可以在算法初始阶段计算（全局），也可以在每次split之后重新计算（局部），一般地，全局策略需要更多的候选分裂点，可以重复使用；而局部策略在每次split之后计算，在层数较深的树中会比较好。</p>
<h6 id="稀疏性"><a href="#稀疏性" class="headerlink" title="稀疏性"></a>稀疏性</h6><p>现实中，输入很可能是稀疏的：</p>
<ul>
<li>缺失值</li>
<li>未见过的值</li>
<li>类似ont-hot的人工特征</li>
</ul>
<p>算法对于缺失值的处理如下：</p>
<ul>
<li>遇到缺失值，算法将其划分到<strong>默认的分支</strong></li>
<li>默认分支选取是通过非缺失样本算出来的最优解</li>
</ul>
<p>下图是计算划分以及默认分支的算法</p>
<p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/xgboost-1.jpg" alt="image"></p>
<h4 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h4><ul>
<li>Column Block：支持列采样；使得列的划分点查找可以并行化</li>
<li>Cache-aware Access：预取技术、block大小</li>
<li>外存（Out-of-core）计算：主存有限，需要外存，如何解决外存<ul>
<li>block压缩</li>
<li>block分片，即使用多个外存</li>
</ul>
</li>
</ul>
<hr>
<p>[1]. Tianqi Chen, Carlos Guestrin. XGBoost: A Scalable Tree Boosting System. 2016</p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="atlantic8.github.io/2020/08/30/XGboost/" data-id="ckjflh7zr00bjwophkde75b7i" class="article-share-link"><i class="fas fa-share"></i>分享到</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fab fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fab fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fab fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fab fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    

        </footer>
    </div>
    
</article>



    <article id="post-Bert" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2020/08/30/Bert/">Bert</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fas fa-calendar-alt"></i>
        <a href="/2020/08/30/Bert/">
            <time datetime="2020-08-30T04:58:01.000Z" itemprop="datePublished">2020-08-30</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fas fa-folder"></i>
        <a class="article-category-link" href="/categories/Algorithm/">Algorithm</a>
    </div>

                        
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/NLP/">NLP</a>, <a class="tag-link" href="/tags/deep-learning/">deep learning</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>BERT=Bidirectional Encoder Representation from Transformers，就是用<strong>双向transformer编码器</strong>学习表征</p>
<p>基本结构如下</p>
<p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/bert-1.jpg" alt="image"></p>
<p>模型是层级结构，每层一个transformer的encoder。与模型体量相关的变量是：</p>
<ul>
<li>层数$L$：即transformer encoder的个数</li>
<li>隐层维度$H$：等于word embedding的维度</li>
<li>多头注意力的头数$A$：self-attention中multi-head的head数量</li>
</ul>
<h3 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h3><p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/bert-2.jpg" alt="image"></p>
<p>输入token表征是由三个加起来得到的，分别是token的embedding、位置编码、句子的embedding。bert中位置编码是当作参数学习出来的（transformer则是写死的）</p>
<h3 id="预训练"><a href="#预训练" class="headerlink" title="预训练"></a>预训练</h3><h5 id="Masked语言模型"><a href="#Masked语言模型" class="headerlink" title="Masked语言模型"></a>Masked语言模型</h5><p>训练过程中随机mask 15%的token，而不是把像cbow一样把每个词都预测一遍。最终的损失函数只计算被mask掉那个token。</p>
<p><strong>如果一直用标记[MASK]代替（在实际预测时是碰不到这个标记的）会影响模型</strong>，所以随机mask的时候10%的单词会被替代成其他单词，10%的单词不替换，剩下80%才被替换为[MASK]</p>
<h5 id="下个句子预测"><a href="#下个句子预测" class="headerlink" title="下个句子预测"></a>下个句子预测</h5><p>涉及到QA、推理方面的任务，所以训练加入了句子关系建模。训练的输入是句子A和B，模型预测B是不是A的下一句。</p>
<p>语料的选取很关键，要选用document-level的而不是sentence-level的，这样可以具备抽象连续长序列特征的能力。</p>
<h3 id="微调与应用"><a href="#微调与应用" class="headerlink" title="微调与应用"></a>微调与应用</h3><p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/bert-3.jpg" alt="image"></p>
<ul>
<li>单个句子分类：结果在CLS对应的位置</li>
<li>句子对分类：结果在CLS对应的位置</li>
<li>问答任务：第二个句子是答案段落，</li>
</ul>
<p>调参</p>
<ul>
<li>Batch size: 16, 32</li>
<li>学习率 (Adam): 5e-5, 3e-5, 2e-5</li>
<li>Number of epochs: 3, 4</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>优点</p>
<ul>
<li>用的是Transformer，也就是相对rnn更加高效、能捕捉更长距离的依赖</li>
<li>效果很好</li>
</ul>
<p>缺点：</p>
<ul>
<li>[MASK]标记在实际预测中不会出现，训练时用过多[MASK]影响模型表现</li>
<li>每个batch只有15%的token被预测，所以BERT收敛得比left-to-right模型要慢</li>
</ul>
<hr>
<h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><h5 id="ELMO"><a href="#ELMO" class="headerlink" title="ELMO"></a>ELMO</h5><p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/bert-4.jpg" alt="image"></p>
<p>ELMO使用两层双向LSTM抽取特征，最后将双向的结果拼接起来</p>
<h5 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a>GPT</h5><p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/bert-5.jpg" alt="image"></p>
<p>GPT使用的是自左向右的transformer，即不能看到后面的数据，只能与前面的word计算attention</p>
<hr>
<p>[1]. BERT: Pre-training of Deep Bidirectional Transformers for<br>Language Understanding.</p>
<p>[2]. <a href="https://zhuanlan.zhihu.com/p/46652512" target="_blank" rel="noopener">Google BERT详解</a></p>
<hr>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="atlantic8.github.io/2020/08/30/Bert/" data-id="ckjflh7qa0006wophfdmj6l5e" class="article-share-link"><i class="fas fa-share"></i>分享到</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fab fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fab fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fab fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fab fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    

        </footer>
    </div>
    
</article>



    <article id="post-Transformer" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2020/08/30/Transformer/">Transformer</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fas fa-calendar-alt"></i>
        <a href="/2020/08/30/Transformer/">
            <time datetime="2020-08-30T04:53:14.000Z" itemprop="datePublished">2020-08-30</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fas fa-folder"></i>
        <a class="article-category-link" href="/categories/Algorithm/">Algorithm</a>
    </div>

                        
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/deep-learning/">deep learning</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>Transformer放弃了将RNN/CNN作为encoder-decoder，仅仅用attention组件。不仅取得了更好的效果，并且其可并行的结构也可以降低训练时间</p>
<p>整体上看，Transformer是一个序列到序列的模型，基于encoder-decoder框架。编码器、解码器多个叠加在一起，大致如下所示：</p>
<p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/transformer-1.jpg" alt="image"></p>
<h3 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h3><p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/transformer-2.jpg" alt="image"></p>
<p>每个编码器包括两个层，分别是多头注意力层和position-wise的前向网络，每个层都有一个残差连接+层normalization，</p>
<h5 id="多头注意力层"><a href="#多头注意力层" class="headerlink" title="多头注意力层"></a>多头注意力层</h5><p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/transformer-3.jpg" alt="image"></p>
<p>先看<strong>单头注意力</strong>，其核心是Scaled Dot-Product Attention（编码器中的Scaled Dot-Product Attention不需要mask，因为编码时<strong>可以看到整个序列</strong>）。基本是这样，每个头有3个线性映射矩阵$Q, K, V$，对于输入（向量序列构成矩阵），乘以3个矩阵映射到$Q’,K’,V’$，然后计算</p>
<script type="math/tex; mode=display">
softmax(\frac{Q'\times K'^T}{\sqrt{d_k}})V'</script><p>其实也就是计算$Q’$每个向量和$K’$每个向量的关系，归一化后当作$V’$的系数加权求和，其中$d_k$是$Q’$中单个向量的维度。</p>
<p>多头注意力，每个头有不同的$Q, K, V$（目的是学习到不同的表征），得到的多个<strong>结果拼接起来</strong>，最后做一个线性变换</p>
<p>encoder是并行的体现，<strong>并行主要是可以同时计算多个head的输出</strong></p>
<h5 id="前向网络"><a href="#前向网络" class="headerlink" title="前向网络"></a>前向网络</h5><script type="math/tex; mode=display">
F(x)=\max(0, xW_1+b_1)W_2+b_2</script><p>这一层的输入输出维度一直，并且，属于输入序列中的每个位置i，其对应的参数是一致的，所以叫position-wise</p>
<h3 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h3><p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/transformer-4.jpg" alt="image"></p>
<p>解码器有两种attention，第一种直接作用在输入上的self-attention，多了mask的概念（因为<strong>解码按顺序进行的，不能获取未来的信息</strong>）。第二种不是self-attention，其中的$K’,V’$均来自编码器，$Q’$来自解码器</p>
<p>多个解码器叠加，每个解码器中的第二个attention中的$K’,V’$均来自编码器。最后的输出经过线性变换+softmax得到输出</p>
<h3 id="输入与位置编码"><a href="#输入与位置编码" class="headerlink" title="输入与位置编码"></a>输入与位置编码</h3><p>对输入序列的每一个word，先将其通过词嵌入算法转换为词向量，第一个编码器接受词向量序列，后面的编码器接受前面编码器的输出</p>
<p>但是问题是这种方法没有考虑加入位置信息，所以作者加入了位置向量，并且<strong>将每个word的位置向量和词向量加起来作为这个词的特征向量</strong>。每个word的位置向量和其词向量维度一样，假设其位置为$pos$，则其位置向量为</p>
<script type="math/tex; mode=display">
PE_{(pos,2i)}=\sin(\frac{pos}{10000^{2i/d}}) \\
PE_{(pos,2i+1)}=\cos(\frac{pos}{10000^{2i/d}})</script><p>其中$d$是词向量的维度。这个编码可以表示词之间的相对位置。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>self-attention处理特别长的序列时，计算复杂度会比较高，会做一些限制，比如当前位置只能看到其前后$r$个位置的词</p>
<p>self-attention之于CNN、RNN的优势</p>
<ul>
<li>每层的计算复杂度</li>
<li>序列操作</li>
<li>最大路径长度（信号需要在网络中前向、后向传递的长度）</li>
<li>可解释性</li>
</ul>
<p>前三项的比较如下图</p>
<p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/transformer-5.png" alt="image"></p>
<p>其中，$n$序列长度，$d$是模型维度，$k$是卷积核大小，$r$是受限的self-attention对应的neighborhood大小</p>
<p>transformer的缺陷如下：</p>
<ul>
<li>是不是对局部特征的捕捉能力降低了</li>
<li>位置编码用三角函数是不是不够</li>
</ul>
<hr>
<p>最后贴上经典的transformer动态图</p>
<p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/transform20fps.gif" alt="image"></p>
<hr>
<h3 id="Transformer-XL"><a href="#Transformer-XL" class="headerlink" title="Transformer XL"></a>Transformer XL</h3><p>理论上，Transformer的encoder可以接受无限长的输入，但是限于计算资源问题，通常encoder处理的长度也是有限的。Transformer XL就是要<strong>解决输入长度过长的情况</strong></p>
<h6 id="语言模型建模"><a href="#语言模型建模" class="headerlink" title="语言模型建模"></a>语言模型建模</h6><p>以语言模型为例，语言模型就是要计算输入序列的概率</p>
<script type="math/tex; mode=display">
P(t_{0:L})=p(t_0)\prod_{i=1}^Lp(t_i|t_{0:t-1})</script><p>对于条件概率$p(t_i|t_{0:t-1})$，可以使用transformer对其建模。需要注意的一点是，上面的条件概率要求<strong>只能看到当前左侧的token</strong>，所以需要使用类似masked attention的方法</p>
<p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/transformer-xl.PNG" alt="image"></p>
<h6 id="vanilla-model"><a href="#vanilla-model" class="headerlink" title="vanilla model"></a>vanilla model</h6><p>实作上，一种简单粗暴的方法是<strong>对输入进行截断</strong>，在每个segment内分别处理，<strong>忽略了段之间的上下文信息</strong>。具体地</p>
<ul>
<li>训练阶段：把文本切成segment，每个segment单独训练</li>
<li>预测阶段：按segment处理，移动步长为1</li>
</ul>
<p>大致的训练方法见<a href="https://zhuanlan.zhihu.com/p/87576748" target="_blank" rel="noopener"> 深度Transformer构建字符语言模型 </a></p>
<h6 id="recurrent-model"><a href="#recurrent-model" class="headerlink" title="recurrent model"></a>recurrent model</h6><p>主要思想是将上一个segment对应的hidden state保存起来，论文图中当前segment也只会用到上一segment中的信息，不用上上个segment的信息。可以形成segment的recurrent结构，不过只要增大cache，可以考虑使用前面更多的segment信息</p>
<hr>
<p>[1]. Attention Is All You Need. 2017</p>
<p>[2]. <a href="https://blog.csdn.net/longxinchen_ml/article/details/86533005" target="_blank" rel="noopener">图解Transformer（完整版）</a></p>
<p>[3]. <a href="">Transformer-XL: Attentive Language Models<br>Beyond a Fixed-Length Context</a><a href="https://arxiv.org/pdf/1901.02860.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1901.02860.pdf</a></p>
<hr>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="atlantic8.github.io/2020/08/30/Transformer/" data-id="ckjflh7zl00b9woph0bh376u4" class="article-share-link"><i class="fas fa-share"></i>分享到</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fab fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fab fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fab fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fab fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    

        </footer>
    </div>
    
</article>



    <article id="post-First-Order-Optimization" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2020/08/30/First-Order-Optimization/">First Order Optimization</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fas fa-calendar-alt"></i>
        <a href="/2020/08/30/First-Order-Optimization/">
            <time datetime="2020-08-30T04:46:31.000Z" itemprop="datePublished">2020-08-30</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fas fa-folder"></i>
        <a class="article-category-link" href="/categories/Math/">Math</a>
    </div>

                        
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/Optimization/">Optimization</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <h5 id="SGD：Stochastic-Gradient-Descent"><a href="#SGD：Stochastic-Gradient-Descent" class="headerlink" title="SGD：Stochastic Gradient Descent"></a>SGD：Stochastic Gradient Descent</h5><p>mini-batch的更新方法</p>
<hr>
<ul>
<li>输入学习率$\epsilon$</li>
<li>停止条件未满足<ul>
<li>从样本集合中采样$m$个样本的batch</li>
<li>计算梯度$g=\frac{1}{m}\bigtriangledown_{\theta} \sum_i L(f(x_i,\theta),y_i)$</li>
<li>参数更新$\theta=\theta-\epsilon g$</li>
</ul>
</li>
</ul>
<hr>
<p>学习率是SGD中的关键参数。在实践中，有必要随着时间推移减小学习率，一般的实践是将学习率线形衰减指导第$\tau$次迭代<br>math<br>\epsilon_k=(1-\alpha)\epsilon_0+\alpha \epsilon_{\tau}</p>
<p>其中$\alpha=\frac{k}{\tau}$。在$\tau$次迭代后，一般使$\epsilon$保持常数。$\tau_t$可以设置为$\tau_0$的1%。</p>
<h5 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h5><p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/momentum.jpg" alt="image"></p>
<p>SGD在处理高曲率、小但一致的梯度，或者带噪声的梯度时，学习过程有时会很慢。动量算法引入了变量$v$充当速度角色。</p>
<hr>
<ul>
<li>输入初始速度$v$，学习率$\epsilon$</li>
<li>停止条件未满足<ul>
<li>从样本集合中采样$m$个样本的batch</li>
<li>计算梯度$g=\frac{1}{m}\bigtriangledown_{\theta} \sum_i L(f(x_i,\theta),y_i)$</li>
<li>计算更新速度$v=\alpha v-\epsilon g$</li>
<li>参数更新$\theta=\theta+v$</li>
</ul>
</li>
</ul>
<hr>
<p>$\alpha$叫做动量参数，一般取值为0.5、0.9、0.99。</p>
<h5 id="Nesterov：Nesterov-Accelerated-Gradient（NAG）"><a href="#Nesterov：Nesterov-Accelerated-Gradient（NAG）" class="headerlink" title="Nesterov：Nesterov Accelerated Gradient（NAG）"></a>Nesterov：Nesterov Accelerated Gradient（NAG）</h5><p>此方法与动量方法的不同在于计算梯度步骤，<strong>Nesterov</strong>在每一步更新中，使用当前参数和速度得到临时更新，然后在临时更新后的参数的基础上计算梯度。<strong>Nesterov方法可以解释为往标准动量方法中添加了一个校正因子</strong>。</p>
<hr>
<ul>
<li>输入初始速度$v$，学习率$\epsilon$</li>
<li>停止条件未满足<ul>
<li>从样本集合中采样$m$个样本的batch</li>
<li>计算临时更新$\hat{\theta}=\theta+\alpha v$</li>
<li>计算梯度$g=\frac{1}{m}\bigtriangledown_{\hat{\theta}} \sum_i L(f(x_i,\hat{\theta}),y_i)$</li>
<li>计算更新速度$v=\alpha v-\epsilon g$</li>
<li>参数更新$\theta=\theta+v$</li>
</ul>
</li>
</ul>
<hr>
<p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/nesterov.jpg" alt="image"></p>
<h5 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h5><p>AdaGrad<strong>记录参数在每个维度上的梯度累计量，然后缩放每个参数反比于其梯度累积量平方根</strong>，减小梯度过大的方向更新过快、梯度过小的方向更新过满的缺陷。</p>
<hr>
<ul>
<li>输入小常数$\delta(10^{-7})$，学习率$\epsilon$</li>
<li>初始化梯度累计量$r=\bold{0}$</li>
<li>停止条件未满足<ul>
<li>从样本集合中采样$m$个样本的batch</li>
<li>计算梯度$g=\frac{1}{m}\bigtriangledown_{\theta} \sum_i L(f(x_i,\theta),y_i)$</li>
<li>累计平方梯度$r=r+g\odot g$</li>
<li>计算更新$\Delta \theta\gets- \frac{\epsilon}{\delta+\sqrt{r}}\odot g$</li>
<li>应用更新$\theta= \theta+\Delta \theta$</li>
</ul>
</li>
</ul>
<hr>
<p>在凸优化背景下，AdaGrad有一些令人满意的性质。但经验上，对于训练深度模型，AdaGrad<strong>从训练开始时累计梯度会导致有小学习率过早、过量的减小</strong>。此算法在某些模型上效果不错，但不是全部。</p>
<h5 id="RMSProp：Root-Mean-Square-Prop"><a href="#RMSProp：Root-Mean-Square-Prop" class="headerlink" title="RMSProp：Root Mean Square Prop"></a>RMSProp：Root Mean Square Prop</h5><p>RMSProp是为了解决AdaGrad中<strong>从训练开始时累计梯度会导致有小学习率过早、过量的减小</strong>的缺陷，也有忘掉过去的功能，方法是引入参数$\rho$进行权重衰减。</p>
<hr>
<ul>
<li>输入小常数$\delta(10^{-6})$，学习率$\epsilon$，衰减速率$\rho$</li>
<li>初始化梯度累计量$r=\bold{0}$</li>
<li>停止条件未满足<ul>
<li>从样本集合中采样$m$个样本的batch</li>
<li>计算梯度$g=\frac{1}{m}\bigtriangledown_{\theta} \sum_i L(f(x_i,\theta),y_i)$</li>
<li>累计平方梯度$r=\rho r+(1-\rho)g\odot g$</li>
<li>计算更新$\Delta \theta\gets- \frac{\epsilon}{\sqrt{\delta+r}}\odot g$</li>
<li>应用更新$\theta= \theta+\Delta \theta$</li>
</ul>
</li>
</ul>
<hr>
<p>RMSProp已被证明是一种有效且实用的深度神经网络优化算法，是实践者常采用的方法之一。</p>
<h5 id="Adam：A-Method-for-Stochastic-Optimization"><a href="#Adam：A-Method-for-Stochastic-Optimization" class="headerlink" title="Adam：A Method for Stochastic Optimization"></a>Adam：A Method for Stochastic Optimization</h5><p>Adam是采用了梯度的一阶估计、二阶估计的算法，并且加入了偏差修正，可以看成是AdaGrad、RMSProp思想的结合。</p>
<hr>
<ul>
<li>输入矩估计的指数衰减速率$\rho_1,\rho_2$(默认建议为0.9、0.99)</li>
<li>输入小常数$\delta(10^{-6})$，步长$\epsilon$，衰减速率$\rho$</li>
<li>初始化一阶矩、二阶矩量$s=\bold{0},r=\bold{0}$</li>
<li>初始化时间步$t=0$</li>
<li>停止条件未满足<ul>
<li>从样本集合中采样$m$个样本的batch</li>
<li>计算梯度$g=\frac{1}{m}\bigtriangledown_{\theta} \sum_i L(f(x_i,\theta),y_i)$</li>
<li>$t=t+1$</li>
<li>更新有偏一阶矩估计$s=\rho_1 s+(1-\rho_1)g$</li>
<li>更新有偏二阶矩估计$r=\rho_2 r+(1-\rho_2)g\odot g$</li>
<li>修正一阶矩的偏差$\hat{s}=\frac{s}{1-\rho_1^t}$</li>
<li>修正二阶矩的偏差$\hat{r}=\frac{r}{1-\rho_2^t}$</li>
<li>计算更新$\Delta \theta=-\epsilon \frac{\hat{s}}{\sqrt{\hat{r}}+\delta}\odot g$</li>
<li>应用更新$\theta= \theta+\Delta \theta$</li>
</ul>
</li>
</ul>
<p>这里的偏差修正可以这么看，刚开始一般会给定一个$s_0=0$，初期计算的几个结果会与真是的平均值有较大的差异，也就是有冷启动问题。用上面的修正公式进行修正，随着$t$增大，$\hat{s}$与$s$越来越接近，刚开始差距大一些，后期影响逐渐减小。</p>
<p>至于为什么第一步是$\frac{1}{1-\beta}$，是因为给定$\beta$，指数加权平均可以近似看成$\frac{1}{1-\beta}$个数据的移动平均值。见参考文献</p>
<hr>
<p>Adam通常被认为对超参数的选择相当鲁棒。</p>
<hr>
<p>[1]. <a href="http://www.bubuko.com/infodetail-2524026.html" target="_blank" rel="noopener">什么是指数加权平均、偏差修正?</a></p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="atlantic8.github.io/2020/08/30/First-Order-Optimization/" data-id="ckjflh7ut004awoph26gbatyv" class="article-share-link"><i class="fas fa-share"></i>分享到</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fab fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fab fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fab fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fab fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    

        </footer>
    </div>
    
</article>



    <article id="post-CherryPy-Torturial" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2019/09/21/CherryPy-Torturial/">CherryPy Torturial</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fas fa-calendar-alt"></i>
        <a href="/2019/09/21/CherryPy-Torturial/">
            <time datetime="2019-09-21T15:51:48.000Z" itemprop="datePublished">2019-09-21</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fas fa-folder"></i>
        <a class="article-category-link" href="/categories/Dev/">Dev</a>
    </div>

                        
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/python/">python</a>, <a class="tag-link" href="/tags/web/">web</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <p>python有多种工具包，其中就包括一些可以提供网页服务的package，比如Django、CherryPy等。在不同的情况下一般有不同的选择，比如如果只想是通过浏览器下载服务器上的文件，那么通过SimpleHTTPServer即可<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m SimpleHTTPServer <span class="number">8000</span></span><br></pre></td></tr></table></figure></p>
<p>今天介绍的是一种上手极快的工具，CherryPy，下面会通过一些例子展示如何快速搭建自己需要的简单网页。</p>
<h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>pip安装即可</p>
<h4 id="返回静态网页"><a href="#返回静态网页" class="headerlink" title="返回静态网页"></a>返回静态网页</h4><p>一般的使用方法都是封装一个app类，然后在这个类中定义函数，将函数设置为cherrypy.expose则表示可以通过url访问这个函数。生效的时候通过<code>quickstart(Test(), &#39;/&#39;, conf)</code>函数生效，这个函数有三个参数，后两个是应用的根位置和配置词典，为可选参数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cherrypy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span><span class="params">(object)</span>:</span></span><br><span class="line"><span class="meta">    @cherrypy.expose</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">"Hello world!"</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @cherrypy.expose</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generate</span><span class="params">(self, param=<span class="string">'bingo'</span>)</span>:</span> <span class="comment">#给定param参数</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">'calling generate %s'</span> % param </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    cherrypy.quickstart(Test())</span><br></pre></td></tr></table></figure></p>
<p>上面这个例子，我们可以通过<code>http://localhost:8080/generate?param=success</code>返回<code>calling generate success</code>. </p>
<h4 id="提交form"><a href="#提交form" class="headerlink" title="提交form"></a>提交form</h4><p>如果我们希望在网页端采集用户的输入，那么我们就需要通过form获取了。网页端用户操作的组件由html中的name属性指示<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cherrypy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span><span class="params">(object)</span>:</span></span><br><span class="line"><span class="meta">    @cherrypy.expose</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">"""&lt;html&gt;</span></span><br><span class="line"><span class="string">          &lt;head&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">          &lt;body&gt;</span></span><br><span class="line"><span class="string">            &lt;form method="get" action="generate"&gt;</span></span><br><span class="line"><span class="string">              &lt;input type="text" value="bingo" name="param" /&gt;</span></span><br><span class="line"><span class="string">              &lt;button type="submit"&gt;generate&lt;/button&gt;</span></span><br><span class="line"><span class="string">            &lt;/form&gt;</span></span><br><span class="line"><span class="string">          &lt;/body&gt;</span></span><br><span class="line"><span class="string">        &lt;/html&gt;"""</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @cherrypy.expose</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generate</span><span class="params">(self, param=<span class="string">'bingo'</span>)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">'calling generate %s'</span> % param</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    cherrypy.quickstart(Test())</span><br></pre></td></tr></table></figure></p>
<p>如果想返回一个网页，那么直接return这个网页的内容即可。这里是通过get方式发送form数据，也可以使用post，推荐使用post</p>
<h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><p>默认配置一般在Lib/site-packages/cherrypy/scaffold/site.conf中，内容如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[<span class="keyword">global</span>]</span><br><span class="line"><span class="comment"># Uncomment this when you're done developing</span></span><br><span class="line"><span class="comment">#environment: "production"</span></span><br><span class="line"></span><br><span class="line">server.socket_host: <span class="string">"0.0.0.0"</span></span><br><span class="line">server.socket_port: <span class="number">8088</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Uncomment the following lines to run on HTTPS at the same time</span></span><br><span class="line"><span class="comment">#server.2.socket_host: "0.0.0.0"</span></span><br><span class="line"><span class="comment">#server.2.socket_port: 8433</span></span><br><span class="line"><span class="comment">#server.2.ssl_certificate: '../test/test.pem'</span></span><br><span class="line"><span class="comment">#server.2.ssl_private_key: '../test/test.pem'</span></span><br><span class="line"></span><br><span class="line">tree.myapp: cherrypy.Application(scaffold.root, <span class="string">"/"</span>, <span class="string">"example.conf"</span>)</span><br></pre></td></tr></table></figure></p>
<h6 id="全局配置"><a href="#全局配置" class="headerlink" title="全局配置"></a>全局配置</h6><p>这里主要是全局【global】配置，在代码中可以通过<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cherrypy.config.update(&#123;&apos;server.socket_host&apos;: &apos;64.72.221.48&apos;,</span><br><span class="line">                        &apos;server.socket_port&apos;: 80&#125;)</span><br></pre></td></tr></table></figure></p>
<p>进行更改</p>
<blockquote>
<p>如果修改端口后浏览器上打不开网页，其他都ok的话，需要看一下这个端口是不是系统默认端口，比如9090</p>
</blockquote>
<h6 id="局部配置"><a href="#局部配置" class="headerlink" title="局部配置"></a>局部配置</h6><p>局部配置仅在单个app内部生效，由<code>/</code>符号开头，形式如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[/]</span><br><span class="line">tools.trailing_slash.on = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">[/app1]</span><br><span class="line">tools.trailing_slash.on = <span class="keyword">True</span></span><br></pre></td></tr></table></figure></p>
<p>代码中这样用<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">config = &#123;<span class="string">'/'</span>:</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">'tools.trailing_slash.on'</span>: <span class="keyword">False</span>,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">cherrypy.tree.mount(Root(), config=config)</span><br></pre></td></tr></table></figure></p>
<h6 id="其他配置"><a href="#其他配置" class="headerlink" title="其他配置"></a>其他配置</h6><p>也可以加其他配置，与上面所述配置区分开即可<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[Databases]</span><br><span class="line">driver: &quot;postgres&quot;</span><br><span class="line">host: &quot;localhost&quot;</span><br><span class="line">port: 5432</span><br></pre></td></tr></table></figure></p>
<p>当然这些配置自己准备配置文件也可以</p>
<h4 id="用户session"><a href="#用户session" class="headerlink" title="用户session"></a>用户session</h4><p>session的使用就是要记住用户的一些设置或历史数据，主要是通过<code>cherrypy.session</code>这个字典完成<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cherrypy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span><span class="params">(object)</span>:</span></span><br><span class="line"><span class="meta">    @cherrypy.expose</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">"Hello world!"</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @cherrypy.expose</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generate</span><span class="params">(self, param=<span class="string">'bingo'</span>)</span>:</span> <span class="comment">#给定param参数</span></span><br><span class="line">        ret = <span class="string">'calling generate %s'</span> % param</span><br><span class="line">        cherrypy.session[<span class="string">'buf'</span>] = ret</span><br><span class="line">        <span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line"><span class="meta">    @cherrypy.expose</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">display</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> cherrypy.session[<span class="string">'buf'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    conf = &#123;</span><br><span class="line">        <span class="string">'/'</span>: &#123;</span><br><span class="line">            <span class="string">'tools.sessions.on'</span>: <span class="keyword">True</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cherrypy.quickstart(Test(), <span class="string">'/'</span>, conf)</span><br></pre></td></tr></table></figure></p>
<h4 id="多应用"><a href="#多应用" class="headerlink" title="多应用"></a>多应用</h4><p>单个应用的时候，我们通过<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cherrypy.quickstart(Blog())</span><br></pre></td></tr></table></figure></p>
<p>启动应用，但是多个应用的时候这个函数的capacity不够，这时候用<code>cherrypy.tree.mount</code>函数，如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cherrypy.tree.mount(Blog(), <span class="string">'/blog'</span>, blog_conf)</span><br><span class="line">cherrypy.tree.mount(Forum(), <span class="string">'/forum'</span>, forum_conf)</span><br><span class="line"></span><br><span class="line">cherrypy.engine.start()</span><br><span class="line">cherrypy.engine.block()</span><br></pre></td></tr></table></figure></p>
<p>实现上，mount函数是把quickstart函数的返回结果当作一个参数使用，所以mount与quickstart并不互斥</p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="atlantic8.github.io/2019/09/21/CherryPy-Torturial/" data-id="ckjflh7qv000vwoph78vnhykk" class="article-share-link"><i class="fas fa-share"></i>分享到</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fab fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fab fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fab fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fab fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    

        </footer>
    </div>
    
</article>



    <article id="post-Hough-Transform" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2018/12/16/Hough-Transform/">Hough Transform</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fas fa-calendar-alt"></i>
        <a href="/2018/12/16/Hough-Transform/">
            <time datetime="2018-12-16T13:32:21.000Z" itemprop="datePublished">2018-12-16</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fas fa-folder"></i>
        <a class="article-category-link" href="/categories/Algorithm/">Algorithm</a>
    </div>

                        
                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>Hough转换是由Hough于1959年首次提出的，是图像分析、计算视觉中的一种特征提取算法，这个算法的目的是通过投票程序找到具有特定形状物体的不完美实例，其中投票程序在参数空间完成。在参数空间中，目标候选是选取名为累积空间的局部最大。</p>
<p>在数字图像处理领域，存在寻找直线、圆、椭圆的子问题。许多情况下，边界检测是此问题的预处理步骤，然而，由于数据本身、边界检测算法存在的不足，可能会导致边界数据缺失、空间错位等问题。所以，需要将提取的边界特征组合成一些规则的图形（线、圆、椭圆）。<strong>Hough转换的目标就是将边界特征组合成物体候选</strong>。</p>
<h3 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h3><p>Hough转换最简单的应用是检测直线，一条直线可以由斜率$k$和截距$b$确定，这里$<k,b>$就构成了参数空间的一个点。给定一个点，可以找到经过这个点的无数条直线，每个直线在参数空间都对应一个点。但是这种方法有个缺陷，就是直线的斜率可能无限大。所以一般都把Hesse normal形式当做参数空间。</k,b></p>
<p><img src="/images/hough-transform-1.jpg" alt="parameter space"></p>
<p>具体地，以$y=kx+b$为例，可以将其写成$r=x\cos\theta+y\sin\theta$，如上图所示，$r$是直线到原点的距离，所以一条直线就对应参数空间中的一个点$<r,\theta>$，这个参数空间就是直线对应的<code>Hough Space</code>。</r,\theta></p>
<p>经过平面中的一个点可以确定无数条直线，每个直线都在参数空间对应一个点，这些点构成一个正弦波行。也就是说一个点在参数空间中对应一个正弦线。并且，共线的点在参数空间中会交于点$<r_0,\theta_0>$，这个点就是这个直线对应的参数空间中的点。所以，<strong>查找共线点问题可以转化为检测共点曲线问题</strong>。</r_0,\theta_0></p>
<h3 id="数值计算方法"><a href="#数值计算方法" class="headerlink" title="数值计算方法"></a>数值计算方法</h3><p>直线检测的方法如下，以二维直线为例。构建一个二维累加器，记录对应的离散$r,\theta$对应的累加值。对每一个点及其邻居点</p>
<ul>
<li>算法决定这两个点之间是否会构成直线，如果是，计算出这条直线对应的$<r,\theta>$值</r,\theta></li>
<li>在二位累加器中找到对应的位置，加一</li>
</ul>
<p>计算完后，检查二维累加器，局部极大值点可能就对应一条直线，当然直线的数量需要合适阈值决定。下图是一个例子，<img src="http://ww1.sinaimg.cn/mw690/9bcfe727ly1fwzy5ji9qgj218g0mq0vr.jpg" alt="example"></p>
<h3 id="泛化"><a href="#泛化" class="headerlink" title="泛化"></a>泛化</h3><blockquote>
<p>To Be Continue<br>上面是直线检测的方法，参数空间是二维的。同理地，圆和椭圆都可以通过三维参数空间搞定。方法同上。</p>
</blockquote>
<p>广义的方法于1981年由Dana H. Ballard提出，见<a href="https://en.wikipedia.org/wiki/Generalised_Hough_transform" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Generalised_Hough_transform</a></p>
<hr>
<p>引用</p>
<p>[1]. <a href="https://en.wikipedia.org/wiki/Hough_transform" target="_blank" rel="noopener">Hough transform. From Wikipedia, the free encyclopedia</a></p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="atlantic8.github.io/2018/12/16/Hough-Transform/" data-id="ckjflh7v8004ywophl36am8aa" class="article-share-link"><i class="fas fa-share"></i>分享到</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fab fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fab fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fab fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fab fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    

        </footer>
    </div>
    
</article>



    <article id="post-GRU-and-LSTM" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2018/12/16/GRU-and-LSTM/">GRU and LSTM</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fas fa-calendar-alt"></i>
        <a href="/2018/12/16/GRU-and-LSTM/">
            <time datetime="2018-12-16T13:27:29.000Z" itemprop="datePublished">2018-12-16</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fas fa-folder"></i>
        <a class="article-category-link" href="/categories/Algorithm/">Algorithm</a>
    </div>

                        
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/Deep-Learning/">Deep Learning</a>, <a class="tag-link" href="/tags/Machine-Learning/">Machine Learning</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <p>GRU和LSTM都是RNNs中的特殊cell，目的是为了解决标准RNNs中的长期依赖的问题。这个问题是由于简单的RNNs求导公式中存在多个相同矩阵相乘的问题，容易造成梯度消散。使用Relu也只能说在一定程度解决了消散问题，但是会存在梯度爆炸的问题（见参考文献2）。</p>
<h3 id="基本结构"><a href="#基本结构" class="headerlink" title="基本结构"></a>基本结构</h3><p>相似点：都是通过引入门结构来解决长期依赖问题<br>不同点：门的数量，种类有差异</p>
<h4 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h4><p>每个GRU单元的输入有$x^{(t)}$、$h^{(t-1)}$，分别表示当前步的输入和上一步的隐状态。<strong>基本思想是先构建新的memory，然后再和上一隐含状态加权得到新的隐含状态</strong>。</p>
<p>基本结构如下图所示</p>
<p><img src="http://ww1.sinaimg.cn/mw690/9bcfe727ly1fwkv73w0v5j20gy08y75m.jpg" alt="image"></p>
<p>GRU包含几个门，分别是</p>
<ul>
<li>reset($r^{(t)}$)：从构建新new memory的角度出发，$r^{(t)}$决定$h^{(t-1)}$对new memory的贡献多大</li>
<li>new memory($\hat{h}^{(t)}$)：由当前输入和上一步的隐含状态决定，当然，上一阶段隐含状态的重要性也受到reset gate的影响</li>
<li>update($z^{(t)}$)：决定$h^{(t-1)}$对$h^{(t)}$的贡献多大</li>
<li>hidden state($h^{(t)}$)：有上一步的隐含状态和new memory加权得到，权重有update gate决定</li>
</ul>
<p>公式如下，懒得打了：</p>
<p><img src="http://ww1.sinaimg.cn/mw690/9bcfe727ly1fwkv5yp61gj20a30323yt.jpg" alt="image"></p>
<h4 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h4><p>同样地，每个LSTM单元的输入有$x^{(t)}$、$h^{(t-1)}$，分别表示当前步的输入和上一步的隐状态。需要注意的是，<strong>LSTM cell中的流动数据不仅包括隐含状态，还包括final memory</strong> 。然后生成final memory，这个过程需要input gate和forget gate。最后<strong>由output gate辅助生成当前的隐含状态(GRU没有这一步)</strong>。结构图如下</p>
<p><img src="http://ww1.sinaimg.cn/mw690/9bcfe727ly1fwkw7pv9lvj20gy0c2mys.jpg" alt="image"></p>
<ul>
<li>new memory：由当前输入和前一步的隐含状态决定，前一步的隐含状态贡献度由</li>
<li>final memory：由上一步的final memory和当前的new memory生成。其中上一步final memory的贡献度由forget gate决定，当前new memory的贡献度由input gate决定</li>
<li>input gate：作用在上面已经说明了，由上一步隐含状态和当前输入决定</li>
<li>forget gate：同input gate</li>
<li>output gate：决定final memory对当前隐层状态的贡献</li>
</ul>
<p>贴一下公式</p>
<p><img src="http://ww1.sinaimg.cn/mw690/9bcfe727ly1fwkwdq6le8j20ay0473z1.jpg" alt="image"></p>
<p>需要注意的是，上面公式倒数第二个写错了，forget gate决定的是$c^{(t-1)}$.</p>
<p>关于LSTM、GRU是如何避免梯度问题的，关键是将简单RNN的求导过程中的乘法变成了加法，之前的记忆不会受到乘法的影响，因此不会过分衰减。同时又通过其他的门结构保证灵活性。</p>
<hr>
<p><strong>引用</strong></p>
<p>[1]. <a href="https://blog.csdn.net/u012223913/article/details/77724621" target="_blank" rel="noopener">LSTM 和GRU的区别</a></p>
<p>[2]. <a href="https://blog.csdn.net/hx14301009/article/details/80401227" target="_blank" rel="noopener">理解RNN梯度消失和弥散以及LSTM为什么能解决</a></p>
<hr>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="atlantic8.github.io/2018/12/16/GRU-and-LSTM/" data-id="ckjflh7uv004ewophsy890hfp" class="article-share-link"><i class="fas fa-share"></i>分享到</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fab fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fab fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fab fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fab fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    

        </footer>
    </div>
    
</article>



    <article id="post-how-does-shazam-work" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2018/12/16/how-does-shazam-work/">how does shazam work</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fas fa-calendar-alt"></i>
        <a href="/2018/12/16/how-does-shazam-work/">
            <time datetime="2018-12-16T13:06:11.000Z" itemprop="datePublished">2018-12-16</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fas fa-folder"></i>
        <a class="article-category-link" href="/categories/Algorithm/">Algorithm</a>
    </div>

                        
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/IR/">IR</a>, <a class="tag-link" href="/tags/MIR/">MIR</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <p>音乐信息检索是一个复杂的工作，需要涉及信号处理、计算机算法等知识。以下是粗略介绍。</p>
<h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><h4 id="声音的物理特性"><a href="#声音的物理特性" class="headerlink" title="声音的物理特性"></a>声音的物理特性</h4><p>中学物理告诉我们，声音来源于振动，声音需要在介质中传播。声音有纯音（pure tone）和实音（real tone）之分，前者是标准的正弦波，后者则是前者的复杂组合。中学数学告诉我们，正弦波有两个主要的特质，分别是振幅dB（amplitude）和频率（frequency）。</p>
<h4 id="音乐简单背景"><a href="#音乐简单背景" class="headerlink" title="音乐简单背景"></a>音乐简单背景</h4><h5 id="音符（musical-notes）"><a href="#音符（musical-notes）" class="headerlink" title="音符（musical notes）"></a>音符（musical notes）</h5><p>乐谱是由多个音符构成的，每个音符都有持续时间（duration）和响度（loudness）这两个性质。乐谱的音符可以划分成八度音阶（octaves），每个八度音阶就是8个音符（A-G or Do-Si），八度音阶有如下特点：</p>
<ul>
<li>一个八度音阶中的音符的频率是上一个八度音阶中的音符的频率的2倍</li>
</ul>
<p>多数乐器都提供了不止8个音符，这些多出来的就叫做半音（半拍）。</p>
<h5 id="音色（Timbre）"><a href="#音色（Timbre）" class="headerlink" title="音色（Timbre）"></a>音色（Timbre）</h5><p>对于同一个音符，不同乐器也会有不同的音色。乐器的声音通常都是有一个基础频率加上多种弦外之音（overtones）合成的。多数乐器都产生和声，但是打击乐器不是。</p>
<h4 id="频谱图"><a href="#频谱图" class="headerlink" title="频谱图"></a>频谱图</h4><p><img src="http://ww1.sinaimg.cn/mw690/9bcfe727ly1fww1agvvlfj20gf0cct93.jpg" alt="频谱图示例"></p>
<p>以上是频谱图示例，信息包含时间、频率和振幅，振幅大小由颜色深度指示。这种图在深度学习处理声音数据的时候也要用到。</p>
<h4 id="傅立叶变换"><a href="#傅立叶变换" class="headerlink" title="傅立叶变换"></a>傅立叶变换</h4><p>傅立叶变换FT可以将时域信号$x(t)$转变为频域信号$f(w)$，有如下几种：</p>
<h5 id="连续时间傅立叶变换"><a href="#连续时间傅立叶变换" class="headerlink" title="连续时间傅立叶变换"></a>连续时间傅立叶变换</h5><script type="math/tex; mode=display">
\begin{aligned}
f(w)=\int_{-\infty}^{+\infty}x(t)e^{-jwt}\,dt
\end{aligned}</script><p>具体原理推导省略，其逆变换为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
x(t)=\int_{-\infty}^{+\infty}f(w)e^{-jwt}\,dw
\end{aligned}</script><h5 id="离散时间傅立叶变换"><a href="#离散时间傅立叶变换" class="headerlink" title="离散时间傅立叶变换"></a>离散时间傅立叶变换</h5><p>以上公式是连续时间信号的变换，离散信号的变换可以使用离散傅立叶变换DFT，公式如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
f(w)=\sum_{t=-\infty}^{+\infty}x(t)e^{-jwt}
\end{aligned}</script><p>为了在科学计算和数字信号处理等领域使用计算机进行傅里叶变换，必须将函数定义在离散点上而非连续域内，且须满足有限性或周期性条件。这种情况下有：</p>
<script type="math/tex; mode=display">
\begin{aligned}
f(k)=\sum_{t=0}^{N-1}x(t)e^{-j(2\pi tk/N)},\quad k\in \{0,...,N-1\}
\end{aligned}</script><p>N个结果，表示N个频率（每个k对应一个频率）以及其对应的振幅。也就是说其计算复杂度为O(N^2)，每个结果都是复数，其模就是对应的振幅。</p>
<h3 id="基本过程"><a href="#基本过程" class="headerlink" title="基本过程"></a>基本过程</h3><p>音频检索的基本思想和生物信息检索的思路比较类似，都是在server端建立大量样本构成的数据库，client发送检索请求后，server端提取请求特征，然后在数据库中进行检索匹配，最后将结果返回给client。</p>
<p>在音频检索的场景下，这里面比较重要的部分是</p>
<ul>
<li>适用于部分匹配的特征提取</li>
<li>样本存储（上千万的歌曲）</li>
<li>高效、健壮的检索</li>
</ul>
<p>由于部分匹配要求存在，所以音频检索的特征提取算法不可能使用MD5、SHA等，并且要能处理不同格式的音乐（MP2、WMA等）。shazam选择从声音的频谱图中提取特征。</p>
<h4 id="采样"><a href="#采样" class="headerlink" title="采样"></a>采样</h4><p>和信号处理的大多数case一样，人声输入是连续的音频，比如一段mp3，是连续信号，需要对信号进行采样、数字化。采样要做的就是信号损失和存储压力之间的tradeoff，奈奎斯特定理指出，<strong>要以大于2倍于原始信号的采样频率，才能从数字信号中恢复出原始信</strong>。人类听觉上限大约是20kHZ，所以标准的数字音乐采样频率是44.1kHZ，是20kHZ的两倍多一点。</p>
<h4 id="量化"><a href="#量化" class="headerlink" title="量化"></a>量化</h4><p>采样是针对频率上的数字化，振幅的数字化则需要量化来完成。振幅的大小受到设备音量的影响。所以振幅的表示则有相对量表示，可以选定整个音乐中振幅的最值，并将其离散化，然后用这些离散值表示。标准的量化方法将振幅范围编码为16个bit，也就是65536个level，这时的信息损失已经很小了。</p>
<h4 id="脉冲编码调制"><a href="#脉冲编码调制" class="headerlink" title="脉冲编码调制"></a>脉冲编码调制</h4><p>经过采样、量化两个步骤之后，设备会对数据进行编码（称为PCM信号）并且送到耳机/扬声器进行播放，PCM的样例如下：</p>
<p><img src="http://ww1.sinaimg.cn/mw690/9bcfe727ly1fww2n0ujtbj20gl05ja9y.jpg" alt="16位的PCM信号数据"></p>
<p>采样率为44.1kHZ的音乐，每秒钟有44100个这样的数据。</p>
<h4 id="生成频谱图"><a href="#生成频谱图" class="headerlink" title="生成频谱图"></a>生成频谱图</h4><p>本节讲的是如何由一段数字信号生成频谱图，需要用到离散傅立叶变换技术。将时序信号等时间间隔划分成多个bin，在每个bin内使用DFT得到其频率。</p>
<p>这里有个概念，每个bin在频率上的表示也是有固定间隔的，这个值叫做<strong>频率分辨率</strong>（frequency resolution），计算方法是：</p>
<blockquote>
<p>frequency resolution = 采样率 / 窗口大小</p>
</blockquote>
<p>这里窗口大小是每个bin内采样窗口（window）。比如在44.1kHZ的标准采样率情况下，4096个样本的窗口对应的频率分辨率是10.7HZ。所以一个窗口的时长大约是4096/44100=0.1s，也就是说每隔0.1s就能检测出一个变化。</p>
<p>为了处理一个1s长度的音频，就需要分别处理10个bin的数据。实际上也就是是用了<strong>窗口函数</strong>（处理第一个bin的时候其他的系数为0）。简单的窗口函数是矩形，也还有hamming窗口和blackbox窗口，图示如下：<br><img src="http://ww1.sinaimg.cn/mw690/9bcfe727ly1fww56abkmdj20yj0mfq2w.jpg" alt="窗口函数"></p>
<p>不同的窗口效果不同，如下所示，左图是完美的图，右图是是用了不同的窗口函数的图像，可以看到，右图中存在被称为<strong>频谱泄漏</strong>的现象，即真是频率对应的数据蔓延到邻居点。</p>
<figure class="half">
    <img src="http://ww1.sinaimg.cn/mw690/9bcfe727ly1fww5bbcq5qj20yf0m7747.jpg" width="400">
    <img src="http://ww1.sinaimg.cn/mw690/9bcfe727ly1fww5bvw5srj20yh0m5jri.jpg" width="400">
</figure>

<p>图中blackman窗口函数的效果要优于其他窗口函数，但是换一个大小不同的窗口也许就不一样了，他们的特性如下：</p>
<ul>
<li>矩形窗口函数：可比振幅的正弦曲线效果较好，完全不同的振幅情况则比较差（音乐的振幅变动就比较大）</li>
<li>blackman窗口函数：擅长处理<strong>频谱泄漏时出现的强频率掩盖弱频率的问题</strong>，同时也导致了噪声会掩盖更多的频率</li>
<li>hamming窗口函数：上面两者的均衡</li>
</ul>
<hr>
<p>DFT的计算复杂度较高，在数量为1000的曲库上计算可能需要数天甚至上月才能完成。这里可以使用两个方面的优化：</p>
<ol>
<li>使用快速傅立叶变换FFT</li>
<li>降采样：因为一首歌中大多数重要的部分都在0-5kHZ区间上，所以我们只需要11kHZ的采样率即可（奈奎斯特）。为了保持相同的频率分辨率，窗口大小降为1024即可。可以将之前4个sample的数据求均值作为一个，采样频率降为原来的1/4</li>
</ol>
<blockquote>
<p>0.1s的bin size, bin的频率分辨率10.7HZ，512个可能的频率（5kHZ/10.7HZ），频率范围0-5kHZ</p>
</blockquote>
<p>这里我们就得到了频谱图，考虑到对噪声的鲁棒性问题，可以将振幅最大的音符留下，但是这样会存在如下问题：</p>
<ul>
<li>许多歌曲中都会包含一些人耳不容易听见的声音（&lt;500HZ），发行前都会特意加强这些音符。只保留振幅最大的可能导致保留的都是这些人耳不容易听见的声音</li>
<li>频谱泄露问题导致不存在的频率出现，要确保不会选中不存在的</li>
</ul>
<p>解决上述问题的方法如下</p>
<ol>
<li>对每一个FFT结果（N个），把512个当成6个bands（6是超参数），bands由振幅区间划分，把这些结果放到这些bin中</li>
<li>每个band只保留最大值</li>
<li>计算6个band中最大值的均值（由于开头、结尾可能振幅较小，均值较小，但是我们并不想要这部分频率，所以可以考虑计算整首歌振幅最大的6个的均值）</li>
<li>保留大于均值的band值作为结果（可以乘一个参数）</li>
</ol>
<p>以下是示例：</p>
<figure class="half">
    <img src="http://ww1.sinaimg.cn/mw690/9bcfe727ly1fwwcb9f0sdj20g50cg0th.jpg" width="400">
    <img src="http://ww1.sinaimg.cn/mw690/9bcfe727ly1fwwcc3kgsmj20g10cfq2x.jpg" width="400">
</figure>

<hr>
<h4 id="特征存储与匹配"><a href="#特征存储与匹配" class="headerlink" title="特征存储与匹配"></a>特征存储与匹配</h4><p>如上图所示，特征数据是<code>&lt;time, frequency&gt;</code>对，根据时长进行滑动窗口逐一匹配的复杂度过高。shazam中使用多个点同时匹配的方法，引入target zone的概念。</p>
<p>阐述方便，将目标区域的大小固定为5，将二维数据线性化，需要严格的先后顺序保持唯一性，比如time相同时，frequency小的在前面。所以m个<code>&lt;time, frequency&gt;</code>对的数据，可以生成m-4个目标区域。</p>
<p>下一步是为每个目标区域创建一个地址，当然这是在server端做的。我们还需要一个anchor锚点，anchor的选取不限制，只要是可重复的即可（比如当前目标区域之前的一个点或者前三个啥的）。把每个目标位置当做一个key<code>&lt;anchor频率, 首位频率, 首位和anchor的时间差&gt;</code>，每个key映射到一个地址，地址的形式为<code>&lt;anchor在歌曲中的绝对位置/时间, 歌曲ID&gt;</code>。</p>
<p>在检索阶段，对输入的音频，算法生成一个个<code>&lt;&lt;anchor频率, 首位频率, 首位和anchor的时间差&gt;, 锚点在音频中的绝对位置&gt;</code>，并上传到server端。server进行检索，可能会返回大量结果，这里由于没有逐一比较target zone的每个数据点，所以即使命中了也可能不一样，但是这样节省了时间，也能过滤掉大部分negative样本。细致的比较下面继续。</p>
<p>对于上一步得到的结果，我们需要进一步比较，策略如下</p>
<ul>
<li>去除没有target zone完全匹配的结果</li>
<li>卡一下阈值</li>
</ul>
<hr>
<p><img src="http://ww1.sinaimg.cn/mw690/9bcfe727ly1fwwhngsh0ij20en0ft74z.jpg" alt="image"></p>
<p>最后还需要考虑时间先后的问题，必要性见上图，这时需要</p>
<ul>
<li>计算候选歌曲中的音符及其在歌曲中的绝对位置</li>
<li>计算输入音频中的音符及其在输入中的绝对位置</li>
<li>匹配的音符应该满足：音符在歌曲中的绝对位置=音符在输入中的绝对位置+匹配开始的位置。对于每首歌，我们需要找到匹配音节最多的开始位置</li>
<li>返回音符匹配最多的候选</li>
</ul>
<hr>
<p>引用</p>
<p>[1]. <a href="http://coding-geek.com/how-shazam-works/" target="_blank" rel="noopener">How does Shazam work</a></p>
<hr>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="atlantic8.github.io/2018/12/16/how-does-shazam-work/" data-id="ckjflh80300bzwoph84i2dfif" class="article-share-link"><i class="fas fa-share"></i>分享到</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fab fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fab fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fab fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fab fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    

        </footer>
    </div>
    
</article>



    <article id="post-Conditional-Random-Field" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2017/08/27/Conditional-Random-Field/">Conditional Random Field</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fas fa-calendar-alt"></i>
        <a href="/2017/08/27/Conditional-Random-Field/">
            <time datetime="2017-08-27T06:19:20.000Z" itemprop="datePublished">2017-08-27</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fas fa-folder"></i>
        <a class="article-category-link" href="/categories/Algorithm/">Algorithm</a>
    </div>

                        
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/machine-learning/">machine learning</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <h4 id="CRF"><a href="#CRF" class="headerlink" title="CRF"></a>CRF</h4><p>同朴素贝叶斯一样，HMM是生成式模型。它可以做线性序列预测分析，为了计算复杂度上的可行性，其<strong>假设观测变量仅依赖于隐含变量</strong>。然而，实际中<strong>观测变量之间也存在不可忽略的依赖关系</strong>，这导致HMM的假设会严重影响模型的精确性。</p>
<p>CRF现在是自然语言处理领域中多个任务的state-of-art方法，包括分词、词性标注，浅解析（shallow parsing）等。并且在命名实体识别、基因预测、图像标注、物体识别等领域有着重要的应用。</p>
<p>CRF是<strong>判别</strong>式模型。</p>
<hr>
<h5 id="概率图模型"><a href="#概率图模型" class="headerlink" title="概率图模型"></a>概率图模型</h5><p>一般地，在概率图模型中，节点表示随机变量，边表示依赖关系。概率图模型的表示的前提是对图的划分，也就是因子分解，可以按有向图和无向图分别讨论。</p>
<h6 id="马尔可夫性"><a href="#马尔可夫性" class="headerlink" title="马尔可夫性"></a>马尔可夫性</h6><p>给定一个随机变量$y$及其联合概率分布$p(y)$和它的无向图表示$G$，下面给出关于马尔可夫性的三个等价定义。</p>
<ul>
<li>成对马尔可夫性：设$u,v$是无向图中没有连接的两个点，$o$是其他节点，则有$p(u,v|o)=p(u|o)p(v|o)$</li>
<li>局部马尔可夫性：设$u$是无向图中任意一个节点，$w$是与$u$有连接的节点，$o$是其他节点，则有$p(v,o|w)=p(v|w)p(o|w)$</li>
<li>全局马尔可夫性：设$u,v$是被节点集$o$分隔开的任意节点集合，则有$p(u,v|o)=p(u|o)p(v|o)$</li>
</ul>
<p>总结一下意思就是：<strong>无连接的变量在以中继变量为条件的情况下相互独立</strong>。</p>
<h6 id="有向图"><a href="#有向图" class="headerlink" title="有向图"></a>有向图</h6><p>定义在有向图上的条件概率模型的联合分布为<strong>所有节点条件概率的乘积</strong>，比如贝叶斯网络，马尔可夫链等。</p>
<hr>
<h6 id="无向图"><a href="#无向图" class="headerlink" title="无向图"></a>无向图</h6><p>满足马尔可夫性的联合概率分布被称为概率无向图模型，也叫做<strong>马尔可夫随机场</strong>。定义在无向图上的条件概率模型的联合分布为<strong>最大团上非负函数的乘积</strong>（这也称为概率无向图模型的因子分解）。这里最大团（极大团）指的是不能再添加节点的团（团指的是两两相交的节点集）。形式化定义单个节点$v$的概率为$v$在所有最大团上的乘积，即</p>
<script type="math/tex; mode=display">
\begin{aligned}
p(v)=\frac{1}{Z}\prod_{c\in C}\Psi_c(v_c)
\end{aligned}</script><p>其中$\Psi_c(v_c) \ge 0$称为节点$v$在团$c$上的势函数。$Z$是归一化因子满足$Z=\sum_vp(v)$（其实最大熵模型也可以看成是势函数的乘积）。</p>
<hr>
<h4 id="CRF的表示"><a href="#CRF的表示" class="headerlink" title="CRF的表示"></a>CRF的表示</h4><p>CRF是定义在无向图上的判别式模型，是给定随机变量$x$的条件下，随机变量$y$的马尔可夫随机场。按照无向图上的定义，可以有</p>
<script type="math/tex; mode=display">
\begin{aligned}
p(y|x)&=\frac{p(x,y)}{p(x)}=\frac{p(x,y)}{\sum_{y'}p(x,y')} \\
&=\frac{\frac{1}{Z}\prod_{c\in C}\Psi_c(x_c,y_c)}{\frac{1}{Z}\sum_{y'}\prod_{c\in C}\Psi_c(x_c,y'_c)} \\
&=\frac{1}{Z(x)}\prod_{c\in C}\Psi_c(x_c,y_c)
\end{aligned}</script><p>这就是CRF的基本形式。下面分别介绍线性链CRF和任意结构的CRF。</p>
<h5 id="线性链CRF"><a href="#线性链CRF" class="headerlink" title="线性链CRF"></a>线性链CRF</h5><p>CRF的一种特殊形式，也是比较常用的形式-线性链式。在这种情况下，相邻点变成了最大团，即满足马尔可夫性</p>
<script type="math/tex; mode=display">
\begin{aligned}
p(y_i|x,y_1,..,y_{i-1},y_{i+1},...,y_{n+1})=p(y_i|x,y_{i-1},y_{i+1})
\end{aligned}</script><p>假设$x=(x_1,…x_{n+1})$，$y=(y_1,…y_{n+1})$（都是向量），链的长度为$n+1$，所以最大团的数量为$n$，上式就可以写成：</p>
<script type="math/tex; mode=display">
\begin{aligned}
p(y|x)=\frac{1}{Z(x)}\prod_{j=1}^n\Psi_j(x,y)
\end{aligned}</script><p>给定势函数$\Psi_j(x,y)$的形式为</p>
<script type="math/tex; mode=display">
\begin{aligned}
\Psi_j(x,y)=\exp\left(\sum_{i=1}^m\lambda_if_i(x,y_{j-1},y_j,j)\right)
\end{aligned}</script><p>其中，$j$表示序列位置（与$n$相关）。所以线性链的CRF可以表示为</p>
<script type="math/tex; mode=display">
\begin{aligned}
p_{\lambda}(y|x)&=\frac{1}{Z_{\lambda}(x)}\cdot \exp\left( \sum_{j=1}^n \sum_{i=1}^m\lambda_if_i(x,y_{j-1},y_j,j) \right) \\
&=\frac{1}{Z_{\lambda}(x)}\prod_{j=1}^n \exp\left( \sum_{i=1}^m\lambda_if_i(x,y_{j-1},y_j,j) \right)
\end{aligned}</script><p>其中，$Z_{\lambda}(x)$就是在$y$上对$p_{\lambda}(y|x)$求和的结果，这结构与最大熵的形式类似。</p>
<hr>
<p>与HMM的模式类似，应用模型之前还需要解决一些问题，分别是</p>
<ol>
<li>给定序列集合$X$和对应的标注数据$Y$，如何训练CRF模型参数使得$p(Y|X,\mathcal{M})$最大</li>
<li>给定模型$\mathcal{M}$和输入序列$X$，如何求输出序列$Y$</li>
</ol>
<p>这里就不考虑求$p(X|\mathcal{M})$了，因为CRF是<strong>判别式</strong>模型。</p>
<hr>
<h6 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h6><p>目标是估计参数$\lambda$。给定数据集$T$，参数估计常用的方法就是MLE了，我们再取一个log，考虑regularization，推导如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathcal{L}(T)&=\sum_{(x,y)\in T}\log p(y|x) - \frac{1}{2\sigma^2}||\lambda||_2^2 \\
&=\sum_{(x,y)\in T} \log\left( \frac{\exp\left(\sum_{j=1}^n \sum_{i=1}^m\lambda_if_i(x,y_{j-1},y_j,j)\right)}{\sum_{y'}\exp\left(\sum_{j=1}^n \sum_{i=1}^m\lambda_if_i(x,y'_{j-1},y'_j,j)\right) } \right) - \frac{1}{2\sigma^2}\sum_{i=1}^m\lambda_i^2 \\
&=\sum_{(x,y)\in T}\sum_{j=1}^n \sum_{i=1}^m\lambda_if_i(x,y_{j-1},y_j,j) - \sum_{(x,y)\in T}\log Z_{\lambda}(x) - \frac{1}{2\sigma^2}\sum_{i=1}^m\lambda_i^2
\end{aligned}</script><p>这里$\sigma^2$是控制regularization权重的超参数。上式可分为3部分，分别对$\lambda_k$求导</p>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial}{\partial\lambda_k}\sum_{(x,y)\in T}\sum_{j=1}^n \sum_{i=1}^m\lambda_if_i(x,y_{j-1},y_j,j)&=\sum_{(x,y)\in T}\sum_{j=1}^n f_k(x,y_{j-1},y_j,j) \\
&=N\cdot\hat{E}(f_k)
\end{aligned}</script><p>其结果刚好是训练数据集上特征$f_i$的期望值的$N$（训练集数据个数*(n+1)）倍。</p>
<hr>
<script type="math/tex; mode=display">
\begin{aligned}
&\frac{\partial}{\partial\lambda_k}\sum_{(x,y)\in T}\log Z_{\lambda}(x)=\sum_{(x,y)\in T}\frac{1}{Z_{\lambda}(x)}\frac{\partial Z_{\lambda}(x)}{\partial\lambda_k} \\
&=\sum_{(x,y)\in T}\frac{1}{Z_{\lambda}(x)} \frac{\partial}{\partial\lambda_k}\sum_{y'}\exp\left(\sum_{j=1}^n \sum_{i=1}^m\lambda_if_i(x,y'_{j-1},y'_j,j)\right) \\
&=\sum_{(x,y)\in T}\frac{1}{Z_{\lambda}(x)} \sum_{y'}\left[\exp\left(\sum_{j=1}^n \sum_{i=1}^m\lambda_if_i(x,y'_{j-1},y'_j,j)\right)\cdot \sum_{j=1}^n f_k(x,y'_{j-1},y'_j,j)\right] \\
&=\sum_{(x,y)\in T}\sum_{y'}p_{\lambda}(y'|x)\sum_{j=1}^n f_k(x,y'_{j-1},y'_j,j) \\
&=N\cdot E(f_k)
\end{aligned}</script><p>上面倒数第二行第一个求和符号的范围可以退化成$x\in X$，其结果刚好是模型分布上特征$f_i$的期望值的$N$（训练集数据个数*(n+1)）倍。</p>
<hr>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial}{\partial\lambda_k}\frac{1}{2\sigma^2}\sum_{i=1}^m\lambda_i^2=\frac{\lambda_k}{\sigma^2}
\end{aligned}</script><hr>
<p>综上，我们可以得到</p>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial \mathcal{L}(T)}{\partial \lambda_k}=N\cdot(\hat{E}(f_k)-E(f_k))-\frac{\lambda_k}{\sigma^2}
\end{aligned}</script><p>继而，令上式等于0，就可以求出$\lambda_k$的值。这里，$\hat{E}(f_k)$可以通过简单的统计特征$f_k$在数据集中的出现的次数实现。而想要直接计算$E(f_k)$就不容易了，因为CRF这里处理的是序列数据，序列组合导致可能性指数上升。</p>
<hr>
<p>解决方法是利用HMM也用到的<strong>前后向算法</strong>的修改版。<br>定义函数$T_j(s)$为状态$s$在输入位置$j$时，位置$j+1$的可能状态集合。定义函数$T_j^{-1}(s)$为$T_j(s)$的反函数，即输出状态$s$的前置集合。定义序列初始状态为$\vdash$，终止状态为$\dashv$。在此基础上定义<strong>前向、后向函数</strong>：</p>
<ul>
<li>前向函数：$\alpha_j(s|x)=\sum_{s’\in T_j^{-1}(s)}\alpha_{j-1}(s’|x)\cdot \Psi_j(s’,s,x)$，初始化$\alpha_0(\vdash|x)=1$</li>
<li>后向函数：$\beta_j(s|x)=\sum_{s’\in T_j(s)}\beta_{j+1}(s’|x)\cdot \Psi_j(s,s’,x)$，初始化$\beta_{|x|+1}(\dashv|x)=1$</li>
</ul>
<p>其中，与上文的势函数对应，$\Psi_j(s’,s,x)=\exp(\sum_{i=1}^m\lambda_if_j(y_{i-1}=s’,y_i=s,x,j))$。根据前向、后向函数的定义，可以有</p>
<script type="math/tex; mode=display">
\begin{aligned}
p(y_j=s|x)= \frac{\alpha_j(s|x)\beta_j(s|x)}{Z_{\lambda}(x)}
\end{aligned}</script><p>因此，$E(f_k)$的计算就变得可行了</p>
<script type="math/tex; mode=display">
\begin{aligned}
E(f_k)&=\sum_{(x,y)\in T}\frac{1}{Z_{\lambda}(x)}\sum_{j=1}^n\sum_{s\in S}\sum_{s'\in T_j(s)} f_j(s,s',x,j)\alpha_j(s|x)\Psi_j(s,s',x)\beta_{j+1}(s'|x) \\
Z_{\lambda}(x)&=\beta_0(\vdash|x)=\alpha_{|x|+1}(\dashv|x)
\end{aligned}</script><p>其中$S$是状态集合。这相当于计算了所有可能状态序列的可能，$\alpha, \beta$的值只需要计算一次，存储起来就好。前后向算法的时间复杂度为$O(|S|^2n)$。</p>
<p>至此，$\lambda$的更新变得可行，模型训练ok。</p>
<hr>
<h6 id="序列标注"><a href="#序列标注" class="headerlink" title="序列标注"></a>序列标注</h6><p>序列标注即要在给定模型参数情况下找到输入序列对应的概率最大的标注序列，可以采用维特比算法的思想。定义: <strong>$\delta_j(s|x)$表示序列到位置$j$时，状态为$s$的最大概率</strong>，即</p>
<script type="math/tex; mode=display">
\begin{aligned}
\delta_j(s|x)=\max_{y_1,..,y_{j-1}}p(y_1,...,y_{j-1},y_j=s|x)=\max_{s'\in S}\delta_{j-1}(s')\cdot \Psi_j(s',s,x)
\end{aligned}</script><p>还需要<strong>数组$\phi_j(s)$记录下$j$位置状态为$s$时$j-1$位置的状态是什么</strong>。<br>算法的步骤如下：</p>
<hr>
<ol>
<li>从开始状态初始$\vdash$化，对所有的状态$s\in S$，令<br> $\delta_1(s|x)=\Psi_1(\vdash,s,x)$.<br> $\phi_1(s)=\vdash$</li>
<li>递归计算，对每一个$s\in S, 1\le j\le n$<br> $\delta_j(s|x)=\max_{s’\in S}\delta_{j-1}(s’)\cdot \Psi_j(s’,s,x)$<br> $\phi_j(s)=arg\max_{s’\in S}\delta_{j-1}(s’)\cdot \Psi_j(s’,s,x)$</li>
<li>结束迭代<br> $p_{max}=\max_{s’\in S}\delta_{n}(s’)$<br> $y_n=arg\max_{s’\in S}\delta_n(s’|x)$</li>
<li>回溯<br> 根据$\phi$数组和$y_n$求出整个$y$序列。</li>
</ol>
<hr>
<h5 id="任意结构CRF"><a href="#任意结构CRF" class="headerlink" title="任意结构CRF"></a>任意结构CRF</h5><blockquote>
<p>TODO</p>
</blockquote>
<p><strong>参考文献</strong><br>[1]. Classical Probabilistic Models and Conditional Random Fields.pdf</p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="atlantic8.github.io/2017/08/27/Conditional-Random-Field/" data-id="ckjflh7qt000twophm98exab8" class="article-share-link"><i class="fas fa-share"></i>分享到</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fab fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fab fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fab fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fab fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    

        </footer>
    </div>
    
</article>



    <nav id="page-nav">
        <a class="extend prev" rel="prev" href="/">&laquo; 上一页</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/3/">下一页 &raquo;</a>
    </nav>
</section>
            
                
<aside id="sidebar">
   
        
    <div class="widget-wrap">
        <h3 class="widget-title">最新文章</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2021/01/02/Monotonous-Sequence/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/OJ/">OJ</a></p>
                            <p class="item-title"><a href="/2021/01/02/Monotonous-Sequence/" class="title">Monotonous Sequence</a></p>
                            <p class="item-date"><time datetime="2021-01-02T08:12:40.000Z" itemprop="datePublished">2021-01-02</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2021/01/02/Factorization-Machines/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Algorithm/">Algorithm</a></p>
                            <p class="item-title"><a href="/2021/01/02/Factorization-Machines/" class="title">Factorization Machines</a></p>
                            <p class="item-date"><time datetime="2021-01-02T07:49:44.000Z" itemprop="datePublished">2021-01-02</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/09/01/Python-Functions/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Dev/">Dev</a></p>
                            <p class="item-title"><a href="/2020/09/01/Python-Functions/" class="title">Python Functions</a></p>
                            <p class="item-date"><time datetime="2020-09-01T15:15:14.000Z" itemprop="datePublished">2020-09-01</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/09/01/Bounds-in-Binary-Search/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/OJ/">OJ</a></p>
                            <p class="item-title"><a href="/2020/09/01/Bounds-in-Binary-Search/" class="title">Bounds in Binary Search</a></p>
                            <p class="item-date"><time datetime="2020-09-01T15:12:12.000Z" itemprop="datePublished">2020-09-01</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/09/01/BM25/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Algorithm/">Algorithm</a></p>
                            <p class="item-title"><a href="/2020/09/01/BM25/" class="title">BM25</a></p>
                            <p class="item-date"><time datetime="2020-09-01T15:06:49.000Z" itemprop="datePublished">2020-09-01</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a><span class="category-list-count">51</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Dev/">Dev</a><span class="category-list-count">21</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/">Math</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/OJ/">OJ</a><span class="category-list-count">57</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">一月 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">九月 2020</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">八月 2020</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">九月 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">七月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">一月 2017</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">十二月 2016</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">十一月 2016</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">十月 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">九月 2016</a><span class="archive-list-count">35</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">八月 2016</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">七月 2016</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">六月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">五月 2016</a><span class="archive-list-count">8</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/Backtracking/" style="font-size: 11.11px;">Backtracking</a> <a href="/tags/Binary-Search/" style="font-size: 12.22px;">Binary Search</a> <a href="/tags/Binary-Tree/" style="font-size: 16.67px;">Binary Tree</a> <a href="/tags/Cpp/" style="font-size: 15.56px;">Cpp</a> <a href="/tags/DFS/" style="font-size: 10px;">DFS</a> <a href="/tags/DP/" style="font-size: 16.67px;">DP</a> <a href="/tags/Deep-Learning/" style="font-size: 10px;">Deep Learning</a> <a href="/tags/Divide-Conquer/" style="font-size: 10px;">Divide & Conquer</a> <a href="/tags/Game-Theory/" style="font-size: 10px;">Game Theory</a> <a href="/tags/Geometry/" style="font-size: 10px;">Geometry</a> <a href="/tags/Graph/" style="font-size: 11.11px;">Graph</a> <a href="/tags/Greedy/" style="font-size: 13.33px;">Greedy</a> <a href="/tags/IPython/" style="font-size: 10px;">IPython</a> <a href="/tags/IR/" style="font-size: 11.11px;">IR</a> <a href="/tags/Java/" style="font-size: 13.33px;">Java</a> <a href="/tags/LeetCode/" style="font-size: 20px;">LeetCode</a> <a href="/tags/Leetcode/" style="font-size: 11.11px;">Leetcode</a> <a href="/tags/MIR/" style="font-size: 10px;">MIR</a> <a href="/tags/Machine-Learning/" style="font-size: 10px;">Machine Learning</a> <a href="/tags/Math/" style="font-size: 12.22px;">Math</a> <a href="/tags/Matlab/" style="font-size: 10px;">Matlab</a> <a href="/tags/NLP/" style="font-size: 14.44px;">NLP</a> <a href="/tags/Optimization/" style="font-size: 10px;">Optimization</a> <a href="/tags/POJ/" style="font-size: 11.11px;">POJ</a> <a href="/tags/Permutation/" style="font-size: 10px;">Permutation</a> <a href="/tags/STL/" style="font-size: 10px;">STL</a> <a href="/tags/Sliding-window/" style="font-size: 14.44px;">Sliding window</a> <a href="/tags/Sort/" style="font-size: 11.11px;">Sort</a> <a href="/tags/State-Machine/" style="font-size: 10px;">State Machine</a> <a href="/tags/String/" style="font-size: 14.44px;">String</a> <a href="/tags/Tree/" style="font-size: 10px;">Tree</a> <a href="/tags/bit/" style="font-size: 10px;">bit</a> <a href="/tags/deep-learning/" style="font-size: 15.56px;">deep learning</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/machine-learning/" style="font-size: 18.89px;">machine learning</a> <a href="/tags/numpy/" style="font-size: 11.11px;">numpy</a> <a href="/tags/other/" style="font-size: 10px;">other</a> <a href="/tags/pandas/" style="font-size: 11.11px;">pandas</a> <a href="/tags/prime/" style="font-size: 10px;">prime</a> <a href="/tags/python/" style="font-size: 17.78px;">python</a> <a href="/tags/random-algorithm/" style="font-size: 12.22px;">random algorithm</a> <a href="/tags/recommendation/" style="font-size: 10px;">recommendation</a> <a href="/tags/recommender-system/" style="font-size: 10px;">recommender system</a> <a href="/tags/time-series-data/" style="font-size: 10px;">time_series_data</a> <a href="/tags/visualization/" style="font-size: 10px;">visualization</a> <a href="/tags/web/" style="font-size: 10px;">web</a> <a href="/tags/数据分析/" style="font-size: 10px;">数据分析</a> <a href="/tags/文件/" style="font-size: 10px;">文件</a>
        </div>
    </div>

    
        
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">链接</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="https://xueshu.glgoo.org/">Google Scholar Mirror</a>
                    </li>
                
                    <li>
                        <a href="https://www.kaggle.com/">Kaggle</a>
                    </li>
                
                    <li>
                        <a href="http://mlr.cs.umass.edu/ml/datasets.html">UCI dataset</a>
                    </li>
                
                    <li>
                        <a href="https://leetcode.com/problemset/algorithms/">LeetCode</a>
                    </li>
                
            </ul>
        </div>
    </div>


    
    <div id="toTop" class="fas fa-angle-up"></div>
</aside>

            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2021 曹文强<br>
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
        </div>
    </div>
</footer>
        


    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>