<!DOCTYPE html>
<html lang="zh">
<head><meta name="generator" content="Hexo 3.9.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    
    <title>Graph Embedding | 曹文强</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="图嵌入，即用一个低维，稠密的向量去表示图中的点，该向量表示能反映图中的结构。但是在介绍图嵌入之前，可以大概描述一下词嵌入。 bert时代之前，word2vec是很有名的词嵌入技术，训练快，效果提升也比不用词向量明显。本质上就是由输入序列得到每个word的embedding，其目标函数为  \sum_i\log p(w_i|w_{context(i)})即希望：给定上下文，当前词的概率更大。（ski">
<meta name="keywords" content="deep learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Graph Embedding">
<meta property="og:url" content="atlantic8.github.io/2020/09/01/Graph-Embedding/index.html">
<meta property="og:site_name" content="曹文强">
<meta property="og:description" content="图嵌入，即用一个低维，稠密的向量去表示图中的点，该向量表示能反映图中的结构。但是在介绍图嵌入之前，可以大概描述一下词嵌入。 bert时代之前，word2vec是很有名的词嵌入技术，训练快，效果提升也比不用词向量明显。本质上就是由输入序列得到每个word的embedding，其目标函数为  \sum_i\log p(w_i|w_{context(i)})即希望：给定上下文，当前词的概率更大。（ski">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://raw.githubusercontent.com/Atlantic8/picture/master/graph-embedding-1.PNG">
<meta property="og:image" content="https://raw.githubusercontent.com/Atlantic8/picture/master/graph-embedding-2.PNG">
<meta property="og:image" content="https://raw.githubusercontent.com/Atlantic8/picture/master/graph-embedding-3.PNG">
<meta property="og:image" content="https://raw.githubusercontent.com/Atlantic8/picture/master/graph-embedding-4.PNG">
<meta property="og:image" content="https://raw.githubusercontent.com/Atlantic8/picture/master/graph-embedding-5.PNG">
<meta property="og:image" content="https://raw.githubusercontent.com/Atlantic8/picture/master/graph-embedding-6.PNG">
<meta property="og:updated_time" content="2020-09-01T14:53:43.922Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Graph Embedding">
<meta name="twitter:description" content="图嵌入，即用一个低维，稠密的向量去表示图中的点，该向量表示能反映图中的结构。但是在介绍图嵌入之前，可以大概描述一下词嵌入。 bert时代之前，word2vec是很有名的词嵌入技术，训练快，效果提升也比不用词向量明显。本质上就是由输入序列得到每个word的embedding，其目标函数为  \sum_i\log p(w_i|w_{context(i)})即希望：给定上下文，当前词的概率更大。（ski">
<meta name="twitter:image" content="https://raw.githubusercontent.com/Atlantic8/picture/master/graph-embedding-1.PNG">
    

    

    
        <link rel="icon" href="/css/images/logo.png">
    

    <link rel="stylesheet" href="/libs/font-awesome5/css/fontawesome.min.css">
    <link rel="stylesheet" href="/libs/font-awesome5/css/fa-brands.min.css">
    <link rel="stylesheet" href="/libs/font-awesome5/css/fa-solid.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    
        <script>
var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?ff86ad40748d96af89d192e9b0a3ae62";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    


</head>
</html>
<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">曹文强</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/.">Home</a>
                
                    <a class="main-nav-link" href="/archives">Archives</a>
                
                    <a class="main-nav-link" href="/categories/OJ">OJ</a>
                
                    <a class="main-nav-link" href="/categories/Algorithm">Algorithm</a>
                
                    <a class="main-nav-link" href="/categories/Math">Math</a>
                
                    <a class="main-nav-link" href="/categories/Dev">Dev</a>
                
                    <a class="main-nav-link" href="/about">About</a>
                
            </nav>
            
                
                <nav id="sub-nav">
                    <div class="profile" id="profile-nav">
                        <a id="profile-anchor" href="javascript:;">
                            <img class="avatar" src="/css/images/me.png" />
                            <i class="fas fa-caret-down"></i>
                        </a>
                    </div>
                </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fas fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/.">Home</a></td>
                
                    <td><a class="main-nav-link" href="/archives">Archives</a></td>
                
                    <td><a class="main-nav-link" href="/categories/OJ">OJ</a></td>
                
                    <td><a class="main-nav-link" href="/categories/Algorithm">Algorithm</a></td>
                
                    <td><a class="main-nav-link" href="/categories/Math">Math</a></td>
                
                    <td><a class="main-nav-link" href="/categories/Dev">Dev</a></td>
                
                    <td><a class="main-nav-link" href="/about">About</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
                

<aside id="profile" class="profile-fixed">
    <div class="inner profile-inner">
        <div class="base-info profile-block">
            <img id="avatar" src="/css/images/me.png" />
            <h2 id="name">曹文强</h2>
            <h3 id="title">algorithm engineer</h3>
            <span id="location"><i class="fas fa-map-marker-alt" style="padding-right: 5px"></i>Beijing, China</span>
            <a id="follow" target="_blank" href="https://github.com/Atlantic8">关注我</a>
        </div>
        <div class="article-info profile-block">
            <div class="article-info-block">
                132
                <span>文章</span>
            </div>
            <div class="article-info-block">
                48
                <span>标签</span>
            </div>
        </div>
        
        <div class="profile-block social-links">
            <table>
                <tr>
                    
                    
                    <td>
                        <a href="https://github.com/Atlantic8" target="_blank" title="github" class=tooltip>
                            
                                <i class="fab fa-github"></i>
                            
                        </a>
                    </td>
                    
                    <td>
                        <a href="https://www.linkedin.com/in/wenqiang-cao-704236b8/" target="_blank" title="linkedin" class=tooltip>
                            
                                <i class="fab fa-linkedin"></i>
                            
                        </a>
                    </td>
                    
                    <td>
                        <a href="mailto:atlantic8@outlook.com" target="_blank" title="envelope" class=tooltip>
                            
                                <i class="fas fa-envelope"></i>
                            
                        </a>
                    </td>
                    
                    <td>
                        <a href="http://weibo.com/2614093607" target="_blank" title="weibo" class=tooltip>
                            
                                <i class="fab fa-weibo"></i>
                            
                        </a>
                    </td>
                    
                    <td>
                        <a href="/" target="_blank" title="facebook" class=tooltip>
                            
                                <i class="fab fa-facebook"></i>
                            
                        </a>
                    </td>
                    
                </tr>
            </table>
        </div>
        
    </div>
</aside>

            
            <section id="main"><article id="post-Graph-Embedding" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
            Graph Embedding
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fas fa-calendar-alt"></i>
        <a href="/2020/09/01/Graph-Embedding/">
            <time datetime="2020-09-01T14:49:52.000Z" itemprop="datePublished">2020-09-01</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fas fa-folder"></i>
        <a class="article-category-link" href="/categories/Algorithm/">Algorithm</a>
    </div>

                        
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/deep-learning/">deep learning</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <p>图嵌入，即用一个低维，稠密的向量去表示图中的点，该向量表示能反映图中的结构。但是在介绍图嵌入之前，可以大概描述一下词嵌入。</p>
<p>bert时代之前，word2vec是很有名的词嵌入技术，训练快，效果提升也比不用词向量明显。本质上就是由输入序列得到每个word的embedding，其目标函数为</p>
<script type="math/tex; mode=display">
\sum_i\log p(w_i|w_{context(i)})</script><p>即希望：给定上下文，当前词的概率更大。（skip-gram的意思也一致）</p>
<p>基本的图嵌入算法也借鉴了这个思想，问题就是图如何转化为序列</p>
<h4 id="DeepWalk"><a href="#DeepWalk" class="headerlink" title="DeepWalk"></a>DeepWalk</h4><blockquote>
<p>DeepWalk: Online Learning of Social Representations. 2014</p>
</blockquote>
<p>DeepWalk通过<strong>截断随机游走</strong>(truncated random walk)学习网络的嵌入表示，就是等于对图进行采样，得到多个<strong>节点序列</strong>，跳转概率可以由节点之间的权重决定。然后对节点序列学习节点的embedding表示</p>
<p><strong>random walk实际上是一种可回头的DFS</strong></p>
<h4 id="LINE"><a href="#LINE" class="headerlink" title="LINE"></a>LINE</h4><blockquote>
<p>Large scale information network embedding. 2015</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/graph-embedding-1.PNG" alt="一阶二阶相似度"></p>
<p>高维空间中相近的点在低维空间中也是相近的，相近的定义如下</p>
<h6 id="一阶相近"><a href="#一阶相近" class="headerlink" title="一阶相近"></a>一阶相近</h6><ul>
<li>高维空间中：节点$i,j$之间的权重有经验分布：$\hat{p}_1(i,j)=\frac{w_{i,j}}{\sum_{(i,j)\in E}}$</li>
<li>低维空间中：则可以理解为embedding$\mu_i,\mu_j$的sigmoid函数（$p_1(i,j)=\frac{1}{1+\exp{(-u_i^Tu_j)}}$）</li>
<li>目标为最小化两个分布的距离，距离用KL散度，$O_1=-\sum_{(i,j)\in E}w_{i,j}\log p_1(i,j)$</li>
</ul>
<h6 id="二阶相近，用于有向图"><a href="#二阶相近，用于有向图" class="headerlink" title="二阶相近，用于有向图"></a>二阶相近，用于有向图</h6><ul>
<li>高维：node之间有多少公共一度节点(比如5和6之间有4个公共一度节点，也就是有多少相同的邻居)，经验分布为$\hat{p}_2(i,j)=\frac{w_{i,j}}{d_i}$，$d_i$是节点的出边的权值和</li>
<li>低维：条件概率$p_2(j|i)$可以表示为softmax形式</li>
<li>目标为最小化两个分布的距离，距离用KL散度，$O_2=-\sum_{(i,j)\in E}w_{i,j}\log p_2(j|i)$</li>
</ul>
<p>每个顶点维护两个embedding向量，一个是该顶点本身的表示向量，一个是该点作为其他顶点的上下文顶点时的表示向量</p>
<h4 id="Node2vec"><a href="#Node2vec" class="headerlink" title="Node2vec"></a>Node2vec</h4><blockquote>
<p>node2vec: Scalable Feature Learning for Networks. 2016</p>
</blockquote>
<p>Node2vec基于二阶随机游走，通过参数$p,q$来控制游走策略，平衡BFS和DFS（<strong>DFS倾向于获取结构相似性，BFS倾向于获取内容相似性，即局部相似性</strong>）。通过改变采样结果来优化效果</p>
<p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/graph-embedding-2.PNG" alt="image"></p>
<p>定义当前节点为$v$，上一节点为$t$，随机游走到下一个节点$x$的概率为</p>
<script type="math/tex; mode=display">
\pi(x|v)=\frac{\alpha(t,x)}{\sum_{(y,v)\in E}\alpha(t,y)}</script><p>其中，$\alpha$是控制函数，其定义为</p>
<script type="math/tex; mode=display">
\alpha(t,x)=\left\{
\begin{aligned}
\frac{1}{p}, &  &  d_{tx}=0 \\
1, &  &  d_{tx}=1 \\
\frac{1}{q}, &  &  d_{tx}=2
\end{aligned}
\right.</script><p>其中，$d_{tx}$是节点$t,x$之间的最短路径长度，因为最大就为2，所以有二阶的概念。$q$为<strong>前进参数</strong>（决定搜索远离$t$的节点的概率），$p$为<strong>回溯参数</strong>（决定了有多少概率下一个节点还是$t$）</p>
<p>如果图的边存在初始权重，则计算下一节点为$x$的概率时需要考虑权重，也就是归一化的时候乘上权重。</p>
<p>BTY：当$p=1,q=1$时，Node2vec等价于random walk</p>
<h4 id="SDNE"><a href="#SDNE" class="headerlink" title="SDNE"></a>SDNE</h4><blockquote>
<p>Structural Deep Network Embedding. 2016</p>
</blockquote>
<p>SDNE使用深度学习模型学习网络嵌入，<strong>使用自编码器的思想尝试对图的邻接矩阵进行嵌入表示，并且加入节点相似的考虑，属于半监督方法</strong>。其损失函数与LINE类似，可以分为一阶相似损失和二阶相似损失，其中</p>
<ul>
<li>一阶损失：<strong>邻居节点之间的表示向量应该接近</strong><ul>
<li>$\mathcal{L}_1=\sum_{i,j} s_{i,j}||u_i-u_j||_2^2$，其中$s_{i,j}$表示两个节点的权值，$u$是节点的embedding</li>
<li>这一部分是<strong>监督模式</strong></li>
</ul>
</li>
<li>二阶损失：<strong>具有相似邻居的节点之间的表示向量应该相似</strong><ul>
<li>$\mathcal{L}_2=\sum_{i} ||(\hat{x}_i-x_i)\odot b_i||_2^2$</li>
<li>这个便是自编码器的<strong>重建误差</strong>，$x_i$是原始的邻接向量，$\hat{x}_i$是重建的邻接向量</li>
<li>这里的$b_i$主要用来<strong>惩罚</strong>$x_i=0$的情况，因为邻接向量一般比较<strong>稀疏</strong>，解码器输出全0向量也是不错的解；另外不邻接也不代表没关系</li>
<li>这一部分是<strong>无监督模式</strong></li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/graph-embedding-3.PNG" alt="image"></p>
<p>整体的损失函数如下：</p>
<script type="math/tex; mode=display">
\mathcal{L}=\alpha\mathcal{L}_1+\mathcal{L}_2+\mathcal{L}_{reg}</script><p>最后一项是正则项，主要对网络中的参数进行惩罚</p>
<h4 id="Struc2vec"><a href="#Struc2vec" class="headerlink" title="Struc2vec"></a>Struc2vec</h4><blockquote>
<p>struc2vec:Learning Node  Representations from Structural  Identity. 2017</p>
</blockquote>
<p>Struc2vec认为embedding不应该任何相邻性，而只考虑空间结构相似性。也就是要从：<strong>相似的节点往往有比较相似的空间结构</strong></p>
<p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/graph-embedding-4.PNG" alt="image"></p>
<p>论文表示空间结构相似的方法是：如果两个节点的所有邻接节点构成的序列相似，那么这两个节点相似.</p>
<p>定义$R_k(u)$为与节点$\mu$距离为$k$的节点集合，$s(K)$表示节点集合$K$的<strong>有序度序列</strong>，函数$g$可以表示两个序列的相似度函数(这里可以使用DTW算法)，令</p>
<script type="math/tex; mode=display">
f_k(u,v)=f_{k-1}(u,v)+g\left(s\left(R_k(u)\right),s(R_k(v))\right)</script><p>表示节点$u,v$之间的结构不相似性。我们按照不同的$k$分层，同层之间的节点权重为</p>
<script type="math/tex; mode=display">
w_k(u,v)=e^{-f_k(u,v)}</script><p>不同层的话，需要先层级转换，有上一层、下一层两种选择，对应权重为</p>
<script type="math/tex; mode=display">
\left\{
\begin{aligned}
w(u_k,u_{k+1})&=\log{\Gamma_k(u)+e}, &  & \Gamma(u)=\sum_v1(w_k(u,v)>\overline{w_k})  \\
w(u_k,u_{k-1})&=1
\end{aligned}
\right.</script><p>其中，$\overline{w_k}$是第$k$层的平均权值，$\Gamma_k(u)$表示第$k$层与$u$相连的边的边权大于平均边权的边的数量。是每一步会以一个概率$p$留在当前层，$1-p$跳出本层，如果留在本层，则下一个节点的概率是</p>
<script type="math/tex; mode=display">
p_k(v|u)=\frac{w_k(u,v)}{Z_k(u)}</script><p>如果跳出本层，则有</p>
<script type="math/tex; mode=display">
\left\{
\begin{aligned}
p(u_{k+1}|u_k)&=\frac{w(u_k,u_{k+1})}{w(u_k,u_{k+1})+w(u_k,u_{k-1})} \\
p(u_{k-1}|u_k)&=1-p(u_{k+1}|u_k)
\end{aligned}
\right.</script><hr>
<p>综上所述，基本流程如下：</p>
<ul>
<li>根据上面的权重公式计算：<ul>
<li>同一层中的节点权重($w_k(u,v)$)</li>
<li>不同层次的同一顶点权重($w(u_k,u_{k\pm1})$)</li>
</ul>
</li>
<li>获取顶点序列<ul>
<li>在当前层游走($p_k(u,v)$)</li>
<li>切换到上下层的层游走($p(u_k,u_{k\pm 1})$)</li>
</ul>
</li>
<li>Skip-Gram来生成representation，然后训练embedding表示</li>
</ul>
<p>Struc2vec有成功的工业应用案例，蚂蚁金服风控模型应用了Struc2vec后，较之前的node2vec有了质的提升</p>
<h4 id="GraphSAGE"><a href="#GraphSAGE" class="headerlink" title="GraphSAGE"></a>GraphSAGE</h4><blockquote>
<p>Inductive representation learning on large graph. 2017</p>
</blockquote>
<p>上面的方法都是<strong>直推式</strong>的学习方法，可以从graph中学习到一个矩阵表示，当<strong>图结构变化时是需要重新学习</strong>的。而GraphSAGE是一种归纳式学习方法，可以用邻居节点直接学习出新增节点的embedding</p>
<p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/graph-embedding-5.PNG" alt="GraphSAGE的算法流程"></p>
<p>对每一层，主要有以下几个步骤</p>
<ol>
<li>采样当前节点的邻居顶点</li>
<li>用聚合函数将上一层邻居的表示聚合起来<ul>
<li>聚合函数应该对输入顺序不敏感，且有较好的表达能力，候选有</li>
<li>mean aggregator</li>
<li>pooling aggregator</li>
<li>LSTM aggregator</li>
</ul>
</li>
<li>将上一层邻居的聚合表示和上一层当前节点的表示拼接起来，做一个线性映射</li>
</ol>
<h6 id="参数学习"><a href="#参数学习" class="headerlink" title="参数学习"></a>参数学习</h6><ul>
<li>有监督：比如节点分类，可以根据任务目标直接设置</li>
<li>无监督：临近的顶点具有相似的向量表示，分离的顶点的表示尽可能区分</li>
</ul>
<h4 id="GraphGAN"><a href="#GraphGAN" class="headerlink" title="GraphGAN"></a>GraphGAN</h4><blockquote>
<p>GraphGAN: Graph Representation Learning with Generative Adversarial Nets. 2018</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/graph-embedding-6.PNG" alt="image"></p>
<p>主要思想：</p>
<h6 id="Discriminator-D-v-v-c-theta-D"><a href="#Discriminator-D-v-v-c-theta-D" class="headerlink" title="Discriminator$D(v,v_c;\theta_D)$"></a>Discriminator$D(v,v_c;\theta_D)$</h6><p>D判断一条边是否为原始图中的边，即给定节点，判断是否存在边$p(e_{i,j}|v_i,v_j)$</p>
<p>给定两个节点的表示，D判定两个节点有边的概率是</p>
<script type="math/tex; mode=display">
p(e_{i,j}|v_i,v_j)=\sigma(d_i^Td_j)</script><p>这里$d_i,d_j$是D中的节点embedding，<strong>所有节点构成的embedding集合就可以看成是D的参数$\theta_D$</strong></p>
<h6 id="Generator-G-v-v-c-theta-G"><a href="#Generator-G-v-v-c-theta-G" class="headerlink" title="Generator$G(v|v_c;\theta_G)$"></a>Generator$G(v|v_c;\theta_G)$</h6><p>G生成图中一条不存在的边，也就是要根据给定节点做一个连接，也就是要学习$p(v|v_c)$.（毕竟我们的主要目的就是学习到采样算法）。容易想到用softmax来表示，</p>
<script type="math/tex; mode=display">
G(v|v_c)=\frac{\exp(g_v^Tg_{v_c})}{\sum_{v'\ne v_c}\exp(g_{v'}^Tg_{v_c})}</script><p>这里$g_v,g_{v_c}$是G中的节点embedding，所有节点构成的embedding集合就可以看成是G的参数$\theta_G$。<strong>G和D中不共用节点表达，所以最后的训练结果不能当作节点embedding</strong>。但是存在两个问题</p>
<ul>
<li>计算量大</li>
<li>没有考虑网络的拓扑结构</li>
</ul>
<h6 id="Graph-Softmax"><a href="#Graph-Softmax" class="headerlink" title="Graph Softmax"></a>Graph Softmax</h6><p>文章提出了Graph Softmax的概念，解决上述两个问题</p>
<ul>
<li>以$v_c$为根，BFS构建树，树中$v_c$到任意节点可达且路径唯一，通过定义父子节点的关联概率（softmax，这里因为是父子节点，所以维度小很多了）和路径概率连乘，我们可以求得$v_c$到任意节点的概率</li>
</ul>
<hr>
<p>模型训练的时候就是训练D和G的参数，然后利用G进行路径采样，按照skip-gram的方式训练embedding，G的采样可以是：</p>
<ul>
<li>根据Graph Softmax的结果直接进行采样</li>
<li>文章还提供了一种方法，不介绍了</li>
</ul>
<p>效果：链接预测任务在效果上并没有提升太多，比DeepWalk好，跟node2vec差不多。但是也就是套上了GAN吧</p>
<hr>
<p><strong>引用</strong></p>
<p>[1]. Graph Neural Network Review. 2018 </p>
<p>[2]. All the paper mentioned above.</p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="atlantic8.github.io/2020/09/01/Graph-Embedding/" data-id="ckiri7oo0003iqsph15zacw0d" class="article-share-link"><i class="fas fa-share"></i>分享到</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fab fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fab fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fab fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fab fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    

        </footer>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2020/09/01/Graph-Convolutional-Networks/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">上一篇</strong>
            <div class="article-nav-title">
                
                    Graph Convolutional Networks
                
            </div>
        </a>
    
    
        <a href="/2020/08/30/NLP-Pre-train-Models-after-Bert/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">下一篇</strong>
            <div class="article-nav-title">NLP Pre-train Models after Bert</div>
        </a>
    
</nav>


    
</article>


    
    

</section>
            
                
<aside id="sidebar">
   
        
    <div class="widget-wrap">
        <h3 class="widget-title">最新文章</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/09/01/Python-Functions/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Dev/">Dev</a></p>
                            <p class="item-title"><a href="/2020/09/01/Python-Functions/" class="title">Python Functions</a></p>
                            <p class="item-date"><time datetime="2020-09-01T15:15:14.000Z" itemprop="datePublished">2020-09-01</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/09/01/Bounds-in-Binary-Search/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/OJ/">OJ</a></p>
                            <p class="item-title"><a href="/2020/09/01/Bounds-in-Binary-Search/" class="title">Bounds in Binary Search</a></p>
                            <p class="item-date"><time datetime="2020-09-01T15:12:12.000Z" itemprop="datePublished">2020-09-01</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/09/01/BM25/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Algorithm/">Algorithm</a></p>
                            <p class="item-title"><a href="/2020/09/01/BM25/" class="title">BM25</a></p>
                            <p class="item-date"><time datetime="2020-09-01T15:06:49.000Z" itemprop="datePublished">2020-09-01</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/09/01/Similarity-and-Relativity-Metrics/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Math/">Math</a></p>
                            <p class="item-title"><a href="/2020/09/01/Similarity-and-Relativity-Metrics/" class="title">Similarity and Relativity Metrics</a></p>
                            <p class="item-date"><time datetime="2020-09-01T15:04:31.000Z" itemprop="datePublished">2020-09-01</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/09/01/Entropy-and-Related-Metrics/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Math/">Math</a></p>
                            <p class="item-title"><a href="/2020/09/01/Entropy-and-Related-Metrics/" class="title">Entropy and Related Metrics</a></p>
                            <p class="item-date"><time datetime="2020-09-01T15:01:41.000Z" itemprop="datePublished">2020-09-01</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a><span class="category-list-count">50</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Dev/">Dev</a><span class="category-list-count">21</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/">Math</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/OJ/">OJ</a><span class="category-list-count">56</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">九月 2020</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">八月 2020</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">九月 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">七月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">一月 2017</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">十二月 2016</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">十一月 2016</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">十月 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">九月 2016</a><span class="archive-list-count">35</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">八月 2016</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">七月 2016</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">六月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">五月 2016</a><span class="archive-list-count">8</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/Backtracking/" style="font-size: 11.11px;">Backtracking</a> <a href="/tags/Binary-Search/" style="font-size: 12.22px;">Binary Search</a> <a href="/tags/Binary-Tree/" style="font-size: 16.67px;">Binary Tree</a> <a href="/tags/Cpp/" style="font-size: 15.56px;">Cpp</a> <a href="/tags/DFS/" style="font-size: 10px;">DFS</a> <a href="/tags/DP/" style="font-size: 16.67px;">DP</a> <a href="/tags/Deep-Learning/" style="font-size: 10px;">Deep Learning</a> <a href="/tags/Divide-Conquer/" style="font-size: 10px;">Divide & Conquer</a> <a href="/tags/Game-Theory/" style="font-size: 10px;">Game Theory</a> <a href="/tags/Geometry/" style="font-size: 10px;">Geometry</a> <a href="/tags/Graph/" style="font-size: 11.11px;">Graph</a> <a href="/tags/Greedy/" style="font-size: 13.33px;">Greedy</a> <a href="/tags/IPython/" style="font-size: 10px;">IPython</a> <a href="/tags/Java/" style="font-size: 13.33px;">Java</a> <a href="/tags/LeetCode/" style="font-size: 20px;">LeetCode</a> <a href="/tags/Leetcode/" style="font-size: 11.11px;">Leetcode</a> <a href="/tags/MIR/" style="font-size: 10px;">MIR</a> <a href="/tags/Machine-Learning/" style="font-size: 10px;">Machine Learning</a> <a href="/tags/Math/" style="font-size: 12.22px;">Math</a> <a href="/tags/Matlab/" style="font-size: 10px;">Matlab</a> <a href="/tags/NLP/" style="font-size: 14.44px;">NLP</a> <a href="/tags/Optimization/" style="font-size: 10px;">Optimization</a> <a href="/tags/POJ/" style="font-size: 11.11px;">POJ</a> <a href="/tags/Permutation/" style="font-size: 10px;">Permutation</a> <a href="/tags/STL/" style="font-size: 10px;">STL</a> <a href="/tags/Sliding-window/" style="font-size: 14.44px;">Sliding window</a> <a href="/tags/Sort/" style="font-size: 11.11px;">Sort</a> <a href="/tags/State-Machine/" style="font-size: 10px;">State Machine</a> <a href="/tags/String/" style="font-size: 14.44px;">String</a> <a href="/tags/Tree/" style="font-size: 10px;">Tree</a> <a href="/tags/bit/" style="font-size: 10px;">bit</a> <a href="/tags/deep-learning/" style="font-size: 15.56px;">deep learning</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/machine-learning/" style="font-size: 18.89px;">machine learning</a> <a href="/tags/music-information-retrieval/" style="font-size: 10px;">music information retrieval</a> <a href="/tags/numpy/" style="font-size: 11.11px;">numpy</a> <a href="/tags/other/" style="font-size: 10px;">other</a> <a href="/tags/pandas/" style="font-size: 11.11px;">pandas</a> <a href="/tags/prime/" style="font-size: 10px;">prime</a> <a href="/tags/python/" style="font-size: 17.78px;">python</a> <a href="/tags/random-algorithm/" style="font-size: 12.22px;">random algorithm</a> <a href="/tags/recommender-system/" style="font-size: 10px;">recommender system</a> <a href="/tags/search/" style="font-size: 10px;">search</a> <a href="/tags/time-series-data/" style="font-size: 10px;">time_series_data</a> <a href="/tags/visualization/" style="font-size: 10px;">visualization</a> <a href="/tags/web/" style="font-size: 10px;">web</a> <a href="/tags/数据分析/" style="font-size: 10px;">数据分析</a> <a href="/tags/文件/" style="font-size: 10px;">文件</a>
        </div>
    </div>

    
        
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">链接</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="https://xueshu.glgoo.org/">Google Scholar Mirror</a>
                    </li>
                
                    <li>
                        <a href="https://www.kaggle.com/">Kaggle</a>
                    </li>
                
                    <li>
                        <a href="http://mlr.cs.umass.edu/ml/datasets.html">UCI dataset</a>
                    </li>
                
                    <li>
                        <a href="https://leetcode.com/problemset/algorithms/">LeetCode</a>
                    </li>
                
            </ul>
        </div>
    </div>


    
    <div id="toTop" class="fas fa-angle-up"></div>
</aside>

            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2020 曹文强<br>
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
        </div>
    </div>
</footer>
        


    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>