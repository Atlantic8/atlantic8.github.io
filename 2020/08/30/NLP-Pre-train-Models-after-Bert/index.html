<!DOCTYPE html>
<html lang="zh">
<head><meta name="generator" content="Hexo 3.9.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    
    <title>NLP Pre-train Models after Bert | atlantic8</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="BERT开启了NLP领域预训练模型的时代，BERT之后大量的改型出现，以下会介绍一些。 ALBERTALBERT的设计目标是解决BERT参数量大的问题 其主要做了如下的修改  embedding分解 intuition是：transformer的输入词的embedding维度和隐层输出维度一样大，但是隐层除了词本身信息还包含了上下文信息，所以词的embedding维度可以小一点 降低维度的方法是对">
<meta name="keywords" content="deep learning">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP Pre-train Models after Bert">
<meta property="og:url" content="atlantic8.github.io/2020/08/30/NLP-Pre-train-Models-after-Bert/index.html">
<meta property="og:site_name" content="atlantic8">
<meta property="og:description" content="BERT开启了NLP领域预训练模型的时代，BERT之后大量的改型出现，以下会介绍一些。 ALBERTALBERT的设计目标是解决BERT参数量大的问题 其主要做了如下的修改  embedding分解 intuition是：transformer的输入词的embedding维度和隐层输出维度一样大，但是隐层除了词本身信息还包含了上下文信息，所以词的embedding维度可以小一点 降低维度的方法是对">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://raw.githubusercontent.com/Atlantic8/picture/master/xlnet-1.PNG">
<meta property="og:image" content="https://raw.githubusercontent.com/Atlantic8/picture/master/electra-1.PNG">
<meta property="og:updated_time" content="2020-08-30T05:19:25.971Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="NLP Pre-train Models after Bert">
<meta name="twitter:description" content="BERT开启了NLP领域预训练模型的时代，BERT之后大量的改型出现，以下会介绍一些。 ALBERTALBERT的设计目标是解决BERT参数量大的问题 其主要做了如下的修改  embedding分解 intuition是：transformer的输入词的embedding维度和隐层输出维度一样大，但是隐层除了词本身信息还包含了上下文信息，所以词的embedding维度可以小一点 降低维度的方法是对">
<meta name="twitter:image" content="https://raw.githubusercontent.com/Atlantic8/picture/master/xlnet-1.PNG">
    

    

    
        <link rel="icon" href="/css/images/logo.png">
    

    <link rel="stylesheet" href="/libs/font-awesome5/css/fontawesome.min.css">
    <link rel="stylesheet" href="/libs/font-awesome5/css/fa-brands.min.css">
    <link rel="stylesheet" href="/libs/font-awesome5/css/fa-solid.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    
        <script>
var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?ff86ad40748d96af89d192e9b0a3ae62";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    


</head>
</html>
<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">atlantic8</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/.">Home</a>
                
                    <a class="main-nav-link" href="/archives">Archives</a>
                
                    <a class="main-nav-link" href="/categories/OJ">OJ</a>
                
                    <a class="main-nav-link" href="/categories/Algorithm">Algorithm</a>
                
                    <a class="main-nav-link" href="/categories/Math">Math</a>
                
                    <a class="main-nav-link" href="/categories/Dev">Dev</a>
                
                    <a class="main-nav-link" href="/about">About</a>
                
            </nav>
            
                
                <nav id="sub-nav">
                    <div class="profile" id="profile-nav">
                        <a id="profile-anchor" href="javascript:;">
                            <img class="avatar" src="/css/images/me.png" />
                            <i class="fas fa-caret-down"></i>
                        </a>
                    </div>
                </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fas fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/.">Home</a></td>
                
                    <td><a class="main-nav-link" href="/archives">Archives</a></td>
                
                    <td><a class="main-nav-link" href="/categories/OJ">OJ</a></td>
                
                    <td><a class="main-nav-link" href="/categories/Algorithm">Algorithm</a></td>
                
                    <td><a class="main-nav-link" href="/categories/Math">Math</a></td>
                
                    <td><a class="main-nav-link" href="/categories/Dev">Dev</a></td>
                
                    <td><a class="main-nav-link" href="/about">About</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
                

<aside id="profile" class="profile-fixed">
    <div class="inner profile-inner">
        <div class="base-info profile-block">
            <img id="avatar" src="/css/images/me.png" />
            <h2 id="name">Atlantic8</h2>
            <h3 id="title">algorithm engineer</h3>
            <span id="location"><i class="fas fa-map-marker-alt" style="padding-right: 5px"></i>Beijing, China</span>
            <a id="follow" target="_blank" href="https://github.com/Atlantic8">关注我</a>
        </div>
        <div class="article-info profile-block">
            <div class="article-info-block">
                124
                <span>文章</span>
            </div>
            <div class="article-info-block">
                46
                <span>标签</span>
            </div>
        </div>
        
        <div class="profile-block social-links">
            <table>
                <tr>
                    
                    
                    <td>
                        <a href="https://github.com/Atlantic8" target="_blank" title="github" class=tooltip>
                            
                                <i class="fab fa-github"></i>
                            
                        </a>
                    </td>
                    
                    <td>
                        <a href="https://www.linkedin.com/in/wenqiang-cao-704236b8/" target="_blank" title="linkedin" class=tooltip>
                            
                                <i class="fab fa-linkedin"></i>
                            
                        </a>
                    </td>
                    
                    <td>
                        <a href="mailto:atlantic8@outlook.com" target="_blank" title="envelope" class=tooltip>
                            
                                <i class="fas fa-envelope"></i>
                            
                        </a>
                    </td>
                    
                    <td>
                        <a href="http://weibo.com/2614093607" target="_blank" title="weibo" class=tooltip>
                            
                                <i class="fab fa-weibo"></i>
                            
                        </a>
                    </td>
                    
                    <td>
                        <a href="/" target="_blank" title="facebook" class=tooltip>
                            
                                <i class="fab fa-facebook"></i>
                            
                        </a>
                    </td>
                    
                </tr>
            </table>
        </div>
        
    </div>
</aside>

            
            <section id="main"><article id="post-NLP-Pre-train-Models-after-Bert" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
            NLP Pre-train Models after Bert
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fas fa-calendar-alt"></i>
        <a href="/2020/08/30/NLP-Pre-train-Models-after-Bert/">
            <time datetime="2020-08-30T05:16:49.000Z" itemprop="datePublished">2020-08-30</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fas fa-folder"></i>
        <a class="article-category-link" href="/categories/Algorithm/">Algorithm</a>
    </div>

                        
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/deep-learning/">deep learning</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <p>BERT开启了NLP领域预训练模型的时代，BERT之后大量的改型出现，以下会介绍一些。</p>
<h3 id="ALBERT"><a href="#ALBERT" class="headerlink" title="ALBERT"></a>ALBERT</h3><p>ALBERT的设计目标是解决BERT参数量大的问题</p>
<p>其主要做了如下的修改</p>
<ul>
<li>embedding分解<ul>
<li>intuition是：transformer的输入词的embedding维度和隐层输出维度一样大，但是<strong>隐层除了词本身信息还包含了上下文信息</strong>，所以词的embedding维度可以小一点</li>
<li>降低维度的方法是<strong>对输入的onehot矩阵进行分解，映射到低维度空间E，然后再映射到H维</strong>，输入到Transformer中。将参数量由O(VH)降到O(VE+EH)，当E远小于H时，参数量会下降很多。（假设V为词的总数）</li>
</ul>
</li>
<li>参数贡献<ul>
<li>共享encoder内的所有参数，包含多头注意力和前向网络</li>
</ul>
</li>
<li>Sentence-Order Prediction<ul>
<li>BERT的next sentence prediction是个二分类任务，负样本是通过采用两个不同的文档的句子，后续的研究发现该任务效果并不好。NSP其实<strong>包含主题预测与句子关系一致性预测两个子任务</strong>，但是主题预测相比于关系一致性预测简单太多了，模型学习NSP任务的时候可能<strong>只学到了主题预测</strong>，而没学到句子关系一致性</li>
<li>SOP则在样本选取上去除了主题不同的因素，将<strong>正样本反过来当作负样本</strong></li>
</ul>
</li>
</ul>
<p>ALBERT论文表示在训练了100w步之后，模型依旧没有过拟合，于是乎作者移除了dropout，没想到对下游任务的效果竟然有一定的提升。这也是业界<strong>第一次发现dropout对大规模的预训练模型会造成负面影响</strong></p>
<h3 id="ERNIE"><a href="#ERNIE" class="headerlink" title="ERNIE"></a>ERNIE</h3><p>ERNIE是大百度的中文预训练模型，有两个版本</p>
<h5 id="1-0"><a href="#1-0" class="headerlink" title="1.0"></a>1.0</h5><p>ERNIE1.0在BERT的基础上做了如下事情</p>
<ul>
<li>在mask语言模型上，不再局限于mask单个token，而是考虑mask短语和实体</li>
<li><strong>直接对先验语义知识单元进行建模，增强了模型语义表示能力</strong></li>
<li>海量中文数据，Dialogue Language Model</li>
</ul>
<h5 id="2-0"><a href="#2-0" class="headerlink" title="2.0"></a>2.0</h5><p>ERNIE2.0的要点如下：</p>
<ul>
<li>多任务学习的引入，<strong>输入层加入了task embedding</strong></li>
<li>构建了词法级别，语法级别，语义级别的预训练任务<ul>
<li>词法<ul>
<li><strong>mask短语和实体</strong>，同1.0</li>
<li><strong>大写字母预测</strong>：大写的词一般会有特殊含义</li>
<li><strong>Token-Document关系预测</strong>：预测一个词在文中的A 段落出现，是否会在文中的B 段落出现</li>
</ul>
</li>
<li>语法<ul>
<li><strong>句子顺序预测</strong>：文本分段，所有shuffle的组合后模型预测正确顺序</li>
<li><strong>句子距离预测</strong>：三分类任务（0表示两个句子是同一个文章中相邻的句子，1表示两个句子是在同一个文章，但是不相邻，2表示两个句子是不同的文章）</li>
</ul>
</li>
<li>语义<ul>
<li>判断句子对之间的<strong>语义关系</strong>，比如修辞</li>
<li>搜索下<strong>query和title的相关性</strong></li>
</ul>
</li>
</ul>
</li>
<li>大量的百度生态语料<ul>
<li>搜索日志</li>
<li>贴吧对话</li>
<li>百科数据</li>
<li>新闻内容</li>
</ul>
</li>
</ul>
<h3 id="XLNET"><a href="#XLNET" class="headerlink" title="XLNET"></a>XLNET</h3><blockquote>
<p>XLNet: Generalized Autoregressive Pretraining<br>for Language Understanding</p>
</blockquote>
<p>Elmo、GPT这种单向语言模型属于<strong>自回归语言模型(<br>autoregressive)</strong>，模型在当前位置只能看到之前看到过的数据。Bert这类双向语言模型，属于自编码语言模型（autoencoder），可以<strong>对上下文进行完整建模</strong>，在BERT与GPT的对比数据中也可以看出来其优点。但是这种模型也存在问题：</p>
<ul>
<li>bert训练时用到了mask语言模型，引入了[MASK]标识，但是fine-tuning阶段没有，导致<strong>预训练阶段和fine-tuning阶段存在不一致的问题</strong></li>
<li>模型在预测一个被mask掉的单词，<strong>无法利用其他被mask掉的单词信息</strong></li>
</ul>
<p>xlnet就是想鱼和熊掌兼得，那么怎么能够在单词Ti的上文中Contenxt_before中揉入下文Context_after的内容呢?</p>
<h5 id="Permutation-Language-Model"><a href="#Permutation-Language-Model" class="headerlink" title="Permutation Language Model"></a>Permutation Language Model</h5><p>最naive的思想就是：在预测$x_k$时，固定$x_k$，将$x_{!= k}$打乱，这样当前单词就能看见原来在其之后的单词了。在随机排列组合后的各种可能里，再选择一部分作为模型预训练的输入。</p>
<p>但是这样会有问题，假设出现一个长度为n的序列，原序列为$x$，两个排列$z^{(1)},z^{(2)}$，第t个位置不一样(对应于之前的$x_i,x_j$)，之前的位置都一样，所以由自回归语言模型定义可知</p>
<script type="math/tex; mode=display">
p_{\theta}(z^{(1)}_t(x)=x_i)=p_{\theta}(z^{(2)}_t(x)=x_j)</script><p>即，<strong>对$x_i,x_j$的预测满足同一分布</strong>，这显然是不合理的</p>
<p>并且，<strong>fine-tuning时不可能也去排列组合原始输入</strong></p>
<h4 id="双流自注意力机制"><a href="#双流自注意力机制" class="headerlink" title="双流自注意力机制"></a>双流自注意力机制</h4><p>双流注意力机制就是为了解决上述问题的，分为<strong>query流</strong>和<strong>内容流</strong>，其实就是在两个层面表示当前输入（内容层面和位置层面），其中</p>
<ul>
<li>内容流self-attention<ul>
<li>内容编码信息$h_t$，计算方式和标准的self-attention一致</li>
<li>能看到自己</li>
<li>内容流输入是token的Embedding向量</li>
</ul>
</li>
<li>query流self-attention<ul>
<li>位置编码信息$g_t$，后一层的query向量不包含当前位置的查询向量</li>
<li>不能看到自己</li>
<li>在模型输入端对每个token都是统一的，是可学习的参数</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/xlnet-1.PNG" alt="xlnet-1"></p>
<p>上图中，预测下一层的内容向量时，用到当前层能看到的所有内容向量（<strong>包括自己</strong>）[a]；预测下一层的query向量时，用到当前层能看到的所有内容向量（<strong>不包括自己</strong>）[b]。</p>
<p>整体上来看，以序列$x=[x_1,x_2,x_3,x_4]$为例，通过<strong>attention mask矩阵</strong>来完成mask操作，决定排列顺序后即可得到mask矩阵。假如排列之后得到$[x_3,x_2,x_4,x_1]$，mask矩阵也有两个分为内容流（能看见自己）、query流（不能看见自己）两个，上图中，红色表示可见，白色表示不可见，第$k$行表示第$k$个位置能看到哪些位置的信息</p>
<h5 id="Transformer-XL"><a href="#Transformer-XL" class="headerlink" title="Transformer XL"></a>Transformer XL</h5><p>借助transformer xl，<strong>增强对长文本的友好程度</strong>，其主要思想就是分段然后引入recurrent连接结构</p>
<h5 id="pretrain-amp-finetune"><a href="#pretrain-amp-finetune" class="headerlink" title="pretrain &amp; finetune"></a>pretrain &amp; finetune</h5><ul>
<li>pretrain阶段<ul>
<li>在输出端<strong>对query流向量</strong>预测相应的token</li>
<li>只预测有足够长的依赖上下文的token，降低训练难度</li>
<li><strong>放弃了Next Sentence Prediction任务</strong></li>
<li>与BERT相比，加大增加了预训练阶段使用的数据规模</li>
</ul>
</li>
<li>finetune阶段<ul>
<li><strong>只需要内容流向量</strong>，不再需要query流向量</li>
<li>使用的时候，<strong>只需要内容流向量</strong></li>
</ul>
</li>
</ul>
<h3 id="RoBerta"><a href="#RoBerta" class="headerlink" title="RoBerta"></a>RoBerta</h3><blockquote>
<p>RoBERTa: A Robustly Optimized BERT Pretraining Approach</p>
</blockquote>
<p>较于BERT，其升级点如下</p>
<ul>
<li>训练模型时间更长，Batch Size更大，数据更多</li>
<li>放弃Next Sentence Prediction训练任务</li>
<li>对较长序列的训练</li>
<li>动态mask应用于训练数据的mask模式<ul>
<li>BERT静态mask：随机mask和替换在开始时只执行一次，后续保存</li>
<li>作者将训练数据重复10次，以便在40个epoch中以10种不同的方式对每个序列进行mask，<strong>避免在每个epoch中对每个训练实例使用相同的mask</strong></li>
</ul>
</li>
<li>新建数据集（CC-NEWS）</li>
<li>使用Sennrich[2]等人提出的Byte-Pair Encoding (BPE)字符编码<ul>
<li>避免出现较多的未登录词</li>
</ul>
</li>
</ul>
<h3 id="T5"><a href="#T5" class="headerlink" title="T5"></a>T5</h3><h3 id="ELECTRA"><a href="#ELECTRA" class="headerlink" title="ELECTRA"></a>ELECTRA</h3><blockquote>
<p>Efficiently Learning an Encoder that Classifies Token Replacements Accurately</p>
</blockquote>
<p>ELECTRA的特色如下</p>
<ul>
<li>放弃BERT随机选取token预测的方法，而是通过MLM过滤非常容易学到的token，加大学习难度</li>
<li>预测目标不是预测目标究竟是哪个token，而是预测这个句子中哪些词被替换过，也就是说<strong>模型需要看输入的每一个token，而不仅仅是被mask选取的那些，加速了学习过程</strong></li>
<li>解决BERT中MASK标志在train和finetune阶段的不一致问题</li>
</ul>
<h5 id="GAN视角"><a href="#GAN视角" class="headerlink" title="GAN视角"></a>GAN视角</h5><p><img src="https://raw.githubusercontent.com/Atlantic8/picture/master/electra-1.PNG" alt="GAN视角"></p>
<p>模型整体可以看成有两部分，一部分是Generator，一部分是Discriminator。模型依然需要随机地mask一部分token，但是用途不一样</p>
<p>流程</p>
<ul>
<li>对于输入文本序列，随机mask一部分token（15%）</li>
<li>带MASK标志的输入序列，G会<strong>预测每个被MASK掉的token具体是什么</strong>，这里其实就是MLM做的事情</li>
<li>D<strong>判别这个序列中哪些token是G生成的</strong><ul>
<li>二分类，</li>
</ul>
</li>
</ul>
<p>需要注意的是，G的训练方式与传统的GAN不一样，<strong>G的训练目标不是去糊弄Discriminator，而是通过极大似然估计训练</strong>。因为<strong>D的梯度不能直接流到G</strong>，原因是G输出的token在表示上是离散的</p>
<script type="math/tex; mode=display">
\mathcal{L}_{MLM}(x,\theta_G)=\mathbb{E}\left(\sum_{i}-\log p_G(x_i|x^{masked})\right)</script><p>其中，$i$是被选中mask的token序号。作者也尝试了用强化学习的训练思路做，但是效果没有直接使用MLE效果好</p>
<p>而Discriminator因为是要对每个token判断是否是原始token，所以可以看成一个二分类问题（序列上看也可以看成序列标注，只是tag之间没有直接关系），其损失函数为交叉熵形式</p>
<script type="math/tex; mode=display">
\mathcal{L}_{D}(x,\theta_G)=\mathbb{E}\left(-\sum_{t=1}^n\mathbf{I}(x_t^{G}=x_t)\log D(x^G,t) + \mathbf{I}(x_t^{G}\ne x_t)\log (1-D(x^G,t)) )\right)</script><p>这里可以看成是使用MLM的<strong>负采样</strong>方法，颇有word2vec的CBOW意味。类似地，把多分类换成二分类也可以有效降低参数数量。此外，D的目标也刚好消除了BERT中MASK标识导致的mismatch问题</p>
<p>所以，整体的目标就是</p>
<script type="math/tex; mode=display">
\min_{\theta_G,\theta_D}\sum_{x\in X}\mathcal{L}_{MLM}+\lambda\mathcal{L}_{D}(x,\theta_G)</script><p>其中，$X$是整体的数据集，$\lambda$是平衡系数，作者设为50，原因是D的任务较G简单，损失也小。</p>
<h5 id="其他点"><a href="#其他点" class="headerlink" title="其他点"></a>其他点</h5><ul>
<li>G和D共享token的embedding<ul>
<li>G会对embedding进行调整，但是D不会，所以需要参数共享</li>
</ul>
</li>
<li>建议G要小一点<ul>
<li>G太猛了，D学起来会比较费劲。D可能会将注意力更多放在对G的建模上而不是实际的数据分布</li>
<li>建议G的规模为D的1/4-1/2</li>
</ul>
</li>
</ul>
<hr>
<p>[1]. <a href="https://blog.csdn.net/u012526436/article/details/101924049" target="_blank" rel="noopener">一文揭开ALBERT的神秘面纱</a></p>
<p>[2]. <a href="https://blog.csdn.net/PaddlePaddle/article/details/102713947" target="_blank" rel="noopener">一文读懂最强中文NLP预训练模型ERNIE</a></p>
<p>[3]. <a href="https://zhuanlan.zhihu.com/p/70257427" target="_blank" rel="noopener">XLNet:运行机制及和Bert的异同比较</a></p>
<p>[4]. <a href="https://zhuanlan.zhihu.com/p/86845458" target="_blank" rel="noopener">自然语言处理之XLNet</a></p>
<p>[5]. <a href="https://arxiv.org/pdf/1906.08237.pdf" target="_blank" rel="noopener">XLNet: Generalized Autoregressive Pretraining<br>for Language Understanding</a></p>
<p>[6]. <a href="https://arxiv.org/pdf/1907.11692.pdf" target="_blank" rel="noopener">RoBERTa: A Robustly Optimized BERT Pretraining Approach</a></p>
<p>[7]. <a href="https://www.zhihu.com/question/337776337" target="_blank" rel="noopener">如何评价RoBERTa?</a></p>
<p>[8]. <a href="https://arxiv.org/pdf/1910.10683.pdf" target="_blank" rel="noopener">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a></p>
<p>[10]. <a href="https://openreview.net/pdf?id=r1xMH1BtvB" target="_blank" rel="noopener">ELECTRA: PRE-TRAINING TEXT ENCODERS AS DISCRIMINATORS RATHER THAN GENERATORS</a></p>
<p>[11]. <a href="https://www.zhihu.com/question/354070608/answer/885907890" target="_blank" rel="noopener">如何评价NLP算法ELECTRA的表现？</a></p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="atlantic8.github.io/2020/08/30/NLP-Pre-train-Models-after-Bert/" data-id="ckeiowf9l006k4gphzisb5xj2" class="article-share-link"><i class="fas fa-share"></i>分享到</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fab fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fab fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fab fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fab fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    

        </footer>
    </div>
    
        
<nav id="article-nav">
    
    
        <a href="/2020/08/30/XGboost/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">下一篇</strong>
            <div class="article-nav-title">XGboost</div>
        </a>
    
</nav>


    
</article>


    
    

</section>
            
                
<aside id="sidebar">
   
        
    <div class="widget-wrap">
        <h3 class="widget-title">最新文章</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/08/30/NLP-Pre-train-Models-after-Bert/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Algorithm/">Algorithm</a></p>
                            <p class="item-title"><a href="/2020/08/30/NLP-Pre-train-Models-after-Bert/" class="title">NLP Pre-train Models after Bert</a></p>
                            <p class="item-date"><time datetime="2020-08-30T05:16:49.000Z" itemprop="datePublished">2020-08-30</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/08/30/XGboost/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Algorithm/">Algorithm</a></p>
                            <p class="item-title"><a href="/2020/08/30/XGboost/" class="title">XGboost</a></p>
                            <p class="item-date"><time datetime="2020-08-30T05:00:24.000Z" itemprop="datePublished">2020-08-30</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/08/30/Bert/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Algorithm/">Algorithm</a></p>
                            <p class="item-title"><a href="/2020/08/30/Bert/" class="title">Bert</a></p>
                            <p class="item-date"><time datetime="2020-08-30T04:58:01.000Z" itemprop="datePublished">2020-08-30</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/08/30/Transformer/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Algorithm/">Algorithm</a></p>
                            <p class="item-title"><a href="/2020/08/30/Transformer/" class="title">Transformer</a></p>
                            <p class="item-date"><time datetime="2020-08-30T04:53:14.000Z" itemprop="datePublished">2020-08-30</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/08/30/First-Order-Optimization/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Math/">Math</a></p>
                            <p class="item-title"><a href="/2020/08/30/First-Order-Optimization/" class="title">First Order Optimization</a></p>
                            <p class="item-date"><time datetime="2020-08-30T04:46:31.000Z" itemprop="datePublished">2020-08-30</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a><span class="category-list-count">46</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Dev/">Dev</a><span class="category-list-count">20</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/">Math</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/OJ/">OJ</a><span class="category-list-count">55</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">八月 2020</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">九月 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">七月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">一月 2017</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">十二月 2016</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">十一月 2016</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">十月 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">九月 2016</a><span class="archive-list-count">35</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">八月 2016</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">七月 2016</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">六月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">五月 2016</a><span class="archive-list-count">8</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/Backtracking/" style="font-size: 11.11px;">Backtracking</a> <a href="/tags/Binary-Search/" style="font-size: 11.11px;">Binary Search</a> <a href="/tags/Binary-Tree/" style="font-size: 16.67px;">Binary Tree</a> <a href="/tags/Cpp/" style="font-size: 15.56px;">Cpp</a> <a href="/tags/DFS/" style="font-size: 10px;">DFS</a> <a href="/tags/DP/" style="font-size: 16.67px;">DP</a> <a href="/tags/Deep-Learning/" style="font-size: 10px;">Deep Learning</a> <a href="/tags/Divide-Conquer/" style="font-size: 10px;">Divide & Conquer</a> <a href="/tags/Game-Theory/" style="font-size: 10px;">Game Theory</a> <a href="/tags/Geometry/" style="font-size: 10px;">Geometry</a> <a href="/tags/Greedy/" style="font-size: 13.33px;">Greedy</a> <a href="/tags/IPython/" style="font-size: 10px;">IPython</a> <a href="/tags/Java/" style="font-size: 13.33px;">Java</a> <a href="/tags/LeetCode/" style="font-size: 20px;">LeetCode</a> <a href="/tags/Leetcode/" style="font-size: 11.11px;">Leetcode</a> <a href="/tags/MIR/" style="font-size: 10px;">MIR</a> <a href="/tags/Machine-Learning/" style="font-size: 10px;">Machine Learning</a> <a href="/tags/Math/" style="font-size: 12.22px;">Math</a> <a href="/tags/Matlab/" style="font-size: 10px;">Matlab</a> <a href="/tags/NLP/" style="font-size: 13.33px;">NLP</a> <a href="/tags/Optimization/" style="font-size: 10px;">Optimization</a> <a href="/tags/POJ/" style="font-size: 11.11px;">POJ</a> <a href="/tags/Permutation/" style="font-size: 10px;">Permutation</a> <a href="/tags/STL/" style="font-size: 10px;">STL</a> <a href="/tags/Sliding-window/" style="font-size: 14.44px;">Sliding window</a> <a href="/tags/Sort/" style="font-size: 11.11px;">Sort</a> <a href="/tags/State-Machine/" style="font-size: 10px;">State Machine</a> <a href="/tags/String/" style="font-size: 14.44px;">String</a> <a href="/tags/Tree/" style="font-size: 10px;">Tree</a> <a href="/tags/bit/" style="font-size: 10px;">bit</a> <a href="/tags/deep-learning/" style="font-size: 13.33px;">deep learning</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/machine-learning/" style="font-size: 18.89px;">machine learning</a> <a href="/tags/music-information-retrieval/" style="font-size: 10px;">music information retrieval</a> <a href="/tags/numpy/" style="font-size: 11.11px;">numpy</a> <a href="/tags/other/" style="font-size: 10px;">other</a> <a href="/tags/pandas/" style="font-size: 11.11px;">pandas</a> <a href="/tags/prime/" style="font-size: 10px;">prime</a> <a href="/tags/python/" style="font-size: 17.78px;">python</a> <a href="/tags/random-algorithm/" style="font-size: 12.22px;">random algorithm</a> <a href="/tags/recommender-system/" style="font-size: 10px;">recommender system</a> <a href="/tags/time-series-data/" style="font-size: 10px;">time_series_data</a> <a href="/tags/visualization/" style="font-size: 10px;">visualization</a> <a href="/tags/web/" style="font-size: 10px;">web</a> <a href="/tags/数据分析/" style="font-size: 10px;">数据分析</a> <a href="/tags/文件/" style="font-size: 10px;">文件</a>
        </div>
    </div>

    
        
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">链接</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="https://xueshu.glgoo.org/">Google Scholar Mirror</a>
                    </li>
                
                    <li>
                        <a href="https://www.kaggle.com/">Kaggle</a>
                    </li>
                
                    <li>
                        <a href="http://mlr.cs.umass.edu/ml/datasets.html">UCI dataset</a>
                    </li>
                
                    <li>
                        <a href="https://leetcode.com/problemset/algorithms/">LeetCode</a>
                    </li>
                
            </ul>
        </div>
    </div>


    
    <div id="toTop" class="fas fa-angle-up"></div>
</aside>

            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2020 Atlantic8<br>
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
        </div>
    </div>
</footer>
        


    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>