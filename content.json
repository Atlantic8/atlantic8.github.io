{"meta":{"title":"atlantic8","subtitle":"A note is preferable to the best memory","description":"A note is preferable to the best memory","author":"Atlantic8","url":"atlantic8.github.io"},"pages":[{"title":"About Me","date":"2019-08-24T02:35:31.970Z","updated":"2019-08-24T02:35:31.970Z","comments":true,"path":"about/index.html","permalink":"atlantic8.github.io/about/index.html","excerpt":"","text":"Interested FieldNatural Language Processing, Machine Learning, Data Mining, Computing Theory, Privacy Preserving, Information Security Working Experience [Apr 2018 - Now], Full Time, Baidu,Inc, Machine Learning &amp; NLP Engineer, MEG [Jul 2017 - Oct 2017], Intern, Baidu,Inc, Machine Learning &amp; NLP Engineer, MMS Publiction Zijian Zhang[supervisor], Wenqiang Cao, Zhan Qin, Liehuang Zhu, Zhengtao Yu, Kui Ren. “When privacy meets economics : Enabling differentially-private battery-supported meter reporting in smart grid” IEEE/ACM 25th International Symposium on Quality of Service(IWQoS), Acceptance Rate 19.9% Wenqiang Cao, Zijian Zhang, Feng Wang, “ 基于云计算的安全指纹识别系统和方法 ” Patent (Publication Number : 105553980A) Skills C/C++, Python, Java, PHP Data Structure, Algorithm, Computing Theory Statistics, Machine Learning, Neural Networks, NLP Git, Linux, Latex, etc English CET6, Decent Reading, Writing, Speaking Ability Award &amp; Honor [Mar 2019], Excellent Project Team (member) [Jan 2018], Excellent Postgraduate Model of School [Dec 2017], Excellent Graduate of Beijing [Oct 2017], National Scholarship for Postgraduate [Jun 2017], Best Paper Award of IEEE/ACM International Symposium on Quality of Service [Nov 2016], First-Class Scholarship for Postgraduate [Nov 2014], National Encouragement Scholarship for Undergraduate Education[Sep 2015 - Mar 2018], Master Degree, Beijing Institute of Technology Computer Science and Technology, Advanced Institute of Network and Data Security Beijing, China [Sep 2011 - Jun 2015], Bachelor Degree, Beijing Institute of Technology Computer Science and Technology Beijing, China Hobby Jogging, Table Tennis, Basketball, Badminton, Jogging, Bike-Riding Military Technology, Ancient Creatures, FPS Games, Space Exploration Music, Movie [Latest Update on Aug 23th 2019]"}],"posts":[{"title":"Hough Transform","slug":"Hough-Transform","date":"2018-12-16T13:32:21.000Z","updated":"2019-08-23T16:03:11.081Z","comments":true,"path":"2018/12/16/Hough-Transform/","link":"","permalink":"atlantic8.github.io/2018/12/16/Hough-Transform/","excerpt":"","text":"概念Hough转换是由Hough于1959年首次提出的，是图像分析、计算视觉中的一种特征提取算法，这个算法的目的是通过投票程序找到具有特定形状物体的不完美实例，其中投票程序在参数空间完成。在参数空间中，目标候选是选取名为累积空间的局部最大。 在数字图像处理领域，存在寻找直线、圆、椭圆的子问题。许多情况下，边界检测是此问题的预处理步骤，然而，由于数据本身、边界检测算法存在的不足，可能会导致边界数据缺失、空间错位等问题。所以，需要将提取的边界特征组合成一些规则的图形（线、圆、椭圆）。Hough转换的目标就是将边界特征组合成物体候选。 内容Hough转换最简单的应用是检测直线，一条直线可以由斜率$k$和截距$b$确定，这里$$就构成了参数空间的一个点。给定一个点，可以找到经过这个点的无数条直线，每个直线在参数空间都对应一个点。但是这种方法有个缺陷，就是直线的斜率可能无限大。所以一般都把Hesse normal形式当做参数空间。 具体地，以$y=kx+b$为例，可以将其写成$r=x\\cos\\theta+y\\sin\\theta$，如上图所示，$r$是直线到原点的距离，所以一条直线就对应参数空间中的一个点$$，这个参数空间就是直线对应的Hough Space。 经过平面中的一个点可以确定无数条直线，每个直线都在参数空间对应一个点，这些点构成一个正弦波行。也就是说一个点在参数空间中对应一个正弦线。并且，共线的点在参数空间中会交于点$$，这个点就是这个直线对应的参数空间中的点。所以，查找共线点问题可以转化为检测共点曲线问题。 数值计算方法直线检测的方法如下，以二维直线为例。构建一个二维累加器，记录对应的离散$r,\\theta$对应的累加值。对每一个点及其邻居点 算法决定这两个点之间是否会构成直线，如果是，计算出这条直线对应的$$值 在二位累加器中找到对应的位置，加一 计算完后，检查二维累加器，局部极大值点可能就对应一条直线，当然直线的数量需要合适阈值决定。下图是一个例子， 泛化 To Be Continue上面是直线检测的方法，参数空间是二维的。同理地，圆和椭圆都可以通过三维参数空间搞定。方法同上。 广义的方法于1981年由Dana H. Ballard提出，见https://en.wikipedia.org/wiki/Generalised_Hough_transform 引用 [1]. Hough transform. From Wikipedia, the free encyclopedia","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[]},{"title":"GRU and LSTM","slug":"GRU-and-LSTM","date":"2018-12-16T13:27:29.000Z","updated":"2018-12-16T14:08:06.246Z","comments":true,"path":"2018/12/16/GRU-and-LSTM/","link":"","permalink":"atlantic8.github.io/2018/12/16/GRU-and-LSTM/","excerpt":"","text":"GRU和LSTM都是RNNs中的特殊cell，目的是为了解决标准RNNs中的长期依赖的问题。这个问题是由于简单的RNNs求导公式中存在多个相同矩阵相乘的问题，容易造成梯度消散。使用Relu也只能说在一定程度解决了消散问题，但是会存在梯度爆炸的问题（见参考文献2）。 基本结构相似点：都是通过引入门结构来解决长期依赖问题不同点：门的数量，种类有差异 GRU每个GRU单元的输入有$x^{(t)}$、$h^{(t-1)}$，分别表示当前步的输入和上一步的隐状态。基本思想是先构建新的memory，然后再和上一隐含状态加权得到新的隐含状态。 基本结构如下图所示 GRU包含几个门，分别是 reset($r^{(t)}$)：从构建新new memory的角度出发，$r^{(t)}$决定$h^{(t-1)}$对new memory的贡献多大 new memory($\\hat{h}^{(t)}$)：由当前输入和上一步的隐含状态决定，当然，上一阶段隐含状态的重要性也受到reset gate的影响 update($z^{(t)}$)：决定$h^{(t-1)}$对$h^{(t)}$的贡献多大 hidden state($h^{(t)}$)：有上一步的隐含状态和new memory加权得到，权重有update gate决定 公式如下，懒得打了： LSTM同样地，每个LSTM单元的输入有$x^{(t)}$、$h^{(t-1)}$，分别表示当前步的输入和上一步的隐状态。需要注意的是，LSTM cell中的流动数据不仅包括隐含状态，还包括final memory 。然后生成final memory，这个过程需要input gate和forget gate。最后由output gate辅助生成当前的隐含状态(GRU没有这一步)。结构图如下 new memory：由当前输入和前一步的隐含状态决定，前一步的隐含状态贡献度由 final memory：由上一步的final memory和当前的new memory生成。其中上一步final memory的贡献度由forget gate决定，当前new memory的贡献度由input gate决定 input gate：作用在上面已经说明了，由上一步隐含状态和当前输入决定 forget gate：同input gate output gate：决定final memory对当前隐层状态的贡献 贴一下公式 需要注意的是，上面公式倒数第二个写错了，forget gate决定的是$c^{(t-1)}$. 关于LSTM、GRU是如何避免梯度问题的，关键是将简单RNN的求导过程中的乘法变成了加法，之前的记忆不会受到乘法的影响，因此不会过分衰减。同时又通过其他的门结构保证灵活性。 引用 [1]. LSTM 和GRU的区别 [2]. 理解RNN梯度消失和弥散以及LSTM为什么能解决","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"atlantic8.github.io/tags/Deep-Learning/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"atlantic8.github.io/tags/Machine-Learning/"}]},{"title":"how does shazam work","slug":"how-does-shazam-work","date":"2018-12-16T13:06:11.000Z","updated":"2018-12-16T14:08:06.470Z","comments":true,"path":"2018/12/16/how-does-shazam-work/","link":"","permalink":"atlantic8.github.io/2018/12/16/how-does-shazam-work/","excerpt":"","text":"音乐信息检索是一个复杂的工作，需要涉及信号处理、计算机算法等知识。以下是粗略介绍。 基本概念声音的物理特性中学物理告诉我们，声音来源于振动，声音需要在介质中传播。声音有纯音（pure tone）和实音（real tone）之分，前者是标准的正弦波，后者则是前者的复杂组合。中学数学告诉我们，正弦波有两个主要的特质，分别是振幅dB（amplitude）和频率（frequency）。 音乐简单背景音符（musical notes）乐谱是由多个音符构成的，每个音符都有持续时间（duration）和响度（loudness）这两个性质。乐谱的音符可以划分成八度音阶（octaves），每个八度音阶就是8个音符（A-G or Do-Si），八度音阶有如下特点： 一个八度音阶中的音符的频率是上一个八度音阶中的音符的频率的2倍 多数乐器都提供了不止8个音符，这些多出来的就叫做半音（半拍）。 音色（Timbre）对于同一个音符，不同乐器也会有不同的音色。乐器的声音通常都是有一个基础频率加上多种弦外之音（overtones）合成的。多数乐器都产生和声，但是打击乐器不是。 频谱图 以上是频谱图示例，信息包含时间、频率和振幅，振幅大小由颜色深度指示。这种图在深度学习处理声音数据的时候也要用到。 傅立叶变换傅立叶变换FT可以将时域信号$x(t)$转变为频域信号$f(w)$，有如下几种： 连续时间傅立叶变换 \\begin{aligned} f(w)=\\int_{-\\infty}^{+\\infty}x(t)e^{-jwt}\\,dt \\end{aligned}具体原理推导省略，其逆变换为： \\begin{aligned} x(t)=\\int_{-\\infty}^{+\\infty}f(w)e^{-jwt}\\,dw \\end{aligned}离散时间傅立叶变换以上公式是连续时间信号的变换，离散信号的变换可以使用离散傅立叶变换DFT，公式如下： \\begin{aligned} f(w)=\\sum_{t=-\\infty}^{+\\infty}x(t)e^{-jwt} \\end{aligned}为了在科学计算和数字信号处理等领域使用计算机进行傅里叶变换，必须将函数定义在离散点上而非连续域内，且须满足有限性或周期性条件。这种情况下有： \\begin{aligned} f(k)=\\sum_{t=0}^{N-1}x(t)e^{-j(2\\pi tk/N)},\\quad k\\in \\{0,...,N-1\\} \\end{aligned}N个结果，表示N个频率（每个k对应一个频率）以及其对应的振幅。也就是说其计算复杂度为O(N^2)，每个结果都是复数，其模就是对应的振幅。 基本过程音频检索的基本思想和生物信息检索的思路比较类似，都是在server端建立大量样本构成的数据库，client发送检索请求后，server端提取请求特征，然后在数据库中进行检索匹配，最后将结果返回给client。 在音频检索的场景下，这里面比较重要的部分是 适用于部分匹配的特征提取 样本存储（上千万的歌曲） 高效、健壮的检索 由于部分匹配要求存在，所以音频检索的特征提取算法不可能使用MD5、SHA等，并且要能处理不同格式的音乐（MP2、WMA等）。shazam选择从声音的频谱图中提取特征。 采样和信号处理的大多数case一样，人声输入是连续的音频，比如一段mp3，是连续信号，需要对信号进行采样、数字化。采样要做的就是信号损失和存储压力之间的tradeoff，奈奎斯特定理指出，要以大于2倍于原始信号的采样频率，才能从数字信号中恢复出原始信。人类听觉上限大约是20kHZ，所以标准的数字音乐采样频率是44.1kHZ，是20kHZ的两倍多一点。 量化采样是针对频率上的数字化，振幅的数字化则需要量化来完成。振幅的大小受到设备音量的影响。所以振幅的表示则有相对量表示，可以选定整个音乐中振幅的最值，并将其离散化，然后用这些离散值表示。标准的量化方法将振幅范围编码为16个bit，也就是65536个level，这时的信息损失已经很小了。 脉冲编码调制经过采样、量化两个步骤之后，设备会对数据进行编码（称为PCM信号）并且送到耳机/扬声器进行播放，PCM的样例如下： 采样率为44.1kHZ的音乐，每秒钟有44100个这样的数据。 生成频谱图本节讲的是如何由一段数字信号生成频谱图，需要用到离散傅立叶变换技术。将时序信号等时间间隔划分成多个bin，在每个bin内使用DFT得到其频率。 这里有个概念，每个bin在频率上的表示也是有固定间隔的，这个值叫做频率分辨率（frequency resolution），计算方法是： frequency resolution = 采样率 / 窗口大小 这里窗口大小是每个bin内采样窗口（window）。比如在44.1kHZ的标准采样率情况下，4096个样本的窗口对应的频率分辨率是10.7HZ。所以一个窗口的时长大约是4096/44100=0.1s，也就是说每隔0.1s就能检测出一个变化。 为了处理一个1s长度的音频，就需要分别处理10个bin的数据。实际上也就是是用了窗口函数（处理第一个bin的时候其他的系数为0）。简单的窗口函数是矩形，也还有hamming窗口和blackbox窗口，图示如下： 不同的窗口效果不同，如下所示，左图是完美的图，右图是是用了不同的窗口函数的图像，可以看到，右图中存在被称为频谱泄漏的现象，即真是频率对应的数据蔓延到邻居点。 图中blackman窗口函数的效果要优于其他窗口函数，但是换一个大小不同的窗口也许就不一样了，他们的特性如下： 矩形窗口函数：可比振幅的正弦曲线效果较好，完全不同的振幅情况则比较差（音乐的振幅变动就比较大） blackman窗口函数：擅长处理频谱泄漏时出现的强频率掩盖弱频率的问题，同时也导致了噪声会掩盖更多的频率 hamming窗口函数：上面两者的均衡 DFT的计算复杂度较高，在数量为1000的曲库上计算可能需要数天甚至上月才能完成。这里可以使用两个方面的优化： 使用快速傅立叶变换FFT 降采样：因为一首歌中大多数重要的部分都在0-5kHZ区间上，所以我们只需要11kHZ的采样率即可（奈奎斯特）。为了保持相同的频率分辨率，窗口大小降为1024即可。可以将之前4个sample的数据求均值作为一个，采样频率降为原来的1/4 0.1s的bin size, bin的频率分辨率10.7HZ，512个可能的频率（5kHZ/10.7HZ），频率范围0-5kHZ 这里我们就得到了频谱图，考虑到对噪声的鲁棒性问题，可以将振幅最大的音符留下，但是这样会存在如下问题： 许多歌曲中都会包含一些人耳不容易听见的声音（&lt;500HZ），发行前都会特意加强这些音符。只保留振幅最大的可能导致保留的都是这些人耳不容易听见的声音 频谱泄露问题导致不存在的频率出现，要确保不会选中不存在的 解决上述问题的方法如下 对每一个FFT结果（N个），把512个当成6个bands（6是超参数），bands由振幅区间划分，把这些结果放到这些bin中 每个band只保留最大值 计算6个band中最大值的均值（由于开头、结尾可能振幅较小，均值较小，但是我们并不想要这部分频率，所以可以考虑计算整首歌振幅最大的6个的均值） 保留大于均值的band值作为结果（可以乘一个参数） 以下是示例： 特征存储与匹配如上图所示，特征数据是&lt;time, frequency&gt;对，根据时长进行滑动窗口逐一匹配的复杂度过高。shazam中使用多个点同时匹配的方法，引入target zone的概念。 阐述方便，将目标区域的大小固定为5，将二维数据线性化，需要严格的先后顺序保持唯一性，比如time相同时，frequency小的在前面。所以m个&lt;time, frequency&gt;对的数据，可以生成m-4个目标区域。 下一步是为每个目标区域创建一个地址，当然这是在server端做的。我们还需要一个anchor锚点，anchor的选取不限制，只要是可重复的即可（比如当前目标区域之前的一个点或者前三个啥的）。把每个目标位置当做一个key&lt;anchor频率, 首位频率, 首位和anchor的时间差&gt;，每个key映射到一个地址，地址的形式为&lt;anchor在歌曲中的绝对位置/时间, 歌曲ID&gt;。 在检索阶段，对输入的音频，算法生成一个个&lt;&lt;anchor频率, 首位频率, 首位和anchor的时间差&gt;, 锚点在音频中的绝对位置&gt;，并上传到server端。server进行检索，可能会返回大量结果，这里由于没有逐一比较target zone的每个数据点，所以即使命中了也可能不一样，但是这样节省了时间，也能过滤掉大部分negative样本。细致的比较下面继续。 对于上一步得到的结果，我们需要进一步比较，策略如下 去除没有target zone完全匹配的结果 卡一下阈值 最后还需要考虑时间先后的问题，必要性见上图，这时需要 计算候选歌曲中的音符及其在歌曲中的绝对位置 计算输入音频中的音符及其在输入中的绝对位置 匹配的音符应该满足：音符在歌曲中的绝对位置=音符在输入中的绝对位置+匹配开始的位置。对于每首歌，我们需要找到匹配音节最多的开始位置 返回音符匹配最多的候选 引用 [1]. How does Shazam work","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"MIR","slug":"MIR","permalink":"atlantic8.github.io/tags/MIR/"},{"name":"music information retrieval","slug":"music-information-retrieval","permalink":"atlantic8.github.io/tags/music-information-retrieval/"}]},{"title":"Conditional Random Field","slug":"Conditional-Random-Field","date":"2017-08-27T06:19:20.000Z","updated":"2018-12-16T14:08:06.183Z","comments":true,"path":"2017/08/27/Conditional-Random-Field/","link":"","permalink":"atlantic8.github.io/2017/08/27/Conditional-Random-Field/","excerpt":"","text":"CRF同朴素贝叶斯一样，HMM是生成式模型。它可以做线性序列预测分析，为了计算复杂度上的可行性，其假设观测变量仅依赖于隐含变量。然而，实际中观测变量之间也存在不可忽略的依赖关系，这导致HMM的假设会严重影响模型的精确性。 CRF现在是自然语言处理领域中多个任务的state-of-art方法，包括分词、词性标注，浅解析（shallow parsing）等。并且在命名实体识别、基因预测、图像标注、物体识别等领域有着重要的应用。 CRF是判别式模型。 概率图模型一般地，在概率图模型中，节点表示随机变量，边表示依赖关系。概率图模型的表示的前提是对图的划分，也就是因子分解，可以按有向图和无向图分别讨论。 马尔可夫性给定一个随机变量$y$及其联合概率分布$p(y)$和它的无向图表示$G$，下面给出关于马尔可夫性的三个等价定义。 成对马尔可夫性：设$u,v$是无向图中没有连接的两个点，$o$是其他节点，则有$p(u,v|o)$=p(u|o)p(v|o) 局部马尔可夫性：设$u$是无向图中任意一个节点，$w$是与$u$有连接的节点，$o$是其他节点，则有$p(v,o|w)=p(v|w)p(o|w)$ 全局马尔可夫性：设$u,v$是被节点集$o$分隔开的任意节点集合，则有$p(u,v|o)=p(u|o)p(v|o)$ 总结一下意思就是：无连接的变量在以中继变量为条件的情况下相互独立。 有向图定义在有向图上的条件概率模型的联合分布为所有节点条件概率的乘积，比如贝叶斯网络，马尔可夫链等。 无向图满足马尔可夫性的联合概率分布被称为概率无向图模型，也叫做马尔可夫随机场。定义在无向图上的条件概率模型的联合分布为最大团上非负函数的乘积（这也称为概率无向图模型的因子分解）。这里最大团指的是节点数量最多的团，而团指的是互有连接的节点集合。形式化定义单个节点$v$的概率为$v$在所有最大团上的乘积，即 \\begin{aligned} p(v)=\\frac{1}{Z}\\prod_{c\\in C}\\Psi_c(v_c) \\end{aligned}其中$\\Psi_c(v_c) \\ge 0$称为节点$v$在团$c$上的势函数。$Z$是归一化因子满足$Z=\\sum_vp(v)$（其实最大熵模型也可以看成是势函数的乘积）。 CRF的表示CRF是定义在无向图上的判别式模型，是给定随机变量$x$的条件下，随机变量$y$的马尔可夫随机场。按照无向图上的定义，可以有 \\begin{aligned} p(y|x)&=\\frac{p(x,y)}{p(x)}=\\frac{p(x,y)}{\\sum_{y'}p(x,y')} \\\\ &=\\frac{\\frac{1}{Z}\\prod_{c\\in C}\\Psi_c(x_c,y_c)}{\\frac{1}{Z}\\sum_{y'}\\prod_{c\\in C}\\Psi_c(x_c,y'_c)} \\\\ &=\\frac{1}{Z(x)}\\prod_{c\\in C}\\Psi_c(x_c,y_c) \\end{aligned}这就是CRF的基本形式。下面分别介绍线性链CRF和任意结构的CRF。 线性链CRFCRF的一种特殊形式，也是比较常用的形式-线性链式。在这种情况下，相邻点变成了最大团，即满足马尔可夫性 \\begin{aligned} p(y_i|x,y_1,..,y_{i-1},y_{i+1},...,y_{n+1})=p(y_i|x,y_{i-1},y_{i+1}) \\end{aligned}假设$x=(x_1,…x_{n+1})$，$y=(y_1,…y_{n+1})$（都是向量），链的长度为$n+1$，所以最大团的数量为$n$，上式就可以写成： \\begin{aligned} p(y|x)=\\frac{1}{Z(x)}\\prod_{j=1}^n\\Psi_j(x,y) \\end{aligned}给定势函数$\\Psi_j(x,y)$的形式为 \\begin{aligned} \\Psi_j(x,y)=\\exp\\left(\\sum_{i=1}^m\\lambda_if_i(x,y_{j-1},y_j,j)\\right) \\end{aligned}其中，$j$表示序列位置（与$n$相关）。所以线性链的CRF可以表示为 \\begin{aligned} p_{\\lambda}(y|x)&=\\frac{1}{Z_{\\lambda}(x)}\\cdot \\exp\\left( \\sum_{j=1}^n \\sum_{i=1}^m\\lambda_if_i(x,y_{j-1},y_j,j) \\right) \\\\ &=\\frac{1}{Z_{\\lambda}(x)}\\prod_{j=1}^n \\exp\\left( \\sum_{i=1}^m\\lambda_if_i(x,y_{j-1},y_j,j) \\right) \\end{aligned}其中，$Z_{\\lambda}(x)$就是在$y$上对$p_{\\lambda}(y|x)$求和的结果，这结构与最大熵的形式类似。 与HMM的模式类似，应用模型之前还需要解决一些问题，分别是 给定序列集合$X$和对应的标注数据$Y$，如何训练CRF模型参数使得$p(Y|X,\\mathcal{M})$最大 给定模型$\\mathcal{M}$和输入序列$X$，如何求输出序列$Y$ 这里就不考虑求$p(X|\\mathcal{M})$了，因为CRF是判别式模型。 模型训练目标是估计参数$\\lambda$。给定数据集$T$，参数估计常用的方法就是MLE了，我们再取一个log，考虑regularization，推导如下： \\begin{aligned} \\mathcal{L}(T)&=\\sum_{(x,y)\\in T}\\log p(y|x) - \\frac{1}{2\\sigma^2}||\\lambda||_2^2 \\\\ &=\\sum_{(x,y)\\in T} \\log\\left( \\frac{\\exp\\left(\\sum_{j=1}^n \\sum_{i=1}^m\\lambda_if_i(x,y_{j-1},y_j,j)\\right)}{\\sum_{y'}\\exp\\left(\\sum_{j=1}^n \\sum_{i=1}^m\\lambda_if_i(x,y'_{j-1},y'_j,j)\\right) } \\right) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^m\\lambda_i^2 \\\\ &=\\sum_{(x,y)\\in T}\\sum_{j=1}^n \\sum_{i=1}^m\\lambda_if_i(x,y_{j-1},y_j,j) - \\sum_{(x,y)\\in T}\\log Z_{\\lambda}(x) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^m\\lambda_i^2 \\end{aligned}这里$\\sigma^2$是控制regularization权重的超参数。上式可分为3部分，分别对$\\lambda_k$求导 \\begin{aligned} \\frac{\\partial}{\\partial\\lambda_k}\\sum_{(x,y)\\in T}\\sum_{j=1}^n \\sum_{i=1}^m\\lambda_if_i(x,y_{j-1},y_j,j)&=\\sum_{(x,y)\\in T}\\sum_{j=1}^n f_k(x,y_{j-1},y_j,j) \\\\ &=N\\cdot\\hat{E}(f_k) \\end{aligned}其结果刚好是训练数据集上特征$f_i$的期望值的$N$（训练集数据个数*(n+1)）倍。 \\begin{aligned} &\\frac{\\partial}{\\partial\\lambda_k}\\sum_{(x,y)\\in T}\\log Z_{\\lambda}(x)=\\sum_{(x,y)\\in T}\\frac{1}{Z_{\\lambda}(x)}\\frac{\\partial Z_{\\lambda}(x)}{\\partial\\lambda_k} \\\\ &=\\sum_{(x,y)\\in T}\\frac{1}{Z_{\\lambda}(x)} \\frac{\\partial}{\\partial\\lambda_k}\\sum_{y'}\\exp\\left(\\sum_{j=1}^n \\sum_{i=1}^m\\lambda_if_i(x,y'_{j-1},y'_j,j)\\right) \\\\ &=\\sum_{(x,y)\\in T}\\frac{1}{Z_{\\lambda}(x)} \\sum_{y'}\\left[\\exp\\left(\\sum_{j=1}^n \\sum_{i=1}^m\\lambda_if_i(x,y'_{j-1},y'_j,j)\\right)\\cdot \\sum_{j=1}^n f_k(x,y'_{j-1},y'_j,j)\\right] \\\\ &=\\sum_{(x,y)\\in T}\\sum_{y'}p_{\\lambda}(y'|x)\\sum_{j=1}^n f_k(x,y'_{j-1},y'_j,j) \\\\ &=N\\cdot E(f_k) \\end{aligned}上面倒数第二行第一个求和符号的范围可以退化成$x\\in X$，其结果刚好是模型分布上特征$f_i$的期望值的$N$（训练集数据个数*(n+1)）倍。 \\begin{aligned} \\frac{\\partial}{\\partial\\lambda_k}\\frac{1}{2\\sigma^2}\\sum_{i=1}^m\\lambda_i^2=\\frac{\\lambda_k}{\\sigma^2} \\end{aligned} 综上，我们可以得到 \\begin{aligned} \\frac{\\partial \\mathcal{L}(T)}{\\partial \\lambda_k}=N\\cdot(\\hat{E}(f_k)-E(f_k))-\\frac{\\lambda_k}{\\sigma^2} \\end{aligned}继而，令上式等于0，就可以求出$\\lambda_k$的值。这里，$\\hat{E}(f_k)$可以通过简单的统计特征$f_k$在数据集中的出现的次数实现。而想要直接计算$E(f_k)$就不容易了，因为CRF这里处理的是序列数据，序列组合导致可能性指数上升。 解决方法是利用HMM也用到的前后向算法的修改版。定义函数$T_j(s)$为状态$s$在输入位置$j$时，位置$j+1$的可能状态集合。定义函数$T_j^{-1}(s)$为$T_j(s)$的反函数，即输出状态$s$的前置集合。定义序列初始状态为$\\vdash$，终止状态为$\\dashv$。在此基础上定义前向、后向函数： 前向函数：$\\alpha_j(s|x)=\\sum_{s’\\in T_j^{-1}(s)}\\alpha_{j-1}(s’|x)\\cdot \\Psi_j(s’,s,x)$，初始化$\\alpha_0(\\vdash|x)=1$ 后向函数：$\\beta_j(s|x)=\\sum_{s’\\in T_j(s)}\\beta_{j+1}(s’|x)\\cdot \\Psi_j(s,s’,x)$，初始化$\\beta_{|x|+1}(\\dashv|x)=1$ 其中，与上文的势函数对应，$\\Psi_j(s’,s,x)=\\exp(\\sum_{i=1}^m\\lambda_if_j(y_{i-1}=s’,y_i=s,x,j))$。根据前向、后向函数的定义，可以有 \\begin{aligned} p(y_j=s|x)= \\frac{\\alpha_j(s|x)\\beta_j(s|x)}{Z_{\\lambda}(x)} \\end{aligned}因此，$E(f_k)$的计算就变得可行了 \\begin{aligned} E(f_k)&=\\sum_{(x,y)\\in T}\\frac{1}{Z_{\\lambda}(x)}\\sum_{j=1}^n\\sum_{s\\in S}\\sum_{s'\\in T_j(s)} f_j(s,s',x,j)\\alpha_j(s|x)\\Psi_j(s,s',x)\\beta_{j+1}(s'|x) \\\\ Z_{\\lambda}(x)&=\\beta_0(\\vdash|x)=\\alpha_{|x|+1}(\\dashv|x) \\end{aligned}其中$S$是状态集合。这相当于计算了所有可能状态序列的可能，$\\alpha, \\beta$的值只需要计算一次，存储起来就好。前后向算法的时间复杂度为$O(|S|^2n)$。 至此，$\\lambda$的更新变得可行，模型训练ok。 序列标注序列标注即要在给定模型参数情况下找到输入序列对应的概率最大的标注序列，可以采用维特比算法的思想。定义: $\\delta_j(s|x)$表示序列到位置$j$时，状态为$s$的最大概率，即 \\begin{aligned} \\delta_j(s|x)=\\max_{y_1,..,y_{j-1}}p(y_1,...,y_{j-1},y_j=s|x)=\\max_{s'\\in S}\\delta_{j-1}(s')\\cdot \\Psi_j(s',s,x) \\end{aligned}还需要数组$\\phi_j(s)$记录下$j$位置状态为$s$时$j-1$位置的状态是什么。算法的步骤如下： 从开始状态初始$\\vdash$化，对所有的状态$s\\in S$，令 $\\delta_1(s|x)=\\Psi_1(\\vdash,s,x)$. $\\phi_1(s)=\\vdash$ 递归计算，对每一个$s\\in S, 1\\le j\\le n$ $\\delta_j(s|x)=\\max_{s’\\in S}\\delta_{j-1}(s’)\\cdot \\Psi_j(s’,s,x)$ $\\phi_j(s)=arg\\max_{s’\\in S}\\delta_{j-1}(s’)\\cdot \\Psi_j(s’,s,x)$ 结束迭代 $p_{max}=\\max_{s’\\in S}\\delta_{n}(s’)$ $y_n=arg\\max_{s’\\in S}\\delta_n(s’|x)$ 回溯 根据$\\phi$数组和$y_n$求出整个$y$序列。 任意结构CRF TODO 参考文献[1]. Classical Probabilistic Models and Conditional Random Fields.pdf","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"Maximum Entropy Model","slug":"Maximum-Entropy-Model","date":"2017-08-27T04:11:22.000Z","updated":"2019-08-24T02:27:17.197Z","comments":true,"path":"2017/08/27/Maximum-Entropy-Model/","link":"","permalink":"atlantic8.github.io/2017/08/27/Maximum-Entropy-Model/","excerpt":"","text":"定义最大熵模型也是判别模型，其基本思想是最大熵思想，即在给定关于概率分布不完全信息的情况下，仅有的无偏假设就是使得模型尽可能地均匀，通俗点说就是对一个随机事件的概率分布进行预测时，预测应当满足全部已知的约束，而对未知的情况不要做任何主观假设。在这种思想下，合适的模型就是在满足给定限制情况下最大化模型的熵。对于条件模型$p(y|x)$，其条件熵的定义为 \\begin{aligned} H(p)=-\\sum_{(x,y)\\in Z}p(x,y)\\log p(y|x) \\end{aligned}其中，$Z$包含$x,y$的所有可能组合。 训练样本由输入、标签表征。这里引入特征函数的概念，特征函数和以前看到的特征不大一样，它是对输入和输出同时抽取特征，表示为$f(x,y)$。特征函数可以定义为二值函数，如果$x,y$满足一定的事实，那么$f(x,y)$为1，否则为0。 约束假设训练数据集$T$有$n$条数据，特征个数为$m$个，第$i$个特征对应的特征函数为$f_i(x,y)$。令由训练数据得到的经验联合分布为$\\hat{p}(x,y)$，那么特征$f_i$关于经验分布的期望值为 \\begin{aligned} \\hat{E}(f_i)=\\sum_{(x,y)\\in T}\\hat{p}(x,y)f_i(x,y)=\\frac{1}{n}\\sum_{(x,y)\\in T}f_i(x,y) \\end{aligned}同样地，在模型分布上的特征函数均值可以表示为 \\begin{aligned} E(f_i)&=\\sum_{(x,y)\\in Z}p(x,y)f_i(x,y)=\\sum_{(x,y)\\in Z}p(x)p(y|x)f_i(x,y) \\\\ &\\approx\\sum_{x,y}\\hat{p}(x)p(y|x)f_i(x,y)=\\frac{1}{n}\\sum_{x\\in T}\\sum_{y\\in Y}p(y|x)f_i(x,y) \\end{aligned}其中，$Z$是$x,y$所有可能组合。（这里因为$x,y$所有可能组合会很多，计算上不可行）。$x$仅考虑训练集中的$x$，而$y$则是所有可能的取值，但是在实际中，$y$的可能取值是有限的、比较少的，所以这里的计算也是高效的。 至此，得到第一种约束。如果模型可以从数据中获取足够多的信息，就可以认为经验值约等于期望值，即 \\begin{aligned} \\hat{E}(f_i)\\approx E(f_i) \\end{aligned} 第二种约束为概率本身的限制，即： \\begin{aligned} p(y|x) &\\ge 0 \\quad for\\;all\\;x,y \\\\ \\sum_y p(y|x)&=1\\quad for\\;all\\;x \\end{aligned} 类似地，可以得到 \\begin{aligned} H(p) = -\\sum_{x,y}\\hat{p}(x)p(y|x)\\log p(y|x) \\end{aligned}目标函数按照最优化问题的优化习惯，将最大化问题改写成最小化问题 \\begin{aligned} arg\\min_{p(y|x)}&-H(p) \\\\ &s.t.\\quad \\hat{E}(f_i) = E(f_i) \\quad for\\;i\\;in\\,\\lbrace 1,..,m \\rbrace \\\\ &\\sum_y p(y|x)=1\\quad for\\;all\\;x \\end{aligned}模型训练带约束的优化问题可以参考拉格朗日乘子法，引入参数$\\lambda=(\\lambda_1,…,\\lambda_{m+1})$，令 \\begin{aligned} \\Gamma(p,\\lambda) = -H(p)+\\sum_{i=1}^m\\lambda_i\\left(E(f_i)-\\hat{E}(f_i)\\right)+\\lambda_{m+1}\\left(\\sum_{y\\in Y}p(y|x)-1\\right) \\end{aligned}考虑上式与原始优化问题之间联系，对于约束问题，如果有一个不满足条件，那么将对应的$\\lambda$分量扩展到$\\infty$，那么整个公式的值就变成了$+\\infty$。所以可以得到 \\begin{aligned} \\min_{p(y|x)}\\Gamma(p,\\lambda) = \\min_{p(y|x)}\\max_{\\lambda}\\Gamma(p,\\lambda) \\end{aligned}因为函数$\\Gamma(p,\\lambda)$是$p(y|x)$的凸函数，所以根据拉格朗日对偶性有 \\begin{aligned} \\min_{p(y|x)}\\max_{\\lambda}\\Gamma(p,\\lambda)=\\max_{\\lambda} \\min_{p(y|x)}\\Gamma(p,\\lambda) \\end{aligned} 首先看$\\min_{p(y|x)}\\Gamma(p,\\lambda)$:我们可以求$\\Gamma(p,\\lambda)$对$p(y|x)$的导数。逐项考虑，首先 \\begin{aligned} \\frac{\\partial{H(y|x)}}{\\partial p(y|x)} = -\\hat{p}(x)\\cdot[\\log p(y|x)+1] \\end{aligned}第二项 \\begin{aligned} &\\frac{\\partial{\\sum_{i=1}^m\\lambda_i\\left(E(f_i)-\\hat{E}(f_i)\\right)}}{\\partial p(y|x)} \\\\ &= \\frac{\\partial}{\\partial p(y|x)}\\sum_{i=1}^m\\lambda_i \\left( \\sum_{(x,y)\\in Z}\\hat{p}(x)p(y|x)f_i(x,y) - \\sum_{(x,y)\\in T}\\hat{p}(x,y)f_i(x,y) \\right) \\\\ &= \\sum_{i=1}^m\\lambda_i \\hat{p}(x) f_i(x,y) \\end{aligned}第三项比较简单，就不单独列出来了，所以$\\Gamma(p,\\lambda)$对$p(y|x)$的导数可以表示为： \\begin{aligned} \\frac{\\partial \\Gamma(p,\\lambda)}{\\partial p(y|x)} = -\\hat{p}(x)\\cdot[\\log p(y|x)+1] + \\sum_{i=1}^m\\lambda_i \\hat{p}(x) f_i(x,y) + \\lambda_{m+1} \\end{aligned}令上式等于0可以得到： \\begin{equation} p(y|x) =\\exp\\left( \\sum_{i=1}^m \\lambda_if_i(x,y) \\right)\\cdot \\exp\\left( \\frac{\\lambda_{m+1}}{\\hat{p}(x)}-1 \\right) \\end{equation}为了使$p(y|x)$的表达式只与特征函数有关，我们最好消去$\\hat{p}(x)$。注意到$\\sum_y p(y|x)=1$，将上式两边对$y$求和，可以得到 \\begin{equation} \\exp\\left( \\frac{\\lambda_{m+1}}{\\hat{p}(x)}-1 \\right)=\\frac{1}{\\sum_y \\exp\\left( \\sum_{i=1}^m \\lambda_if_i(x,y) \\right)} \\end{equation}进一步可以得到 \\begin{equation} p(y|x) = \\exp\\left( \\sum_{i=1}^m \\lambda_if_i(x,y) \\right)\\cdot \\frac{1}{\\sum_y \\exp\\left( \\sum_{i=1}^m \\lambda_if_i(x,y) \\right)} \\end{equation}综上所述，最大熵模型也就是 \\begin{equation} p_{\\lambda}^{*}(y|x) = \\exp\\left( \\sum_{i=1}^m \\lambda_if_i(x,y) \\right)\\cdot \\frac{1}{\\sum_y \\exp\\left( \\sum_{i=1}^m \\lambda_if_i(x,y) \\right)} \\end{equation} 第二步，求解$\\lambda^{}$:令$\\Psi_{p^{}}= \\min_{p(y|x)}\\Gamma(p,\\lambda)$，下一步就是 \\begin{equation} \\lambda^{*}=arg\\max_{\\lambda} \\Psi_{p^{*}} \\end{equation} 可以证明，最大熵模型是适定的（well-defined），其解存在且唯一。 参考文献[1]. Classical Probabilistic Models and Conditional Random Fields.pdf[2]. 统计学习方法. 李航","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"WordRank","slug":"WordRank","date":"2017-07-30T06:35:42.000Z","updated":"2018-12-16T14:08:06.459Z","comments":true,"path":"2017/07/30/WordRank/","link":"","permalink":"atlantic8.github.io/2017/07/30/WordRank/","excerpt":"","text":"introduction单词向量化在近些年一直是被广泛研究的课题，虽然state-of-the-art方法（word2vec）提供了通过低维矩阵嵌入方法有效地计算词之间相似性的方法，但是他们的motivation通常是不明确的。他们通用的模式是维护单词-上下文共现矩阵，初始化向量化的单词向量$u_w$、上下文单词向量$v_c$，然后使用一个可以近似表示$X_{w,c}$（$w,c$的共现次数）的函数$f(u_w,v_c)$，通过优化这个函数不断地更新$u_w,v_c$的值。（注意上下文也是一个单词，这个单词在当前单词的上下文环境中） wordrankwordrank把单词向量化定义成一个rank的问题，也就是：给定一个单词$w$，我们想要输出一个上下文列表$\\lbrace c_1,c_2,…\\rbrace$单词列表，并且要求与单词$w$共现的上下文单词出现在列表的前面。具体地，单词全集为$W$，上下文全集为$C$，$\\Omega$是给定数据单词、上下文的共现矩阵，$\\Omega_w$是与$w$共现的上下文集合，$\\Omega_c$同理。 定义单词$w$的词向量为$u_w\\in U$，上下文$c$的向量为$v_c\\in V$，词和上下文的相关性越大，他们的向量内积就越大。给定单词$w$，上下文$c$的rank可以定义为其他上下文向量与单词向量乘积比当前上下文向量与但词向量乘积大的个数，也就是有多少个上下文不必当前的”差”，即： \\begin{aligned} rank(w,c)&=\\sum_{c^{'}\\in C-\\lbrace c\\rbrace} I(\\langle u_w,v_c \\rangle-\\langle u_w,v_{c^{'}}\\rangle) \\\\ &=\\sum_{c^{'}\\in C-\\lbrace c\\rbrace}I(\\langle u_w, v_c-v_{c^{'}}\\rangle) \\end{aligned}其中函数$I(x)$是0、1损失函数，当$x\\leq 0$时输出为1，否则为0。由于函数$I(x)$是不连续的函数，我们将其近似为连续函数$l(x)$，要求$l$是$I(x)$的凸上界，可以使用的候选有$l(x)=max(0,1-x)$或者$l(x)=log_2(1+2^{-x})$，所以可以得到： \\begin{equation} rank(w,c)\\leq \\overline{rank}(w,c)=\\sum_{c^{'}\\in C-\\lbrace c\\rbrace}l(\\langle u_w, v_c-v_{c^{'}}\\rangle) \\end{equation}我们希望rank模型将与当前单词有关的context的rank值变小，所以模型的目标函数可以是： \\begin{aligned} J(U,V)=\\sum_{w\\in W}\\sum_{c\\in \\Omega_w}r_{w,c} \\cdot \\rho\\left( \\frac{\\overline{rank}(w,c)+\\beta}{\\alpha} \\right) \\end{aligned}其中$r_{w,c}$是用以量化$w,c$之间关联的权重，定义为： \\begin{aligned} r_{w,c}= \\begin{cases} (X_{w,c}/x_{max})^{\\epsilon} & X_{w,c}< x_{max} \\\\ 1 & otherwize \\end{cases} \\end{aligned}其中，$x_{max},\\epsilon$是超参数，可以看出共现次数越大，权重越大。$\\rho(\\cdot)$是一个单调递增的凹rank损失函数，量化rank的”好坏”，首先，递增是明显的，要求是凹函数是因为希望其一阶导数非递增，从而使得相关性低的context拥有较小的敏感度（增长得慢，attention减少，想想y=x-1和y=logx），使得模型的健壮性得到提高，是很关键的一步。可能的损失函数有： \\begin{aligned} \\rho(x)&=log_2(1+x) \\\\ \\rho(x)&=1-\\frac{1}{log_2(2+x)} \\\\ \\rho(x)&=\\frac{x^{1-t}-1}{1-t},\\quad t\\neq 1 \\end{aligned}$\\alpha,\\beta$是超参数，控制模型“放弃rank高的上下文、注重rank低的上下文”的程度，the rate at which the algorithm gives up is determined by the hyperparameters a and b。 optimization目标函数可以等价定义为 \\begin{aligned} J(U,C)=\\sum_{(w,c)\\in \\Omega}r_{w,c}\\cdot\\rho\\left( \\frac{\\sum_{c^{'}\\in C-\\lbrace c\\rbrace} l(\\langle u_w, v_c-v_{c^{'}}\\rangle)+\\beta }{\\alpha} \\right) \\end{aligned}这是一个包含对$\\Omega$和$C$求和的公式，当语料库很大时，问题就会变得难以处理。随机梯度下降（SGD）可以解决$\\Omega$这一层的问题，但是$C$这一层的却难以解决，除非函数$\\rho(\\cdot)$是一个线性函数。可惜的是，函数$\\rho(\\cdot)$的特性要求其不是线性函数。 解决方法是对函数$\\rho(\\cdot)$进行一阶泰勒分解，由于其凹函数的性质，可以有 \\begin{aligned} \\rho(x) \\le \\rho(\\xi)+\\rho'(\\xi)\\cdot(x-\\xi) \\end{aligned}对于所有的$x$和$\\xi$都成立，并且当$x=\\xi$时等号成立。令$\\Xi=\\lbrace \\xi_{w,c} \\rbrace_{(w,c)\\in\\Omega}$，于是我们可以得到一个$J(U,V)$的上界 \\begin{aligned} \\overline{J}(U,V,\\Xi)&=\\sum_{(w,c)\\in\\Omega}r_{w,c}\\cdot \\left\\lbrace \\rho(\\xi_{w,c})+\\rho'(\\xi_{w,c})\\cdot \\left( \\frac{\\sum_{c^{'}\\in C-\\lbrace c\\rbrace} l(\\langle u_w, v_c-v_{c^{'}}\\rangle)+\\beta }{\\alpha} - \\xi_{w,c} \\right) \\right\\rbrace \\\\ &=\\sum_{w,c,c^{'}} r_{w,c}\\cdot \\left( \\frac{\\rho(\\xi_{w,c})+\\rho'(\\xi_{w,c})\\cdot (\\frac{\\beta}{\\alpha}-\\xi_{w,c})} {|C|-1} + \\frac{1}{\\alpha}\\rho'(\\xi_{w,c})\\cdot l(\\langle u_w, v_c-v_{c^{'}}\\rangle) \\right) \\end{aligned}其中$(w,c,c^{‘}) \\in \\Omega\\times (C-\\lbrace c \\rbrace)$，等号成立的条件是 \\begin{aligned} \\xi_{w,c} = \\frac{\\sum_{c^{'}\\in C-\\lbrace c\\rbrace} l(\\langle u_w, v_c-v_{c^{'}}\\rangle)+\\beta }{\\alpha} \\end{aligned}最小化上面这个函数就等于最小化原目标函数的上界，也就是最小化目标函数了。并且$\\overline{J}(U,V,\\Xi)$很好地支持SGD（内层不需要求和）。 algorithm 学习率$\\eta$ 重复 阶段 1 重复 从$\\Omega$中均匀采样$(w,c)$ 从$C-\\lbrace c\\rbrace$中均匀采样$(c^{‘})$ // update $u_w\\gets u_w-\\eta\\cdot r_{w,c}\\cdot \\rho’(\\xi_{w,c})\\cdot l(\\langle u_w, v_c-v_{c^{‘}}\\rangle) \\cdot (v_c-v_{c^{‘}})$ $v_c\\gets v_c-\\eta\\cdot r_{w,c}\\cdot \\rho’(\\xi_{w,c})\\cdot l(\\langle u_w, v_c-v_{c^{‘}}\\rangle) \\cdot u_w$ $v_{c^{‘}}\\gets v_{c^{‘}}-\\eta\\cdot r_{w,c}\\cdot \\rho’(\\xi_{w,c})\\cdot l(\\langle u_w, v_c-v_{c^{‘}}\\rangle) \\cdot u_w$ 直到$U$和$V$都收敛 阶段2 对所有的$(w,c)\\in \\Omega$ $\\xi_{w,c}=\\left( \\sum_{c^{‘}\\in C-\\lbrace c\\rbrace} l(\\langle u_w, v_c-v_{c^{‘}}\\rangle)+\\beta \\right)/\\alpha$ 直到所有的$U,V,\\Xi$都收敛 阶段1的时间复杂度为$O(|\\Omega|)$，阶段2的时间复杂度为$O(|\\Omega||C|)$，复杂度较高。考虑到阶段2其实包含矩阵乘法运算，可以考虑使用一些高效的矩阵乘法算法。训练完成后，$U,V$分别就是对应的词向量。 引用[1]. WordRank: Learning Word Embeddings via Robust Ranking","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"},{"name":"NLP","slug":"NLP","permalink":"atlantic8.github.io/tags/NLP/"}]},{"title":"Course Schedule","slug":"Course-Schedule","date":"2017-06-28T05:24:03.000Z","updated":"2019-08-24T02:23:57.349Z","comments":true,"path":"2017/06/28/Course-Schedule/","link":"","permalink":"atlantic8.github.io/2017/06/28/Course-Schedule/","excerpt":"","text":"课程调度这个题目一共有3个，以下分别描述其题目和解法。 Course Schedule 1一共有标号从0到n-1的n个课程，有些课程需要在其他课程的基础上才能学，现在给定课程总数n和先决课程对（目标课程，先决课程）。输出这些课程能否学完 Solution 1BFS拓扑排序可以做，DFS查找回路也可以。 1234567891011121314151617181920212223242526272829303132333435public class Solution &#123; public boolean canFinish(int numCourses, int[][] prerequisites) &#123; if (prerequisites.length==0 || prerequisites[0].length==0) return true; List&lt;Set&lt;Integer&gt;&gt; in = new ArrayList&lt;&gt;(), out = new ArrayList&lt;&gt;(); for (int i=0; i&lt;numCourses; i++) &#123; in.add(new HashSet&lt;&gt;()); out.add(new HashSet&lt;&gt;()); &#125; for (int i=0; i&lt;prerequisites.length; i++) &#123; in.get(prerequisites[i][0]).add(prerequisites[i][1]); // pre-course out.get(prerequisites[i][1]).add(prerequisites[i][0]); // later-course &#125; List&lt;Integer&gt; ready = new ArrayList&lt;&gt;(); for (int i=0; i&lt;numCourses; i++) if (in.get(i).size() == 0) ready.add(i); while (ready.size() &gt; 0) &#123; int pos = ready.remove(0); Set&lt;Integer&gt; set = out.get(pos); for (Object it : set.toArray()) &#123; in.get((int)it).remove(pos); if (in.get((int)it).size() == 0) ready.add((int)it); &#125; &#125; for (int i=0; i&lt;numCourses; i++) if (in.get(i).size() &gt; 0) return false; return true; &#125;&#125; Course Schedule 2在上一题的基础上输出，如果可以学完，输出任意一个顺序即可，否则，输出一个空的顺序[]。 Solution 21234567891011121314151617181920212223242526272829303132333435363738public class Solution &#123; public int[] findOrder(int numCourses, int[][] prerequisites) &#123; int[] ret = new int[numCourses]; List&lt;Set&lt;Integer&gt;&gt; in = new ArrayList&lt;&gt;(), out = new ArrayList&lt;&gt;(); for (int i=0; i&lt;numCourses; i++) &#123; in.add(new HashSet&lt;&gt;()); out.add(new HashSet&lt;&gt;()); &#125; for (int i=0; i&lt;prerequisites.length; i++) &#123; in.get(prerequisites[i][0]).add(prerequisites[i][1]); // pre-course out.get(prerequisites[i][1]).add(prerequisites[i][0]); // later-course &#125; int k = 0; List&lt;Integer&gt; ready = new ArrayList&lt;&gt;(); for (int i=0; i&lt;numCourses; i++) &#123; if (in.get(i).size()==0 &amp;&amp; out.get(i).size()==0) ret[k++] = i; else if (in.get(i).size()==0 &amp;&amp; out.get(i).size()&gt;0) ready.add(i); &#125; while (ready.size() &gt; 0) &#123; int pos = ready.remove(0); ret[k++] = pos; Set&lt;Integer&gt; set = out.get(pos); for (Object it : set.toArray()) &#123; in.get((int)it).remove(pos); if (in.get((int)it).size() == 0) ready.add((int)it); &#125; &#125; for (int i=0; i&lt;numCourses; i++) if (in.get(i).size() &gt; 0) return new int[0]; return ret; &#125;&#125; Course Schedule 3一共有标号从0到n-1的n个课程，每个课程都有一个持续时间。给定每个课程的持续时间t和最晚结束时间d对（t,d），要求找到能够完成的课程的最大数量。其中，1 &lt;= d, t, n &lt;= 10,000，同一时刻不能同时学习两门课。 [[100, 200], [200, 1300], [1000, 1250], [2000, 3200]] output: 3 Solution 3先对每个课程按最晚结束时间从小到大排序。在前k-1个课程处理之后，对与第k个课程（tk,dk），前k个课程的最晚结束时间为dk，如果前k-1个课程中最优课程组合的总时长为x 如果此时tk + x &gt; dk，那么这个课程就不能直接放进去，处理方法是将这个课程放进去，然后从已选课程中删除时长最大的课程（删除时长最大的肯定是最好的选择，最大堆） 否则，直接将当前课程放进去即可 12345678910111213141516171819202122232425class Solution &#123;public: int scheduleCourse(vector&lt;vector&lt;int&gt;&gt;&amp; courses) &#123; int ret = 0, sum = 0, n = 0; priority_queue&lt;int&gt; pq; sort(courses.begin(), courses.end(), [](const vector&lt;int&gt;&amp; a, const vector&lt;int&gt;&amp; b)&#123; if (a[1] == b[1]) return a[0] &lt; b[0]; return a[1] &lt; b[1]; &#125;); for (int i=0; i&lt;courses.size(); i++) &#123; pq.push(courses[i][0]); sum += courses[i][0]; if (sum &gt; courses[i][1]) &#123; sum -= pq.top(); pq.pop(); &#125; &#125; return pq.size(); &#125;&#125;;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Sliding Window Median","slug":"Sliding-Window-Median","date":"2017-06-17T02:03:17.000Z","updated":"2019-08-25T01:22:32.519Z","comments":true,"path":"2017/06/17/Sliding-Window-Median/","link":"","permalink":"atlantic8.github.io/2017/06/17/Sliding-Window-Median/","excerpt":"","text":"题目描述给定数组nums和滑动窗口长度k，求滑动窗口由左向右滑动时窗口内元素的中位数。 Given nums = [1,3,-1,-3,5,3,6,7], and k = 3. Window position Median --------------- ----- [1 3 -1] -3 5 3 6 7 1 1 [3 -1 -3] 5 3 6 7 -1 1 3 [-1 -3 5] 3 6 7 -1 1 3 -1 [-3 5 3] 6 7 3 1 3 -1 -3 [5 3 6] 7 5 1 3 -1 -3 5 [3 6 7] 6 解题思路容易想到用set的思想，由于数组可能会有重复，所以使用的数据结构为multiset。思想如下： 维护一个名为window的multiset 每次通过迭代器获取中位数 12345678910111213141516vector&lt;double&gt; medianSlidingWindow(vector&lt;int&gt;&amp; nums, int k) &#123; multiset&lt;int&gt; ms(nums.begin(), nums.begin()+k); vector&lt;double&gt; ret; for (int i=k; i&lt;=nums.size(); i++) &#123; // k/2处，基数数组正好是中位数，偶数数组则是中间偏右的那一个 auto mid = next(ms.begin(), k/2); if (k % 2 == 0) ret.push_back((double(*mid) + *prev(mid))/2.0); else ret.push_back(*mid); if (i == nums.size()) break; ms.insert(nums[i]); // 删除要用迭代器，否则将会删除所有值相同的元素 // lower_bound取到值相同的最左边的元素 ms.erase(ms.lower_bound(nums[i-k])); &#125; return ret;&#125; 时间复杂度为O(kn)。 更好的方法 使用一个指针mid用以指向median值（基数指向中间那个元素、偶数指向中间两个元素的后一个）。 向window中加入/删除元素时，考虑两边比较麻烦（没做对==!）。这里的做法是保证mid左边的元素个数不变，不管右侧如何，这样结束后还是mid该在的位置 添加元素时，如果添加的元素在mid左边，mid左移一位 删除元素时，如果删除的元素在mid左边，mid右移一位 12345678910111213141516171819202122232425262728vector&lt;double&gt; medianSlidingWindow(vector&lt;int&gt;&amp; nums, int k) &#123; multiset&lt;int&gt; window(nums.begin(), nums.begin() + k); auto mid = next(window.begin(), k / 2); vector&lt;double&gt; medians; for (int i=k; ; i++) &#123; // Push the current median. medians.push_back((double(*mid) + *prev(mid, 1 - k%2)) / 2); // If all done, return. if (i == nums.size()) return medians; // Insert nums[i]. window.insert(nums[i]); // 只保证左边的元素个数不变，右边不用管 // 如果新插入的在左边，则左移一位，保证左边元素数量不变 if (nums[i] &lt; *mid) mid--; // Erase nums[i-k]. // 只保证左边的元素个数不变，右边不用管 // 如果删除的在左边，右移一位保证左边的元素个数不变 if (nums[i-k] &lt;= *mid) mid++; window.erase(window.lower_bound(nums[i-k])); &#125;&#125; Find Median from Data Stream实现一个数据结构，满足两种操作： 加入元素 计算结构中元素的中位数 解题思路 使用两个优先队列（大根堆），将数据分成两部分，左边存较小的一部分，右边存较大一部分的相反数 计算中位数时，如果左边的个数大于右边，则左边的堆顶就是中位数；否则，两个堆的堆顶元素计算中位数 需要加入一个新的数时，先push进左边的堆，然后从左边的堆中pop出最大值到右边的堆 如果左侧堆的数量小于右侧的数量，右侧弹出一个元素并将其相反数放入左侧堆 123456789101112131415161718priority_queue&lt;int&gt; left;priority_queue&lt;int&gt; right;MedianFinder() &#123;&#125; void addNum(int num) &#123; left.push(num); // push到左侧 right.push(-left.top()); // 左侧的最大值push到右侧 left.pop(); if (left.size() &lt; right.size()) &#123; // 确保左右两边的数量关系 int tmp = -right.top(); right.pop(); left.push(tmp); &#125;&#125; double findMedian() &#123; return left.size()&gt;right.size()?double(left.top()) : (double(left.top())-right.top())/2;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Sliding window","slug":"Sliding-window","permalink":"atlantic8.github.io/tags/Sliding-window/"}]},{"title":"MultiThreads in Cpp","slug":"MultiThreads-in-Cpp","date":"2017-06-12T01:41:32.000Z","updated":"2018-12-16T14:08:06.358Z","comments":true,"path":"2017/06/12/MultiThreads-in-Cpp/","link":"","permalink":"atlantic8.github.io/2017/06/12/MultiThreads-in-Cpp/","excerpt":"","text":"thread1#include &lt;thread&gt; 构造 用途 说明 创建一个空的 thread 执行对象 thread() noexcept; 创建一个 thread对象，该 thread对象可被 joinable，新产生的线程会调用 fn 函数，该函数的参数由 args 给出 template &lt;class Fn, class... Args&gt; explicit thread (Fn&amp;&amp; fn, Args&amp;&amp;... args); copy [deleted] thread (const thread&amp;) = delete; 调用成功之后 x 不代表任何 thread 执行对象 thread (thread&amp;&amp; x) noexcept; 其他成员 get_id : 获取线程 ID joinable : 检查线程是否可被 join join : 同步操作，线程所有的操作完成此函数才返回，阻塞调用此函数的线程。调用此函数后，对应thread对象变成non-joinable，并可以安全销毁 detach : 将目标线程与调用线程分离开，调用此函数后，对应thread对象变成non-joinable，并可以安全销毁（这里很奇怪—!） swap : void swap (thread&amp; x) noexcept，与x互换状态 native_handle : 返回可以访问此线程详细实现信息的值 hardware_concurrency [static] : 返回硬件线程上下文的数量 mutexMutex 又称互斥量，C++ 11中与 Mutex 相关的类（包括锁类型）和函数都声明在 头文件中. std::mutexstd::mutex 对象提供了独占所有权的特性——即不支持递归地对 std::mutex 对象上锁(重复上锁)，其相关函数如下： 构造函数，std::mutex不允许拷贝构造，也不允许 move 拷贝，最初产生的 mutex 对象是处于 unlocked 状态的 lock()，调用线程将锁住该互斥量。线程调用该函数会发生下面 3 种情况：(1). 如果该互斥量当前没有被锁住，则调用线程将该互斥量锁住，直到调用 unlock之前，该线程一直拥有该锁。(2). 如果当前互斥量被其他线程锁住，则当前的调用线程被阻塞住。(3). 如果当前互斥量被当前调用线程锁住，则会产生死锁(deadlock) unlock()， 解锁，释放对互斥量的所有权 try_lock()，尝试锁住互斥量，如果互斥量被其他线程占有，则当前线程也不会被阻塞。线程调用该函数也会出现下面 3 种情况，(1). 如果当前互斥量没有被其他线程占有，则该线程锁住互斥量，直到该线程调用 unlock 释放互斥量。(2). 如果当前互斥量被其他线程锁住，则当前调用线程返回 false，而并不会被阻塞掉。(3). 如果当前互斥量被当前调用线程锁住，则会产生死锁(deadlock) 123456789101112131415161718std::mutex mtx;volatile int counter(0);void func() &#123; for (int i=0; i&lt;10000; ++i) &#123; if (mtx.try_lock()) &#123; // 没被上锁时才自增 ++counter; mtx.unlock(); &#125; &#125;&#125;int main (int argc, const char* argv[]) &#123; std::thread threads[10]; for (int i=0; i&lt;10; ++i) threads[i] = std::thread(func); for (auto&amp; th : threads) th.join(); std::cout &lt;&lt; counter &lt;&lt; \" successful increases of the counter.\\n\"; return 0;&#125; std::recursive_mutexrecursive_mutex与mutex类似。但是和 std::mutex 不同的是，std::recursive_mutex 允许同一个线程对互斥量多次上锁（即递归上锁），来获得对互斥量对象的多层所有权，std::recursive_mutex 释放互斥量时需要调用与该锁层次深度相同次数的 unlock()，可理解为 lock() 次数和 unlock() 次数相同 std::time_mutex定时Mutex类，有两个特殊函数： try_lock_for : 接受一个时间范围，表示在这一段时间范围之内线程如果没有获得锁则被阻塞住，超时则返回false try_lock_until : 接受一个时间点作为参数，在指定时间点未到来之前线程如果没有获得锁则被阻塞住，超时则返回false 123456789101112#include &lt;chrono&gt;void fireworks() &#123; // 等待获取锁，每200ms打印一个'-' while (!mtx.try_lock_for(std::chrono::milliseconds(200))) &#123; std::cout &lt;&lt; \"-\"; &#125; // 获取锁后休息1秒，然后打印'*' std::this_thread::sleep_for(std::chrono::milliseconds(1000)); std::cout &lt;&lt; \"*\\n\"; mtx.unlock();&#125; std::recursive_timed_mutexstd::recursive_timed_mutex之于std::timed_mutex如同std:recursive_mutex之于std::mutex，就是允许重复上锁。 std::lock_guard方便线程对互斥量上锁，不用考虑销毁、异常时的解锁问题。1234567891011121314151617#include &lt;stdexcept&gt;void print_even (int x) &#123; if (x%2 == 0) std::cout &lt;&lt; x &lt;&lt; \" is even\\n\"; else throw (std::logic_error(\"not even\"));&#125;void print_thread_id (int id) &#123; try &#123; // 实用局部的lock_guard锁定mtx保证在销毁、异常中的解锁 std::lock_guard&lt;std::mutex&gt; lck (mtx); print_even(id); &#125; catch (std::logic_error&amp;) &#123; std::cout &lt;&lt; \"[exception caught]\\n\"; &#125;&#125; std::unique_lock方便线程对互斥量上锁，但提供了更好的上锁和解锁控制。12345678void print_block (int n, char c) &#123; // 临界区 (lck生存周期内对std::cout的互斥访问权) std::unique_lock&lt;std::mutex&gt; lck (mtx); for (int i=0; i&lt;n; ++i) &#123; std::cout &lt;&lt; c; &#125; std::cout &lt;&lt; '\\n';&#125; future1#include &lt;future&gt; std::future从异步任务中获取结果，通过查询future的状态（future_status）可获取异步操作的结果。future_status有三种状态： deferred：异步操作还没开始 ready：异步操作已经完成 timeout：异步操作超时 1234567891011std::future_status status; do &#123; status = future.wait_for(std::chrono::seconds(1)); if (status == std::future_status::deferred) &#123; std::cout &lt;&lt; \"deferred\\n\"; &#125; else if (status == std::future_status::timeout) &#123; std::cout &lt;&lt; \"timeout\\n\"; &#125; else if (status == std::future_status::ready) &#123; std::cout &lt;&lt; \"ready!\\n\"; &#125; &#125; while (status != std::future_status::ready); 获取future结果有三种方式：get、wait、wait_for get等待异步操作结束并返回结果 wait只是等待异步操作完成，没有返回值 wait_for是超时等待返回结果。 头文件中包含了以下几个类和函数： Providers 类：std::promise, std::package_task Futures 类：std::future, shared_future Providers 函数：std::async() 其他类型：std::future_error, std::future_errc, std::future_status, std::launch std::promisestd::promise为获取线程函数中的某个值提供便利，在线程函数中给外面传进来的promise赋值，当线程函数执行完成之后就可以通过promis获取该值了，值得注意的是取值是间接的通过promise内部提供的future来获取的.1234567std::promise&lt;int&gt; pr; std::thread t ( [] (std::promise&lt;int&gt;&amp; p) &#123; p.set_value_at_thread_exit(9); &#125; , std::ref(pr) ); std::future&lt;int&gt; f = pr.get_future(); auto r = f.get(); 函数 说明 promise(); 默认构造函数，初始化一个空的共享状态 template promise (allocator_arg_t aa, const Alloc&amp; alloc); 带自定义内存分配器的构造函数，与默认构造函数类似，但是使用自定义分配器来分配共享状态 promise (const promise&amp;) = delete; 删除的拷贝构造函数 promise (promise&amp;&amp; x) noexcept; 移动构造函数 promise 对象可以保存某一类型 T 的值，该值可被 future 对象读取（可能在另外一个线程中），因此 promise 也提供了一种线程同步的手段 在 promise 对象构造时可以和一个共享状态（通常是std::future）相关联，并可以在相关联的共享状态(std::future)上保存一个类型为 T 的值。 可以通过 get_future 来获取与该 promise 对象相关联的 future 对象，调用该函数之后，两个对象共享相同的共享状态 promise 对象是异步 Provider，它可以在某一时刻设置共享状态的值 future 对象可以异步返回共享状态的值，或者在必要的情况下阻塞调用者并等待共享状态标志变为 ready，然后才能获取共享状态的值 promise对象可以通过set_value函数设置共享状态的值 std::promise::set_value_at_thread_exit : 设置共享状态的值，但是不将共享状态的标志设置为 ready，当线程退出时该 promise 对象会自动设置为 ready 12345678910111213void print_int(std::future&lt;int&gt;&amp; fut) &#123; int x = fut.get(); // 获取共享状态的值. std::cout &lt;&lt; \"value: \" &lt;&lt; x &lt;&lt; '\\n'; // 打印 value: 10.&#125;int main () &#123; std::promise&lt;int&gt; prom; // 生成一个 std::promise&lt;int&gt; 对象. std::future&lt;int&gt; fut = prom.get_future(); // 和 future 关联. std::thread t(print_int, std::ref(fut)); // 将 future 交给另外一个线程t. prom.set_value(10); // 设置共享状态的值, 此处和线程t保持同步. t.join(); return 0;&#125; std::promise::set_exception为 promise 设置异常，此后 promise 的共享状态变标志变为 ready。下面程序的意义是：线程1从终端接收一个整数，线程2将该整数打印出来，如果线程1接收一个非整数，则为 promise 设置一个异常(failbit) ，线程2 在std::future::get 是抛出该异常。 123456789101112131415161718192021222324252627282930313233void get_int(std::promise&lt;int&gt;&amp; prom) &#123; int x; std::cout &lt;&lt; \"Please, enter an integer value: \"; std::cin.exceptions (std::ios::failbit); // throw on failbit try &#123; std::cin &gt;&gt; x; // sets failbit if input is not int prom.set_value(x); &#125; catch (std::exception&amp;) &#123; prom.set_exception(std::current_exception()); &#125;&#125;void print_int(std::future&lt;int&gt;&amp; fut) &#123; try &#123; int x = fut.get(); std::cout &lt;&lt; \"value: \" &lt;&lt; x &lt;&lt; '\\n'; &#125; catch (std::exception&amp; e) &#123; std::cout &lt;&lt; \"[exception caught: \" &lt;&lt; e.what() &lt;&lt; \"]\\n\"; &#125;&#125;int main ()&#123; std::promise&lt;int&gt; prom; std::future&lt;int&gt; fut = prom.get_future(); std::thread th1(get_int, std::ref(prom)); std::thread th2(print_int, std::ref(fut)); th1.join(); th2.join(); return 0;&#125; std::packaged_taskstd::packaged_task包装了一个可调用的目标（如function, lambda expression, bind expression, or another function object）,以便异步调用，它和promise在某种程度上有点像，promise保存了一个共享状态的值，而packaged_task保存的是一个函数。1234std::packaged_task&lt;int()&gt; task([]()&#123; return 7; &#125;);std::thread t1(std::ref(task));std::future&lt;int&gt; f1 = task.get_future();auto r1 = f1.get(); std::asyncstd::async先将异步操作用std::packaged_task包装起来，然后将异步操作的结果放到std::promise中，这个过程就是创造未来的过程。外面再通过future.get/wait来获取这个未来的结果，std::async的原型async(std::launch::async | std::launch::deferred, f, args...)，第一个参数是线程的创建策略，有两种策略，默认的策略是立即创建线程： std::launch::async：在调用async就开始创建线程 std::launch::deferred：延迟加载方式创建线程。调用async时不创建线程，直到调用了future的get或者wait时才创建线程 第二个参数是线程函数，第三个参数是线程函数的参数.123456789std::future&lt;int&gt; f1 = std::async( std::launch::async, []() &#123;return 8;&#125;);std::future&lt;int&gt; f2 = std::async( std::launch::async, [](int x) &#123;return 8+x;&#125;, 100); std::condition_variable1#include &lt;condition_variable&gt; std::condition_variable 是条件变量，其构造方法如下： 方法 说明 condition_variable(); 默认构造函数 condition_variable (const condition_variable&amp;) = delete; 删除的拷贝函数 当 std::condition_variable 对象的某个 wait 函数被调用的时候，它使用 std::unique_lock(通过 std::mutex) 来锁住当前线程。当前线程会一直被阻塞，直到另外一个线程在相同的 std::condition_variable 对象上调用了 notify_one或者’notify_all’ 函数来唤醒当前线程。 wait函数有两种形式： void wait( std::unique_lock&lt;std::mutex&gt;&amp; lock ) : 一直阻塞直到notify_one或者’notify_all’ 函数被调用。 template&lt; class Predicate &gt; void wait( std::unique_lock&lt;std::mutex&gt;&amp; lock, Predicate pred ) : 只有当谓词pred()不为真的时候才等待，否则直接跳过wait 1234567891011121314151617181920212223242526272829303132333435std::mutex mtx; // 全局互斥锁.std::condition_variable cv; // 全局条件变量.bool ready = false; // 全局标志位.void do_print_id(int id)&#123; std::unique_lock &lt;std::mutex&gt; lck(mtx); while (!ready) // 如果标志位不为 true, 则等待... cv.wait(lck); // 当前线程被阻塞, 当全局标志位变为 true 之后, // 线程被唤醒, 继续往下执行打印线程编号id. std::cout &lt;&lt; \"thread \" &lt;&lt; id &lt;&lt; '\\n';&#125;void go()&#123; std::unique_lock &lt;std::mutex&gt; lck(mtx); ready = true; // 设置全局标志位为 true. cv.notify_all(); // 唤醒所有线程.&#125;int main()&#123; std::thread threads[10]; // spawn 10 threads: for (int i = 0; i &lt; 10; ++i) threads[i] = std::thread(do_print_id, i); std::cout &lt;&lt; \"10 threads ready to race...\\n\"; go(); // go! for (auto &amp; th:threads) th.join(); return 0;&#125; 引用[1]. C++11 并发指南二[2]. C++11 并发指南三[3]. C++11 并发指南[4]. C++11 并发指南五","categories":[],"tags":[{"name":"Cpp","slug":"Cpp","permalink":"atlantic8.github.io/tags/Cpp/"}]},{"title":"Convex Hull","slug":"Convex-Hull","date":"2017-05-18T03:57:01.000Z","updated":"2018-12-16T14:08:06.186Z","comments":true,"path":"2017/05/18/Convex-Hull/","link":"","permalink":"atlantic8.github.io/2017/05/18/Convex-Hull/","excerpt":"","text":"概念凸包(Convex Hull)是一个计算几何（图形学）中的概念。凸包的求解方法之一是由葛立恒(Graham)发明的。给定二维平面上的点集，凸包就是将最外层的点连接起来构成的凸多边型，它能包含点集中所有点。 求解方法选取点集中纵坐标最小的点，如果纵坐标相同则选择横坐标较小的点，设为点H（如下图） 考虑除H之外所有点和H构成的向量，按与向量$(1,0)$之间的夹角从小到大的顺序进行排序；对于夹角一样的点，则考虑其距离，如下图所示;夹角的大小由余弦值决定，因为cos函数在$[0,\\pi]$上递减，所以cos值越大的点夹角越小，这里可能会遇到数值的精确度问题，开方精确度有差异的话最好比较平方大小。向量$a,b$的余弦值计算方法为 \\begin{aligned} cos(a,b)=\\frac{a\\cdot b}{|a||b|} \\end{aligned} $(3,0)$即为基点，这里$(4,0),(5,0)$与基点共线，$(0,3),(1,2),(2,1)$与基点共线。但是这里的处理方法是不一样的。在逆时针扫描过程中，开始阶段，共线状态的点按距离远近进行排序，近的先；而对于最后的共线点，我们需要把距离远的点放前面，$(0,3)$先于$(1,2)$先于$(2,1)$。所以统一的处理方法是，共线的点先按距离由小到大排序，然后看排在最后面的点，如果有共线的就按他们的顺序反转。（不是最后的没关系，比如上图如果还有个$(1,1)$点，那么$(1,2),(2,1)$排在$(0,3)$前面没有影响） 最后一步，就是处理排好序的点集。逆时针扫描，基点和第一个点肯定在凸包中，然后逐个加入栈中。看第一个图，栈中点包括$(H,K)$时，向量$CK$相对于$KH$往逆时针方向偏，$C$入栈(方向不变也可以)，下一个点是$D$，由于$DC$相对于$CK$往顺时针方向偏，所以将$C$出栈；由于$DK$和$KH$满足条件，所以将$D$入栈，下一个点看$L$，以此类推。。。那么问题是如何判断两个向量是否是逆时针旋转关系呢？ 可以通过向量的叉积，向量$a\\times b$的方向通过右手定则判断，具体地，四指并拢指向$a$的方向，四指转动一定角度（小于180度）指向$b$的方向，大拇指的方向就是$a\\times b$的方向，如下图所示 那么如何通过计算得到方向呢？由于二维向量的叉积会产生第三个维度，所以可以假设$a=(a_1,a_2)=(a_1,a_2,0),b=(b_1,b_2)=(b_1,b_2,0)$，$a\\times b$计算如下 \\begin{aligned} a\\times b = \\left[ \\begin{matrix} i & j & k \\\\ a_1 & a_2 & 0 \\\\ b_1 & b_2 & 0 \\end{matrix} \\right]=\\left[0, 0, a_1b_2-a_2b_1\\right] \\end{aligned}第三维的分量为$a_1b_2-a_2b_1$，举个栗子判断一下不难发现，逆时针方向转动的向量第三维分量大于0，顺时针转动的小于0.比如图中的$a\\times b$指向z轴正向。所以通过计算$a_1b_2-a_2b_1$就可以知道转动方向了。 以下是c++实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950vector&lt;Point&gt; outerTrees(vector&lt;Point&gt;&amp; points) &#123; if (points.size() &lt; 4) return points; Point bottom = points[0]; int index = 0; for (int i=0; i&lt;points.size(); i++) &#123; // search for lowest node Point point = points[i]; if (point.y==bottom.y &amp;&amp; point.x&lt;bottom.x) &#123;bottom = point; index = i;&#125; if (point.y &lt; bottom.y) &#123;bottom = point; index = i;&#125; &#125; swap(points[0], points[index]); sort(points.begin()+1, points.end(), [bottom](const Point &amp;p1, const Point &amp;p2)&#123; double d1 = (p1.x-bottom.x)*(p1.x-bottom.x)+(p1.y-bottom.y)*(p1.y-bottom.y); double d2 = (p2.x-bottom.x)*(p2.x-bottom.x)+(p2.y-bottom.y)*(p2.y-bottom.y); double x1 = 1.0*(p1.x-bottom.x)*abs(p1.x-bottom.x)/d1; double x2 = 1.0*(p2.x-bottom.x)*abs(p2.x-bottom.x)/d2; if (x1 != x2) return x1 &gt; x2; // angle from small to big return d1 &lt; d2; // distance from close to far &#125;); int rl = points.size()-2, rr = points.size()-1; while (rl &gt;= 1) &#123; // reverse co-linear nodes from behind if necessary Point p1 = points[rl]; Point p2 = points[rr]; double d1 = (p1.x-bottom.x)*(p1.x-bottom.x)+(p1.y-bottom.y)*(p1.y-bottom.y); double d2 = (p2.x-bottom.x)*(p2.x-bottom.x)+(p2.y-bottom.y)*(p2.y-bottom.y); double x1 = 1.0*(p1.x-bottom.x)*abs(p1.x-bottom.x)/d1; double x2 = 1.0*(p2.x-bottom.x)*abs(p2.x-bottom.x)/d2; if (x1 == x2) rl--; else break; &#125; if (++rl &lt; rr &amp;&amp; rl &gt;= 1)while (rl &lt; rr) swap(points[rl++], points[rr--]); vector&lt;Point&gt; ret; ret.push_back(points[0]); ret.push_back(points[1]); for (int i=2; i&lt;points.size(); i++) &#123; remove clock-wize node int num = 0; while (ret.size() &gt; 2) &#123; // last vector int v1x=ret[ret.size()-1].x-ret[ret.size()-2].x, v1y=ret[ret.size()-1].y-ret[ret.size()-2].y; // current vector int v2x=points[i].x-ret[ret.size()-1].x, v2y=points[i].y-ret[ret.size()-1].y; // cross product x1*y2-x2*y1, positive is ok if (v1x*v2y-v2x*v1y &lt; 0) ret.pop_back(); else break; &#125; ret.push_back(points[i]); &#125; return ret;&#125; 类似题目LeeCode题目Erect the Fence就是求点的凸包问题。 还有类似的题目：求二维平面上多个点构成的最大三角形。思路是先求多个点的凸包，然后枚举凸包中的点，找到最大三角形。（$S=\\sqrt{p(p-a)(p-b)(p-c)},p=\\frac{a+b+c}{2}$）. 引用[1]. Graham’s Scan法求解凸包问题[2]. 百度百科-向量积","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Math","slug":"Math","permalink":"atlantic8.github.io/tags/Math/"}]},{"title":"Softmax","slug":"Softmax","date":"2017-05-10T02:40:25.000Z","updated":"2018-12-16T14:08:06.411Z","comments":true,"path":"2017/05/10/Softmax/","link":"","permalink":"atlantic8.github.io/2017/05/10/Softmax/","excerpt":"","text":"Softmax函数Softmax函数的作用是归一化，对于向量$z=(z_1,…,z_n)$，Softmax函数的形式如下： \\begin{aligned} softmax(z)=(\\frac{e^{z_1}}{\\sum_je^{z_j}},...,\\frac{e^{z_n}}{\\sum_je^{z_j}}) \\end{aligned}Softmax Regression形式Softmax regression是logistic regression的多分类版本，也是线性分类器，假设一共有$K$个类别，样本特征空间维度为$n$。其基本形式如下 \\begin{aligned} f(x)=softmax(\\theta^T x) \\end{aligned}其中，$\\theta$是系数矩阵，维度为$n\\times K$，$x$是维度为$n$的样本，输出一个$K\\times 1$的向量，选择最大值对应的类为结果。 训练为了方便描述，假设$z=\\theta^Tx$，所以有$f(x)=softmax(z)$。损失函数的定义与logistic regression类似，采用交叉熵形式。假设当前样本为$x_i$，输出为$y_i$，属于第$k$类，输出为$y_i$，对应的真实结果为$\\hat{y_i}=[0 0 … 1 … 0]$，第$k$位为1，其余位为0。优化方法采用梯度下降。对所有的样本$x_1,…,x_m$，首先损失函数为： \\begin{aligned} L=-\\sum_i^m\\hat{y_i}logy_i \\end{aligned}首先，根据$y_i$的分量可知，对$y_i$求导的导数只有第$k$个分量的梯度不为0 \\begin{aligned} \\frac{\\partial L}{\\partial y_{i}}=\\frac{\\partial L}{\\partial y_{ik}}=-\\frac{1}{y_{ik}} \\end{aligned}然后再求$y_{ik}$对$z_i$的导数（其他的$y_{i}$分量梯度都是0，就不用考虑了）。具体来说，考虑$y_{ik}$对$z_{ij}$的导数。如果$j==k$，那么 \\begin{aligned} \\frac{\\partial y_{ik}}{\\partial z_{ij}}&=\\frac{\\partial }{\\partial z_{ik}} \\frac{e^{z_{ik}}}{\\sum_j e^{z_{ij}}} \\\\ &= \\frac{e^{z_{ik}} \\sum_j e^{z_{ij}}-e^{z_{ik}}e^{z_{ik}}}{\\left( \\sum_j e^{z_{ij}} \\right)^2} \\\\ &= y_{ik}(1-y_{ik}) \\end{aligned}所以有 \\begin{aligned} \\frac{\\partial L}{\\partial z_{ij}}=-\\frac{1}{y_{ik}} y_{ik}(1-y_{ik})=y_{ik}-1 \\end{aligned}如果$j!=k$，那么 \\begin{aligned} \\frac{\\partial y_{ik}}{\\partial z_{ij}}&=\\frac{\\partial }{\\partial z_{ij}} \\frac{e^{z_{ik}}}{\\sum_j e^{z_{ij}}} \\\\ &= \\frac{-e^{z_{ij}}e^{z_{ik}}}{\\left( \\sum_j e^{z_{ij}} \\right)^2} \\\\ &= -y_{ij}y_{ik} \\end{aligned}所以有 \\begin{aligned} \\frac{\\partial L}{\\partial z_{ij}}=y_{ij} \\end{aligned}由于$\\hat{y_i}$只有第$k$位为1，其余位都为0，所以综上所述 \\begin{aligned} \\frac{\\partial L}{\\partial z_{i}}=y_{i}-\\hat{y_i} \\end{aligned}有了$z_i=\\theta^Tx_i$的梯度，$\\theta$（其中，$\\theta_j$是$\\theta$的第$j$列）的梯度就简单了 \\begin{aligned} \\frac{\\partial L}{\\partial \\theta}&=\\frac{\\partial L}{\\partial z_{i}} \\frac{\\partial z_i}{\\partial \\theta} \\\\ &=x_i(y_{i}-\\hat{y_i})^T \\end{aligned}有了梯度就可以使用梯度下降方法更新权值了$\\theta=\\theta-\\frac{\\partial L}{\\partial \\theta}$。这是随机梯度下降的梯度表示，对完整梯度下降的表示为 \\begin{aligned} \\frac{\\partial L}{\\partial \\theta}&=\\sum_{i=1}^m\\frac{\\partial L}{\\partial z_{i}} \\frac{\\partial z_i}{\\partial \\theta} \\\\ &=\\sum_{i=1}^mx_i(y_{i}-\\hat{y_i})^T \\end{aligned} 但是，上面方法训练出来的模型还存在冗余问题，具体来说对于$\\theta$的每一列$\\theta_k$满足 \\begin{aligned} \\frac{e^{(\\theta_k^T-\\theta_0^T)x}}{\\sum_je^{(\\theta_j^T-\\theta_0^T)x}}=\\frac{e^{\\theta_k^Tx}}{\\sum_je^{\\theta_j^Tx}} \\end{aligned}也就是说会有无穷多个能达到最优解的参数，解决方法是给损失函数加上一个权重衰减项 \\begin{aligned} L=-\\sum_i^m\\hat{y_i}logy_i+\\frac{\\lambda}{2} \\Vert \\theta \\Vert^2 \\end{aligned}所以有 \\begin{aligned} \\frac{\\partial L}{\\partial \\theta}&=\\sum_{i=1}^mx_i(y_{i}-\\hat{y_i})^T+\\lambda\\theta \\end{aligned}Softmax和logistic regression的关系根据上文描述的Softmax存在的参数冗余性，构造一个二分类情况下的softmax分类器，形式如下 \\begin{aligned} h_{\\theta}(x)=\\frac{1}{\\sum_{i=1}^2e^{\\theta_i^Tx}} \\begin{bmatrix} e^{\\theta_1^Tx} \\\\ e^{\\theta_2^Tx} \\end{bmatrix} \\end{aligned}把上式中的$\\theta$因子全部减去$\\theta_1^T$，则有 \\begin{aligned} h_{\\theta}(x)&=\\frac{1}{\\sum_{i=1}^2e^{\\theta_i^Tx}} \\begin{bmatrix} e^{\\theta_1^Tx} \\\\ e^{\\theta_2^Tx} \\end{bmatrix} \\\\ &=\\frac{1}{1+e^{(\\theta_2-\\theta_1)^Tx}} \\begin{bmatrix} 1 \\\\ e^{(\\theta_2-\\theta_1)^Tx} \\end{bmatrix} \\end{aligned}这样就又回到logistic regression的格式了！ 引用[1]. UFLDL Softmax回归[2]. 手打例子一步一步带你看懂softmax函数以及相关求导过程","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"Recurrent Neural Networks","slug":"Recurrent-Neural-Networks","date":"2017-05-05T03:58:31.000Z","updated":"2018-12-16T14:08:06.389Z","comments":true,"path":"2017/05/05/Recurrent-Neural-Networks/","link":"","permalink":"atlantic8.github.io/2017/05/05/Recurrent-Neural-Networks/","excerpt":"","text":"RNN中文名为递归神经网络，是深度学习理论的典型模型之一。DNN和CNN都假设输入是相互独立的，但在某些情况中，比如机器翻译，输入往往还应该包含上下文信息，所以DNN和CNN在处理时序或者顺序数据时会丢失上下文信息。RNN就是处理时序数据的典型代表，其延伸版本LSTM已经在诸多领域取得了辉煌的成绩。 vanilla RNNs以vanilla RNNs为例，为了达到记忆效果，其RNN的基本结构及展开结构如下： 展开后的结构通俗易懂，其中$x_i$时序列输入，比如单词中的字母序列，$o_i$表示输出序列，比如当前字母的下一个字母，$s_i$表示隐层的值，$U,V,W$是连接权值矩阵（共享），$s_i$经过$V$映射得到$y_i$，$y_i$经过softmax(这里的softmax只做归一化操作，不改变维度)得到结果$o_i$。 前向传播前向传播和DNN的前向传播类似，不同点在于RNN中隐层的输入不仅包含当前时刻的输入，还包含前一时刻的隐层输入。前向传播可由以下公式给出： \\begin{aligned} s_t &= f(Ws_{t-1}+Ux_t+b_1) \\\\ y_t &= Vs_t+b_2 \\\\ o_t &=softmax(y_t) \\end{aligned}Back Propagation Through Time反向训练的过程与DNN的反响传导类似，不同点在于权值共享和隐层的处理，基本思路还是链式求导法则,误差函数可以是平方误差，也可以是交叉熵，这里选用交叉熵 E_t=-o_tlog\\hat{o_t}激活函数可以是tanh，也可以是LeRU。训练过程就是计算参数梯度累加值，最后更新参数。对一个序列$t=1,…,T$，训练过程如下： \\begin{aligned} &1. 初始化d_W,d_V,d_U, d_{b_1}, d_{b_2}, d_s,d_{s_{next}} \\\\ &2. For\\ t\\ from\\ T\\ to\\ 1: \\\\ &3. \\; \\; \\; \\; \\; \\; \\; \\; d_y=\\hat{o_t}-o_t \\\\ &4. \\; \\; \\; \\; \\; \\; \\; \\;dV+=d_ys_t^T \\\\ &5. \\; \\; \\; \\; \\; \\; \\; \\; d_{b_2}+=d_y \\\\ &6. \\; \\; \\; \\; \\; \\; \\; \\; d_s=V^Td_y+d_{s_{next}} \\\\ &7. \\; \\; \\; \\; \\; \\; \\; \\; d_{s_{raw}}=\\frac{df(s_t)}{d_{s_t}}d_s \\\\ &8. \\; \\; \\; \\; \\; \\; \\; \\; d_{b_1}+=d_{s_{raw}} \\\\ &9. \\; \\; \\; \\; \\; \\; \\; \\; d_U+= d_{s_{raw}}x_t^T \\\\ &10. \\; \\; \\; \\; \\; \\; \\; d_W+= d_{s_{raw}}s_{t-1}^T \\\\ &11. \\; \\; \\; \\; \\; \\; \\; d_{s_{next}}= W^Td_{s_{raw}} \\end{aligned}需要说明的是第3行$d_y=\\frac{\\partial E_t}{\\partial y_t}$，其中推导比较麻烦，见文献[4]。由于在$t$时刻时就已经对$s_{t-1}$进行求导了，所以下一次需要加上这个导数，每一轮中对下一轮的$s$求导结果存储在$ d_{s_{raw}}$中，下一轮到的时候让$s_t$梯度加上$ d_{s_{raw}}$即可。此外式中的$d_{s_{raw}}$表示的是$Ws_{t-1}+Ux_t+b_1$的梯度，如果写成$s_{raw}=Ws_{t-1}+Ux_t+b_1,s_t=f(s_{raw})$可能会更好理解。训练完成得到各参数梯度和后，使用梯度下降思想更新参数即可。 RNN的用途 one to many ：输入一个图片，输出一句描述图片的话。many to one ：输入一句话，判断是正面还是负面情绪。many to many ：有个延时的，譬如机器翻译。many to many ：输入一个视频，判断每帧类别。 RNN的限制vanilla RNN无法解决长时依赖问题(即当前的输出与前面很长的一段序列有关，一般超过十步就无能为力了)，vanilla RNN存在着梯度爆炸和梯度消散的问题（因为梯度需要不断乘以矩阵$U,V,W$，如果矩阵最大特征值大于1，乘多次以后就会出现梯度爆炸；如果小于1，乘多次则会出现梯度消散（联想一下多次乘以一个标量，大于1则爆炸，小于1则接近0））。 解决这个问题的方案： 梯度爆炸：梯度裁剪的方式避免，譬如梯度大于5就强制梯度等于5 梯度消散：LSTM（LSTM也可能出现梯度爆炸，所以需要梯度裁剪） vanilla RNN简单，但是效果不好！ LSTM（Long Short Term Memory）上一节描述了vanilla RNN以及其局限性，vanilla RNN结构简单，LSTM的结构就稍微复杂点，如下图所示： 在LSTM中引入了细胞结构的概念，并引入“门”结构来去除或者增加信息到细胞状态的能力，门是一种让信息选择式通过的方法，他们包含一个 sigmoid 神经网络层和一个 pointwise 乘法操作。这里箭头合并符号表示向量堆叠拼接，(比如$w_1x_1+w_2x_2+b$可以写成$[w_1\\ w_2][x_1\\ x_2]^T+b=WX^T+b$)，箭头合并表示拷贝复用。 LSTM 拥有三个门，分别是：忘记门 忘记门读取上一状态的隐层输出$h_{t-1}$和$x_t$，输出一个与$C_{t-1}$长度相同的向量，每个元素都是$[0,1]$之间的数字，表示$C_{t-1}$的通过率，1 表示完全保留，0 表示完全舍弃。 输入门 这一步是要更新细胞状态，先将旧细胞状态$C_{t-1}$与$f_t$相乘，丢弃掉我们确定需要丢弃的信息。$\\hat{C_t}$使用的激活函数是tanh，输出范围是$[-1,1]$，比sigmoid有更广的范围。$i_t$的功能与$f_t$类似，决定$\\hat{C_t}$的通过情况。然后将$C_{t-1}$与$f_t$乘积加到$C_{t-1}$上更新细胞状态为$C_t$. 输出门 首先，运行一个sigmoid层来确定$[h_{t-1}, x_t]$的哪个部分将输出出去。接着，我们把细胞状态通过 tanh 进行处理（得到一个在 -1 到 1 之间的值）并将它和sigmoid门的输出相乘，最终我们仅仅会输出我们确定输出的那部分。 引用[1]. 斯坦福大学深度学习资料 CS231n[2]. Standford CS231n 循环神经网络 简要笔记[3]. 简书：理解 LSTM 网络[4]. softmax分类器+cross entropy损失函数的求导","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"},{"name":"deep learning","slug":"deep-learning","permalink":"atlantic8.github.io/tags/deep-learning/"}]},{"title":"Maximum XOR of Two Numbers in an Array","slug":"Maximum-XOR-of-Two-Numbers-in-an-Array","date":"2017-05-02T12:05:02.000Z","updated":"2018-12-16T14:08:06.340Z","comments":true,"path":"2017/05/02/Maximum-XOR-of-Two-Numbers-in-an-Array/","link":"","permalink":"atlantic8.github.io/2017/05/02/Maximum-XOR-of-Two-Numbers-in-an-Array/","excerpt":"","text":"题目描述给定一个非空数组$a_0,a_1,…,a_{n-1}$满足$0\\le a_i \\le 2^{31}$，找到两个元素异或的最大值。要求时间复杂度为O(n)。 Input: [3, 10, 5, 25, 2, 8] Output: 28 Explanation: The maximum result is 5 ^ 25 = 28. 解题思路思路是Trie Tree，第一步将每一个元素按二进制位存储在树中，第二步对于每一个元素$a_i$，尝试找到树中能和$a_i$构成最大异或值的元素，记录这个最大值。 1234567891011121314151617181920212223242526272829303132333435363738394041struct TrieNode &#123; TrieNode *son[2]; // 0 int val; TrieNode(int v) :val(v) &#123; son[0] = NULL; son[1] = NULL; &#125;&#125;;class Solution &#123;public:int findMaximumXOR(vector&lt;int&gt;&amp; nums) &#123; TrieNode *root = new TrieNode(-1), *p; for (int i=0; i&lt;nums.size(); i++) &#123; // 建树 int cur = nums[i]; TrieNode *father=root; for (int k=31; k&gt;=0; k--) &#123; int x = (cur&gt;&gt;k) &amp; 1; if (father-&gt;son[x] == NULL) &#123; p = new TrieNode(x); father-&gt;son[x] = p; &#125; else p = father-&gt;son[x]; father = p; &#125; &#125; int ret = 0; vector&lt;int&gt; res; for (int j=0; j&lt;nums.size(); j++) &#123; // 找最值 int cur = nums[j], tmp=0; p = root; for (int i=31; i&gt;=0; i--) &#123; // 按位找 int x = (cur&gt;&gt;i) &amp; 1; if (p-&gt;son[1^x] != NULL) &#123; tmp += 1&lt;&lt;i; p = p-&gt;son[1^x]; &#125; else p = p-&gt;son[0^x]; &#125; ret = max(ret, tmp); &#125; return ret;&#125;&#125;; 再来看看解题报告上别人写的NB解法，大致思想是从高到低确定最终结果的每一位上究竟是0还是1，通过迭代剔除不可能的元素12345678910111213141516171819202122public int findMaximumXOR(int[] nums) &#123; int max = 0, mask = 0; for (int i = 31; i &gt;= 0; i--) &#123; mask |= (1 &lt;&lt; i); // 掩码每轮多一个1 HashSet&lt;Integer&gt; set = new HashSet&lt;Integer&gt;(); for (int num : nums) set.add(num &amp; mask); // 计算通过掩码能得到的最大值 /* Use 0 to keep the bit, 1 to find XOR * 0 ^ 0 = 0 * 0 ^ 1 = 1 * 1 ^ 0 = 1 * 1 ^ 1 = 0 */ int tmp = max | (1 &lt;&lt; i); // in each iteration, there are pair(s) whoes Left bits can XOR to max for (int prefix : set) &#123; if (set.contains(tmp ^ prefix)) max = tmp; &#125; &#125; return max;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Introduction to Recommender System","slug":"Introduction-to-Recommender-System","date":"2017-05-02T12:00:30.000Z","updated":"2018-12-16T14:08:06.272Z","comments":true,"path":"2017/05/02/Introduction-to-Recommender-System/","link":"","permalink":"atlantic8.github.io/2017/05/02/Introduction-to-Recommender-System/","excerpt":"","text":"推荐系统在电子商务以及基于social的社会化网站上取得了巨大的成功，web2.0下，海量的用户数据使我们能够更加智能地发现用户的口味和需求。 推荐系统接受的输入包括： 要推荐物品、内容的元数据，比如关键字 系统用户的基本信息，比如姓名、年龄等 用户对物品信息的偏好，评分、查看记录、购买记录等 显示的用户反馈：评分、评价 隐式的用户反馈：购买记录，查看记录 推荐系统分类根据不同用户的推荐大众行为推荐 给每个用户推荐一致的信息 个性化推荐 根据用户的口味、偏好进行推荐 根据数据源基于人口统计学的推荐 通过用户的基本信息发现用户的相关程度 推荐相似用户的喜好物品、内容 优点： 没有冷启动问题 不依赖物品本身数据，是领域独立的 缺点 方法过于粗糙，尤其对于对品味要求高的领域（音乐、图书等） 个人隐私信息的获取不容易 根据推荐物品或内容的元数据 根据推荐物品或内容的元数据发现物品或内容的相关性 根据用户的历史喜好记录推荐类似的物品 优点 较好的对用户口味进行建模 缺点 推荐的质量依赖于物品模型的完整性、全面程度（tag是一种简单有效的方法） 物品相似度仅考虑物品本身的特征，没有考虑人对物品的态度偏好 需要历史偏好，所以有冷启动问题 基于协同过滤的推荐 根据用户对物品、内容的偏好，发现物品、内容本身的相关性，或者发现用户的相关性 一般使用k近邻的思想 喜欢类似物品的用户可能有相似的口味偏好 优点 不需要对物品、用户进行严格建模，不要求机器理解物品属性，领域无关 计算出的推荐是开放的，可以共用他人经验，支持用户发现潜在的偏好 缺点 对新物品、新用户有冷启动问题 推荐效果依赖于用户历史偏好数据的多少和准确性 稀疏矩阵的问题 特殊品味用户的问题 由于以历史数据为基础，获得用户模型后，很难修改或者根据用户的使用演变，灵活性较差 1） 基于用户的协同过滤机制和基于人口统计学的推荐都是基于邻居的相似度计算推荐，前者是基于用户偏好数据计算用户相似度。 2） 基于项目的协同过滤机制根据用户对物品的偏好信息，计算物品的相似度，然后根据用户历史信息推荐相似物品。 3） 基于模型的协同过滤机制基于用户历史偏好信息，训练模型，然后根据实时的用户喜好信息进行预测，计算推荐。 基于推荐模型的建立方式基于物品和用户本身的推荐 将每个用户、物品都当成独立的实体 预测每个用户对每个物品的喜好程度（稀疏的二维矩阵） 对用户和物品进行聚类可以减小计算量 基于关联规则的推荐 挖掘数据的依赖关系，共现关系 统计信息 基于模型的推荐 用已有用户喜好数据训练用户的喜好模型 SVD在推荐系统中的应用SVD的公式如下 \\begin{aligned} A_{m\\times n} = U_{m\\times m} \\Sigma_{m\\times n} V^T_{n\\times n} \\end{aligned}其中，$\\Sigma$是对角矩阵，对角元素为从大到小排好序的$AA^T$特征值的平方根(也就是奇异值)。$U$的每一列称作左奇异向量，$V$的每一列（即$V$的转置$V^T$的每一行）称作右奇异向量，满足$U^TU=I, V^TV=I$。计算SVD实际上就是计算$A^TA$或者$AA^T$的特征值和特征向量，然后将它们组合成上边表达式形式。$AA^T$的特征向量按照特征值的大小按列排列便组成了$U$矩阵，同样$A^TA$的特征向量按照其特征值的大小按列排列便组成了$V$矩阵。 在协同过滤算法中，$A$是用户行为矩阵，$m$表示用户个数，$n$表示商品数。计算用户或商品相似度时，需要大量的操作，单个向量长度也比较长。考虑采用SVD对原始数据进行简化。如果用于基于物品的协同过滤推荐，那么就直接使用$V$矩阵代替$A$矩阵（$V$的每行代表一个物品）；如果是基于用户的协同过滤推荐，就直接用$U$矩阵代替$A$矩阵（每行代表一个用户）。这时，在计算上述的两个向量之间的距离的时候，向量的长度不再是对这两个物品都有过反馈的用户的个数，而是简化后数据的维度，即$S$矩阵中我们保留前$k$个奇异值，那么这个$k$就是现在向量的长度（取前k个元素[0:k-1]）。 混合推荐机制 加权混合 切换混合：适合的机制用在适合的场景 分区推荐：amazon，不同推荐结果展示于不同位置 分层推荐：多种推荐机制，将一个推荐机制的结果作为另一个推荐机制的输入","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"recommender system","slug":"recommender-system","permalink":"atlantic8.github.io/tags/recommender-system/"}]},{"title":"Super Washing Machines","slug":"Super-Washing-Machines","date":"2017-04-02T02:08:53.000Z","updated":"2018-12-16T14:08:06.428Z","comments":true,"path":"2017/04/02/Super-Washing-Machines/","link":"","permalink":"atlantic8.github.io/2017/04/02/Super-Washing-Machines/","excerpt":"","text":"题目描述You have $n$ super washing machines on a line. Initially, each washing machine has some dresses or is empty. For each move, you could choose any $m (1 ≤ m ≤ n)$ washing machines, and pass one dress of each washing machine to one of its adjacent washing machines at the same time . Given an integer array representing the number of dresses in each washing machine from left to right on the line, you should find the minimum number of moves to make all the washing machines have the same number of dresses. If it is not possible to do it, return -1. Example1 Input: [1,0,5] Output: 3 Explanation: 1st move: 1 0 &lt;-- 5 =&gt; 1 1 4 2nd move: 1 &lt;-- 1 &lt;-- 4 =&gt; 2 1 3 3rd move: 2 1 &lt;-- 3 =&gt; 2 2 2 Example2 Input: [0,3,0] Output: 2 Explanation: 1st move: 0 &lt;-- 3 0 =&gt; 1 2 0 2nd move: 1 2 --&gt; 0 =&gt; 1 1 1 Example3 Input: [0,2,0] Output: -1 Explanation: It&#39;s impossible to make all the three washing machines have the same number of dresses. Note: The range of n is [1, 10000]. The range of dresses number in a super washing machine is [0, 1e5]. 解题思路首先，如果所有洗衣机的衣服总和不能被$n$整除，返回-1.然后对于每个洗衣机，计算它的gain/lose数组，表示还需要移除多少件衣服使得自己达到平衡状态。 举个栗子：对于[0,0,11,5]，每个洗衣机应该有4件衣服，所以它的gain/lose数组为[-4,-4,7,1]。从第一个机器开始考虑，第一个要加入4件，得从第二个机器中过来，所以这个状态可以以4次移动的代价变成[0,-8,7,1]。同理第二个状态也可以以8次移动的代价变成状态三[0,0,-1,1]，最后以一次移动的代价变成[0,0,0,0]。 因为每一次移动可以选取任意个元素，并朝左边或者右边移动一个元素，所以总共需要的移动次数就是gain/lose数组中出现的最大值。 12345678910int findMinMoves(vector&lt;int&gt;&amp; machines) &#123; int sum = accumulate(machines.begin(), machines.end(), 0); if (sum % machines.size() != 0) return -1; int ret=0, tmp=0, n=sum / machines.size(); for (int num : machines) &#123; tmp += num-n; ret = max(max(ret, num-n), abs(tmp)); &#125; return ret;&#125; 代码中num-n没加绝对值，我的理解是对于初始gain/lose数组的负数，可以从两边同时添加衣服，如果是正数，那么那么每次只能移除一件衣服。而tmp加了绝对值，是因为tmp表示左边一个缺少/多的衣服数，这些衣服得从右边过来，并且一个一个达到当前位置，所以得加绝对值。","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Contiguous Array","slug":"Contiguous-Array","date":"2017-04-01T06:09:56.000Z","updated":"2018-12-16T14:08:06.185Z","comments":true,"path":"2017/04/01/Contiguous-Array/","link":"","permalink":"atlantic8.github.io/2017/04/01/Contiguous-Array/","excerpt":"","text":"题目描述给定一个只包含0和1的整形数组，输出最长的连续子串的长度，要求子串中0和1的个数相同。 Input: [0,1] Output: 2 Explanation: [0, 1] is the longest contiguous subarray with equal number of 0 and 1. Input: [0,1,0] Output: 2 Explanation: [0, 1] (or [1, 0]) is a longest contiguous subarray with equal number of 0 and 1. 数组长度不会超过50000. 解题思路$O(n^2)$的思路容易想到，但是数组长度太长，会超时。 方法如下： 先将数组中的0变成-1，这样连续子序列的和为0的时候满足条件 记录下0-k位置的和与k的对应关系，可以hash map的方法。和相同的只记录最左边的，毕竟长度要最长嘛 如果后面遇到了记录过的和，位置相减就能得到满足条件的子序列长度 时间复杂度为$O(n)$ 代码如下：12345678910111213141516int findMaxLength(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(), ret=0, sum=0; unordered_map&lt;int, int&gt; map; map[0] = -1; // 没有数和也为0，防止只有[0,1]时输出0 for (int i=0; i&lt;n; i++) if (nums[i]==0) nums[i] = -1; for (int i=0; i&lt;n; i++) &#123; sum += nums[i]; // 以前遇到过sum值，现在位置-以前位置可以得到一个满足要求的序列长度 if (map.find(sum) != map.end()) &#123; ret = max(ret, i-map[sum]); &#125; else &#123; // 第一次遇到sum值，记录就行 map[sum] = i; &#125; &#125; return ret;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Remove Boxes","slug":"Remove-Boxes","date":"2017-04-01T02:17:56.000Z","updated":"2018-12-16T14:08:06.393Z","comments":true,"path":"2017/04/01/Remove-Boxes/","link":"","permalink":"atlantic8.github.io/2017/04/01/Remove-Boxes/","excerpt":"","text":"题目描述Given several boxes with different colors represented by different positive numbers.You may experience several rounds to remove boxes until there is no box left. Each time you can choose some continuous boxes with the same color (composed of k boxes, k &gt;= 1), remove them and get k*k points.Find the maximum points you can get. Example 1 Input: [1, 3, 2, 2, 2, 3, 4, 3, 1] Output: 23 Explanation: [1, 3, 2, 2, 2, 3, 4, 3, 1] ----&gt; [1, 3, 3, 4, 3, 1] (3*3=9 points) ----&gt; [1, 3, 3, 3, 1] (1*1=1 points) ----&gt; [1, 1] (3*3=9 points) ----&gt; [] (2*2=4 points) Note: The number of boxes n would not exceed 100. 解题思路本题可以采用递归+memory（DP）的方法解决，思路是：使用数组map[i][j][k]表示从第i个元素到第j个元素，并且后面还有k个boxes[j]，也就是说现在至少有k+1个boxes[j]。对于i-j之间的满足boxes[p]=boxes[j]的元素，满足一下条件 \\begin{aligned} for\\;& p\\; with\\;boxes[p]==boxes[j]: \\\\ &map[i][j][k]=\\max_p(map[i][j][k], map[i][p][k+1]+map[p+1][r-1][0]) \\end{aligned}代码为：123456789101112131415161718int dfs(vector&lt;int&gt;&amp; boxes, int start, int end, int k, int map[100][100][100]) &#123; int ret=0; if (start &gt; end) return 0; if (map[start][end][k] &gt; 0) return map[start][end][k]; // 记录后面连续boxes[end]的数量 while (start&lt;end &amp;&amp; boxes[end-1]==boxes[end]) &#123;--end; ++k;&#125; map[start][end][k] = dfs(boxes, start, end-1, 0, map)+(k+1)*(k+1); for (int i=start; i&lt;end; i++) &#123; if (boxes[i] == boxes[end]) &#123; map[start][end][k]=max(map[start][end][k], dfs(boxes, start, i, k+1, map)+dfs(boxes, i+1, end-1, 0, map)); &#125; &#125; return map[start][end][k];&#125;int removeBoxes(vector&lt;int&gt;&amp; boxes) &#123; int map[100][100][100]=&#123;0&#125;; return dfs(boxes, 0, boxes.size()-1, 0, map);&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"DP","slug":"DP","permalink":"atlantic8.github.io/tags/DP/"},{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"word2vec","slug":"word2vec","date":"2017-03-31T02:50:31.000Z","updated":"2018-12-16T14:08:06.510Z","comments":true,"path":"2017/03/31/word2vec/","link":"","permalink":"atlantic8.github.io/2017/03/31/word2vec/","excerpt":"","text":"统计语言模型自然语言处理中的一个基本问题是计算一段文本序列在某种语言下出现的概率，统计语言模型给出了这一类问题的一个基本解决框架。 对于一段文本序列$S=w_1,…,w_T$，它的概率是 \\begin{aligned} P(S)=P(w_1,...,w_T)=\\prod_{t=1}^Tp(w_t|w_1,...,w_{t-1}) \\end{aligned}问题变成了如何去预测这些条件概率. Ngram上述模型的参数空间巨大，一个改进方法是Ngram，有 \\begin{aligned} p(w_t|w_1,...,w_{t-1}) \\approx p(w_t|w_{t-n+1},...,w_{t-1}) \\end{aligned}Ngram本质上是将词当做一个个孤立的原子单元去处理的，用ont-hot的方式向量化word，向量维度等于词典大小。Ngram及其他gram模型仍有局限性： 由于参数空间的爆炸式增长，它无法处理更长程的context 没有考虑词与词之间内在的联系性 Distributed Representation用ont-hot的方式向量化单词面临着维度灾难问题，能否用一个连续的稠密向量去刻画一个word的特征呢？这样不仅可以直接刻画词与词之间的相似度，还可以建立一个从向量到概率的平滑函数模型，使得相似的词向量可以映射到相近的概率空间上。这个稠密连续向量也被称为word的distributed representation. 在信息检索领域里，这个概念被称为向量空间模型（Vector Space Model），VSM是基于一种Statistical Semantics Hypothesis，比较广为人知的两个版本是Bag of Words Hypothesis和Distributional Hypothesis，分别表示 Bag of Words Hypothesis：一篇文档的词频（而不是词序）代表了文档的主题 Distributional Hypothesis：上下文环境相似的两个词有着相近的语义 基于Bag of Words Hypothesis，我们可以构造一个term-document矩阵$A$，矩阵里的元素$A_{ij}$代表着word $w_i$在文档$D_j$中出现的次数（或频率）。可以提取行向量做为word的语义向量。 基于Distributional Hypothesis，我们可以构造一个word-context的矩阵$B$，矩阵里的元素$B_{ij}$代表着word $w_i$在context $C_j$中出现的次数（或频率） 这种co-occurrence矩阵仍然存在着数据稀疏性和维度灾难的问题，解决方法是基于SVD的稀疏矩阵分解方法。 word2vec原理假设预料为$D=\\lbrace w_1,…,w_V \\rbrace$ CBoW模型（Continuous Bag-of-Words Model） CBoW的描述(N对应图中的|V|) 利用位置$t$前后的$2m$个words，以它们的one-hot编码$x_k$作为输入。通过一个共享的$n\\times N$投影矩阵$V$，将每个输入投影成$n$维词向量，$N$是词典大小。$v_{t+j}=Vx_{t+j},j\\in \\lbrace -m,…-1,1,…,m \\rbrace$这里的$V$矩阵最终包含的就是我们要的结果。 在PROJECTION层上，将$2m$个投影结果汇总（平均值，舍弃了位置信息）.$\\hat{v_t}=\\frac{1}{2m}\\sum_{j}v_{t+j},j\\in \\lbrace -m,…-1,1,…,m \\rbrace$，通过矩阵$U_{Nn}(U^T=[u_1,…,u_N])$连接到输出层。 最后是softmax层，$N$个节点，每个节点表示中心词是$w_i$的概率。输出层的输入向量为$z$，$z_i=u_i^T\\hat{v_t}$，输出结果为$y$，$\\hat{y_i}=softmax(z_i)$ 模型参数是两个词向量矩阵：$U,V$，对于中心词$w_t$，模型对它的损失函数为： \\begin{aligned} J_t&=-logP(w_t|w_{t-m},...,w_{t-1},w_{t+1},...,w_{t+m}) \\\\ &=-log(softmax(z_t)) \\\\ &=-log\\frac{e^{u_t^T\\hat{v_t}}}{\\sum_{k=1}^V e^{u_k^T\\hat{v_t}}} \\\\ &=-z_t+log\\sum_{k=1}^V e^{z_k} \\end{aligned}所以，整个模型的经验风险为 \\begin{aligned} J&=\\sum_{w_{t+m},w_{t-m}\\in D} J_t \\end{aligned}风险$J$对$U,V$的导数为： \\begin{aligned} \\frac{\\partial J}{\\partial u_i} &= (\\hat{y_i}-y_i)\\hat{v_t} \\\\ \\frac{\\partial J}{\\partial U^T} &= \\hat{v_t}(\\hat{y_t}-y)^T \\\\ \\frac{\\partial J}{\\partial v_{t+j}} &= \\frac{1}{2m}U^T(\\hat{y}-y) \\end{aligned}采取sgd更新方式，梯度下降。 Skip-gram Skip-gram以当前词为中心，预测window内的词语，细节图中描述的很清楚了。为了描述方便，不妨假设图中的矩阵$W,W{\\’}$分别为$U,V$。 由于输入向量$w_t$是one-hot向量(不妨假设第$k$行是1)，所以$Uw_t$就相当于$U$的第$k$列，在这里将其命名为$u_k$。经过$V$矩阵，得到$z=Vu_k,z_i=v_iu_k$，$v_i$是$V$的第$i$行。这里$V$也可以看成包含了所有单词对应向量的矩阵，$z$就表示了$u_k$和$V$中其他向量的相似度。最后对$z$做softmax归一化得到结果$y$(假设应该是$w_{t+1}$)，最大的对应输出。 假设真实的输出为$\\hat{y}$（one-hot，$p$行为1），损失函数使用交叉熵，则对这单个样例的损失函数为 \\begin{aligned} l(t,t+1)=-logy_p=-log\\frac{e^{v_iu_k}}{\\sum_ie^{v_iu_k}} \\end{aligned}所以一个句子的损失为 \\begin{aligned} L=-\\frac{1}{T}\\sum_{t=1}^T\\sum_{i=t-m}^{t+m}l(t,i) \\end{aligned}然后分别对$U,V$求导即可得到梯度。 Negative Sampling继续skip-gram模型，在计算$l(t,i)$的时候，需要计算$w_t$对应的向量与每一个其他向量的相似程度$v_iu_k$，softmax对于特别大的词汇计算量很大。 负采样的思想就是把这里计算其他所有词的相似度改成只计算一部分的相似度，具体地，将这里的类softmax分类的方法变成logistic regression的方法，当前词的context的词为正样本，然后采样一部分其余的词作为负样本。 也就是将$log\\frac{e^{v_iu_k}}{\\sum_ie^{v_iu_k}}$变成 \\begin{aligned} log\\;\\sigma(v_iu_k)+\\sum_{j=1}^n E_{w_i\\sim p_{neg}(w_t)}[log\\;\\sigma(-v_ju_k)] \\end{aligned}其中，$n$是超参数，表示负采样的数量，一般地，对小的训练集$n\\in [20,50]$；对大的数据集，$n$可能只有$[2,5]$之间。$ p_{neg}(w_t)$表示对$w_t$负采样的分布。启发式的采样方法可以如下： 随机选取非正样本$w_i$，然后以一定的概率舍弃之，这个概率是 \\begin{aligned} p(w_i)=1-\\sqrt{\\frac{c}{f(w_i))}} \\end{aligned}其中，$f(w_i)$是词$w_i$的词频，$c$是常数，一般在$10^{-5}$左右。这样选择，会过滤掉词频小于$c$的词，并且保证词频大的词语被选中的概率更大。 层次Softmax由于原始的CBoW和skip-gram最后都有softmax层，导致复杂度能达到O(nN)，Hierarchical Softmax是一种对输出层进行优化的策略，输出层从原始模型的利用softmax计算概率值改为了利用Huffman树计算概率值。 投影层的输出沿着huffman树不断进行logistic二分类，并修正各中间向量和词向量 词表中的全部词作为叶子节点，词频作为节点的权，叶子结点包含word本身 每一个非叶子结点都看作是一个logistic分类器，决定下一层的走向，它包含权值 从根节点出发，到达指定叶子节点的路径是唯一的 路过非叶子结点，修正logistic参数，并且累计误差，误差最后用来修正投影矩阵$V$ Hierarchical Softmax正是利用这条唯一路径来计算指定词的概率 实现过程中，可以 不考虑投影矩阵，而是将每个词对应的向量（投影后的）设置为随机向量 通过huffman的每一个节点时都计算累加误差，利用累计误差更新当前节点的LR参数 累计误差将被用来调整词向量 word2vec的应用广告投放U1 a1,a2,a3…… U2 a2,a3,a5,…… U3 a1,a3,a6,…… 公司A目前有很多用户的浏览数据，如用户u浏览了公司A的页面a1，a2，a3等。把每个用户的整体浏览记录当作一篇doc，每个记录就是一个word。利用word2vec算法，将每个记录转化为一个向量。向量化的页面就能够计算相似度，进而根据各种推荐规则进行推荐。 ctr预估模型CTR（Click-Through-Rate）即点击通过率，是互联网广告常用的术语，指网络广告（图片广告/文字广告/关键词广告/排名广告/视频广告等）的点击到达率，即该广告的实际点击次数（严格的来说，可以是到达目标页面的数量）除以广告的展现量（Show content）。 广告ctr计算存在冷启动的问题，冷启动问题就是一个广告是新上线的，之前没有任何的历史投放数据，这样的广告由于数据不足，点击率模型经常不怎么凑效。 解决方法：使用同类型广告点击率来缓解，拿一个同行的广告的各种特征作为这个广告的特征，对这个新广告的点击率进行预估。比如在媒体公司A上面有1000个广告主，它们的主页分别是a1、a2、……、a1000，运行word2vec得到每一个页面的向量，然后运行kmean或者其他聚类算法，把这1000个广告主聚成100个簇，然后每个簇里面的广告主看成是一个。 引用[1] word2vec前世今生[2] 深度学习word2vec笔记之应用篇[3] 自己动手写word2vec[4] word2vec的python实现","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"},{"name":"NLP","slug":"NLP","permalink":"atlantic8.github.io/tags/NLP/"}]},{"title":"Latent Dirichlet Allocation","slug":"Latent-Dirichlet-Allocation","date":"2017-03-31T02:16:10.000Z","updated":"2018-12-16T14:08:06.294Z","comments":true,"path":"2017/03/31/Latent-Dirichlet-Allocation/","link":"","permalink":"atlantic8.github.io/2017/03/31/Latent-Dirichlet-Allocation/","excerpt":"","text":"TF-IDF问题的起源是文档排名，就像使用搜索引擎那样，给定关键字，返回排好序的文档列表。既然提到排序，就肯定有衡量标准，给定关键词，一个文档的重要性或者说相关性如何度量呢？ TF首先，直观地，如果一篇文档中出现要查询的词的次数越多，相关性应该越大。于是很容易想到词频(TF)这个标准 词频TF(t)就是关键词t在文档中出现的次数 IDF但是仅仅考虑词频必然会出现问题，因为不同的词应该有不同的重要性，举个例子：在计算机科学类的paper中，出现算法和文学类paper中出现算法的重要性是不一样的，又或者“的”这个字在汉语中出现的次数相当大，一篇文档中没有“的”字的概率是很小的，此时仅仅按照关键词中的“的”判断文档排名显然是不准确的。于是，我们希望加大稀缺词的权重，所以定义了逆文档频率(IDF)，IDF的定义如下IDF(t) = log\\frac{N} {DF(t)}其中，$N$为文档总数，$DF(t)$为所有文档中出现了关键词$t$的文档个数。所以，越是普遍的单词（“的”，“因此”等）IDF越小，而稀缺的单词（如文学paper中的“算法”）就对应着比较大的IDF。 将TF和IDF结合到一起，得到TF-IDF的计算方法：TF-IDF(t,d) = TF(t,d) * IDF(t)所以，一篇文档和一条Query的相关度为Query中所有单词在这篇文档中的TF-IDF值之和。而两个文档间的相关度是文档向量的余弦值，余弦值越接近1，就表明夹角越接近0度，也就是两个向量越相似，这就叫”余弦相似性”。 TF-IDF的缺陷 单纯地认为文本频数小的单词就越重要，文本频数大的单词就越无用，并不是完全正确的 不能有效地反映单词的重要程度和特征词的分布情况，TF-IDF的精度并不是很高 没有体现出单词的位置信息，这也是空间向量模型的不足 主题模型TF-IDF模型中没有考虑文字背后的语义关联，即语义层面上的关联，可能在两个文档共同出现的单词很少甚至没有，但两个文档是相似的。判断文档相关性的时候需要考虑到文档的语义，而语义挖掘的利器是主题模型，LDA就是其中一种比较有效的模型。 主题模型的思想源于生成模型，其思想如下：一篇文章的每个词都是通过：以一定概率选择了某个主题，并从这个主题中以一定概率选择某个词语，形式化表述为p(word|doc)=\\sum_{topic}p(word|topic)\\times p(topic|doc)，具体内容在下文中描述。 能够发现文档-词语之间所蕴含的潜在语义关系（即主题）——将文档看成一组主题的混合分布，而主题又是词语的概率分布——从而将高维度的“文档-词语”向量空间映射到低维度的“文档-主题”和“主题-词语”空间，有效提高了文本信息处理的性能。 基础知识二项分布（Binomial distribution）$n$次重复伯努利试验，一次概率为$p$，$k$次试验概率函数为P(K=k)=C_n^kp^k(1-p)^{n-k}，二项分布计为$X\\sim b(n,p)$。 多项式分布每次试验可能有$k$种结果，每种结果的可能性是$p_i$，则$n$次试验各种结果出现次数分别为$x_1,…,x_k$的概率是 \\begin{aligned} P(x_1,...,x_k;n,p_1,...,p_k)=\\frac{n!}{x_1!...x_k!}p_1^{x_1}...p_k^{x_k} \\end{aligned}是二项分布的扩展。 gamma函数gamma函数形如\\Gamma(x)=\\int_0^{\\infty}t^{x-1}e^{-t}dt这个函数有如下性质$\\Gamma(x+1)=x\\Gamma(x)$，因此gamma函数可以看作是阶乘在实数集上的延拓\\Gamma(n)=(n-1)!此外，gamma函数还有如下性质 对$x\\in (0,1)$，$\\Gamma(1-x)\\Gamma(x)=\\frac{\\pi}{sin(\\pi x)}$ $\\Gamma(\\frac{1}{2})=\\sqrt{\\pi}$ 共轭先验分布定义设$\\theta$是总体分布中的参数，$p(\\theta)$是$\\theta$的先验密度函数，假如由抽样信息$x$算得的后验密度函数$p(\\theta|x)$与$p(\\theta)$有相同的函数形式(同一个分布簇)，则称$p(\\theta)$是$p(\\theta|x)$的(自然)共轭先验分布，称$p(\\theta)$和$p(\\theta|x)$为共轭分布。 Beta分布-二项分布的共轭先验分布给定参数$\\alpha&gt;0,\\beta&gt;0$，取值范围为$[0,1]$的随机变量$x$的概率密度函数为 \\begin{aligned} f(x;\\alpha,\\beta)&=\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}x^{\\alpha-1}(1-x)^{\\beta-1} \\\\ &=\\frac{1}{B(\\alpha,\\beta)} x^{\\alpha-1}(1-x)^{\\beta-1} \\end{aligned}则称$x$满足Beta分布，Beta分布的均值为$\\frac{\\alpha}{\\alpha+\\beta}$，方差为$\\frac{\\alpha\\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}$。参数$\\alpha,\\beta$共同控制Beta分布的函数的形状，见下图。 假定先验分布$p(\\theta)$和似然概率$p(x|\\theta)$满足 \\begin{aligned} p(\\theta)&=\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}\\\\&=\\frac{1}{B(\\alpha,\\beta)}\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1} \\\\ p(x|\\theta)&=C_n^k\\theta^k(1-\\theta)^{n-k} \\end{aligned}那么，考虑到$p(x)$为常数项，可知后验概率 \\begin{aligned} p(\\theta|x)&=\\frac{p(x|\\theta)p(\\theta)}{p(x)} \\\\ &= \\frac{1}{Z} \\theta^{\\alpha+k-1}(1-\\theta)^{\\beta+n-k-1}. \\end{aligned}所以，根据定义，$p(\\theta)$和$p(\\theta|x)$是共轭分布。 Dirichlet分布维度$k \\ge 2$的狄利克雷分布在参数$\\alpha_1, …, \\alpha_k &gt; 0$上，其概率密度函数为 \\begin{aligned} f(\\theta_1,..,\\theta_k;\\alpha_1,...,\\alpha_k)&=\\frac{1}{B(\\alpha)} \\prod_{i=1}^k\\theta_i^{\\alpha_i-1} \\\\ B(\\alpha) &= \\frac{\\prod_{i=1}^k\\Gamma(\\alpha_i)}{\\Gamma(\\sum_{i=1}^k\\alpha_i)} \\end{aligned}同上，假设$\\theta=(\\theta_1,…,\\theta_k)$有先验分布和似然函数,可以有 \\begin{aligned} p(\\theta)&= \\frac{1}{B(\\alpha)} \\prod_{i=1}^k\\theta_i^{\\alpha_i-1} \\\\ p(x|\\theta)&= \\frac{n!}{n_1!...n_k!}\\theta_1^{n_1}...\\theta_k^{n_k} \\\\ p(\\theta|x)&= \\frac{1}{Z} \\prod_{i=1}^k\\theta_i^{\\alpha_i+n_i-1} \\end{aligned}和Dirichlet分布形式一致。Dirichlet分布的均值向量为$\\left( \\frac{\\alpha_1}{\\sum_i^k \\alpha_i},…,\\frac{\\alpha_k}{\\sum_i^k \\alpha_i} \\right)$。 铺垫模型定义： $w$表示词，$V$表示所有单词的个数（固定值） $z$表示主题，$k$是主题的个数（预先给定，固定值） $D=(d_1,…,d_M)$表示语料库，其中$M$是语料库中的文档数（固定值） $d=(w_1,…,w_N)$表示一个文档，其中$N$表示一个文档中的词数（随机变量） Unigram model对于文档$d=(w_1,…,w_N)$，用$p(w_n)$表示$w_n$的先验概率，生成文档$d$的概率为p(d)=\\prod_{n-1}^Np(w_n)unigram model假设文本中的词服从Multinomial分布，而Multinomial分布的先验分布为Dirichlet分布。 上图中，$w_n$是在文本中观察到的第$n$个词，$p$和$α$是隐含未知变量,其中 $p$是词服从的Multinomial分布的参数 $\\alpha$是Dirichlet分布（即Multinomial分布的先验分布）的参数 一般$\\alpha$由经验事先给定，$p$由观察到的文本中出现的词学习得到，表示文本中出现每个词的概率。 Mixture of unigrams modelMixture of unigrams model生成过程是：给某个文档先选择一个主题，再根据该主题生成文档，该文档中的所有词都来自一个主题。假设主题有$z_1,…,z_k$，生成文档$d$的概率为 \\begin{aligned} p(d)=\\sum_zp(z) \\prod_{n=1}^N p(w_n|z) \\end{aligned} 如上图所示。 PLSA模型Mixture of unigrams model中假定一篇文档只由一个主题生成，可实际中，一篇文章往往有多个主题，只是这多个主题各自在文档中出现的概率大小不一样。PLSA是一种词袋模型，不关注词和词之间的出现顺序。 假设一组共现(co-occurrence)词项关联着一个隐含的主题类别$z_k\\in \\lbrace z_1,…,z_K \\rbrace$。同时定义 $p(d_i)$表示海量文档中某篇文档被选中的概率 $p(w_j|d_i)$表示词$w_j$在给定文档$d_i$中出现的概率 $p(z_k|d_i)$表示具体某个主题$z_k$在给定文档$d_i$下出现的概率 $p(w_j|z_k)$表示具体某个词$w_j$在给定主题$z_k$下出现的概率，与主题关系越密切的词，其条件概率越大 文档到词项的生成方法 按照概率$p(d_i)$选择一篇文档$d_i$ 选定文档$d_i$后，从主题分布中按照概率$p(z_k|d_i)$选择一个隐含的主题类别$z_k$ 选定$z_k$后，从词分布中按照概率$p(w_j|z_k)$选择一个词$w_j$ 整个过程便是：选定文档-&gt;生成主题-&gt;确定主题生成词。 发现文档集中的主题（分布） 如上图所示，文档$d$和单词$w$是可被观察到的（样本），但主题$z$却是隐藏的。因为$p(w_j|d_i)$是已知的(统计文档词频)，根据大量已知的文档-词项信息可以训练出$p(z_k|d_i),p(w_j|z_k)$。文档中每个词的生成概率为 \\begin{aligned} p(w_j,d_i) &= p(d_i)p(w_j|d_i) \\\\ &= p(d_i)\\sum_{k=1}^Kp(w_j|z_k)p(z_k|d_i) \\end{aligned}其中$p(d_i)$可事先计算求出，$p(z_k|d_i),p(w_j|z_k)$未知。 考虑词和词($N$)之间、文档($M$)和文档之间的独立性，则整个语料库中词的分布为 \\begin{aligned} p(w,D)=\\prod_{i=1}^M\\prod_{j=1}^Np(w_j,d_i)^{n(w_j,d_i)} \\end{aligned}其中$n(w_j,d_i)$表示词项$w_j$在文档$d_i$中出现的次数，$n(d_i)$表示文档$d_i$中词的总数，并且令$p(w_j|z_k)=\\phi_{kj},p(z_k|d_i)=\\theta_{ik}$将未知量矩阵化成$\\Phi,\\Theta$。所以得到对数似然函数 \\begin{aligned} l(\\Phi,\\Theta)&= \\sum_{i=1}^M\\sum_{j=1}^Nn(w_j,d_i)\\log p(w_j,d_i) \\\\ &= \\sum_{i=1}^M\\sum_{j=1}^Nn(w_j,d_i)\\left(\\log p(d_i)+\\log\\sum_{k=1}^Kp(w_j|z_k)p(z_k|d_i)\\right) \\\\ &= \\sum_{i=1}^Mn(d_i)\\left( \\log p(d_i)+ \\sum_{j=1}^N \\frac{n(w_j,d_i)}{n(d_i)} \\log\\sum_{k=1}^K \\phi_{kj}\\theta_{ik} \\right) \\\\ &\\propto \\sum_{i=1}^M \\sum_{j=1}^N n(w_j,d_i) \\log\\sum_{k=1}^K \\phi_{kj}\\theta_{ik} \\\\ & \\ge \\sum_{i=1}^M \\sum_{j=1}^N n(w_j,d_i) \\sum_{k=1}^K p(z_k|d_i,w_j) \\log(\\phi_{kj}\\theta_{ik}) \\end{aligned}含有隐含变量的优化可以使用EM算法求解，很复杂，不具体写了E步 \\begin{aligned} p(z_k|d_i,w_j)&=\\frac{p(z_k,d_i,w_j)}{\\sum_{l=1}^Kp(z_l,d_i,w_j)}=\\frac{\\phi_{kj}\\theta_{ik}}{\\sum_{l=1}^M\\phi_{lj}\\theta_{il}} \\end{aligned}M步经过E步，还需考虑约束条件，即 \\begin{aligned} \\sum_{j=1}^N\\phi_{kj}&=1 \\\\ \\sum_{k=1}^K\\theta_{ik}&=1 \\end{aligned}用拉格朗日乘子法解得 \\begin{aligned} \\phi_{kj} &= \\frac{\\sum_{i=1}^M n(d_i,w_j)p(z_k|d_i,w_j)} {\\sum_{i=1}^M\\sum_{j=1}^N n(d_i,w_j)p(z_k|d_i,w_j)} \\\\ \\theta_{ik} &= \\frac{\\sum_{j=1}^N n(d_i,w_j)p(z_k|d_i,w_j) }{n(d_i)} \\end{aligned}这样就求解出了$\\Phi,\\Theta$。PLSA的模型示意如下图所示: LDA(Latent Dirichlet Allocation)LDA在pLSA的基础上加层贝叶斯框架，在贝叶斯框架下的LDA中，我们不再认为主题分布（各个主题在文档中出现的概率分布）和词分布（各个词语在某个主题下出现的概率分布）是唯一确定的（而是随机变量）。这体现了贝叶斯派的核心思想，把未知参数当作是随机变量，不再认为是某一个确定的值。即选主题和选词依然都是两个随机的过程。 LDA需要两个Dirichlet先验参数，这个Dirichlet先验为某篇文档随机抽取出某个主题分布和词分布。 LDA模型中文档生成方式 $\\alpha$是主题分布的先验分布，$\\beta$是词分布的先验分布。 按照先验概率$p(d_i)$选择一篇文档$d_i$ 从Dirichlet分布$\\alpha$中取样生成文档$d_i$的主题分布$\\theta_i$，换言之，主题分布$\\theta_i$由超参数为$\\alpha$的Dirichlet分布生成 从主题的多项式分布$\\theta_i$中取样生成文档$d_i$第$j$个词的主题$z_{ij}$ 从Dirichlet分布$\\beta$中取样生成主题$z_{ij}$对应的词语分布$\\phi_{z_{ij}}$，换言之，词语分布$\\phi_{z_{ij}}$由参数为$\\beta$的Dirichlet分布生成 从词语的多项式分布$\\phi_{z_{ij}}$中采样最终生成词语$w_{ij}$ 示意图如下: LDA在pLSA的基础上给这两参数$p(z_k|d_i),p(w_j|z_k)$加了两个先验分布的参数（贝叶斯化）：一个主题分布的先验分布Dirichlet分布$\\alpha$，和一个词语分布的先验分布Dirichlet分布$\\beta$。这里$\\alpha,\\beta$都是参数向量。 LDA生成文档的过程中，先从dirichlet先验中“随机”抽取出主题分布，然后从主题分布中“随机”抽取出主题，最后从确定后的主题对应的词分布中“随机”抽取出词。虽说是随机取值，但是不同的参数$\\alpha,\\beta$导致可选值的分布是不一样的，如下图所示 LDA发现文档集中的主题文档生成后，LDA把这两参数$p(z_k|d_i),p(w_j|z_k)$变成随机变量，且加入dirichlet先验。 在pLSA中，我们使用EM算法去估计“主题-词项”矩阵和“文档-主题”矩阵：$\\Phi,\\Theta$，这两参数都是个固定的值。在LDA中，估计$\\Phi,\\Theta$这两未知参数可以用变分(Variational inference)-EM算法，也可以用gibbs采样，前者的思想是最大后验估计MAP（MAP与MLE类似，都把未知参数当作固定的值），后者的思想是贝叶斯估计。 Gibbs采样Gibbs抽样是马尔可夫链蒙特卡尔理论（MCMC）中用来获取一系列近似等于指定多维概率分布（比如2个或者多个随机变量的联合概率分布）观察样本的算法。 给定一个文档集合，$w$是可以观察到的已知变量，$\\alpha,\\beta$和是根据经验给定的先验参数，其他的变量$z，\\Theta和\\Phi$都是未知变量。 求解$\\Theta,\\Phi$的过程很复杂，最终求解的Dirichlet分布期望为： \\begin{aligned} \\phi_{kt}&=\\frac{n_k^{t}+\\beta_t} {\\sum_{t=1}^V(n_k^{t}+\\beta_t)} \\\\ \\theta_{mk}&=\\frac{n_m^{k}+\\alpha_k}{\\sum_{k=1}^K(n_m^{k}+\\alpha_k)} \\end{aligned}其中，$\\phi_{kt}=p(w_t|z_k),\\theta_{mk}=p(z_k|d_m)$，$n_t^k$是词$w_t$在主题$z_k$中出现的次数，$n_m^k$是主题$z_k$在文章$d_m$中出现的次数。 引用[1] LDA-math-神奇的Gamma函数[2] 共轭先验分布[3] 通俗理解LDA主题模型[4] 关于Beta分布、二项分布与Dirichlet分布、多项分布的关系","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"},{"name":"NLP","slug":"NLP","permalink":"atlantic8.github.io/tags/NLP/"}]},{"title":"Prime Factor Index in Factorial","slug":"Prime-Factor-Index-in-Factorial","date":"2017-03-18T02:37:24.000Z","updated":"2018-12-16T14:08:06.383Z","comments":true,"path":"2017/03/18/Prime-Factor-Index-in-Factorial/","link":"","permalink":"atlantic8.github.io/2017/03/18/Prime-Factor-Index-in-Factorial/","excerpt":"","text":"题目的中文翻译是：阶乘中质因数的指数。比如说一道谷歌面试题，求2014!尾部0的个数. 求尾部0的个数，也就是求这个数中质因子5的个数，有定理 在$n!$ 中质因子$p(p&lt;=n)$的指数为：$h=[\\frac{n}{p}]+[\\frac{n}{p^2}]+…$，其中[]表示取整符号。 所以2014!中5的指数是 \\begin{aligned} &\\left[\\frac{2014}{5}\\right]+\\left[\\frac{2014}{25}\\right]+\\left[\\frac{2014}{125}\\right]+\\left[\\frac{2014}{625}\\right] \\\\ &= 402+80+16+3 \\\\ &= 501 \\end{aligned}","categories":[{"name":"Other","slug":"Other","permalink":"atlantic8.github.io/categories/Other/"}],"tags":[{"name":"Math","slug":"Math","permalink":"atlantic8.github.io/tags/Math/"}]},{"title":"Cpp Rule Fragment3","slug":"Cpp-Rule-Fragment3","date":"2017-03-16T02:05:38.000Z","updated":"2018-12-16T14:08:06.207Z","comments":true,"path":"2017/03/16/Cpp-Rule-Fragment3/","link":"","permalink":"atlantic8.github.io/2017/03/16/Cpp-Rule-Fragment3/","excerpt":"","text":"模板与泛型编程定义模板 函数模板可以定义为inline、constexpr，关键字位置应该在模板参数列表之后，返回类型之前 编译器遇到模板时不生成代码，只有在实例化特定版本（使用）时，编译器才会生成代码 使用普通类对象时，类定义必须可用但成员函数的定义不必已经出现，因此类定义和函数声明放在头文件，函数、类成员函数定义在源文件。但实例化模板时，编译器需要知道模板定义，所以函数模板、类模板的定义通常放在头文件中 大多数编译错误在实例化时期报告 1234567template &lt;typename T&gt; // typename有的也写做class，意义相同.....template &lt;typename T&gt;inline T sort(const T&amp;, const T&amp;); // okinline template &lt;typename T&gt; T sort(const T&amp;, const T&amp;); // wrong 非类型模板参数 非类型模板参数表示值，而非类型 非类型模板参数被用户提供的或者编译器推断的值替代，这些实参值必须是常量表达式 非类型参数可以是整型（实参必须是常量表达式），指向对象或函数类型的指针、左值引用（实参必须具有静态生存期（局外变量、静态变量、栈）） 类模板 类的作用域包括：类定义中，源文件类成员函数的函数体内({}之内) 类的作用域中，编译器处理模板自身引用时可以不带类型名 1234567891011121314template &lt;typename T&gt;void Blob&lt;T&gt;::check (const T&amp; t1, const T&amp; t2) &#123; // ......&#125;// 类作用域中Blob&lt;T&gt;&amp; func(); // okBlob&amp; func(); // ok// 之外Blob&amp; func &#123; // wrong Blob ret = *this; // ok, in scope ... return ret;&#125; 类模板和友元 如果类模板包含非模板友元，则该友元可以访问所有模板实例 如果类模板包含模板友元，类可以授权给所有模板实例，也可以只授权给特定实例 12345template &lt;typename T&gt;class A &#123;friend B&lt;T&gt;; // 授权给特定实例，要求类型相同friend C&lt;F&gt;; // 授权给所有模板实例&#125; 模板类型别名1234567typedef Blob&lt;string&gt; strBlob;// 为类模板定义一个类型别名template&lt;typename T&gt; using twin = pair&lt;T, T&gt;;twin&lt;int&gt; p; // 定义类型为&lt;int, int&gt;类型// 可以固定一个、多个模板参数template&lt;typename T&gt; using partNo = pair&lt;T, unsigned&gt;; 静态成员 模板的static成员也定义成模板，每个模板的实例都可以有一个自己的静态成员 template&lt;typename T&gt; size_t Foo&lt;T&gt;::ctr = 0; 通过引用特定实例、作用域运算符访问成员Foo&lt;int&gt;::ctr; 模板参数 模板内不能重用模板参数名 模板声明必须包含模板参数 使用模板类型参数的类型成员，必须通过关键字typename(class不行)显式地告诉编译器该名字是一个类型 123T::size_type *p; // 可以是定义指向size_type类型的指针，也可以是T的静态成员乘以p的结果typename T::size_type *p; // 定义指向size_type类型的指针 成员模板 成员模板不能是虚函数 实例化类模板的成员模板，必须同时提供类和函数模板的实参Blob&lt;int&gt; a1(vi.begin(), vi.end()); 123456class Blob &#123;template&lt;typename T&gt; void func(const T&amp;);&#125;string s = \"hello\";Blob b;b.func(s); 12345template&lt;typename T&gt; class Blob &#123;template&lt;typename F&gt; Blob(const F&amp;);&#125;string s = \"hello\";Blob&lt;int&gt; b(s); 控制实例化 模板在使用时才会实例化，多个文件中的模板实例化可能会造成严重额外开销 通过显示实例化避免开销，编译器遇到extern模板声明时就不会在本文件中生成实例化代码 类模板的实例化会实例化所有成员（包括内联）（和普通类不同） 12extern template declaration; // 实例化声明template declaration; // 实例化定义 模板实参推断模板转换 如果函数形参使用了模板类型参数，其采用特殊的初始化规则 编译器通常不是对实参进行类型转换，而是生成一个新的模板实例，例外在下面 const转换，忽略顶层const 数组、函数指针转换（函数形参不能为引用类型） 显式模板实参、remove_reference 显式模板参数在&lt;&gt;中给出，函数名后，参数列表之前 显式模板实参按从左向右的顺序与对应的模板参数匹配，尾部的可以忽略 123456789101112131415161718192021template&lt;typename T1, typename T2, typename T3&gt;T1 func(T2, T3); // badT1 func&lt;int&gt;(T2, T3); // T1 is intT1 func&lt;int, string&gt;(T2, T3); // T1 is int, T2 is stringtemplate&lt;typename T1, typename T2, typename T3&gt;T3 func(T2, T1); // wrongT3 func&lt;int&gt;(T2, T1); // wrong, T3是int，但不能推断T1、T2T3 func&lt;int, int, int&gt;(T2, T1); // ok// 尾后类型的使用template&lt;typename T&gt;auto func(T beg, T end) -&gt; decltype(*beg) &#123; return *beg;&#125;// 上面迭代器返回的是引用，如果希望返回原来类型，如下template&lt;typename T&gt;auto func(T beg, T end) -&gt; typename remove_reference&lt;delctype(*beg)&gt;::type &#123; return *beg; // 返回元素的拷贝&#125; 其中，remove_reference&lt;T&amp;&gt;将得到原本的T类型，类型由其类型成员type表示","categories":[],"tags":[{"name":"Cpp","slug":"Cpp","permalink":"atlantic8.github.io/tags/Cpp/"}]},{"title":"Sunday","slug":"Sunday","date":"2017-03-15T14:01:25.000Z","updated":"2018-12-16T14:08:06.422Z","comments":true,"path":"2017/03/15/Sunday/","link":"","permalink":"atlantic8.github.io/2017/03/15/Sunday/","excerpt":"","text":"算法描述Sunday算法是用于字符串匹配的算法，平均复杂度为O(n)，平均效率高于KMP和BM。 示例如下：匹配时，从左到右匹配，第一个字符不匹配，看模式串后一位t对应的字符，因为t位的字符也总是要匹配的。所以我们需要查找t位字符在模式串中最右侧的位置，然后移动模式串。如果t位的字符在模式串中不存在，那么移动模式串首到当前模式串尾部的下一个位置。 suck kmy balls kmy 对齐字母k，如下 suck kmy balls kmy 还不匹配，继续 suck kmy balls kmy 匹配出现，记录下。然后再看下一个字符 ，其在模式串没出现，移动模式串到 suck kmy balls kmy 依此类推，直到结束。 下面看一下具体移动的步长，设当前p和s的位置分别在pi和si，p结尾的最后一个位置对应于s中序号为skey = si+p.length()-pi的位置： 如果skey中的字符在模式串p中没有，则将pi=0，si移到skey+1位置 否则，要令skey与p中对应的最右相同元素对齐，设p中序号为k的元素满足条件，si需要移动变成skey-k=si+p.length()-pi-k，同样地pi=0 代码sunday算法需要维护一个数组，记录s串中下一个字符为x时模式串移动的距离。命其名为next1234567891011121314151617181920void get_next(string p, vector&lt;int&gt; &amp;next) &#123; for (int i=0; i&lt;p.length(); i++) &#123; next[p[i]] = p.length()-i; // 模式串有的字符 &#125;&#125;void sunday(string s, string p) &#123; vector&lt;int&gt; next(255, p.length()+1); // 默认不存在模式串中的字符对应的移动长度为p.length()+1 get_next(); int si=0, pi=0; while (si+p.length() &lt; s.length()) &#123; pi = 0; for (pi=0; pi&lt;p.length(), s[si++] != p[pi]; pi++); // matching if (pi == p.length()) // match found cout &lt;&lt; \"match found, index is \" &lt;&lt; si-p.length()+1 &lt;&lt; endl; int skey = si + p.length() - pi; if (skey &gt;= s.length) break; si += next(s[skey]) - pi; &#125;&#125;","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"String","slug":"String","permalink":"atlantic8.github.io/tags/String/"}]},{"title":"K-Nearest Neighbor","slug":"K-Nearest-Neighbor","date":"2017-03-07T02:08:37.000Z","updated":"2018-12-16T14:08:06.281Z","comments":true,"path":"2017/03/07/K-Nearest-Neighbor/","link":"","permalink":"atlantic8.github.io/2017/03/07/K-Nearest-Neighbor/","excerpt":"","text":"KNNKNN的算法思想非常简单，不赘述。K值的选择有讲究，一般使用交叉验证的方法来确定K值。 KD树KNN naive的实现实现方法是线性扫描法，但是这种方法效率很差，训练集很大时非常耗时。好一点的方法是使用一个最大堆，时间复杂度为$O(nlogK)$。 下面介绍基于树的方法：kd树。 kd树是二叉树，表示对k维空间的一个划分。相当于不断地用垂直于坐标轴的超平面将k维空间切分，构成一系列的超矩形区域。 kd树的构造方法如下： 输入：数据集$D=\\lbrace x_1,x_2,…,x_n \\rbrace$其中$x_i=(x_i^{(1)},…,x_i^{(k)})$为$k$维空间的样本 1) 构造根结点，根节点对应于包含$D$的$k$维空间超矩形区域。选择$x^{(1)}$为坐标轴，以$D$中所有样本的$x^{(1)}$坐标的中位数作为切分点，切成两部分。落在超平面上的点保存在根节点，在超平面左侧、右侧的节点分别根节点深度为1的左右孩子。2) 重复：对深度为$j$的节点，选择$x^{(l)}$作为切分的坐标轴，满足$l=j\\; mod\\; k + 1$，坐标轴轮流选，一轮完了再重复.3) 迭代停止条件：如果一个节点的左右孩子中都没有样本，那么停止迭代 输出：kd树 下面介绍使用kd树进行k近邻搜索，使用最大堆辅助结构 输入：已构造的kd树，目标点$x$，近邻数$K$，空最大堆$hp$ 从根节点出发，递归地向下访问kd树，若目标$x$当前维的坐标小于切分点的坐标，则移动到左子结点，否则移动到右子结点，直到结点为叶节点为止。对每一个路过的节点，添加元素维护最大推（留下小的）。 递归的向上回退，在每个节点$p$进行以下操作 检查该结点未被访问过的结点$p_c$对应的区域是否有比堆顶元素更近的点或堆容量未满。具体的，检查$p_c$对应的区域是否与以目标点为求心、以目标点与堆顶元素距离为半径的球体相交 如果相交或$hp$容量未满，以$p_c$结点为根节点执行1，否则继续回溯 当对根节点的回溯完成以后，结束 输出：最大堆$hp$内元素即为$s$的$K$近邻 kd树更适用于训练实例数远大于空间维度数时的计算，空间维度接近训练实例数时，效率会迅速下降，几乎接近线性扫描。","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"Cpp Rule Fragment2","slug":"Cpp-Rule-Fragment2","date":"2017-03-06T07:28:49.000Z","updated":"2018-12-16T14:08:06.204Z","comments":true,"path":"2017/03/06/Cpp-Rule-Fragment2/","link":"","permalink":"atlantic8.github.io/2017/03/06/Cpp-Rule-Fragment2/","excerpt":"","text":"左右的概念左值、右值C++中左值与右值这两概念是从 c 中传承而来的，在 c 中，左值指的是既能够出现在等号左边也能出现在等号右边的变量(或表达式)，右值指的则是只能出现在等号右边的变量(或表达式) 在 C语言中，通常来说有名字的变量就是左值(如 a, b)，而由运算操作(加减乘除，函数调用返回值等)所产生的中间结果(没有名字)就是右值，如 3 + 4， a + b 等。 在 C++ 中，每一个表达式都会产生一个左值，或者右值，相应的，该表达式也就被称作“左值表达式”， “右值表达式”。对于内置的基本数据类型来说，左值右值的概念和 c 没有太多不同，不同的地方在于自定义的类型，具体如下： 对于内置的类型，右值是不可被修改的(non-modifiable)，也不可被 const, volatile 所修饰（volatile关键字的作用是防止优化编译器把变量从内存装入CPU寄存器中，保证每次取的值都是内存中值） 对于自定义的类型(user-defined types)，右值却允许通过它的成员函数进行修改2左值引用、右值引用 左值引用，Type &amp; 左值引用名 = 左值表达式; 声明时必须初始化，初始化之后无法在改变；对别名的一切操作都等价于对原来变量的操作。 右值不能赋值给左值引用，加上const限定符即可 c++中临时变量默认const属性，所以只能传给const引用(延长生命周期) 右值引用，Type &amp;&amp; 右值引用名 = 右值表达式; 可以直接把左值或者右值转换成右值引用，但转换后原对象就不能使用了 123456int val = 10;int &amp; a1 = val+1; // 错误，此时val+1（中间结果用const型的临时变量保存）等价于右值，右值不能赋值给左值引用const int&amp; a2 = val+1; // 正确const int&amp; a3 = 10; // 正确int &amp;&amp; a4 = std::move(val+1); // 正确 动态内存与智能指针 智能指针负责自动释放所指向的对象，定义在memory头文件中 智能指针也是模板，创建智能指针时需要提供类型信息 智能指针的使用与普通指针类似 包括shared_ptr（允许多个指针指向同一个对象）、unique_ptr（独占所指向的对象）、weak_ptr（指向shared_ptr所指向的对象） 注意事项 不用相同的内置指针初始化多个智能指针 不delete get函数返回的值 不用get返回值初始化/reset另一个智能指针 如果智能指针管理的资源不是new分配的资源，需要传给他一个删除器 shared_ptr123456shared_ptr&lt;T&gt; sp; // 空指针if (p) // 如果p指向一个对象则为true*pp-&gt;memp.get() // 返回p中保存的指针swap(p, q) // 交换p和q中的指针 不要将get函数得到的内置指针用于初始化其他智能指针，可能会导致两个智能指针指向同一个对象，且他们的计数器都为1以上操作也适用于unique_ptr，下面的操作则是shared_ptr独占：12345make_shared&lt;T&gt; (args) // 返回一个shared_ptr, 指向类型T的动态内存对象，使用args初始化shared_ptr&lt;T&gt;p(q) // p是q的拷贝；q中的计数器加一，要求q中的指针必须能转化位T*p = q // p,q都是shared_ptr，保存的指针必须能相互转换。p的引用计数器递减，q的递增。若p的引用计数器变为0，则将其管理的资源释放p.unique() // 若p.use_count()为1，返回true；否则返回falsep.use_count // 返回与p共享对象的智能指针个数；一般用于调试 123456auto p1 = new auto(obj); // p指向一个与obj类类型相同的对象，该对象用obj初始化auto p2 = new auto&#123;a,b,c&#125;; // 错误，括号中只能有单个初始化器// 内存耗尽时new操作会抛出bad_alloc异常，下面的方法可以避免抛出异常int *p = new (notthrow) int; // 内存耗尽时返回空指针 delete空指针没有问题 delete之后应该重置指针 shared_ptr和new 可以使用new返回的指针初始化智能指针 接受指针参数的智能指针构造函数为explicit（不准指针隐式转换），必须使用直接初始化形式 123456789shared_ptr&lt;int&gt; p(new int(42));shared_ptr&lt;int&gt; p1 = new int(42); // 错误，可以使用resetshared_ptr&lt;T&gt; p(u); // p从unique_ptr接管对象所有权，将u置空shared_ptr&lt;T&gt; p(q, d) // p接管内置指针q所指向的对象，q必须能转换为T*，p使用可调用对象d代替deletep.reset() // 若p是唯一指向其对象的shared_ptr，reset释放该对象p.reset(q) // 若传递了参数内置指针q，令p指向q，否则将p置空p.reset(q, d); // 有d则使用可调用对象代替delete unique_ptr 一个对象只能有一个unique_ptr，不支持拷贝（除非是返回即将要销毁或局部对象的拷贝）、赋值 必须采用直接初始化形式 123456789unique_ptr&lt;T, D&gt; u // D为可调用对象，用来释放内存unique_ptr&lt;T, D&gt; u(d) // 用d代替Du = nullptr // 释放u指向的对象，将u置空u.release() // u交出控制权，返回内置指针，将u置空u.reset() // 释放u指向的对象u.reset(q) // 提供内置指针q，则令u指向这个对象；否则将u置空u.reset(nullptr) unique_ptr和动态数组123unique_ptr&lt;T[]&gt; u; // u指向一个动态分配的数组unique_ptr&lt;T[]&gt; u(p); // u指向内置指针p指向的动态动态分配的数组，p类型必须能转换为T*u[i]; // 访问数组 shared_ptr没有提供管理动态数组的功能，需要使用需要自己定义删除器。 weak_ptr 不能控制对象生存周期，指向由shared_ptr管理的对象，切不改变shared_ptr引用计数 需要用shared_ptr初始化 指向对象可能被释放掉，所以不能直接访问 123456789101112weak_ptr&lt;T&gt; w(sp); // 初始化w = p; // p可以是weak_ptr或shared_ptr，赋值后两者共享对象w.reset() // w置空w.use_count() // 与w共享对象的shared_ptr的数量w.expired() // w.use_count() == 0返回truew.lock() // w.expired() 为true返回一个空shared_ptr，否则返回一个与w共享对象的shared_ptr// 访问if (shared_ptr&lt;int&gt; np = w.lock()) &#123; // np不为空成立 // 使用np访问对象&#125; allocator类 定义在memory头文件中，是一个模板 allocator分配的内存都是未构造的 123456allocator&lt;T&gt; a;a.allocate(n); // 分配一段原始的、未构造的内存，保存n个类型为T的对象a.deallocate(p, n); // 释放从T*类型的指针p开始的内存，这块内存保存了n个T类型对象；p必须是由allocate函数返回的指针，n必须是p创建时要求的大小。调用之前，必须对这n个T对象调用destorya.construct(p, args); // p必须是类型为T*的指针，指向一块原始内存，args被传递给类型为T的构造函数，用来在p指向的内存中构造一个对象a.destory(p) // 对p指向的对象指向析构函数 构造、填充未初始化内存的算法1234567uninitialized_copy(b, e, b2); // 拷贝迭代器b、e指定范围元素到b2指定的未构造的原始内存中，b2指向的内存必须足够大uninitialized_copy_n(b, n, b2); // 从b开始，n个元素uninitialized_fill(b, e, t); // 拷贝值均为tuninitialized_fill_n(b, n, t);// 这几个算法都返回下一个未初始化的内存位置 拷贝控制拷贝、赋值与销毁拷贝构造函数 成员类型决定拷贝方式，内置类型直接拷贝，类类型需要拷贝构造函数来拷贝 不应该是explicit的 参数是自身类类型的引用 编译器会为我们定义一个（如果我们没有定义） 拷贝初始化发生的时间不仅在用=定义变量时，也会发生在： 将对象作为实参传递给非引用类型的形参 从返回非引用类型的函数返回一个对象 用花括号列表初始化一个数组中的元素或一个聚合类中的成员 拷贝赋值运算符 编译器会为我们定义一个（如果我们没有定义） 析构函数 编译器会为我们定义一个（如果我们没有定义） 一般为空，成员是在析构函数体之后隐含的析构阶段被销毁的 某些类中，析构函数也被用来阻止该类型的对象被销毁 需要析构函数的类也需要拷贝、赋值操作 使用=default 将拷贝控制成员定义为=default可以显式地要求编译器生成合成的版本 类内使用`=default’修饰的成员将隐式地声明为内联的 如果不希望内联，则只对类外的定义使用=default。 阻止拷贝 在函数第一次声明后面写上=delete表示删除的函数，不希望定义这些成员 拷贝构造函数、拷贝赋值运算符定义为删除的函数可以阻止拷贝 析构函数不能是删除的成员，因为存在对象无法销毁的问题 但如果你真的这么干了：如果一个类有数据成员不能默认构造、拷贝、复制、销毁，则对应的成员函数将被定义为删除的 动态内存管理类 在运行时分配可变大小内存的空间 以vector为例，添加元素的成员函数检查是否有更多空间，没有则申请新的空间，将已有元素移到新空间，释放旧空间，添加新元素 移动构造函数和std::move 移动构造函数通常是将资源从给定对象“移动”而不是拷贝到正在创建的对象 调用标准库函数move（utility头文件）表示希望使用移动构造函数 右值引用 右值引用是指必须绑定到右值的引用，通过&amp;&amp;获得 右值引用只能绑定到将要销毁的对象，因此可以将一个将要销毁的资源移动到另一个对象中 左值引用不能绑定到要求转换的表达式、字面常量、返回右值的表达式（变量是左值） 右值引用有相反的要求；一般右值生命周期短（字面常量、临时对象等） 通过move函数显式地将左值转换为对应的右值引用类型，使用move不用using声明，直接用std::move 右值引用做形参时不能为const，因为需要窃取他的数据 1234int &amp;&amp;r1 = 42; // correctint &amp;&amp;r2 = r1; // wrong, 变量表达式r1是左值// 调用move后，意味着除了对r1赋值、销毁外，将不再使用它int &amp;&amp;r3 = std::move(r1); // ok 移动构造函数、移动赋值运算符 移动构造函数的第一个参数是该类型的一个右值引用 必须确保移动后，源对象处于销毁无害的状态，也就是说源对象必须不再指向被移动的资源（指针置为nullptr，因为源对象可以被销毁，如果它的指针还指向被移动的资源，执行析构函数时就会将被移动的资源释放） 移动操作通常不抛出异常。编写不抛出异常的移动操作，应该使用noexcept通知标准库，免去其为了处理可能存在的异常做的额外工作（可能出现异常的还是不要写比较好） noexcept出现在参数列表之后；如果是构造函数，其在初始化列表的:之前 123456789101112A::A(A &amp;&amp;a) noexcept : x(a.x), y(x.y) &#123; a.x = a.y = nullptr;&#125;A &amp;A::operator=(A &amp;&amp; a) noexcept &#123; if (this == &amp;a) return *this; // 自赋值 free(); // 释放现在对象的资源 x = a.x; y = a.y; a.x = a.y = nullptr; // 重置源对象的指针 return *this;&#125; 只有当一个类没有定义任何自己版本的拷贝控制成员，且类的每个非static数据成员都可以移动时，编译器才会为它合成移动构造函数或移动赋值运算符。编译器可以移动内置类型的成员；也可以移动有对应移动操作的类成员 移到构造函数永远不会隐式地定义为删除的函数（delete） 如果显式要求编译器生成=default的移动操作，但编译器不能移动所有成员，则编译器将移动操作定义为删除的 类本身的析构函数为删除的、不可访问的，则其移动构造函数为删除的 如果类成员是const的或者是引用，则类的移动赋值运算符定义为删除的 12345678910struct X &#123; int i; // 内置成员可以移动 std::string s; // string有自己的移动操作&#125;;struct Y &#123; X mem; // X有合成移动操作&#125;;X x1, x = std::move(x1); // 合成移动构造函数Y y1, y = std::move(y1); // 使用合成移动构造函数 既有拷贝构造函数也有移动构造函数时，遵循移动右值，拷贝左值的方法 没有移动构造函数时，右值也被拷贝 1234A a1, a2;a1 = a2; // a2是左值，使用拷贝A getA(istream&amp; is); // 函数getA返回一个右值a2 = getA(); // 返回右值，使用移动赋值 移动迭代器 一般的迭代器解引用操作返回一个指向元素的左值，移动迭代器的解引用操作生成一个右值引用 调用make_move_iterator将一个普通迭代器转化为一个移动迭代器，原迭代器的所有操作在移动迭代器中都正常工作 123auto first = alloc.allocate(new_capacity);// 使用移动构造函数来构造每个元素auto last = uninitialized_copy(make_move_iterator(begin()), make_move_iterator(end()), first); 右值、左值引用成员函数、重载和引用函数 类成员函数的参数列表后可以放置&amp;或&amp;&amp;，称为引用限定符 引用限定符指出this可以指向一个左值或右值 引用限定符只能用在非static成员函数中（类似const限定符），且必须在声明、定义中都出现 引用限定符就是限制调用成员函数的对象有引用限定 &amp;限定的函数，只能将这个函数用于左值；&amp;&amp;则只能用于右值 同时有const限定符的函数，引用限定符应该在const限定符之后const &amp; 引用限定符可以区分重载版本（const也可以），表示其对象是右值还是左值 定义两个及以上具有相同名字和参数列表的函数，就必须对所有函数加上引用限定符，或者所有都不加。（有的加，有的不加不行） 右值执行排序，可以直接进行，因为右值没有其他用户，可以改变；但是，对const右值、左值进行排序时，不能改变对象，所以先拷贝再排序。 重载运算与类型转换 运算符作用域内置类型的运算对象时，运算符的含义无法改变（不能重载） 只能重载已有的运算符 不能被重载的运算符包括:: .* . ?: 下标运算符[]返回的是元素的引用 输入输出运算符 输入、输出运算符必须是非成员函数 一般地，重载输出运算符&lt;&lt;函数的第一个参数是一个非常量ostream对象引用（非常量是因为向流写入内容会改变其状态，引用是因为ostream不能拷贝），第二个参数一般是要打印对象的常量引用；函数返回ostream的形参 重载输入运算符函数的第二个参数非常量对象的引用，返回istream的形参 重载输入运算符要处理可能失败的情况，输出则不需要 123456789ostream&amp; operator&lt;&lt;(ostream&amp; os, const A&amp; a) &#123; // ... return os;&#125;istream&amp; operator&gt;&gt;(istream&amp; is, A&amp; a) &#123; // .... 包括处理失败情况 return is;&#125; 递增递减运算符 区分前置、后置的办法是：后置版本有一个不被使用的int类型形参 后置版本需要先记录对象的状态，操作完成后返回之前记录的状态 后置运算符返回对象的原值，不是引用 显式调用后置运算符需要多加一个参数: a.operator++(0); 12345678A&amp; operator++(); // 前置A operator++(int); // 后置，有形参，返回原值A A::operator++() &#123; A ret = *this; ++*this; return ret; // 返回之前的记录&#125; 成员访问运算符 包括解引用*和箭头运算符-&gt;两种 -&gt;必须是类成员，解引用通常是类成员 12345678910string&amp; operator*() const &#123; // 检查curr是否在有效范围内，如果是，返回curr所知元素的引用 auto p = check(curr, \"dereference past end\"); return (*p)[curr]; // *p是对象所指的vector&#125;string * operator-&gt;() const&#123; // 将工作委托给解引用运算符 return &amp; this-&gt;operator*();&#125; 函数调用运算符 重载函数调用运算符就可以向调用函数一样使用类对象 由于可以像使用函数对象那样使用，重载调用运算符可以替代lambda表达式 12345678910111213141516171819struct absInt() &#123; int operator()(int val) const &#123; // 注意参数放在后面的括号里 return val&lt;0? -val:val; &#125;&#125;absInt ai;ai(-10); // 返回10stable_sort(words.begin(), words.end(), [](const string&amp; s1, const string&amp; s2)&#123;return s1.size &lt; s2.size()&#125;;);// 类似于class short_string &#123;public: bool operator()(const string&amp; s1, const string&amp; s2) const&#123; return s1.size &lt; s2.size(); &#125;&#125;// short_string()构造一个对象，由于重载了调用运算符，就可以看作\"可调用对象\"使用stable_sort(words.begin(), words.end(), short_string()); 标准库定义的函数对象标准库定义了一组表示算术运算符、关系运算符和逻辑运算符的类，每个类分别定义了一个执行命名操作的调用运算符（所以其对象也可以被“调用”）。 算术 关系 逻辑 plus equal_to logical_and minus not_equal_to logical_or multiplies greater logical_not divides greater_equal modules less megate less_equal 12345678910plus&lt;int&gt; intadd;intadd(10, 15); // 25negate&lt;int&gt; intnegate;intnegate(10); // -10intnegate(intadd(10,15)); // -25sort(vec.begin(), vec.end(), greater&lt;string&gt;());// 如果vector里面是string*也照样可以sort(vec.begin(), vec.end(), greater&lt;string*&gt;()); 可调用对象与functionC++中的可调用对象包括：函数、函数指针、lambda表达式、bind创建的对象、重载了调用运算符的类 function类型定义在functional头文件中，是一个模板 12345678910function&lt;T&gt; f; // f是用来存储可调用对象的空的function，T限定函数类型（T就是`返回值 (各个参数)`）function&lt;T&gt; f(nullptr); // 显式构造一个空的functionfunction&lt;T&gt; f(obj); // f中存储可调用对象obj的副本f // f中有可调用对象为真，否则为假f(args); // 调用f中的对象，args是参数// 定义为function&lt;T&gt;的成员类型result_type // 可调用对象的返回类型argument_type // T一个实参时，实参的类型first_argument_type, second_argument_type 使用示例1234567function&lt;int(int, int)&gt; f1 = add; // 函数指针function&lt;int(int, int)&gt; f2 = divide(); // 重载了调用运算符的类的对象function&lt;int(int, int)&gt; f3 = [](int i, int j) &#123;return i+j;&#125;; // lambda表达式f1(3,4);f2(3,4);f3(3,4); 重载、类型转换与运算符 可以通过定义类类型转换运算符达到类类型转换的效果 转换构造函数和类型转换运算符共同定义了类类型转换 类型转换运算符 类型转换运算符是类成员函数 可以面向除了void*之外的任意类型进行定义，只要该类型能作为函数的返回类型（数组、函数类型就不行） 一般形式operator type() const 类型转换运算符是隐式执行的，没有形参，不能传递实参，不能指定返回类型 可能产生意外结果 123456789101112131415161718class smallInt &#123;public: smallInt(int i=0) : val(i) &#123; if (i&lt;0 || i&gt;255) throw std::out_of_range(\"Invalid value\"); &#125; operator int() const &#123;return val;&#125; int operator int() const; // wrong，不能有返回类型 operator int(int = 0) const; // wrong，不能有形式参数private: std::size_t val;&#125;smallInt si;si = 4; // 先将4隐式转换为smallInt，再调用赋值运算符si+3; // 先将si隐式转换为int，再执行整数加法smallInt s = 3.14; // 内置类型转换double-&gt;int，再调用smallInt(int)构造s+3.14 // smallInt先转成int，内置类型再将int转换成double 由于隐式转换可能会带来意想不到的结果，所以有时候需要使用显式的类型转换运算符。定义显式类型转换运算符只需要加上explicit即可，但转换时就行必须使用显式的强制转换方式。有一个例外：当表达式被用作条件判断（if, while, do, for, &amp;&amp;, ||, !, ?:），编译器会将显式的类型转换自动用于它，也就是会隐式执行12345explicit operator int() const &#123;return val;&#125; // 改变的类型转换运算符smallInt si = 3; // oksi+3 // wrong，此处需要隐式转换，但转换函数是显式的static_cast&lt;int&gt;(si) + 3 // 显示请求转换 IO类型可以向void*转换，C++11下支持将IO类型向bool显式类型转换，IO类型向bool的转换一般定义成显式（explicit），因为通常用在条件判断部分，所以也可以隐式执行。 二义性问题二义性类型转换的途径 两个类提供了相同的类型转换（分别通过构造函数和类型转换运算符） 定义了多个转换规则，这些转换涉及的类型本身可以通过其他类型转换联系在一起 1234567891011121314151617struct A &#123; A(int = 0); // 最好不要创建两个转换源都是算术类型的类型转换 A(double); operator int() const; // 最好不要创建两个转换对象都是算术类型的类型转换 operator double() const; // other member&#125;void f2(long double);A a;f2(a); // 二义性错误，两个类型转换函数都可以long lg;A a2(lg); // 二义性，编译器无法区分long转int和double的好坏short s = 42;A a3(s); //ok, 使用A::A(int) 但是short转int确实比short转double好 重载函数于转换构造函数 如果两个或多个类型的转换都提供了同一种可行的匹配，则这些类型转换一样好 即使其中一个能精确匹配，另一个需要额外的标准类型转换，编译器也会将其表示为二义性错误 12345678910111213141516171819202122struct C &#123; C(int); ...&#125;struct D &#123; D(ing); ...&#125;void f(const C&amp;);void f(const D&amp;)f(10); //二义性// ---------------------------------分割线----------------------------------struct E &#123; E(double); ...&#125;void f(const C&amp;);void f(const E&amp;);f(10); // 依旧二义性错误，即使其中一个能精确匹配，另一个需要额外的标准类型转换，编译器也会将其表示为二义性错误 函数匹配与重载运算符 表达式中运算符的候选函数集包括成员函数和非成员函数 如果对同一个类既提供了转换目标是算术类型的类型转换，也提供了重载的运算符，则将会遇到重载运算符与内置运算符的二义性 123456789101112class A &#123;friend A operator+(const A&amp; a, const A&amp; b);public: A(int = 0); operator int() const &#123;return val&#125;;private: size_t val;&#125;A a1, a2;A a3 = s1 + s2; // 使用重载的operator+int i = s3 + 1; // 二义性错误 面向对象程序设计 OOP OOP的核心思想是数据抽象、继承和动态绑定 基类与派生类（父类与子类） 子类经常覆盖父类中的虚函数，如果不覆盖，子类将直接继承父类的版本 能把子类对象当成父类对象来用，也能把父类的指针或引用绑定到子类对象的父类部分上 子类构造函数先初始化父类部分，然后按照声明顺序依次初始化子类成员 派生类可以访问基类的公有和受保护成员 基类中的静态成员在整个继承体系中都只存在该成员的唯一定义，如果是private的，派生类就不能访问 声明派生类时不能加上派生列表 派生类一定要有定义，类不能派生自己 使用final关键字可以禁止类被继承 123class father &#123;&#125;;class A final : public father &#123;&#125;; // ok, 但A不能被继承class B : public A&#123;&#125;; // 错误，A是final的 派生类向基类的自动类型转换只对指针、引用类型有效 用派生类对象为基类对象初始化或者赋值时，其派生类独有的部分会被忽略 虚函数 运行时动态绑定 所有虚函数都必须有定义 派生类中的虚函数可以不加virtual关键字，因为一旦某个函数被声明为虚函数，他在所有派生类中都是虚函数 覆盖基类虚函数的派生类函数必须在形参上与派生类完全一致 override关键字用来说明派生类中的虚函数 final关键字阻止函数派生类覆盖此函数 如果虚函数使用默认实参，实参由本次调用的静态类型决定（使用基类的指针就用基类的虚函数默认实参），所以最好定义派生类、基类虚函数的默认实参一致 回避虚函数机制，可使用作用域运算符机制 12345678910class A &#123;virtual void f1() const;&#125;;class B : A &#123;virtual void f1() const final; // 不允许后续的其他类覆盖f1&#125;;A * a = new B();a-&gt;f1(); // 调用B类中的虚函数f1a-&gt;A::f1(); // 无论a类型是什么，都是用A中的虚函数f1 抽象基类 抽象基类负责定义接口，不能直接创建其对象 纯虚函数 在函数声明加上=0就可以将函数声明为纯虚函数 纯虚函数无需定义，非要定义的话必须在类的外部 访问控制与继承受保护的成员 protected 类的用户不能访问受保护的成员，私有的更不行 派生类的成员、友元可访问继承来的protected、public成员，private不行 派生类的成员、友元只能通过派生类对象访问基类的受保护成员。派生类无法访问基类对象中的受保护成员 1234567891011class base &#123;protected: int mem;&#125;;class sneak : base &#123; friend void get(sneak&amp;); // 可以通过自身对象访问基类的受保护部分 friend void get(base&amp;); // 不能访问基类对象中的受保护成员 int j; // private&#125;;void get(sneaky&amp; s)&#123;s.j = s.mem = 0;&#125;void get(base &amp;b) &#123;b.mem = 0;&#125; // 错误，不能访问 派生类对其继承而来的成员的访问权限收到两个因素影响： 基类中该成员的访问说明符 派生类的派生列表中的访问说明符 派生访问说明符对于派生类的成员及其友元能否访问直接基类的成员没什么影响，其对基类成员的访问权限只与基类中的访问说明符有关 派生访问说明符的目的是控制派生类用户（包括派生类的派生类）对于基类成员的访问权限 如果继承是公有的，成员遵循原有的访问说明符 如果继承是私有的，则所有对象都是私有的 如果继承是protected的，原本public的称为protected的 派生类向基类转换的可访问性（假定D继承自B） 只有继承方式是public，用户代码才能使用派生类向基类的转换 无论以什么方式继承，D的成员和友元都能使用派生类向基类的转换 如果D以public或protected方式继承B，则D的派生类的成员和友元可以使用D向B的转换 要改变个别成员的可访问性，可使用using关键字 12345678910class base &#123;protected: int mem, n;&#125;;class derived : private base&#123;public: using base::mem;protect: using base::n;&#125;; 友元与继承 友元关系不能继承 继承中的类作用域 先名字查找再类型检查（p-&gt;mem(), obj.mem()） 确定p的静态类型，因为调用的是成员，该类型必然是类类型 在p的静态类型对应的类中查找mem，找不到则直接基类中查找直到继承链最顶端。还是找不到就报错 一旦找到mem，就进行常规的类型检查以确认本次调用是否合法 如果调用合法，则编译器将根据调用的是否是虚函数产生不同的代码 内层作用域的函数不会重载声明在外层作用域的函数 名字查找过程中，派生类会隐藏基类的同名成员（即使形参列表不一样） 12345678910class base &#123;int f();&#125;;class derived : private base&#123;int f(int); // 隐藏了基类的f()&#125;;base b; derived d;d.f(10); // okd.f(); // wrong，参数列表为空的f函数被隐藏了 拷贝函数与拷贝控制虚析构函数 派生类会继承基类析构函数的虚属性 基类虚析构函数能保证delete基类指针时使用正确的析构函数版本 定义了虚析构函数的类，编译器就不会为其合成移动操作 派生类中删除的拷贝控制与基类的关系 基类中的默认构造函数、拷贝构造函数、拷贝赋值运算符或析构函数是被删除的或不可访问的，则派生类中对应的成员将是删除的 基类中的析构函数是不可访问或删除的，那么派生类中的合成的默认和拷贝构造函数都是删除的 基类中对应操作是删除的，派生类中的也会是删除的（比如说移动构造函数） 移动操作与继承 带有虚析构函数的类，编译器不会为其合成移动操作，所以其子类也没有 确实需要移动操作时，可以显式地定义（可以使用合成版本） 12345678910class A &#123;public: A() = default; // 默认构造 A(const A&amp;) = default; // 拷贝构造 A(A&amp;&amp;) = default; // 移动构造 A&amp; operator=(const A&amp;) = default; // 拷贝赋值 A&amp; operator=(A&amp;&amp;) = default; // 移动赋值 virtual ~A(); // ......&#125; 派生类的拷贝控制 派生类在拷贝、移动的同时要拷贝、移动基类部分(显式地) 派生类赋值运算符的处理方法也类似 派生类的析构函数只负责销毁派生类自己分配的资源 1234567891011class base &#123;&#125;;class D : private base&#123; D(const D&amp; d) : base(d), /*D的成员初始值*/ &#123;...&#125; // d作为参数将被绑定到类型为base&amp;的实参上 D(D&amp;&amp; d) : base(std::move(d)), /*D的成员初始值*/ &#123;...&#125;&#125;;D&amp; D::operator= (const D&amp; d) &#123; base::operator=(d); // 为基类部分赋值 // 酌情处理自赋值、释放已有资源 return *this;&#125; 在构造函数和虚构函数中调用虚函数 如果构造函数或析构函数调用了某个虚函数，则程序会执行与调用构造函数或析构函数所属类型相对应的虚函数版本 这个例子：创建派生类对象时，先调用基类的构造函数，此时对象的派生类部分是未被初始化的，调用派生类的虚函数存在风险，所以应该调用基类的虚函数。 继承的构造函数 一个类可以继承其直接基类的构造函数 类不能继承默认、移动、拷贝构造函数 继承方式是使用using base::base;就可以继承base的构造函数，对于基类的构造函数，编译器将会为派生类与之对应的派生类版本derived(params) : base(args) {} 构造函数的using声明不会改变该构造函数的访问级别（私有还是私有，公有还是共有） 当基类构造函数有默认实参，派生类将获得多个构造函数，每个构造函数省略掉一个含有默认实参的形参 派生类不继承某些构造函数的原因可能是： 派生类自己定义了有相同参数列表的构造函数 默认、移动、拷贝构造函数按照正常规则被合成 容器与继承 不能把具有继承关系的对象放在一个容器中 在容器中放置（智能）指针而非对象 派生类的（智能）指针可以隐式转换为基类的（智能）指针 123vector&lt;shared_ptr&lt;quote&gt;&gt; basket;basket.push_back(make_shared&lt;quote&gt;(\"00001\", 50));basket.push_back(make_shared&lt;derived_quote&gt;(\"972719\", 35, 21, 7)); 多重继承与虚继承多重继承 每个基类包含一个可选的访问说明符 关键字class的默认访问说明符是private，struct的默认访问说明符是public 派生类的对象包含每个基类的子对象，派生类的构造函数初始值只能初始化它的直接基类 基类的构造顺序与派生列表中的基类出现的顺序一致 多重构造在析构时，顺序与构造时相反，派生类的析构函数只负责销毁自己的部分 派生列表中，同一个基类只能出现一次 多重继承构造函数的继承 C++11中允许派生类从他的基类中继承构造函数 如果继承的多个构造函数相同（形参列表完全相同），程序产生错误 如果不想上述错误出现，这个类必须为该构造函数定义它自己的版本 123456789101112131415161718192021struct base1 &#123; base1() = default; base1(const string&amp;);&#125;;struct base2 &#123;base2() = default;base2(const string&amp;);&#125;;// D1尝试继承两个基类中的参数为 const string&amp; 的构造函数struct D1 : public base1, public base2 &#123; using base1::base1; // 继承base1 using base2::base2; // 继承base2&#125;;struct D2 : public base1, public base2 &#123; using base1::base1; // 继承base1 using base2::base2; // 继承base2 // 定义自己的 参数为 const string&amp; 的构造函数 D2(const string&amp; s) : base1(s), base2(s); D2() = default; // 一旦D2定义了自己的构造函数，就必须出现这个&#125;; 类型转换与多个基类 可以使某个可访问的基类的指针、引用直接指向一个派生类的对象 编译器认为基类们向派生类的转换不分优劣，因此可能会产生二义性错误 虚继承 派生类可能通过直接基类间接继承自同一个间接基类，所以派生类对象会包含两份间接基类的对象 虚继承可以解决上述问题，其目的是令某个类作出声明，承诺愿意共享它的基类 共享的基类称为虚基类 含有虚基类的对象构造顺序：虚基类总是先于非虚基类构造 先虚：虚子对象按照他们在派生列表中出现的顺序从左向右出现，然后才是非虚对象从左向右 123// base是D1、D2的虚基类class D1 : public virtual base &#123;&#125;;class D2 : virtual public base &#123;&#125;; class Character {}; class BookCharacter : public Character{}; class ZooAnimal {}; class Bear : public ZooAnimal{}; class ToyAnimal{}; class TeddyBear : public BookCharacter, public Bear, public virtual ToyAnimal{}; // 构造TeddyBear时，构造顺序如下： ZooAnimal(); ToyAnimal(); Character(); BookCharacter(); Bear(); TeddyBear(); 标准库特殊设施bitset类#include &lt;bitset&gt; 定义与初始化 函数 解释 bitset&lt;n&gt; b b有n位，每一位均是0。此构造函数为constexpr bitset&lt;n&gt; b(u) b是unsigned long long值u的低n位的拷贝，如果u没有n位，则补0。此构造函数为constexpr bitset&lt;n&gt; b(s, pos, m, zero, one) explicit型。从string s的pos（默认为0）位置开始的m（默认为string::npos）个字符，s中只能包含zero（默认&#39;0&#39;）和one（默认&#39;1&#39;） bitset&lt;n&gt; b(cp, pos, m, zero, one) explicit型。从字符数组cp的pos（默认为0）位置开始的m（默认为string::npos）个字符，cp中只能包含zero（默认&#39;0&#39;）和one（默认&#39;1&#39;） 操作 函数 解释 函数 解释 b.any() b中是否有为1的二进制位 b.all() 是否所有的位置都为1 b.none() b中是否所有的位置都为0 b.count() b中1的个数 b.size() b中位数总和，constexpr型 b.test(pos) pos位位1：true，否则false b.set(pos, v) 将pos位置为v(默认true是1)，不带参数pos则设置所有位 b.reset(pos) 将pos复位，没有pos则全部复位 b.flip(pos) 反转pos位或者全部反转 b[pos] 访问pos位置，如果b是const的，返回true/false布尔值 b.to_ulong() 返回b对应的unsigned long值，放不下则抛出异常 b.to_ullong() 返回b对应的unsigned long long值，放不下则抛出异常 b.to_string(zero, one) 将b转换成&#39;0&#39;,&#39;1&#39;组成的string类型 os&lt;&lt;b 打印b中的01流 is&gt;&gt;b 从is读入字符存入b，当下一个字符不是&#39;0&#39;,&#39;1&#39;或是已经到达b.size()时停止 随机数#include &lt;random.h&gt; 随机数引擎类和随机数分布随机数引擎是函数对象类，定义了调用运算符，该运算符不接收参数并返回一个随机unsigned整数12default_random_engine e;e(); 随机数引擎操作如下： 操作 解释 Engine e 默认构造函数，使用默认种子 Engine e(s) 使用整型值s作为种子 e.seed(s) 使用种子s重置e的状态 e.min() 此引擎可生成的最小值 e.max() 最大值 Engine::result_type 此引擎生成的unsigned整型类型 e.discard(u) 将引擎推进u步，u的类型位uul 为了得到一个指定范围内的数，使用一个分布类型的对象12345// 0-9之间的均匀分布// u是一个调用运算符，接受一个随机数引擎作为参数unifrom_int_distribution&lt;unsigned&gt; u(0, 9);default_random_engine e;cout &lt;&lt; u(e) &lt;&lt; endl; 其他随机数分布 使用uniform_real_distribution&lt;double&gt;类型的对象生成随机浮点数，用法类似上面 uniform_real_distribution&lt;&gt;默认为double类型 高斯分布：normal_distribution&lt;&gt; n(u, sigma); // 均值为u，标准差为sigma lround(a)函数对a进行四舍五入转化为整数，来自头文件cmath bernoulli_distribution b(p)一次成功概率为p。它不是模板类（没有&lt;&gt;）","categories":[],"tags":[{"name":"Cpp","slug":"Cpp","permalink":"atlantic8.github.io/tags/Cpp/"}]},{"title":"BM","slug":"BM","date":"2017-03-04T12:33:18.000Z","updated":"2019-08-24T01:19:01.090Z","comments":true,"path":"2017/03/04/BM/","link":"","permalink":"atlantic8.github.io/2017/03/04/BM/","excerpt":"","text":"BM介绍KMP算法是一种利用模式串前缀移动的字符串匹配算法，时间复杂度为O(n)。BM算法是一种使用了两个跳转表的字符串匹配算法，单模式匹配有更加出色的表现。 上图表述了BM算法的大致过程，模式串是AT-THAT，于KMP不同，BM算法对每一次匹配尝试从后向前匹配的方法。 第一次匹配从第7位开始。第7为不能匹配，移动模式串，注意到目标串第7为为F，F不在模式串中，所以可以直接将模式串的首位移到目标串第8位。 接着从后向前匹配，目标串的14位-与模式串最后一位不匹配，但是-在模式串中，所以将模式串中最靠后的-移到与目标串的14位对齐。 再从后向前匹配，目标串的第18位T与模式串的最后一位匹配，向前看一位，17位L不匹配，且L不在模式串中，所以把模式串第一位移到目标串第18位。 接着从后向前匹配，第23、24位匹配，22位不匹配，由于模式串的前两位等于后两位，所以将模式串移动使其前两位到后两位的位置上。 坏字符规则假设目标串T长度为n，模式串P长度为m 坏字符规则分为两种情况： 坏字符没出现在模式串中，这时可以把模式串首移动到坏字符的下一个字符 坏字符出现在模式串中，这时可以把模式串第一个出现的坏字符和母串的坏字符对齐（当然，这样可能造成模式串倒退移动） 使用一个数组bad，bad[&#39;k&#39;]表示坏字符在模式串中最左侧的字符&#39;k&#39;距离模式串末尾的长度，如果字符’k’不在模式串中，bad[&#39;k&#39;]=m。那么遇到坏字符时模式串可以移动的距离为：bad[T[i]]-(m-1-i). 1234567// m为模式串长度void get_bad (const char* P, int m, int* bad) &#123; for (int i=0; i&lt;256; i++) bad[i] = m; for (int i=0; i&lt;m; i++) bad[P[i]] = m-i-1;&#125; 好后缀规则发现某个字符不匹配的同时，已有部分字符匹配成功。假设模式串P已经匹配成功的部分为Q 模式串中有子串匹配上好后缀，此时移动模式串，让该子串和好后缀对齐即可，如果超过一个子串匹配上好后缀，则选择最靠左边的子串对齐 模式串中没有子串匹配上好后缀，此时需要寻找模式串的一个最长前缀，并让该前缀等于好后缀的后缀，寻找到该前缀后，让该前缀和好后缀对齐即可 模式串中没有子串匹配上后后缀，并且在模式串中找不到最长前缀，让该前缀等于好后缀的后缀。此时，直接移动模式到好后缀的下一个字符 为了实现好后缀规则，需要定义一个数组suffix[]，其中suffix[i] = s 表示以i为右边界，与模式串后缀匹配的最大长度为s，即P[i-s:s]==P[m-s:m]， 123456789void suffixes(const char *P, int m, int *suff) &#123; suff[m-1]=m; for (i=m-2；i&gt;=0；--i)&#123; q=i; while(q&gt;=0&amp;&amp;P[q]==P[m-1-i+q]) --q; suff[i]=i-q; &#125;&#125; 定义good[]数组表示遇到好后缀时，模式串应该移动的距离。其中i表示好后缀前面一个字符的位置（也就是坏字符的位置）.对应上面三种情况，good数组构建方法如下： 上面的三种情况，移动的距离是逐渐增大的，在满足不止一种情况时，应该移动最小的距离。所以分三部分考虑， 对第三种情况，移动距离就是P的长度 对第二种情况，我们要找前缀，所以如果位置i到第一个是满足条件的话，必然有suff[i]=i+1，满足条件时，坏字符出现在[0,m-1-i)位置上时都可以移动m-1-i位使得模式串前i+1位与后i+1位重叠。对于i，从大到小计算是因为越长的前缀意味着越小的移动步数，我们希望找到小的，更新时判断good[j]==m也是为了不多次更新。 对第一种情况，我们知道当m-1-suff[i]位置为坏字符时，需要移动m-i-1位 1234567891011121314151617void get_good(const char *P, int m, int bmGs[]) &#123; int i, j, suff[256]; suffixes(x, m, suff); // 第三种情况 for (i = 0; i &lt; m; ++i) good[i] = m; j = 0; // 第二种情况 for (i = m - 1; i &gt;= 0; --i) if (suff[i] == i + 1) for (; j &lt; m - 1 - i; ++j) if (good[j] == m) good[j] = m - 1 - i; // 第一种情况 for (i = 0; i &lt;= m - 2; ++i) good[m - 1 - suff[i]] = m - 1 - i;&#125; 最后给出BM算法，对于出现无法匹配的时候，移动步数取好后缀和坏字符两种情况的最大值。完整代码如下：123456789101112131415161718192021222324void BM(char *P, int m, char *S, int n) &#123; int i, j, good[m], bad[256], k=0; /* Preprocessing */ get_bad(P, m, bad); get_good(P, m, good); i = j = m-1; /* Searching */ j = 0; while (j &lt;= n - m) &#123; while (i!=0 &amp;&amp; P[i]==S[j]) &#123; // 从后向前匹配、直到找到不匹配或者完全匹配 --i; --j; &#125; // 找到一个匹配 if (i==0 &amp;&amp; P[i]==S[j]) &#123; m++; j += good[0]; // 找到匹配算是好后缀情况 &#125; else &#123; j += good[i]&gt;bad[S[j]] ? good[i] : bad[S[j]]; &#125; i = m-1; &#125;&#125;","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"String","slug":"String","permalink":"atlantic8.github.io/tags/String/"}]},{"title":"Decision Tree","slug":"Decision-Tree","date":"2017-03-02T01:39:28.000Z","updated":"2018-12-16T14:08:06.216Z","comments":true,"path":"2017/03/02/Decision-Tree/","link":"","permalink":"atlantic8.github.io/2017/03/02/Decision-Tree/","excerpt":"","text":"决策树模型 决策树是一种基本的分类与回归的方法 决策树由节点和有向边组成 节点分为内部节点和叶节点 决策树的学习其实就是特征选择的过程 决策树学习决策树学习算法包含特征选择、决策树的生成和决策树的剪枝过程 给定数据集$D=\\lbrace (x_1,y_1),…,(x_m,y_m) \\rbrace$其中$m$为样本容量，$x_i=(x_i^{(1)},…,x_i^{(n)})$，$n$为特征个数；$y_i\\in \\lbrace 1,2,…,K \\rbrace$为类标记。 信息增益统计学中，熵是随机变量不确定性的度量，即混乱程度。假设$X$是一个取有限个值的离散随机变量，其概率分布为$P(X=x_i)=p_i,i=1,..,N$，那么$X$的熵定义为H(X)=-\\sum_{i=1}^n p_i log p_i条件熵$H(Y|X)$可以表示为已知随机变量$X$的条件下，随机变量$Y$的不确定性，也可以表示成H(Y|X)=\\sum_{i=1}^N p_iH(Y|X=x_i)其中$p_i=P(X=x_i)$。当熵和条件熵中的概率由数据估计得到时，则分别称之为经验熵和条件经验熵，如果出现0概率，则令$0log0=0$。 信息增益表示在得知特征$X$的情况下而使得$Y$的不确定性减少的程度，形式化表述为：特征$A$对训练数据集$D$的信息增益$g(D,A)$，定义为g(D,A)=H(D)-H(D|A)这里的信息增益等价于训练数据集中类与特征的互信息。计算信息增益的算法如下： 输入：数据集$D$和特征$A$ 1 计算数据集$D$的经验熵$H(D)=-\\sum_{k=1}^K \\frac{|C_k|}{|D|}log_2\\frac{|C_k|}{|D|}$2 计算特征$A$对数据集$D$的经验条件熵H(D|A)=\\sum_{i=1}^N \\frac{|D_i|}{|D|}H(D_i)=-\\sum_{i=1}^N \\frac{|D_i|}{|D|}\\sum_{k=1}^K\\frac{|D_{ik}|}{|D_i|}log_2\\frac{|D_{ik}|}{|D_i|}3 计算信息增益$g(D,A)=H(D)-H(D|A)$. 输出信息增益 信息增益比以信息增益作为划分训练数据集的特征，存在偏向于选择取值较多的特征的问题，使用信息增益比可以缓解这个问题。特征$A$对训练数据集$D$的信息增益比定义为其增益信息$g(D,A)$与训练数据集$D$关于特征$A$的值的熵$H_A(D)$之比，即 \\begin{aligned} g_R(D,A)=\\frac{g(D,A)}{H_A(D)} \\end{aligned}其中，$H_A(D)=-\\sum_{i=1}^{A_n}\\frac{|D_i|}{|D|}log_2\\frac{|D_i|}{|D|}$，$A_n$是特征$A$取值的个数。 ID3ID3算法采用自上而下递归式的算法构建决策树，它使用信息增益作为特征选择的标准。停止条件是节点所有特征的信息增益都很小（阈值$\\epsilon$）或没有特征可以选择为止。 输入：训练数据集$D$，特征集$A$，阈值$\\epsilon$ 1 若$D$中所有实例属于同一类$C_k$，$T$为单节点树，$C_k$为该节点的类标记，返回$T$2 若$A=\\emptyset$则$T$为单节点树，将$D$中实例数最大的类$C_k$作为该节点的类标记，返回$T$3 否则，分别计算$A$中各特征对$D$的信息增益，选择信息增益最大的特征$A_g$4 如果$A_g&lt;\\epsilon$，则置T为单节点树，将$D$中实例数最大的类$C_k$作为该节点的类标记，返回$T$5 否则，对$A_g$的每一个可能值$a_i$，根据$A_g=a_i$将$D$分割成若干非空子集$D_i$，将$D_i$中实例数最大的类作为标记，构建子节点，由节点及其子节点构成树$T$，返回$T$6 对每个子节点$i$，以$D_i$为训练集，以$A-A_g$为特征集，递归调用以上步骤 输出：决策树$T$ C4.5C4.5与ID3的差异在于C4.5使用信息增益比进行选择选择 基尼指数基尼指数表示不确定程度，基尼指数越大，样本集的不确定程度就越大、纯度越低。 分类问题中，假设有$K$个类，样本点属于第$k$类的概率为$p_k$，则概率分布的基尼指数定义为Gini(p)=1-\\sum_{k=1}^K p_k^2对于给定的样本集$D$，其基尼指数为Gini(D)=1-\\sum_{k=1}^K\\left( \\frac{|C_k|}{|D|} \\right)^2其中$C_k$表示第$k$类的样本子集。表示集合$D$的不确定性。 假设样本集$D$根据特征$A$的不同取值被分成$A_n$个部分，则定义在特征$A$下集合$D$的基尼指数为 \\begin{aligned} Gini(D,A)=\\sum_{i=1}^{A_n} \\frac{|D_i|}{|D|}Gini(D_i) \\end{aligned}CARTCART分类树使用基尼指数作为划分属性的标准，每次选择基尼指数最小的属性。 CART回归模型假设已将输入空间划分为$M$个单元$R_1,…,R_M$，并且在每个单元$R_m$上有一个固定的输出值$c_m$，回归树模型可以表示为f(x)=\\sum_{m=1}^Mc_mI(x\\in R_m)当输入空间划分确定时，可以用平方误差$\\sum_{x_i}(y_i-f(x_i))^2$表示训练误差, $c_m$输出值为对应$R_m$上所有样本输出值的均值。 使用启发式的方法划分输入空间，遍历输入变量和可能的切分变量找到最优的切分变量$j$和切分点$s$，即找到切分后部分的误差最小： \\begin{aligned} &R_1(j,s)=\\lbrace{x|x^{(j)}\\le s\\rbrace} \\\\ &R_2(j,s)=\\lbrace x|x^{(j)}> s \\rbrace \\\\ &\\min_{j,s} \\left[ \\min_{c_1}\\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2}\\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2 \\right] \\end{aligned}其中$c_1,c_2$是划分后部分中输出值的均值。最小二乘回归树算法描述如下： 输入：训练集$D$ 选择最优切分变量$j$与最优切分点$s$，求解$\\min_{j,s} \\left[ \\min_{c_1}\\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2}\\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2 \\right]$ 用选定的对$(j,s)$划分区域并决定相应输出值：$R_1,R_2,c_1,c_2$ 继续对两个子区域调用步骤1、2直至满足停止条件 将输入空间划分为$M$个区域$R_1,…,R_M$，生成CART树$f(x)=\\sum_{m=1}^Mc_mI(x\\in R_m)$ 输出：$f(x)$ 决策树的剪枝以上方法可能会产生过拟合现象，适当剪枝会使得决策树的泛化效果变得更好剪枝分为预剪枝和后剪枝两种，预剪枝指的是在决策树生成的过程中进行剪枝，后剪枝则是在生成决策树之后再进行剪枝。 预剪枝大致过程描述：对于一个节点，考虑其剪枝或者不剪枝的情况，看这两种情况下哪种正确率高（一个节点的类别由其包含同类样本数最多的决定），由此决定是否剪枝。 预剪枝基于贪心本质禁止某些节点展开，而这些节点第一次展开效果可能不好，但后续表现可能显著提高，所以会带来欠拟合的风险。 后剪枝大致过程描述：自下而上，叶节点不考虑，考虑其父节点F是否需要剪枝，可以仅仅通过父节点包含的样本，在剪枝和不剪枝的情况下分别计算准确率，然后确定是否需要剪枝。 下面是令一种后剪枝的方法（我不是很了解）：通过极小化决策树整体的损失函数来实现。设树的叶节点个数为$|T|$，$t$是树$T$的叶节点，此叶节点上有$N_t$个样本，属于类$C_k$的样本有$N_{tk}$个，$H_t(T)$为叶节点$t$上的经验熵，$\\alpha \\ge 0$为参数，则决策树学习的损失函数可以定义为 \\begin{aligned} C_{\\alpha}(T)=\\sum_{t=1}^{|T|} N_tH_t(T)+\\alpha |T|=C(T)+\\alpha |T| \\end{aligned}其中经验熵为$H_t(T)=-\\sum_k \\frac{N_{tk}}{N_t}log_2 \\frac{N_{tk}}{N_t}$。$C(T)$表示模型对训练数据的预测误差，|T|表示模型的复杂度。剪枝算法描述如下： 输入：决策树$T$，参数$\\alpha$ 1 计算每个节点的经验熵2 递归地从树的节点向上回溯，如果保留子节点的损失函数更大，剪枝以父节点作为叶子3 返回2直到不能继续为止 输出：修建后的决策树$T_{\\alpha}$","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"Bayesian Classifier","slug":"Bayesian-Classifier","date":"2017-02-26T06:49:57.000Z","updated":"2018-12-16T14:08:06.173Z","comments":true,"path":"2017/02/26/Bayesian-Classifier/","link":"","permalink":"atlantic8.github.io/2017/02/26/Bayesian-Classifier/","excerpt":"","text":"朴素贝叶斯分类器输入空间$\\mathbb{R}$为$n$维向量的集合，输出空间为类标记集合$\\mathcal{Y}=\\lbrace c_1,c_2,…,c_K \\rbrace$，给定训练数据集T=\\lbrace (x_1,y_1),...,(x_N,y_N) \\rbrace由联合概率分布$P(X,Y)$独立同分布产生。 朴素贝叶斯分类器旨在最大化后验概率，即 \\begin{aligned} c&=\\arg\\max_{c_k} P(Y=c_k|X=x) \\\\ &=\\arg\\max_{c_k} \\frac{P(X=x|Y=c_k)P(Y=c_k)} {\\sum_k P(X=x|Y=c_k)P(Y=c_k)} \\end{aligned}由于对于每一个不同的类别，上式中的分母都是一样的，所以上面的目标公式可以写成 \\begin{aligned} c=\\arg\\max_{c_k} P(X=x|Y=c_k)P(Y=c_k) \\end{aligned}对于这个优化目标，可做如下统计 \\begin{aligned} P(Y=c_k) &= \\frac{ I\\lbrace Y=c_k \\rbrace }{N} \\end{aligned}朴素贝叶斯分类器对条件概率分布进行了条件独立性的假设 而$P(X=x|Y=c_k)$可以分解为 \\begin{aligned} P(X=x|Y=c_k)=\\prod_j^n P(X^{(j)}=x^{(j)}|Y=c_k) \\end{aligned}所以上式可以分开考虑，即在满足$Y=c_k$的集合中分别考虑，$P(X^{(1)}=x^{(1)}|Y=c_k)$就等于$Y=c_k$的集合中第一个属性为$x^{(1)}$样本所占的比例，所以上式可以写成 \\begin{aligned} P(X=x|Y=c_k)=\\prod_j^n \\frac {I\\lbrace X^{(j)}=x^{(j)}|Y=c_k \\rbrace} {I\\lbrace Y=c_k \\rbrace} \\end{aligned}所以，经过统计，就可以使用后验概率最大准则进行分类。 当然，也可以使用极大似然估计对单个属性和属性进行建模，用$D_c$表示数据集中第$c$类样本的集合，参数$\\theta_c$表示对第$c$类样本的建模，所以有 \\begin{aligned} \\mathcal{l} &= log \\prod_{x\\in D_c}P(x|\\theta_c) \\\\ &= \\sum_{x\\in D_c} logP(x|\\theta_c) \\end{aligned}对$P(x|\\theta_c)$进行适当建模，比如$P(x|\\theta_c) \\sim \\mathcal{N}(\\mu_c, \\sigma^2_c)$，然后用经典的极大似然估计进行估值即可。 贝叶斯估计对于朴素贝叶斯分类器，做如下统计计算时 \\begin{aligned} P(X=x|Y=c_k)=\\prod_j^n \\frac {I\\lbrace X^{(j)}=x^{(j)}|Y=c_k \\rbrace} {I\\lbrace Y=c_k \\rbrace} \\end{aligned}分子、分母可能为0，所以这里使用拉普拉斯平滑，所以统计方法如下 \\begin{aligned} P(Y=c_k) &= \\frac{ I\\lbrace Y=c_k \\rbrace+\\lambda }{N+\\lambda K} \\\\ P(X=x|Y=c_k)&=\\prod_j^n \\frac {I\\lbrace X^{(j)}=x^{(j)}|Y=c_k \\rbrace+\\lambda} {I\\lbrace Y=c_k \\rbrace+\\lambda K_j} \\end{aligned}其中，$K$是分类类别总数，而$K_j$表示第$j$个属性的可能取值数，$\\lambda$是平滑参数，为1时则为Laplace平滑。","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"Cpp Rule Fragment","slug":"Cpp-Rule-Fragment","date":"2017-02-23T00:50:23.000Z","updated":"2018-12-16T14:08:06.201Z","comments":true,"path":"2017/02/23/Cpp-Rule-Fragment/","link":"","permalink":"atlantic8.github.io/2017/02/23/Cpp-Rule-Fragment/","excerpt":"","text":"变量和基本类型初始化列表初始化C++11中，一下初始化方法都是成立的1234int x = 0;int x = &#123;0&#125;;int x&#123;0&#125;;int x(0); 使用花括号初始化变量在C++11中得到全面应用，但是用于内置类型的变量时，使用花括号初始化形式有个重要的特点： 使用列表初始化且初始化存在丢失信息的风险，编译器将报错 比如 123double db = 3.141592653;int x&#123;db&#125;; // 错误，转换存在丢失信息的风险int y(db); // 正确，转换执行，丢失部分信息 默认初始化如果内置类型的变量未被显示初始化，它的值由定义的位置决定。定义与任何函数体之外的变量初始化为0，定义于函数体内部的内置类型将不会被初始化。 定义与声明 声明使得名字为程序所知，定义负责创建与名字关联的实体 只声明一个变量而非定义它，使用extern关键字，不要显示初始化 任何包含了显示初始化的声明即成了定义 变量只能定义一次，但是可以声明多次 123extern int i; // 声明int j; // 声明且定义extern int k = 2; // 定义 复合类型引用 引用必须被初始化，因为引用是要和初始值绑定到一起的 引用不能被重新绑定到另一个对象 引用不能被绑定到字面值、表达式计算结果 引用类型要与绑定对象类型严格匹配，只在极少数情况下有例外 因为引用不是对象，所以不能创建引用的引用 1234567int x=10, &amp;y = x, z=20;&amp;y = z; // 错误，不能重新绑定y = z; // 正确，相当于赋值int &amp;i = 10; // 错误double j = 2.55;int &amp;k = j; // 错误，类型不匹配 指针 指针是一个对象，可以有指针的指针，且无需定义时赋初值 指针类型要与其指向对象类型严格匹配，只在极少数情况下有例外 1234// 生成空指针的方法int *p1 = nullptr;int *p2 = 0;int *p3 = NULL; void*指针 可以存放任意对象的地址 不能直接操作void*指针指向的对象，因为不知道其类型 const const对象必须初始化，一旦创建，不能修改 利用一个对象去初始化另一个对象，无论他们是不是const都无关紧要，因为拷贝不会改变什么 默认情况下，const变量尽在文件内有效 多个文件共享的方法：声明、定义都添加extern关键字 12345// file 1，定义、初始化extern const int x = getSize();// file 2，再次声明一下，与file 1中的是同一个extern const int x; const引用 不能通过引用改变常量的值 初始化常量引用时允许用任意表达式作为初始值，只要表达式结果能转换成引用类型即可 允许为一个常量引用绑定非常量对象、字面值，甚至表达式，非常量不行 12345int i = 42;const int &amp;r1 = i; // correctconst int &amp;r2 = 42; // correctconst int &amp;r3 = r1*2; // correctint &amp;r4 = r1*2; // 错误，r4是非常量引用 指针和const指向常量的指针 允许指向常量的指针指向非常量对象 常量对象的地址只能存在指向常量的指针里 常量指针 常量指针是常量，必须初始化，且一旦初始化就不能改变，但其指向的对象可以被改变 顶层const顶层const表示指针本身是个常量，顶层const表示指针指向一个常量左为底，右为顶即可分辨1const int k=0; // 这个也是顶层const constexpr和常量表达式 常量表达式的值不会改变，且在编译时期就能得到结果 C++11中将变量声明为constexpr类型，由编译器验证变量的值是否为常量表达式 声明为constexpr的变量一定是常量，且必须用常量表达式初始化 一个constexpr指针的初始值必须是nullprt或者0，或是存储与某个固定地址（比如全局变量，局部变量不行）中的对象 constexpr声明的指针，仅对指针有约束，不能约束指向的对象，顶层const 1constexpr int * p = nullptr; // p是指向整数的常量指针 处理类型类型别名typedef和别名声明123typedef double wage, *p; // wage是double同义词，p相当于double*using vi = vector; auto auto定义的变量必须有初始值 auto可以一次声明多个变量，但是这些变量的初始基本数据类型必须一样 auto推断的类型与原始类型可能会不太一样，比如auto会忽略掉顶层const 引用类型也可以是auto，原来初始化规则适用 1234567const int i = 0;auto a = i; // a是一个整数，顶层const被忽略const auto b = i; // b是一个const intauto &amp;c = i;auto &amp;d = 42; // 错误const auto &amp;e = 42; // 正确 decltype decltype的作用是选择并返回操作数的严格基本类型 如果decltype使用的表达式是一个变量，则decltype返回该变量的类型（包括const和引用） 如果表达式内容是解引用，decltype得到引用类型 如果变量名加上了一层或多层括号，就会被当成表达式，会得到引用类型 12345678910const int ci=0, &amp;cj=ci;decltype(ci) x=0; // x为const intdecltype(cj) y=x; // y为const int&amp;，y绑定到xdecltype(cj) z; // 错误，z是引用，必须初始化int i=42, *p=&amp;i;decltype(*p) c; // 错误，c是int&amp;，必须初始化decltype(i) m; // 正确，一个未初始化的intdecltype((i)) n; // 错误，int&amp; 必须初始化 字符串，向量，数组数组不允许直接拷贝、赋值 字符数组字符数组可以使用字符串字面值进行初始化，但字符串结尾处还有一个空字符&#39;\\0&#39;，这个空字符也会被拷贝到数组中去 1234char a1[] = &#123;'c','+', '+'&#125;; // 长度为3char a2[] = &#123;'c','+', '+', '\\0'&#125;; // 长度为4char a3[] = \"c++\"; // 长度为4char a4[3] = \"c++\"; // 错误，数组空间不足 负载数组声明1234int * ptr[10]; // 含义10个整型指针的数组 int &amp;refs[10]=/*...*/ // 不存在引用的数组int (*Parray)[10]; // 指向一个10个整型元素数组的指针int (&amp;arrRef)[10] // 引用一个10个整型元素数组的指针 显式类型转换static_caststatic_cast可以完成任何具有明确定义的类型转换(支持强制转换)，只要不包含底层const12345int i=2,j=1;double slope = static_cast&lt;double&gt;(j) / i;void* p = &amp;d;double *dp = static_cast&lt;double*&gt;(p); const_castconst_cast只能改变运算对象的底层const，通常用于有函数重载的上下文中1234567const char *pc;char *p = const_cast&lt;char*&gt;(pc);const char *cp;char *q = static_cast&lt;char*&gt;(cp); // 错误，static_cast不能转换掉const性质static_cast&lt;string&gt;(cp); // 正确，字符串字面值转换成string属性const&lt;string&gt;(cp); // 错误，const_cast只改变常量属性 reinterpret_castreinterpret_cast通常为运算对象的位模式提供较低层次上的重新解释，容易引发错误12int *ip;char *cp = reinterpret_cast&lt;char*&gt;(ip); // 虽然转换，但pc所指对象依旧是int型 函数参数传递 用实参初始化形参时会忽略掉顶层const，也就是说给形参传递常量对象或者非常量对象都可以 由于顶层const被忽略，只有形参顶层const差异的函数会被当成同一个函数 可以使用一个非常量初始化一个底层const对象，但是反过来不行 普通引用必须用同类型的对象初始化 12345678910111213141516int func(int i)&#123;...&#125; //int func(const int i)&#123;...&#125; // 错误，重复定义func//————————————————————————————————————————————————————————void reset(int &amp;i)&#123;i=0;&#125;int i=0;const int ci = i;string::size_type ctr = 0;reset(&amp;i); // 调用形参类型是int*的reset函数reset(i); // 调用形参类型是int&amp;的reset函数reset(&amp;ci); // 错误，普通引用必须用同类型的对象初始化reset(ci); // 错误，普通引用必须用同类型的对象初始化reset(42); // 错误，普通引用必须用同类型的对象初始化reset(ctr); // 错误，普通引用必须用同类型的对象初始化 引用返回左值 一般函数的返回值均为右值，但也有返回左值的函数 由函数的返回值类型决定，具体来说，调用一个返回引用的函数得到左值，其他类型为右值 左值可以被赋值，右值不行 如果返回值类型是常量引用，那么就不能赋值了（常量不能修改啊） 12345char &amp;get_val(string &amp;s, string::size_type ix) &#123; //返回的是引用 return s[ix];&#125;string s(\"hello world\");get_val(s,3) = 'A'; // 可以对左值进行赋值 返回数组指针普通的数组指针声明如下 type (*name)[dimension] 返回数组指针的函数形式如下 type ( *function(parameter_list) ) [dimension] 类型别名也可以考虑使用类型别名 typedef int arrT[10]; using arrT = int[10]; arrt* func(int i); 尾置返回类型 任何函数都可以使用尾置返回类型 这种返回方法对复杂的返回类型比较有效 尾置返回类型跟在形参列表后面，以-&gt;开头，在原本返回类型出现的地方加上auto 1auto func(int i) -&gt; int(*) [10]; 使用decltype123456int odd[] = &#123;1,3,5,7,9&#125;;// decltype(odd) 返回的是数组，需要在加一个*变成指针decltype(odd) * func(int i) &#123; // ........... return &amp;odd;&#125; 函数重载 重载函数的名字肯定一样，需要形参类型或者数量上有差异 仅仅返回值不一样不是重载函数，而是重定义 仅有顶层const的差异不构成重载，底层const可以 12345int func(const int i);int func(int i); // 顶层const，重复定义int func(const int * i);int func(int *i); // 底层const，重载函数，指针换引用也一样 作用域 如果在内层作用域中声明名字，它将隐藏外层作用域中所有同名的实体 声明在内部作用域的名字可能会是外部作用域中同名的所有重载函数失效（不声明名字就没事） 不同的作用域中无法承载函数名 默认语言用途默认实参 默认实参填补函数调用缺少的尾部实参，所以默认形参都在尾部 尾部参数没省略时，中间参数不能省略 给定作用域中，一个形参只能被赋予一次默认实参 局部变量不能成为默认实参 12int screen(sz, sz, char=' ');int screen(sz, sz, char='*'); // 错误，重复声明 函数匹配 优先选择精确匹配、最匹配，所谓最匹配要看实参与形参的接近程度 有且只有一个函数满足以下条件，则匹配成功 该函数每个函数的匹配都不劣与其他函数需要的匹配 至少有一个实参的匹配优于其他可行函数提供的匹配 上面两步检查后没有函数脱颖而出，那么判定为二义性，报错 1234int f(int, int);int f(double, double);f(2,2.5); 上面的例子中，对于第一个实参，f(int,int)好；对于第二个实参，f(double,double)好。最终判断此调用具有二义性，拒绝请求。 实参到形参的类型转换分为几个等级，如下 精确匹配 实参、形参类型相同 实参从数组或函数类型转化成对应的指针 向实参添加顶层const、从实参中删除顶层const 通过const转换实现的匹配（比如创建指向非常量的常量指针、引用） 通过类型提升实现的匹配（short+int=int整型提升） 通过算术类型转换（int转double，所有算术类型转换级别一样）或指针实现的匹配 通过类类型转换实现的匹配 inline和constexpr inline函数编译时，一般适用于代码量很少的函数 const是指用于常量表达式的函数，返回类型及所有形参都必须是字面值类型，并且要求有且只有一个return语句 inline函数和constexpr函数可以多次定义，且通常定义在头文件内 调试帮助assertassert的用法是assert(expr);，如果表达式expr的值为true，assert什么也不做；否则，assert输出信息并终止程序执行。 NDEBUG如果定义了NDEBUG，那么调试模式就关闭了，assert就不能起作用了。此外，NDEBUG也有助于开发者编写自己的调试代码。12345#define NDEBUG // 表示关闭了调试模式# ifndef NDEBUG // 没有关闭调试模式// 。。。。# endif 函数指针 函数指针也是指针，可以赋值为nullptr、0等 指向不同函数类型的函数指针不存在类型转换 定义重载函数指针时，指针类型必须与重载函数中的某一个精确匹配 1234567bool func(int);// 定义函数指针bool (*pf)(int) = func; // 定义指向函数func的函数指针bool (*pf)(int) = &amp;func // 与上面等价// 使用函数指针pf(1);(*pf)(2); C++中，形参和返回值都不能是函数，但可以是函数指针，使用类型别名、decltype等可以使得函数指针的声明变得简单123456789101112// 等价的两种定义方式，funcp可以使用在函数实参、返回值typedef bool (*funcp) (int);typedef decltype(func) *funcp;// 使用using、尾置返回类型using pf = bool(*) (int); // pf是函数指针pf f1(int);using f = bool (int); // f类型是函数f *f1(int); // 显示指定返回类型是指向函数的指针auto f1(int) -&gt; bool(*) (int); // 尾置返回类型指定返回类型decltype(func) *f1(int); // 知道返回的函数是哪一个更方便 类定义抽象数据类型const成员函数 const成员函数不能改变调用它的对象的内容 1234567891011double const_func(int a, int b) const &#123;&#125;// 返回this对象的函数// 返回值是引用New_Class&amp; New_Class::hello () &#123; //.... attribute += 1; return *this;&#125;New_Class nc;nc.hello(); // nc的attribute属性已经改变了 类相关的非成员函数 这里的相关非成员函数包括但不限于read、print等 如果非成员函数是类接口的组成部分，这些函数的声明应当与类在同一个头文件内 12345678910// IO类型不能拷贝，所以只能以引用的形式加入形参// 最后需要返回IO类型的引用// ostream、print也类似，定义输出函数应该尽量减少对格式的控制istream &amp;read(istream &amp;is, New_Class &amp;item) &#123; is &gt;&gt; item.a1 &gt;&gt; item.a2 &gt;&gt; item.a3; return is;&#125;// 调用istream &amp;is;read(is, *this) 构造函数 构造函数不能为const const对象和引用都应该在初始值列表中初始化 初始化列表：成员初始化的顺序与类定义中的顺序一致 构造const对象时，知道构造函数完成其初始化过程，对象才能取得其“常量”属性 默认构造函数的规则如下： 如果有别的构造函数，编译器不会生成默认构造函数 如果存在类内初始值，用它来初始化成员 否则，默认初始化（string为””，int块外为0，块内未定义） C++11中，如果需要默认行为可以在参数列表之后写上 =default要求编译器生成默认构造函数 当某个数据成员被构造函数初始值列表忽略时，它将以合成默认构造函数相同的方式隐式初始化 12345// 有其他构造函数的情况下，还想要默认构造函数可以这样New_Class() = default;// 通过默认参数也等与实现了默认构造函数New_Class(string s = \" \"):name(s)&#123;&#125; 委托构造函数就是利用其他构造函数执行自己的初始化过程，其在参数列表初始化位置调用其他构造函数1New_Class() : New_Class(\"zhangsan\")&#123;&#125; 隐式类类型转换 通过一个实参调用的构造函数定义一条从构造函数参数类型向类类型隐式转换的规则 只允许一步类类型转换，隐式转换可能会出错 抑制隐式转换的方法是在构造函数前加上关键字explicit 使用static_cast这样的显式转换也能达到转换的效果1234string lisi = \"lisi\";New_Class zhangsan(\"zhangsan\");// playWith函数的参数类型是New_Classzhangsan.playWith(lisi); 访问控制与封装 class和struct定义类时的唯一区别就是默认访问权限 struct默认为public，而class默认为private 友元 类中使用friend关键字可以使其他类或者函数成为它的友元 成为友元的类、函数可以访问当前类的非公有成员 友元不是类的成员，不受其所在区域访问控制级别的约束 类内友元函数的声明并非普通意义上的声明，所以在其他地方还得声明一次，即便定义在类内部也还要在外面声明 友元函数也可以定义在类内部，隐式inline 友元关系不存在传递性 1234class Class2 &#123;friend class Class1;friend istream &amp; read(istream &amp;is, Class2 &amp; c2);&#125; 其他特性 定义在类内部的成员函数自动是inline类型的 mutable成员用于不会是const，即使在const成员函数内他也是可以被改变的 返回*this的函数返回的是左值引用（返回类型是引用），返回的是对象本身而不是副本 聚合类 所有成员都是public 没有定义任何构造函数 没有类内初始值 没有基类、没有虚函数 12345struct data &#123; int x; char c; string s;&#125; 类的静态成员 静态成员于类本身直接相关 静态成员函数不包含this指针、也不能显式、隐式地使用this指针（不能操作非静态成员） 静态成员函数不能声明成const 在类的外部定义静态成员时，不能重复static关键字 静态成员变量应该在类的外部定义 静态数据成员可以是不完全类型（类在声明之后、定义之前称为不完全类型） 静态成员可以是默认实参，非静态的不可以 12345class A &#123;private: static A a; // 正确，静态成员可以使不完全类型 A b; // 错误，数据成员必须是完全类型，不过可以定义指针、引用&#125; IO库与容器库string流sstream包含三个支持string读写的类型，分别是istringstream、ostringstream和stringstream。sstream的使用可以如下12345sstream strm;sstream strm(s); // strm是sstream的对象，保存string s的拷贝strm.str() // 返回strm所保存的string的拷贝strm.str(s) // copy string s to strm, return void istringstream、ostringstream的用法也很简单，如下所示1234string line(\"suck my balls\"), word;istringstream is(line);while (is &gt;&gt; word) cout &lt;&lt; word &lt;&lt; endl; 向ostringstream对象写入string其实就是将string添加字符。 array array容器的大小是一定的，其大小也是类型的一部分 array容器与普通数组不同的是，array支持拷贝与赋值 12345array&lt;int&gt; arr; // 错误，缺少大小array&lt;int, 10&gt; arr1 // 正确array&lt;int, 3&gt; arr = &#123;0, 1, 2&#125;;array&lt;int, 3&gt; arr1 = arr; //正确，类型一定要一致 顺序容器的操作seq.assign(b,e); // 将seq中的元素替换成迭代器b、e所表示范围中的元素 seq.assign(il); // 将seq中的元素替换成初始化列表il中的元素，比如il={1,2,3,4}，为值列表 seq.assign(n,t); // 将seq中的元素替换成n个元素t c.insert(p, t); // 在迭代器p之前添加元素t，返回添加元素的迭代器 c.insert(p, n, t); // 在迭代器p之前添加n个元素t，返回第一个添加的元素的迭代器 c.insert(p, b, e); // 在迭代器p之前添加迭代器b、e之间的元素 c.insert(p, il); 向一个vector、string、deque插入元素会使所有的指向容器的迭代器、引用和指针失效 emplace_front, emplace_back, emplace分别对应push_front, push_back, insert 这些函数可以构造元素 123456789class person&#123;public: string name; int age; person(string nm, int ag);&#125;c.emplace_front(\"zhangsan\", 10); // 插入10岁的zhangsan的元素c.push_front(\"zhangsan\", 10); // 错误，没有接受三个参数的push_front版本c.push_front(person(\"zhangsan\",10)); // 正确，先构造对象 顺序容器还支持关系运算符，从头向尾比较，比较直观。 swapc1.swap(c2); swap(c1, c2); swap交换元素很快，因为元素本身没有交换，swap只是交换了两个容器的内部数据结构 array是个例外，swap真正交换元素，所以交换所需时间与元素数目成正比 改变容器大小、容量改变size：size是容器当前大小，采用多退少补的方法 函数resize可以改变改变容器大小resize(n)，也可以将新添加的元素设置为t resize(n,t) array不支持 改变capacity：capacity是容器的最大容量 capacity()获取容量 reserve(n)分布至少能容纳n个元素的内存空间 shrink_to_fit()将capacity减少为size大小 string的搜索操作 函数 解释 s.find(args) s中args第一次出现的位置 s.rfind(args) s中args最后一次出现的位置 s.find_first_of(args) s中查找args中任何一个字符第一次出现的位置 s.find_last_of(args) s中查找args中任何一个字符最后一次出现的位置 s.find_first_not_of(args) s中查找第一个不在args中的字符 s.find_last_not_of(args) s中查找最后一个不在args中的字符 其中args的形式为包括（pos默认为0） c, pos ： pos为开始查找的位置，c是一个字符 s2, pos： s2是字符串 cp, pos： cp是指向c风格的字符串的指针（以&#39;\\0&#39;结尾） cp, pos, n： n表示只看前n个字符 搜索失败则返回一个名为string::npos的static成员，其值初始化为-1. string数制转换 函数 解释 to_string(val) 任何算术类型向string转换 stoi(s, p, b) string转int，s是字符串 stol(s, p, b) string转long，b是转换基数（默认为10，十进制） stoul(s, p, b) string转unsigned long，p是起始位置 stoll(s, p, b) string转long long stoull(s, p, b) string转unsigned long long stof(s, p) string转float，p是起始位置 stod(s, p) string转double stold(s, p) string转long double 容器适配器适配器是一种机制，能使某种事物的行为看起来像另外一种事物标准库中有三个顺序容器适配器，stack、queue、priority_queue 泛型算法 泛型算法定义在头文件numeric中 几个基本的泛型算法 find(iter1, iter2, val); // 元素查找，iter1、iter2迭代器至少查找的范围，val是查找的元素。查找失败返回iter2，否则返回对应的迭代器 accumulate(iter1, iter2, sum); // 元素累加，执行+运算，sum是和的初值，返回最终的和 equal(iter1, iter2, another_iter); // 比较两个序列元素是否完全一致，一致返回true。another_iter表示第二个序列的起始迭代器 fill(iter1, iter2, val); // 将迭代器范围中的每个值置为val fill_n(iter, n, val); // 将从iter起的n个元素置为val（必须保证有n个元素） copy(iter1, iter2, another_iter); // 将iter1-iter2范围内的元素拷贝到以another_iter起始的位置上，要求another_iter对应的容器大小不能比iter1对应的容器小，返回another_iter的位置迭代器位置 replace(iter1, iter2, val, new_val); // 迭代器范围内，将所有的val换成 new_val replace_copy(iter1, iter2, new_iter, val, new_val); // 保持iter1对应的容器不变，将替换后的结果写入new_iter对应的容器中 unique(iter1, iter2); // 去重，返回指向不重复区域之后一个位置的迭代器 定制操作lambda表达式[捕获列表] (参数列表) -&gt; 返回类型 {函数体}; lambda可以理解成未命名的inline函数 捕获列表：表达式所在函数的局部变量列表，局部变量间以,分隔，通常为空。&amp;引用捕获，= 参数列表、返回类型、函数体和普通函数一个意思 参数列表和返回类型可以忽略，但捕获列表和函数体必须存在 lambda表达式的返回值是一个可调用对象，不接收参数，直接带括号调用。可调用对象包括函数、函数指针、lambda表达式等 12auto f = []&#123;return 0;&#125; // f是可调用对象cout &lt;&lt; f() &lt;&lt; endl; bind函数 头文件为functional 接受一个可调用对象，生成一个新的可调用对象来适应原对象的参数列表 可以看成一个通用的函数适配器 bind在绑定过程中都是采用参数拷贝的方式，所以对于需要引用的类型，可以使用ref、cref函数表示引用（常量c） auto newCallable = bind(callable, arg_list); arg_list中可能包含_n这样的名字（n是整数），这些是占位符，表示newCallable的参数。_n表示第n个参数。12345678910// f是有5个参数的可调用对象auto g = bind(f, a, b, _2, c, _1);// 传递给g的参数会被分别绑定到_1、_2位置上// g(X, Y) 等价于 f(a, b, Y, c, X)ostream &amp;print(ostream &amp;os, string &amp;s, char c) &#123; return os &lt;&lt; s &lt;&lt; c;&#125;for_each(words.begin(), words.end(), bind(print, os, _1, ' ')); // 错误，os不能拷贝for_each(words.begin(), words.end(), bind(print, ref(os), _1, ' ')); //正确 特殊迭代器插入迭代器包括back_inserter, front_inserter, inserter三种，分别创建使用push_back, push_front, insert的迭代器。使用 inserter(c, iter)时，插入元素位置在iter位置之前，并且插入前后，iter指向的元素不变；但是front_inserter(c)就一直在容器头部插入。123456list&lt;int&gt; lst = &#123;1,2,3,4&#125;;list&lt;int&gt; lst2, lst3;// 插入后lst2为 4 3 2 1copy(lst.begin(), lst.end(), front_inserter(lst2));// 插入后lst3为 1 2 3 4copy(lst.begin(), lst.end(), inserter(lst3, lst3.begin())); iostream迭代器 使用流迭代器，必须指定读写对象的类型 istream_iterator迭代器要读取的内容必须定义了&gt;&gt;运算符，ostream_iterator迭代器要读取的内容必须定义了&lt;&lt;运算符 默认初始化istream_iterator迭代器，创建一个当作尾后值使用的迭代器 流迭代器不支持递减--操作 istream_iterator迭代器支持++, *, -&gt;, ==, !=运算符 ostream_iterator迭代器支持++, =, *运算符 123456789101112istream_iterator&lt;T&gt; in(is); // 迭代器对象in从输入流is中读取类型为T的值istream_iterator&lt;T&gt; eof; // 尾后迭代器vector&lt;T&gt; vec(in, eof); // 从迭代器范围构造vector对象accumulate(in, eof, 0); // 求和ostream_iterator&lt;T&gt; out(os); // out将类型为T的输出值写入到输出流os中ostream_iterator&lt;T&gt; out(os, d); // out将类型为T的输出值写入到输出流os中，每个值后面都额外输出一个d（d是C风格的字符串）for (anto e : vec) *out++ = e; // 直接写out=e;也可以，不过不推荐这么写cout &lt;&lt; endl;copy(vec.begin(), vec.end(), out);cout &lt;&lt; endl; 反向迭代器 在容器中从尾元素向首元素反向移动的迭代器 其递增、递减的操作是反过来的，即++会向前移动，前也是相对移动方向的 除了forward_list外都支持，使用rbegin(),crbegin()等 链表类容器的特殊方法list、forward_list 方法 说明 lst.merge(lst2) 将lst2中的元素合并入lst，要求lst、lst2都必须有序 lst.merge(lst2, comp) comp为特定的比较函数 lst.remove(val) 调用erase删除lst内与val相等的元素 lst.remove(pred) 调用erase删除lst内使得一元谓词pred成立的元素 lst.reverse() 反转lst中元素的顺序 lst.sort() 排序，可以使用comp lst.unique() 调用erase去重 lst.unique(pred) 调用erase去重，重复指的是满足二元谓词pred的元素 谓词是返回可以转换为bool类型值的函数。元对应参数个数 关联容器 关联容器支持高效的关键字查询和访问，可以分为有序集合和无序集合两种 map和set的迭代器都不允许修改关键字分类| 有序类型 | 说明 ||————|————|| map | 关联数组，保存（key, value）对 || set | 只保存关键字 ||multimap| 关键字可重复出现的map||multiset| 关键字可重复出现的set | 无序类型 说明 unordered_map 用哈希函数组织的map unordered_set 用哈希函数组织的set unordered_multimap …. unordered_multiset …. 12345678vector&lt;int&gt; vec;for (int i=0; i&lt;10; i++) &#123; vec.push_back(i); vec.push_back(i);&#125;set&lt;int&gt; iset(vec.cbegin(), vec.cend()); // 10个元素multiset&lt;int&gt; imset(vec.cbegin(), vec.cend()); // 20个元素 关键字类型要求 有序元素的关键字类型必须定义元素比较的方法 不支持比较的复杂类型需要自定义比较函数 1234// compareClass1是进行Class1对象比较的函数，定义时需要添加比较函数的函数指针// 直接使用compareClass1也行，因为函数名会转化为函数指针// 构造函数也使用比较函数的函数指针set&lt;Class1, decltype(compareClass1)*&gt; cls(compareClass1); 关联容器额外的类型别名key_type : 容器的关键字类型 value_type : 对于set，与key_type相同；map则是pair&lt;key, value&gt; mapped_type : 关键字关联的类型 添加元素c.insert(v); c.emplace(args); c.insert(iter1, iter2); c.insert(il); // 花括号列表，返回void c.insert(iter, v); // 迭代器指示搜索新元素存储应该存储的位置。返回一个迭代器，指向具有给定关键字的元素 c.emplace(iter, args); 对于不包含重复关键字的容器，添加单一元素的inert和emplace返回一个pair，指示插入操作是否成功。pair的首元素（first）是一个迭代器，指向具有指定关键字的元素；second是一个bool值，指示元素成功插入还是已经存在于容器中，成功插入为true，否则为false。123auto ret = word_count.insert(&#123;\"hello\", 1&#125;); 尝试插入if (!ret.second) // 元素已经存在map中 ++ret.first-&gt;second; // ret.first是指向“hello”关键字的迭代器，迭代器指向的second元素是原本\"hello\"对应的数目，加一即可 访问元素c.find(k); // 返回指向第一个key为k的迭代器 c.count(k); // 返回关键字k的个数 c.lower_bound(k); // 返回一个迭代器，指向第一个关键字不小于k的元素 c.upper_bound(k); // 返回一个迭代器，指向第一个关键字大于k的元素 c.equal_range(k); // 返回一个迭代器pair，表示关键字等于k的元素的范围。如不存在，则pair的两个成员均为c.end() lower_bound和upper_bound只适用于有序容器通过下标访问元素返回左值，既可以读，也可以写回 无序容器 无序容器在存储上组织为一组桶，每个桶保存0个或多个元素 无序容器的性能依赖于哈希函数的质量和桶的大小 c.bucket_count(); // 正在使用的桶数目 c.max_bucket_count(); // 容器能容纳的最多的桶的数量 c.bucket_size(n); // 第n个桶中有多少个元素 c.bucket(k); // 关键字为k的元素在哪个桶中 local_iterator // 访问桶中元素的迭代器 const_local_iterator // const版本 c.begin(n), c.end(n) // 桶n元素的首、尾迭代器 c.cbegin(n), c.cend(n) c.load_factor(); // 每个桶的平均元素数量，float类型 c.max_load_factor(); // 最大平均桶元素数量，每个桶的平均元素数量大于这个值就需要添加新的桶 c.rehash(n); // 重组存储，使得bucket_count &gt;= n且bucket_count&gt;size/max_load_factor c.reserve(n); // 重组存储，使得c可以保存n个元素且不必rehash 无序容器对关键字的要求 无序容器使用==运算符比较元素 使用hash&lt;key_type&gt;类型的对象生成每个元素的哈希值 123456789size_t hasher(const Class1 &amp; cls) &#123; return hash&lt;string&gt;()(cls.name);&#125;bool eqop(const Class1 &amp; cls1, const Class1 &amp; cls2) &#123; return cls1.name == cls2.name;&#125;using clsset = unordered_set&lt;Class1, hasher, eqop&gt;;// 42是桶大小clsset s(42, hasher, eqop);","categories":[],"tags":[{"name":"Cpp","slug":"Cpp","permalink":"atlantic8.github.io/tags/Cpp/"}]},{"title":"H-Index","slug":"H-Index","date":"2017-02-21T12:30:46.000Z","updated":"2018-12-16T14:08:06.252Z","comments":true,"path":"2017/02/21/H-Index/","link":"","permalink":"atlantic8.github.io/2017/02/21/H-Index/","excerpt":"","text":"H-Index IH-Index维基百科上H-Index的定义如下 一个科学家的H-Index为h，如果他一共有N篇文章，其中有h篇文章每一篇都至少有h次引用，其他N-h篇论文每一篇都不超过h次引用 比如给定citations = [3, 0, 6, 1, 5]，表示当前研究者有5篇论文，其引用为citations中。因为这些论文中有3篇论文每篇都至少有3次引用，其他2篇都没有3次应用，所以他的H-Index为3。 题目描述给定某个科学家论文引用数目的数组（非负），输出他的H-Index 解题方案首先，一个拥有N篇论文的科学家，他的H-Index不可能会超过N，最大就是N，最小是0。所以如果一篇论文的引用超过N，那么这篇论文的引用在计算H-Index时和N个引用是一样的；如果引用小于N，不妨设置为t，这篇论文只在H-Index小于等于t时有用，如果H-Index大于t，这篇论文不能被计数。 所以，设置一个长度为N+1的辅助数组array，扫描citations数组，对于每个引用t，如果 t &lt; N : array[t]++ t &gt;= N : array[N]++ 得到数组array数组，从后向前，判断方式为如果$ \\sum_{k=i}^{N} array[k] &gt;= i $，那么返回$i$，否则继续向前寻找。123456789101112131415int hIndex(vector&lt;int&gt; &amp; citations) &#123; int N = citations.size(); if (N == 0) return 0; vector&lt;int&gt; array(N+1, 0); for (int i=0; i&lt;N; i++) &#123; if (citations[i] &gt; N) array[N]++; else array[citations[i]]++; &#125; int sum = 0; for (int i=N; i&gt;0; i--) &#123; sum += array[i]; if (sum &gt;= i) return i; &#125; return 0;&#125; H-Index II题目描述在H-Index的基础上，假设给定的citations数据是按升序排序的。求H-Index 解题方案对于第k篇论文，其引用为citations[k]，引用数大于等于citations[k]的论文数量为N-k，所以对应的H-Index为min(N-k, citations[k])。从前向后考虑，开始时始终有citations[k]&lt;N-k，对应的候选H-Index为citations[k]，到后面有citations[k]&gt;N-k，对应的H-Index为N-k。也就是说候选H-Index经历了先增大后减小的过程，转折过程就是citations[k]第一次大于等于N-k的时候。由于H-Index也限制“其他N-h篇论文每一篇都不超过h次引用”，所以我们的目标就是找到第一个citations[k]&gt;=N-k的序号k，因为此时k对应的候选H-Index为N-k，而k-1对应的候选H-Index肯定小于N-k+1，所以k必对应着最优解。 现在有了O(n)复杂度的算法，考虑到引用数据是严格有序的，所以可以使用类似于二分搜索的方法。此时，可以稍微换个角度思考。对于第k篇论文，其引用为citations[k]，如果N-k&gt;=citations[k]，那么citations[k]就是合格的H-Index，此时应该向右尝试寻找更大的H-Index（因为左边的citations小）；如果N-k&lt;citations[k]，那么citations[k]就不是一个当前合法的H-Index（N-k是），所以要向左尝试寻找。 出现N-k=citations[k]直接结束了。否则必然存在k满足citations[k]&lt;N-k &amp;&amp; citations[k+1]&gt;N-k-1，现在考虑k,k+1,left,right最终的可能关系，如下 | k k+1 | k k+1 | k k+1 | k k+1 | k k+1 | | left right | left right | left right | left right | left right | 后面两种情况不可能出现，前三种情况的最终结果都是 `N-left` 再来考虑停止条件，两种情况left=right或者left+1=right。 当第一种情况出现，mid=left，此时如果citations[mid] &gt; N-mid，那么mid=left就是最佳位置，H-Index为N-mid；否则最佳位置在left后一位，此时将left=mid+1后，N-left就是最佳H-Index。 当第二种情况出现，left+1=right，mid=left，此时如果citations[mid] &gt; N-mid，那么mid=left就是最佳位置，H-Index为N-mid；否则，设置left=mid+1，回到了第一种情况。 1234567891011int hIndex(vector&lt;int&gt;&amp; citations) &#123; int N=citations.size(), left=0, right=N-1, ret=0; if (N == 0) return 0; while (left &lt;= right) &#123; int mid = left + (right-left)/2; if (citations[mid] == N-mid) return N-mid; else if (citations[mid] &gt; N-mid) right = mid-1; // 向左寻找 else left = mid+1; // 向右寻找 &#125; return N-left;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Partition","slug":"Partition","date":"2017-02-21T05:38:18.000Z","updated":"2018-12-16T14:08:06.373Z","comments":true,"path":"2017/02/21/Partition/","link":"","permalink":"atlantic8.github.io/2017/02/21/Partition/","excerpt":"","text":"partition函数partition函数是快速排序的核心部分，选定一个基准，然后将大于和小于基准的数分别放置于基准的两边，有多种实现方式，以下是参考 123456789101112131415161718// start, end表明作用范围// pivotIndex表示基准的位置int partition(vector&lt;int&gt; &amp; A, int start, int end)&#123; int i = start, j = end; int pivotIndex = rand() % (end-start+1) + start; // 随机选择基准位置 int pivot = A[pivotIndex]; // 把基准换到最后 swap&lt;int&gt;(A[end], A[pivotIndex]); while(i &lt; j)&#123; while(i &lt; j &amp;&amp; A[i] &lt; pivot) ++i; if (i &gt; j) break; while(i &lt; j &amp;&amp; A[j] &gt;= pivot) --j; if (i &gt; j) break; if(i &lt; j) swap&lt;int&gt;(A[i], A[j]); &#125; swap&lt;int&gt;(A[end], A[i]); return i;&#125; 再提供另一种实现方式 123456789101112131415// arr[]为数组，start、end分别为数组第一个元素和最后一个元素的索引// povitIndex为数组中任意选中的数的索引int partition(int arr[], int start, int end, int pivotIndex) &#123; int pivot = arr[pivotIndex]; swap(arr[pivotIndex], arr[end]); int storeIndex = start; for(int i = start; i &lt; end; ++i) &#123; if(arr[i] &lt; pivot) &#123; swap(arr[i], arr[storeIndex]); ++storeIndex; &#125; &#125; swap(arr[storeIndex], arr[end]); return storeIndex;&#125; Partition函数的应用快速排序12345void quick_sort(vector&lt;int&gt; &amp;A, int start, int end) &#123; int mid = partition(A, start, end); if (mid-start &gt; 2) quick_sort(A, start, mid-1); if (end-mid &gt; 2) quick_sort(A, mid+1, end);&#125; Top K问题给定未排序数组A，求排好序的数组中的第k个大个数。因为上面的partition函数是左小右大，所以我们考虑寻找第A.size()-k小的数。思路是调用partition函数，返回基准位置，如果基准位置正好是k，那么返回其对应的值否则，如果基准在k左侧，则考虑基准右边的元素；否则考虑左边的元素。123456789int findKthLargest (vector&lt;int&gt; &amp;A, int k) &#123; int start=0, end=A.size()-1; while (start &lt; end) &#123; int mid = partition(A, start, end); if (mid == k-1) return A[k-1]; else if (mid &lt; k-1) start = mid+1; else end = mid-1; &#125;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Sort","slug":"Sort","permalink":"atlantic8.github.io/tags/Sort/"}]},{"title":"Sliding Window Maximum","slug":"Sliding-Window-Maximum","date":"2017-02-16T07:31:45.000Z","updated":"2018-12-16T14:08:06.406Z","comments":true,"path":"2017/02/16/Sliding-Window-Maximum/","link":"","permalink":"atlantic8.github.io/2017/02/16/Sliding-Window-Maximum/","excerpt":"","text":"题目描述给定数组nums，和滑动窗口的长度k，输出滑动窗口一次一个元素地向前滑动时每一时刻滑动窗口内的最大值。要求在O(n)复杂度内完成。 nums = [1,3,-1,-3,5,3,6,7], k = 3 Window position Max --------------- ----- [1 3 -1] -3 5 3 6 7 3 1 [3 -1 -3] 5 3 6 7 3 1 3 [-1 -3 5] 3 6 7 5 1 3 -1 [-3 5 3] 6 7 5 1 3 -1 -3 [5 3 6] 7 6 1 3 -1 -3 5 [3 6 7] 7 --------------- ----- output [3,3,5,5,6,7] 解题思路滑动窗口内添加新元素简单，但是删除时比较麻烦，所以简单使用堆的思路不行。 双端队列对滑动窗口有比较好的模拟，其尾部、头部都可以添加和删除元素（也有受限的应用版本）。 本题使用的方法也称作单调队列，其定义如下： 队列中元素之间的关系具有单调性，而且，队首和队尾都可以进行出队操作，只有队尾可以进行入队操作 以单调不减队列为例，队列内的元素$(e_1,e_2,…,e_n)$存在$(e_1\\le e_2\\le…\\le e_n)$的关系，所以队首元素$e_1$一定是最小的元素。与优先队列不同的是，当有一个新的元素$e$入队时，先要将队尾的所有大于$e$的元素弹出，以保证单调性，再让元素$e$入队尾。 所以本题的方法描述如下： 队列元素如果超过了k的限制，那么从队头剔除 从队尾起，如果队尾的元素小于当前需要添加的元素，那么剔除队尾元素（它不可能成为最大值），直到队尾元素大于等于当前需要添加的元素。 此时，队列是非递减队列，所以队头元素就是最大值 1234567891011121314vector&lt;int&gt; maxSlidingWindow(vector&lt;int&gt;&amp; nums, int k) &#123; vector&lt;int&gt; ret; deque&lt;int&gt; window; if (nums.size()&lt;1 || k&lt;=0) return ret; for (int i=0; i&lt;nums.size(); i++) &#123; if (!window.empty() &amp;&amp; window.front()&lt;i-k+1) window.pop_front(); while (!window.empty() &amp;&amp; nums[window.back()]&lt;nums[i]) window.pop_back(); window.push_back(i); if (i &gt;= k-1) ret.push_back(nums[window.front()]); &#125; return ret;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"Sliding window","slug":"Sliding-window","permalink":"atlantic8.github.io/tags/Sliding-window/"}]},{"title":"Java Future","slug":"Java-Future","date":"2017-01-18T02:25:54.000Z","updated":"2018-12-16T14:08:06.276Z","comments":true,"path":"2017/01/18/Java-Future/","link":"","permalink":"atlantic8.github.io/2017/01/18/Java-Future/","excerpt":"","text":"Callable与RunnableJava中的多线程实现可以通过继承Thread或者实现Runnable接口来实现，但是这两种方法都不能将执行结果取回。Runnable接口定义如下：123public interface Runnable &#123; public abstract void run();&#125; 由于run()方法返回值为void类型，所以在执行完任务之后无法返回任何结果。 Callable位于java.util.concurrent包下，它也是一个泛型接口，在它里面也只声明了一个方法call()，返回的类型就是传递进来的V类型：123456789public interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125; Callable一般情况下是配合ExecutorService来使用的，在ExecutorService接口中声明了若干个submit方法的重载版本：12345&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);Future&lt;?&gt; submit(Runnable task); 这三个方法中，常用的是第一个和第三个。 FutureFuture是一个接口，位于java.util.concurrent包下，定义如下1234567public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; Future就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果。必要时可以通过get方法获取执行结果，此方法会阻塞直到任务返回结果。上述方法中： 1 cancel方法用来取消任务，如果取消任务成功则返回true，如果取消任务失败则返回false。参数mayInterruptIfRunning表示是否允许取消正在执行却没有执行完毕的任务，如果设置true，则表示可以取消正在执行过程中的任务。如果任务已经完成，则无论mayInterruptIfRunning为true还是false，此方法肯定返回false，即如果取消已经完成的任务会返回false；如果任务正在执行，若mayInterruptIfRunning设置为true，则返回true，若mayInterruptIfRunning设置为false，则返回false；如果任务还没有执行，则无论mayInterruptIfRunning为true还是false，肯定返回true 2 isCancelled方法表示任务是否被取消成功，如果在任务正常完成前被取消成功，则返回 true 3 isDone方法表示任务是否已经完成，若任务完成，则返回true 4 get()方法用来获取执行结果，这个方法会产生阻塞，会一直等到任务执行完毕才返回 5 get(long timeout, TimeUnit unit)用来获取执行结果，如果在指定时间内，还没获取到结果，就直接返回null FutureTask由于Future是个接口，所以其不能实例化，FutureTask应运而生，也是Future接口的唯一实现类。 FutureTask类实现了RunnableFuture接口12345public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; &#123;&#125;public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; void run();&#125; RunnableFuture继承了Runnable接口和Future接口，而FutureTask实现了RunnableFuture接口，关系如图所示。所以它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值。 ![关系图](http://wx1.sinaimg.cn/mw690/9bcfe727ly1fbumuzrzbaj20hz0dhq31.jpg) FutureTask提供了2个构造器12345public FutureTask(Callable&lt;V&gt; callable) &#123;&#125;public FutureTask(Runnable runnable, V result) &#123;&#125; 使用方法使用Callable + Future获取执行结果123456789101112131415161718192021222324ExecutorService executor = Executors.newCachedThreadPool();Task task = new Task();Future&lt;Integer&gt; result = executor.submit(task);executor.shutdown();try &#123; System.out.println(\"task运行结果\"+result.get());&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; catch (ExecutionException e) &#123; e.printStackTrace();&#125;class Task implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; System.out.println(\"子线程在进行计算\"); Thread.sleep(3000); int sum = 0; for(int i=0;i&lt;100;i++) sum += i; return sum; &#125;&#125; 使用Callable + FutureTask获取执行结果1234567891011121314151617181920212223242526ExecutorService executor = Executors.newCachedThreadPool();Task task = new Task();FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(task);executor.submit(futureTask);executor.shutdown();try &#123; System.out.println(\"task运行结果\"+futureTask.get());&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; catch (ExecutionException e) &#123; e.printStackTrace();&#125;class Task implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; System.out.println(\"子线程在进行计算\"); Thread.sleep(3000); int sum = 0; for(int i=0;i&lt;100;i++) sum += i; return sum; &#125;&#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"atlantic8.github.io/tags/Java/"}]},{"title":"Java Thread Pool","slug":"Java-Thread-Pool","date":"2017-01-17T06:43:08.000Z","updated":"2018-12-16T14:08:06.278Z","comments":true,"path":"2017/01/17/Java-Thread-Pool/","link":"","permalink":"atlantic8.github.io/2017/01/17/Java-Thread-Pool/","excerpt":"","text":"ThreadPoolExecutor 构造方法java.uitl.concurrent.ThreadPoolExecutor类是线程池中最核心的一个类，继承自AbstractExecutorService，AbstractExecutorService是一个抽象类，它实现了ExecutorService接口。ThreadPoolExecutor的构造方法如下：1234567891011121314public class ThreadPoolExecutor extends AbstractExecutorService &#123; public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler);&#125; 前面三个构造器都是调用的第四个构造器进行的初始化工作，参数介绍如下： 1 corePoolSize : 核心池的大小。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中。（正式工）2 maximumPoolSize : 线程池最大线程数，表示在线程池中最多能创建多少个线程。最大线程数意味着当核心池不够用时可以额外开辟新线程，但这些新加入的线程在空闲时可以销毁（临时工）。3 keepAliveTime : 线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0。4 unit : keepAliveTime的时间单位. 包括 TimeUnit.DAYS TimeUnit.HOURS TimeUnit.MINUTES TimeUnit.SECONDS TimeUnit.MILLISECONDS TimeUnit.MICROSECONDS TimeUnit.NANOSECONDS 5 workQueue : 一个阻塞队列，用来存储等待执行的任务。可以是如下三种，其中ArrayBlockingQueue和PriorityBlockingQueue使用较少，一般使用LinkedBlockingQueue和Synchronous。线程池的排队策略与BlockingQueue有关。 ArrayBlockingQueue：基于数组的先进先出队列，此队列创建时必须指定大小 LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE SynchronousQueue：不会保存提交的任务，而是将直接新建一个线程来执行新来的任务 PriorityBlockingQueue 6 threadFactory ：线程工厂，主要用来创建线程7 handler ：表示当拒绝处理任务时的策略，可以是 ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程） ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 继承结构Executor是一个顶层接口，在它里面只声明了一个方法execute(Runnable)，返回值为void，参数为Runnable类型，从字面意思可以理解，就是用来执行传进去的任务的。 ExecutorService接口继承了Executor接口，并声明了一些方法：submit、invokeAll、invokeAny以及shutDown等。 抽象类AbstractExecutorService实现了ExecutorService接口，基本实现了ExecutorService中声明的所有方法。 ThreadPoolExecutor继承了类AbstractExecutorService。在ThreadPoolExecutor类中有几个非常重要的方法： 1 execute() : execute()方法实际上是Executor中声明的方法，在ThreadPoolExecutor进行了具体的实现，这个方法是ThreadPoolExecutor的核心方法，通过这个方法可以向线程池提交一个任务，交由线程池去执行。 2 submit() : submit()方法是在ExecutorService中声明的方法，在AbstractExecutorService就已经有了具体的实现，在ThreadPoolExecutor中并没有对其进行重写，这个方法也是用来向线程池提交任务的，但是它和execute()方法不同，它能够返回任务执行的结果(Future) 3 shutdown() : 关闭线程池，不再接受新的任务，等到所有线程完成任务关闭线程池 4 shutdownNow() : 立即结束所有线程，关闭线程池 线程池实现原理 线程状态ThreadPoolExecutor中定义了一个volatile变量volatile int runState表示当前线程池的状态，它是一个volatile变量用来保证线程之间的可见性。还有几个static final变量表示runState可能的几个取值： static final int RUNNING = 0; static final int SHUTDOWN = 1; static final int STOP = 2; static final int TERMINATED = 3; 创建线程池后，初始时，线程池处于RUNNING状态。调用了shutdown()方法，则线程池处于SHUTDOWN状态，此时线程池不能够接受新的任务，它会等待所有任务执行完毕。调用了shutdownNow()方法，则线程池处于STOP状态，此时线程池不能接受新的任务，并且会去尝试终止正在执行的任务。当线程池处于SHUTDOWN或STOP状态，并且所有工作线程已经销毁，任务缓存队列已经清空或执行结束后，线程池被设置为TERMINATED状态。 任务执行ThreadPoolExecutor类中其他的一些比较重要成员变量如下：1234567891011121314151617181920212223private final BlockingQueue&lt;Runnable&gt; workQueue; //任务缓存队列，用来存放等待执行的任务private final ReentrantLock mainLock = new ReentrantLock(); //线程池的主要状态锁，对线程池状态（比如线程池大小、runState等）的改变都要使用这个锁private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); //用来存放工作集private volatile long keepAliveTime; //线程存货时间private volatile boolean allowCoreThreadTimeOut; //是否允许为核心线程设置存活时间private volatile int corePoolSize; //核心池的大小（即线程池中的线程数目大于这个参数时，提交的任务会被放进任务缓存队列）private volatile int maximumPoolSize; //线程池最大能容忍的线程数private volatile int poolSize; //线程池中当前的线程数private volatile RejectedExecutionHandler handler; //任务拒绝策略private volatile ThreadFactory threadFactory; //线程工厂，用来创建线程private int largestPoolSize; //用来记录线程池中曾经出现过的最大线程数private long completedTaskCount; //用来记录已经执行完毕的任务个数 任务提交执行依靠execute()方法，submit()也是提交任务的方法，但是它也是调用了execute()方法。execute()方法处理方法的逻辑如下： 1234567891011public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) &#123; if (runState == RUNNING &amp;&amp; workQueue.offer(command)) &#123; if (runState != RUNNING || poolSize == 0) ensureQueuedTaskHandled(command); &#125; else if (!addIfUnderMaximumPoolSize(command)) reject(command); // is shutdown or saturated &#125;&#125; 首先，判断提交的任务command是否为null，若是null，则抛出空指针异常。接着还是一个判断语句，如果线程池中当前线程数不小于核心池大小，直接执行判断语句中的代码；否则执行addIfUnderCorePoolSize(command)，如果返回false，则继续执行判断语句中的代码，否则整个方法就直接执行完毕了。 第二层判断语句中，如果当前线程池处于RUNNING状态，则将任务放入任务缓存队列(workQueue.offer(command)就是将任务放入缓存队列)；如果当前线程池不处于RUNNING状态或者任务放入缓存队列失败，则执行addIfUnderMaximumPoolSize(command)，如果执行addIfUnderMaximumPoolSize方法失败，则执行reject()方法进行任务拒绝处理。 如果说当前线程池处于RUNNING状态且将任务放入任务缓存队列成功，则继续执行第三层判断语句if (runState != RUNNING || poolSize == 0)，这句判断是为了防止在将此任务添加进任务缓存队列的同时其他线程突然调用shutdown或者shutdownNow方法关闭了线程池的一种应急措施，如果是这样就需要应急处理ensureQueuedTaskHandled(command)。 123456789101112131415private boolean addIfUnderCorePoolSize(Runnable firstTask) &#123; Thread t = null; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (poolSize &lt; corePoolSize &amp;&amp; runState == RUNNING) t = addThread(firstTask); //创建线程去执行firstTask任务 &#125; finally &#123; mainLock.unlock(); &#125; if (t == null) return false; t.start(); return true;&#125; 上面提到的addIfUnderCorePoolSize方法，由字面意思是当低于核心池大小时执行的方法，因为涉及线程池的变化，所以需要加锁。if语句判断当前线程池中的线程数目是否小于核心池大小，虽然前面在execute()方法中已经判断过了，但是没有加锁。因此可能在execute方法判断的时候poolSize小于corePoolSize，而判断完之后，在其他线程中又向线程池提交了任务，就可能导致poolSize不小于corePoolSize了。 123456789101112private Thread addThread(Runnable firstTask) &#123; Worker w = new Worker(firstTask); Thread t = threadFactory.newThread(w); //创建一个线程，执行任务 if (t != null) &#123; w.thread = t; //将创建的线程的引用赋值为w的成员变量 workers.add(w); int nt = ++poolSize; //当前线程数加1 if (nt &gt; largestPoolSize) largestPoolSize = nt; &#125; return t;&#125; 对于runState的判断也是类似的。满足条件的话，通过addThread方法创建线程，创建成功则启动线程。在addThread方法中，首先用提交的任务创建了一个Worker对象，然后调用线程工厂threadFactory创建了一个新的线程t，然后将线程t的引用赋值给了Worker对象的成员变量thread，接着通过workers.add(w)将Worker对象添加到工作集当中。 123456789101112public void run() &#123; try &#123; Runnable task = firstTask; firstTask = null; while (task != null || (task = getTask()) != null) &#123; runTask(task); task = null; &#125; &#125; finally &#123; workerDone(this); &#125;&#125; Worker类实现了Runnable接口，在其run函数中首先执行的是通过构造器传进来的任务firstTask，在调用runTask()执行完firstTask之后，在while循环里面不断通过getTask()去取新的任务来执行，getTask是ThreadPoolExecutor类中的方法，从任务缓存队列中取。 任务提交后，线程池的处理策略总结如下： 如果当前线程池中的线程数目小于corePoolSize，则每来一个任务，就会创建一个线程去执行这个任务； 如果当前线程池中的线程数目&gt;=corePoolSize，则每来一个任务，会尝试将其添加到任务缓存队列当中，若添加成功，则该任务会等待空闲线程将其取出去执行；若添加失败（一般来说是任务缓存队列已满），则会尝试创建新的线程去执行这个任务； 如果当前线程池中的线程数目达到maximumPoolSize，则会采取任务拒绝策略进行处理； 如果线程池中的线程数量大于corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止，直至线程池中的线程数目不大于corePoolSize；如果允许为核心池中的线程设置存活时间，那么核心池中的线程空闲时间超过keepAliveTime，线程也会被终止。 线程初始化默认情况下，创建线程池之后，线程池中是没有线程的，需要提交任务之后才会创建线程。如果需要线程池创建之后立即创建线程，可以通过以下两个方法办到：123456789101112// 初始化一个核心线程public boolean prestartCoreThread() &#123; return addIfUnderCorePoolSize(null); //注意传进去的参数是null&#125;// 初始化所有核心线程public int prestartAllCoreThreads() &#123; int n = 0; while (addIfUnderCorePoolSize(null))//注意传进去的参数是null ++n; return n;&#125; 上面传入参数为null，最后执行线程会阻塞在getTask方法中的workQueue.take()，等待直到任务队列中有任务。 容量的动态调整setCorePoolSize：设置核心池大小 setMaximumPoolSize：设置线程池最大能创建的线程数目大小 线程池应用 ThreadPoolExecutor12345// 缓存任务队列大小为8，核心池大小为5ThreadPoolExecutor executor = new ThreadPoolExecutor(5, 10, 200, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(8));executor.execute(myTask);// myTask 应该是显示了Runnable的类的对象executor.shutdown(); 推荐实现Java官方不推荐直接使用ThreadPoolExecutor，而是使用Executors类中提供的几个静态方法来创建线程池。分别是1234Executors.newCachedThreadPool(); //创建一个缓冲池，缓冲池容量大小为Integer.MAX_VALUEExecutors.newSingleThreadExecutor(); //创建容量为1的缓冲池Executors.newFixedThreadPool(int); //创建固定容量大小的缓冲池Executors.newScheduledThreadPool(int); //创建固定容量的延迟连接池 这三种方法也都是调用了ThreadPoolExecutor，支持参数设定不同而已。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125;ExecutorService pool = Executors.newFixedThreadPool(2);Thread t1 = new MyThread();Thread t2 = new MyThread();pool.execute(t1);pool.execute(t2);pool.shutdown();public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125;ExecutorService pool = Executors.newSingleThreadExecutor();Thread t1 = new MyThread();pool.execute(t1);pool.shutdown();public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125;ExecutorService pool = Executors.newCachedThreadPool();Thread t1 = new MyThread();Thread t2 = new MyThread();pool.execute(t1);pool.execute(t2);pool.shutdown();ScheduledExecutorService pool = Executors.newScheduledThreadPool(2);Thread t1 = new MyThread();Thread t2 = new MyThread();Thread t3 = new MyThread();pool.execute(t1);pool.schedule(t2, 1000, TimeUnit.MILLISECONDS);pool.schedule(t3, 10, TimeUnit.MILLISECONDS);pool.shutdown(); newFixedThreadPool创建的线程池corePoolSize和maximumPoolSize值是相等的，它使用的LinkedBlockingQueue； newSingleThreadExecutor将corePoolSize和maximumPoolSize都设置为1，也使用的LinkedBlockingQueue； newCachedThreadPool将corePoolSize设置为0，将maximumPoolSize设置为Integer.MAX_VALUE，使用的SynchronousQueue，也就是说来了任务就创建线程运行，当线程空闲超过60秒，就销毁线程。 感谢原文","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"atlantic8.github.io/tags/Java/"}]},{"title":"Boosting","slug":"Boosting","date":"2017-01-13T11:50:41.000Z","updated":"2018-12-16T14:08:06.180Z","comments":true,"path":"2017/01/13/Boosting/","link":"","permalink":"atlantic8.github.io/2017/01/13/Boosting/","excerpt":"","text":"Boosting是集成学习中的典型代表之一，与随机森林的不同在于：Boosting中的个体学习器之间有着强依赖、必须串行生成。Boosting族最典型的算法是AdaBoost。AdaBoost每轮迭代尝试调整训练数据的分布以使得下一轮的基学习器能够修正现有学习器的一些错误。Boosting算法从“偏差-方差”的角度看更加专注于降低偏差。 AdaBoost 指数损失函数AdaBoost可以理解成基学习器的叠加，即 \\begin{aligned} H(x)=\\sum_{t=1}^T \\alpha_th_t(x) \\end{aligned}来最小化损失函数 \\begin{aligned} l_{exp}(H|\\mathcal{D})&=E_{x\\sim D}[e^{-f(x)H(x)}] \\\\ &= E_{x\\sim D}[e^{-H(x)}P(f(x)=1|x) + e^{H(x)}P(f(x)=-1|x)] \\end{aligned}其中$\\mathcal{D}$表示数据集$D$的分布，也就是每个样本出现的概率。要选取最佳的$H(x)$使得损失函数$l$最小。这里假设原始数据集的标签$y_i\\in \\lbrace -1,+1 \\rbrace$，$f(x)$是真实函数。自然地考虑$l_{exp}(H|\\mathcal{D})$对$H(x)$求偏导数并且设置为0 \\begin{aligned} \\frac{\\partial l_{exp}(H|\\mathcal{D})}{\\partial H(x)} &= -e^{-H(x)}P(f(x)=1|x) + e^{H(x)}P(f(x)=-1|x) = 0 \\\\ H(x) &= \\frac{1}{2} ln \\frac{P(f(x)=1|x)}{P(f(x)=-1|x)} \\end{aligned}其中，$H(x)$与真实函数输出一致，那么$-f(x)H(x)$为-1；反之$-f(x)H(x)=1$，所以最小化上述损失函数的意义就是希望$H(x)$与真实函数$f(x)$输出尽量一致。最后，考虑到问题本质，$sign \\left( \\frac{1}{2} ln \\frac {P(f(x)=1|x)} {P(f(x)=-1|x)}\\right) $还需要 sign(H(x)) = sign \\left( \\frac{1}{2} ln \\frac {P(f(x)=1|x)} {P(f(x)=-1|x)} \\right) = \\begin{cases} 1 & {P(f(x)=1|x) \\ge P(f(x)=-1|x)} \\\\ -1 & {P(f(x)=1|x) < P(f(x)=-1|x)} \\end{cases}表明$sign(H(x))$达到了贝叶斯最优错误率，也就是：若指数损失函数最小化，那么分类错误率最小化。 权重更新AdaBoost中，第一个分类器$h_1$通过直接将基学习算法用于初始数据分布$\\mathcal{D}$而得，此后迭代地生成$h_t,\\alpha_t$。当基分类器$h_t$基于分布$\\mathcal{D}_t$产生后，$h_t$对应的权重$\\alpha_t$应该使得$\\alpha_th_t$最小化指数损失函数 \\begin{aligned} l_{exp}(\\alpha_th_t|\\mathcal{D}_t) &= E_{x\\sim \\mathcal{D}_t} \\left[ e^{-f(x)\\alpha_th_t(x)} \\right] \\\\ &= E_{x\\sim \\mathcal{D}_t} \\left[ e^{-\\alpha_t}I(f(x)=h_t(x)) + e^{\\alpha_t}I(f(x)\\neq h_t(x)) \\right] \\\\ &= e^{-\\alpha_t}P_{x\\sim \\mathcal{D}_t}(f(x)=h_t(x)) + e^{\\alpha_t}P_{x\\sim \\mathcal{D}_t}(f(x)\\neq h_t(x)) \\\\ &= e^{-\\alpha_t}(1-\\epsilon_t) + e^{\\alpha_t}\\epsilon_t \\end{aligned}其中，$\\epsilon_t=P_{x\\sim \\mathcal{D}_t}(f(x)\\neq h_t(x))$。上式对$\\alpha_t$求导并使之为0可得 \\begin{aligned} \\alpha_t=\\frac{1}{2} ln\\left( \\frac{1-\\epsilon_t}{\\epsilon_t} \\right) \\end{aligned} 样本分布调整获取$H_{t-1}$之后将样本分布进行调整，使下一轮的基学习器$h_t$能纠正$H_{t-1}$的错误，依旧采用最小化指数损失函数的思想，有 \\begin{aligned} l_{exp}(H_{t-1}+h_t | \\mathcal{D}) &= E_{x\\sim \\mathcal{D}} [e^{ -f(x) ( H_{t-1}(x)+h_t(x) ) }] \\\\ &= E_{x\\sim \\mathcal{D}} [ e^{-f(x)H_{t-1}} e^{-f(x)h_t(x)} ] \\\\ \\end{aligned}对上式中的$e^{-f(x)h_t(x)}$做二阶泰勒展开，近似为 \\begin{aligned} l_{exp}(H_{t-1}+h_t|\\mathcal{D}) &\\simeq E_{x\\sim \\mathcal{D}}\\left[e^{-f(x)H_{t-1}(x)} \\left( 1-f(x)h_t(x)+\\frac{f(x)^2h_t(x)^2}{2} \\right) \\right] \\\\ &= E_{x\\sim \\mathcal{D}}\\left[e^{-f(x)H_{t-1}(x)} \\left( \\frac{3}{2}-f(x)h_t(x) \\right)\\right] \\\\ \\end{aligned}因为$\\frac{3}{2}-f(x)h_t(x)&gt;0$并且$f(x)H_{t-1}(x)$也是确定的值，所以最小化上式也就是等价于下式，也可以做一点变化变体 \\begin{aligned} &\\to \\arg\\max_{h} E_{x\\sim \\mathcal{D}}\\left[e^{-f(x)H_{t-1}(x)} f(x)h(x)\\right] \\\\ &\\to \\arg\\max_{h} E_{x\\sim \\mathcal{D}}\\left[\\frac{e^{-f(x)H_{t-1}(x)}} {E_{x\\sim \\mathcal{D}} \\left[ e^{-f(x)H_{t-1}(x) } \\right] } f(x)h(x)\\right] \\end{aligned}因为$E_{x\\sim \\mathcal{D}}e^{-f(x)H_{t-1}(x)}$是一个常数，令$\\mathcal{D}_t$表示一个分布 \\begin{aligned} D_t(x)=\\mathcal{D}(x) \\frac { e^{-f(x)H_{t-1}(x)} } { E_{x\\sim \\mathcal{D}} \\left[ e^{ -f(x)H_{t-1}(x) } \\right] } \\end{aligned}根据数学期望的定义，这等价于令 \\begin{aligned} h_t(x) &= \\arg\\max_{h} E_{x\\sim \\mathcal{D}}\\left[\\frac{e^{-f(x)H_{t-1}(x)}} {E_{x\\sim \\mathcal{D}} [e^{-f(x)H_{t-1}(x)}]} f(x)h(x)\\right] \\\\ &= \\arg\\max_{h} E_{x\\sim \\mathcal{D}_t} [f(x)h(x)] \\end{aligned}由于$f(x),h(x)$都只能取$\\lbrace -1,1 \\rbrace$，所以上式中的优化问题也可以变成 \\begin{aligned} h_t(x) = \\arg\\min_{h} E_{x\\sim \\mathcal{D}_t} [I(f(x) \\neq h(x))] \\end{aligned}所以理想的$h_t$将在分布$\\mathcal{D}_t$下最小化分类误差，因此弱分类器将基于$\\mathcal{D}_t$来训练，且针对$\\mathcal{D}_t$的分类误差应该不小于0.5（二分类至少要比猜的强）。根据上面的推导，分布之间的关系应该是 \\begin{aligned} \\mathcal{D}_{t+1}(x) &= \\mathcal{D}(x) \\frac{e^{-f(x)H_{t-1}(x)}} { E_{x\\sim \\mathcal{D}} [ e^{ -f(x) H_{t-1}(x) } ] } \\\\ &= \\mathcal{D}(x) \\frac{ e^{-f(x)H_{t-1}(x)} e^{-f(x) \\alpha_t h_t(x)} } {E_{x\\sim \\mathcal{D}} [ e^{ -f(x) H_{t-1}(x) } ] } \\\\ &= \\mathcal{D}_{t}(x) e^{-f(x) \\alpha_t h_t(x)} \\frac{E_{x\\sim \\mathcal{D}} [ e^{-f(x)H_{t-1}(x)} ]} {E_{x\\sim \\mathcal{D}} [e^{-f(x)H_{t}(x)}]} \\end{aligned}至此，AdaBoost算法流程介绍完毕，下面是其算法描述 输入：训练集$D=\\lbrace (x_1,y_1),…,(x_m,y_m) \\rbrace$；基学习算法$\\gamma$；训练轮数$T$ $\\mathcal{D}_{1}(x)=\\frac{1}{m}$. //初始为均匀分布 $for\\;t=1,…,T$ $h_t=\\gamma(D,\\mathcal{D}_{t})$. $\\epsilon_t=P_{x\\sim \\mathcal{D}_{t} }(h_t(x)\\neq f(x))$. $if\\;\\epsilon_t&gt;0.5\\;then\\;break\\;$. // 错误率大于0.5的不要，至少比随机猜测好 $\\alpha_t=\\frac{1}{2}ln \\frac {1-\\epsilon_t}{\\epsilon_t}$. //权重更新 $\\mathcal{D}_{t+1}=\\mathcal{D}_{t} \\frac{exp(-\\alpha_t f(x) h_t(x))} {Z_t}$. //分布调整 输出：$H(x)=sign\\left( \\sum_{t=1}^T \\alpha_t h_t(x) \\right)$ 由算法描述的第三行可以看出，基学习算法需要能够对特定的数据分布进行学习，可以通过两种方法实现： 重赋权法：每一轮训练过程中，根据样本分布为每个样本重新赋予一个权重。也可以是在计算误差率的时候，为每个样本对应的项加上权重。 重采样法：每一轮训练过程中，根据样本分布进行重采样，用采样的样本集训练数据。（特别用于样本无法接受权值的基算法场景，此方法还可以在基学习器错误率大于0.5时不用退出，创新采样开始） Boosting Tree 提升树被认为是统计学习中性能最好的方法之一 与RF类似，提升树也可以通过线性叠加基学习器的方法获得准确率的提升 基学习器为二叉树，分为分类、回归两种 提升树提升树的模型可以表示为f_M(x)=\\sum_{m=1}^MT(x;\\theta_m)其中，$M$为树的个数，$T(x;\\theta_m)$表示决策树，$\\theta_m$为决策树的参数。 步骤：首先确定初始提升树$f_0(x)=0$，第$m$步的模型是f_m(x)=f_{m-1}(x)+T(x;\\theta_m)，通过经验风险最小化确定参数$\\theta_m$为 \\begin{aligned} \\theta_m=\\arg\\min_{\\theta_m^{\\*}} \\sum_{i=1}^N L \\left (y_i,f_{m-1}(x_i)+T(x_i;\\theta_m^{\\*}) \\right) \\end{aligned}即使输入数据与输出数据之间的关系很复杂，树的线性组合也可以很好地拟合训练数据。 在回归问题中，考虑使用平方误差损失函数，所以损失变为 \\begin{aligned} &L \\left(y,f_{m-1}(x)+T(x;\\theta_m^{\\*})\\right) \\\\ &= \\left(y-f_{m-1}(x)-T(x;\\theta_m^{\\*})\\right)^2 \\\\ &= \\left(r-T(x;\\theta_m^{\\*})\\right)^2 \\end{aligned}其中$r=y-f_{m-1}(x)$是当前模型拟合数据的残差，所以算法就是拟合当前模型的残差，描述如下： 输入：训练数据集$D$ 初始化$f_0(x)=0$，迭代次数$M$ 对$m=1,…,M$ 计算每个样本的残差$r_{mi}=y_i-f_{m-1}(x_i)$ 拟合残差$r_m$得到一个回归树$T(x;\\theta_m)$ 计算$f_m(x)=f_{m-1}(x)+T(x;\\theta_m)$ 得到回归提升树$f_M(x)=\\sum_{m=1}^MT(x;\\theta_m)$ 输出：$F_M(x)$ 梯度提升 损失函数是平方误差、指数损失函数时每一步优化比较明显；但一般损失函数就不那么容易了 使用最速下降的近似方法 利用损失函数的负梯度在当前模型的值残差的近似值作为提升回归树的残差近似值 下面是梯度提升回归树算法 输入：数据集$D$，数量为$N$，迭代次数$M$ 初始化$f_0(x)=\\arg\\min_{c}\\sum_{y=1}^NL(y_i,c)$ 对$m=1,…,M$ 计算$r_{mi}=-\\left[ \\frac{\\partial{L(y_i,f_{m-1}(x_i))}}{\\partial{f_{m-1}(x_i)}} \\right]$ 对$r_m$拟合一个回归树，对于它的每一个叶节点$R_{mj}$，确定节点的值为$c_{mj}=\\arg\\min_c\\sum_{x_i\\in R_{mj}}L(y_i,f_{m-1}(x_i)+c)$ 更新$f_m(x)=f_{m-1}(x)+\\sum_{j=1}^Jc_{mj}I(x\\in R_{mj})$ 得到回归树$f_M(x)=\\sum_{m=1}^M\\sum_{j=1}^Jc_{mj}I(x\\in R_{mj})$ 输出：$f_M(x)$ GBDT(Gradient Boosting Decision Tree)几乎可用于所有的回归问题","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"Ensemble Learning","slug":"Ensemble-Learning","date":"2017-01-12T03:09:46.000Z","updated":"2018-12-16T14:08:06.223Z","comments":true,"path":"2017/01/12/Ensemble-Learning/","link":"","permalink":"atlantic8.github.io/2017/01/12/Ensemble-Learning/","excerpt":"","text":"集成学习的概念机器学习中有着多种多样的算法，不同的算法有着不同优劣。对于现有单一算法的优化往往比较困难而且不一定会取得更好的效果。集成学习的思想就是将多个个体学习器组合起来以取得更好的性能。这对于弱学习器更加实用，集成学习的很多理论都是针对弱学习器的。集成学习有如下几个优点： 减小“泛化性能不佳”的风险 降低陷入局部极小值的风险 更加全面的假设空间近似(多个学习器可以扩大假设空间) 目前集成学习方法按照个体学习器的生成方法可以分为两类：Boosting和随机森林。Boosting方法不在这里介绍，本文会介绍到随机森林。 学习器的结合方法 平均法平均法的思想很简单，即将各个学习器加权平均 \\begin{aligned} H(x)=\\sum_{i=1}^T \\omega_i h_i(x)\\quad s.t.:\\;\\sum_{i=1}^T\\omega_i=1 \\end{aligned}其中，$h_i(x)$为第$i$个学习器的结果。 投票法投票法的思想也很简单，就是按照一定的规则进行投票选出最佳结果。一般作用于分类任务，定义学习器$h_i(x)$从预测标记集合中$\\lbrace c_1,c_2,…,c_N \\rbrace$。加权投票法可以表示为 \\begin{aligned} H(x)=c_{\\arg\\max_j \\sum_{i=1}^T \\omega_ih_i^j(x)} \\end{aligned}其中，$h_i^j(x)$表示$h_i(x)$在类别标记$c_j$上的输出。 StackingStacking先从数据集中训练出初级学习器，然后再生成“新的数据集”用于生成次级学习器。具体来说，初级学习器的输出被当作次级学习器的样例输入。Stacking算法描述如下（假定初级学习器使用不同的学习算法） 输入：训练集$D=\\lbrace (x_1,y_1),…,(x_m,y_m) \\rbrace$；初级学习器算法$\\gamma_1,…,\\gamma_T$；次级学习算法$\\gamma$ 1 $h_t = \\gamma_t(D), \\; t=1,…,T$2 $D^{‘}=\\varnothing$3 $for\\; i=1,…,m$4 $\\quad for\\; t=1,…,T$5 $\\quad \\quad z_{it}=h_t(x_i)$6 $\\quad D^{‘}=D^{‘} \\cup ((z_{i1},…,z_{iT}),y_i)$7 $h^{‘}=\\gamma(D^{‘})$ 输出：$H(x)=h^{‘}(h_1(x),…,h_T(x))$ 训练阶段，次级训练集的是初级学习器产生的。如果直接使用初级学习器的训练集来产生次级训练集，过拟合风险比较大。一般使用cross validation或者留一法等方法，用初级学习器未使用的样本来产生次级学习器的训练样本。 Bagging与随机森林 （Random Forest） BaggingBagging是并行式集成学习算法的代表，基于自助采样法（bootstrap sampling）。给定包含$m$个样本的训练集，每次随机选择一个样本，采样方式为放回式采样。采样$m$次，得到一个训练集，初始训练集中大约有63.2%的样本出现在新样本集中。 按照上面的方法，采集$T$个新的训练集，然后基于每个新的样本集训练出基学习器，然后将基学习器组合起来。这便是Bagging的基本思想。Bagging算法描述如下 输入：训练集$D=\\lbrace (x_1,y_1),…,(x_m,y_m) \\rbrace$；基学习器算法$\\gamma$；训练轮数$T$ 1 $for\\;t=1,…,T$2 $\\quad D_{bs} \\xleftarrow{bootstrap\\; sampling} D$3 $\\quad h_t=\\gamma(D_{bs})$ 输出：$H(x)=\\arg\\max_{y\\in Y} \\sum_{t=1}^T I(h_t(x)=y)$ 因为自助采样平均只使用初始训练集的63.2%，剩下的样本可用做验证集来对泛化性能进行“包外估计”（out-of-bag estimate）。令$D_t$表示$h_t$使用的样本集，令$H^{oe}(x)$表示对样本$x$的包外估计，且仅考虑那些未使用样本$x$的基学习器再$x$上的预测 \\begin{aligned} H^{oe}(x)=\\arg\\max_{y\\in Y} \\sum_{t=1}^T I(h_t(x)=y)\\times I(x\\not\\in D_t) \\end{aligned}Bagging的泛化误差的包外估计为 \\begin{aligned} \\epsilon^{oe}(x)=\\frac{1}{\\vert D\\vert} \\sum_{(x,y)\\in D} I(H^{oe}(x)\\neq y) \\end{aligned}Bagging主要侧重于降低方差，所以在不剪枝决策树、神经网络等易受样本扰动的学习器上效果明显。 随机森林随机森林是Bagging的扩展，规定基学习器为决策树，在以基学习器为决策树构建Bagging集成学习器的基础上，进一步在决策树的训练过程中引入了随机属性选择。传统决策树在训练时，需要选取当前结点属性集中最佳属性，而在随机森林中则是先从属性集随机选出一个包含$k$个属性的子集，然后再从这个自己中选择最佳属性。很明显，随机森林的效率要比Bagging高，二者收敛性相似。一般地，随机森林的起始性能较差，随着个体学习器的数目增大，随机森林的泛化误差会收敛到更低。","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"Multi-armed Bandit Problem","slug":"Multi-armed-Bandit-Problem","date":"2017-01-06T02:22:34.000Z","updated":"2018-12-16T14:08:06.355Z","comments":true,"path":"2017/01/06/Multi-armed-Bandit-Problem/","link":"","permalink":"atlantic8.github.io/2017/01/06/Multi-armed-Bandit-Problem/","excerpt":"","text":"背景描述多臂老虎机问题来源于赌场，描述的是赌场中的一个赌徒，面对多个老虎机（多个摇臂），如何选择使用摇臂才能使自己的收益最大化的问题。想要最大化收益，赌徒需要知道每个摇臂对应的奖赏，然后选择下一次应该使用哪个摇臂。然而现实中，摇臂对应的奖赏往往不是一个确定的值，而是服从于某个分布的。这个问题属于强化学习研究的范畴。 对于每一次使用摇臂的机会，赌徒有两种选择:1) 探索策略(exploration)：尝试新的摇臂以确定新的要比对应的奖赏2) 利用策略(exploitation)：使用当前已知最好的摇臂探索策略能很好估计每个摇臂的奖赏，却会失去很对选择好的摇臂的机会；而利用策略则相反，它只使用当前最好的选择，可能会错过最佳摇臂。这两个策略的出发点相同，但是操作上是相悖的，所以解决多臂老虎机问题可以从对这两个问题的折中上入手。 $\\epsilon$-贪心$\\epsilon$-贪心法的思想是：每次尝试时，以$\\epsilon$的概率进行搜索（均匀搜索），以$1-\\epsilon$的概率利用现有最佳。 令$Q(k)$表示摇臂$k$的平均奖赏，摇臂$k$被使用了$n$次，收益分别是$v_1,v_2,…,v_n$，所以$Q(k)$可以表示成 \\begin{aligned} Q(k)=\\frac{1}{n} \\sum_{i=1}^n v_i \\end{aligned}每次获得一个摇臂对应的奖赏，则更新其平均奖赏，这个只需要记录摇臂尝试次数和当前平均值即可进行下一次平均值的计算。算法描述如下： 输入：摇臂个数$K$，奖赏函数$R$，尝试次数$T$，搜索概率$\\epsilon$ 1 $r=0$.2 $\\forall i=1,…,K:set\\;Q(i)=0,count(i)=0$.3 $for\\;t=1,…,T$4 $\\quad if\\;rand()&lt;\\epsilon$5 $\\quad \\quad k \\xleftarrow{均匀选取} \\lbrace 1,…,K \\rbrace$.6 $\\quad else$7 $\\quad \\quad k=\\arg\\max_i Q(i)$.8 $\\quad v=R(k)$.9 $\\quad r=r+v$.10 $\\quad Q(k)=\\frac{Q(k)\\times count(k)+v}{count(k)+1}$.11 $\\quad count(k)=count(k)+1$. 输出：累计奖励$r$ 如果摇臂奖赏的不确定性较大，则需要更多的探索，对应的$\\epsilon$也应该更大。反之，较小的$\\epsilon$比较合适。当尝试次数非常大时，摇臂的奖赏可能都能很好地表示出来，而不再需要探索。为了防止问题退化，可让$\\epsilon$随着尝试次数地增加而减少，比如$\\epsilon=\\frac{1}{\\sqrt{t}}$。 SoftmaxSoftmax根据当前已知摇臂的平均奖赏对探索和利用进行折中，令$Q(k)$表示摇臂$k$的平均奖赏，摇臂概率的分布基于波尔兹曼分布 \\begin{equation} P(k)=\\frac{e^{\\frac{Q(k)}{\\tau}}} {\\sum_{i=1}^K e^{\\frac{Q(k)}{\\tau}}} \\end{equation}其中，$\\tau &gt; 0$称为温度，$\\tau$越小则平均奖赏高的摇臂被选取的概率越高。$\\tau$趋近于0时，算法倾向于仅利用，$\\tau$趋近于无穷大时，算法倾向于仅探索。Softmax算法描述如下： 输入：摇臂个数$K$，奖赏函数$R$，尝试次数$T$，温度参数$\\tau$ 1 $r=0$.2 $\\forall i=1,…,K:set\\;Q(i)=0,count(i)=0$.3 $for\\;t=1,…,T$4 $\\quad$根据式$(1)$选取$k\\gets \\lbrace 1,…,K \\rbrace$.5 $\\quad v=R(k)$.6 $\\quad r=r+k$.7 $\\quad Q(k)=\\frac{Q(k)\\times count(k)+v}{count(k)+1}$.8 $\\quad count(k)=count(k)+1$. 输出：累计奖励$r$ $\\epsilon$-贪心和Softmax的优劣与应用相关，下图就是例子。 ![不同算法在不同尝试次数上的效果](http://wx1.sinaimg.cn/mw690/9bcfe727ly1fbgwaininnj213j0q0gv3.jpg)","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"},{"name":"Game Theory","slug":"Game-Theory","permalink":"atlantic8.github.io/tags/Game-Theory/"}]},{"title":"Markov Decision Process","slug":"Markov-Decision-Process","date":"2017-01-06T02:07:53.000Z","updated":"2018-12-16T14:08:06.324Z","comments":true,"path":"2017/01/06/Markov-Decision-Process/","link":"","permalink":"atlantic8.github.io/2017/01/06/Markov-Decision-Process/","excerpt":"","text":"马尔可夫决策过程MDP是经典的增强学习算法。MDP可以表示为一个元组MDP=(S,A,\\lbrace P_{sa} \\rbrace,\\gamma,R)其中$S$是状态集合；$A$是动作集合，也就是可能的操作集合；$P_{sa}$为每一个状态$s$在每一个动作$a$上定义转移概率，转移到不同状态的概率不同；$\\gamma \\in [0,1]$为折扣因子；$R:S\\times A \\to \\mathbb{R}$表示回报函数。 ![MDP模型](http://ww2.sinaimg.cn/large/9bcfe727jw1fbgomcnv49j20b408wwf9.jpg) 贝尔曼方程（Bellman equation）贝尔曼方程是理查德贝尔曼提出的，它是典型的动态规划方程，也是动态规划最优性的必要条件。贝尔曼方程在最优控制理论中有着重要的作用。理查德贝尔曼证明了离散时间上的动态规划问题可以被表示成递归的、一步一步完成的后向推导形式，其中这过程需要写出价值函数的递推关系，其实贝尔曼方程的最基本思想就是重叠子问题思想。代价函数的递推关系被称为贝尔曼方程，其形式化表述如下。 假设时刻$t$时的状态为$s_t$，采取的动作是$a_t$，到达的新状态可以计算成$T(s_t,a_t)$，对应的收益为$F(s_t,a_t)$。联系折扣因子$\\beta$，从$s_0$开始的无穷决策问题的收益是 \\begin{aligned} V(s_0)=\\max_{\\lbrace a_t \\rbrace_{t=0}^{\\infty}} \\sum_{t=0}^{\\infty} \\beta^tF(s_t,a_t) \\\\ s.t.:\\; s_{t+1}=T(s_t,a_t) \\end{aligned}上是可以简化为 \\begin{aligned} V(s_0)=\\max_{a_0} \\lbrace F(s_0,a_0)+\\beta V(s_1) \\rbrace,\\;s.t.:\\;s_1=T(s_0,a_0) \\end{aligned} MDP模型描述 MDP形式定义MDP可表示成这样的过程 \\begin{aligned} s_0 \\xrightarrow{a_0} s_1 \\xrightarrow{a_1} s_2 \\xrightarrow{a_2} s_3 \\xrightarrow{a_3} ... \\end{aligned}在上面的情况下，整体收益可以表示成 \\begin{aligned} R(s_0,a_0)+\\gamma R(s_1,a_1) + \\gamma^2 R(s_2,a_2) + ... \\end{aligned}MDP的目标就是选取一组动作以最大化收益均值即 \\begin{aligned} \\arg \\max_{a_0,a_1,...}E[R(s_0,a_0)+\\gamma R(s_1,a_1) + \\gamma^2 R(s_2,a_2) + ... ] \\end{aligned}一个策略（policy）是由状态到动作的任意映射$\\pi : S \\to A$。执行一个策略$\\pi$也就是对于任意状态$s$，系统采取的动作是$a=\\pi(s)$。定义一个策略$\\pi$的价值函数（value function）为 \\begin{aligned} V^{\\pi}(s)&=E[R(s_0,a_0)+\\gamma R(s_1,a_1) + \\gamma^2 R(s_2,a_2) + ... |s_0=s,\\pi] \\\\ V^{\\pi}(s)&=R(s)+\\gamma \\sum_{s^{'}\\in S}P_{s\\pi(s)}(s^{'})V^{\\pi}(s^{'}) \\end{aligned}表示从状态$s$开始，根据策略$\\pi$执行的累积收益和的均值。定义最优价值函数为 \\begin{aligned} V^{\\*}(s)&=\\max_{\\pi} V^{\\pi}(s) \\\\ V^{\\*}(s)&=R(s)+\\max_{a\\in A}\\gamma \\sum_{s^{'}\\in S}P_{sa}(s^{'})V^{\\*}(s^{'}) \\end{aligned}指的是任何可能的策略下的最优解. 接下来定义最优策略，一个最优策略$\\pi^{*}:S \\to A$可以定义为 \\begin{equation} \\pi^{\\*}(s)=\\arg\\max_{a\\in A}\\sum_{s^{'}\\in S}P_{sa}(s^{'})V^{\\*}(s^{'}) \\end{equation}策略$\\pi^{*}$为每一个状态提供了最优策略，也就是说无论初始状态是什么，$\\pi^{*}$都是最优策略。事实上，对每一个状态$s$和每一个策略$\\pi$，我们有 \\begin{aligned} V^{\\*}(s)=V^{\\pi^{\\*}}(s) \\ge V^{\\pi}(s) \\end{aligned} 价值迭代和策略迭代为了描述简单，这里仅考虑有限状态空间、有限动作空间的MDP。在下面两个算法中，转移概率$\\lbrace P_{sa} \\rbrace$和回报函数$R$都是已知的。 价值迭代（value iteration）1 初始化每个状态的价值$V(s)=0$2 重复迭代直到收敛：3 $\\quad$对每个状态$s$，更新：$V(s)=R(s)+\\max_{a\\in A}\\gamma \\sum_{s^{‘}}P_{sa}(s^{‘})V(s{‘})$ 其中，更新方式有两种同步更新：先计算所有状态的价值函数，然后再将其一起更新异步更新：每计算出一个状态的价值函数，就将其更新但无论是同步还是异步，$V$都会逐渐收敛至$V^{*}$。有了$V^{*}$，就可以根据公式$(1)$计算出对应的策略了。 策略迭代（policy iteration）1 随机初始化$\\pi$2 重复迭代直到收敛：3 $\\quad (a):$使得$V=V^{\\pi}$4 $\\quad (b):$对每个状态$s$，使得$\\pi(s)=\\arg\\max_{a\\in A}\\sum_{s^{‘}}P_{sa}(s^{‘})V(s^{‘})$ 迭代过程中，先计算在当前策略$\\pi$下每个状态的价值函数值，然后根据这些值找到每个状态对应的最佳动作（greedy）。这些动作的集合就构成了下一步的新策略。步骤$(a)$的计算还是先赋值再迭代计算直到收敛，只是要按照$\\pi$策略跳转而已。 学习一个MDP模型上面的讨论中，转移概率$\\lbrace P_{sa} \\rbrace$和回报函数$R$都是已知的，但是实际中这两部分经常是未知的（通常$S,A,\\gamma$是已知的），因此需要通过学习算法来学习。 数据可以是采集的，也可以是通过实验得出来的。对$P_{sa}$的估计方法可以是 \\begin{aligned} P_{sa}(s^{'})=\\frac{times\\; s \\xrightarrow{a} s^{'}}{times\\; s \\xrightarrow{a} any\\; state} \\end{aligned}在样本不够大的情况下，可能出现$\\frac{0}{0}$的情况，如果分母为0，则把对应的概率换成$\\frac{1}{\\vert S\\vert}$. $R$的更新思想类似。 连续状态的MDP现实中，MDP的离散状态假设是比较脆弱的。比如二维坐标中的位置就是连续的。那如何处理连续状态下的MDP呢 离散化离散化的思想很直观，比如二维空间就可以通过网格化来达到离散化的目的。但是离散化有两个缺陷：1 naive representation对于$V^{*}$和$\\pi^{*}$的表示太过简单，因为离散化会主动放弃潜在信息因此对平滑函数的表示效果比较差。比如离散化后的线性回归可能会得到如下图中的结果 ![](http://ww3.sinaimg.cn/large/9bcfe727jw1fbfzpl9gu1j20cf09dq34.jpg) 2 维度诅咒假设状态空间是$n$维的，离散化会使得离散化后的状态个数指数增加。 价值函数近似一般地，在连续MDP问题中通常假设 在价值迭代中，连续状态的迭代公式应该是 \\begin{aligned} V(s)&= R(s)+\\gamma \\max_{a} E_{s^{'}\\sim P_{sa}}[V(s_{'}] \\\\ &= R(s)+\\gamma \\max_{a} \\int_{s^{'}}P_{sa}(s^{'})V(s^{'})\\,ds^{'} \\end{aligned}此式跟上面的区别是把原来的求和改成了积分。 在对应状态为$s^{(1)},s^{(2)},…,s^{(m)}$的有限个数样本情况下，价值函数近似就是要将价值函数近似为状态的函数，即 \\begin{aligned} V(s)=\\theta^T\\phi(s) \\end{aligned}其中$\\phi(s)$是状态$s$的合理映射。对于每一个样本$i$，算法先计算一个 \\begin{aligned} y^{(i)} \\gets R(s)+\\gamma \\max_{a} E_{s^{'}\\sim P_{sa}}[V(s_{'}] \\end{aligned}上式的计算要使用采样逼近的原理，即采集多个样本求均值以逼近收集到每个样本的状态和对应的$y^{(i)}$，就可以使用监督学习算法训练出$V(s)$和$s$的模型。算法描述如下 1 随机采样$m$个状态，$s^{(1)},s^{(2)},…,s^{(m)} \\in S$.2 初始化$\\theta=0$.3 迭代：4 $\\quad for\\;i=1,…,m$.5 $\\quad \\quad for\\;each\\;a\\in A$.5 $\\quad \\quad \\quad $采样$s_1^{‘},…,s_k^{‘} \\sim P_{s^{(i)}a}$.6 $\\quad \\quad \\quad $设置$q(a)=\\frac{1}{k} \\sum_{j=1}^k R(s^{(i)})+\\gamma V(s_j^{‘})$.7 $\\quad \\quad \\quad $//因此$q(a)$就是$R(s^{(i)})+\\gamma E_{s^{‘}\\sim P_{s^{(i)}a}}[V(s_{‘}]$的估计.8 $\\quad \\quad $令$y^{(i)}=\\max_{a}q(a)$.9 $\\quad \\quad $//因此$q(a)$就是$R(s^{(i)})+\\gamma \\max_{a} E_{s^{‘}\\sim P_{s^{(i)}a}}[V(s_{‘}]$的估计.10 $\\quad$使得$\\theta=\\arg\\min_{\\theta}\\frac{1}{2} \\sum_{i=1}^m (\\theta^T\\phi(s^{(i)})-y^{(i)})^2$. 得到了近似于$V^{*}$的$V$，最后选择action时还是根据 \\begin{aligned} \\arg\\max_{a} E_{s^{'}\\sim P_{sa}}[V(s^{'})] \\end{aligned} 上述算法最后求$\\theta$时使用的是线性回归方法，当然其他合适的方法也是可以的。需要注意的是，价值函数近似方法并不能保证收敛，但是通常是收敛得。控制计算量的可用方法是调节算法第5步中的$k$值，有时候设置$k=1$也是可以的。","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"Hidden Markov Model","slug":"Hidden-Markov-Model","date":"2016-12-31T01:41:54.000Z","updated":"2018-12-16T14:08:06.257Z","comments":true,"path":"2016/12/31/Hidden-Markov-Model/","link":"","permalink":"atlantic8.github.io/2016/12/31/Hidden-Markov-Model/","excerpt":"","text":"概率图模型概率图模型是一类用图来表达变量相关关系的概率模型，常见的是用一个节点表示一个或一组随机变量，节点之间的边表示变量之间的概率关系。概率模型可以大致分为两类： 第一类使用有向无环图表示变量之间的依赖关系，称之为有向图模型或者贝叶斯网 第二类使用无向无环图表示变量之间的依赖关系，称之为无向图模型或者马尔可夫网 本文要介绍的隐马尔可夫模型就是结构简单的动态贝叶斯网。 隐马尔可夫模型HMM的主要作用是时序数据建模，应用范围包括语音识别、自然语言处理等领域。与马尔可夫过程不同，HMM中状态是无法直接观测的，取而代之，我们可以获取到与状态值息息相关的观测变量值，图中是经典的海藻与天气例子。 ![经典的海藻于天气示例](http://ww2.sinaimg.cn/large/9bcfe727jw1fb9wwz6vk7j20eq08cdg2.jpg) 一个HMM模型中有两组变量，第一组是状态变量$Y=\\lbrace y_1,y_2,…,y_n \\rbrace$表示隐含的状态，下标表示时序。另一组是观测变量$X=\\lbrace x_1,x_2,…,x_n \\rbrace$，下标表示时序。系统可能会存在多个状态，这些状态的集合为$S=\\lbrace s_1,s_2,…,s_N \\rbrace$，如果$y_i = k$那么表示$i$时刻的状态为$s_k$。观测变量可以是离散的也可以是连续的，不妨假设其为离散值。同样地，定义观测值的集合$O = \\lbrace o_1,o_2,…,o_M \\rbrace$，如果$x_i = k$那么表示$i$时刻的状态为$o_k$。 HMM中有两个重要的性质： 观测变量的取值仅依赖于状态变量 t时刻的状态仅依赖于t-1时刻的状态 基于上面两个性质，可以得到如下公式 \\begin{aligned} p(x_1,y_1,...,x_n,y_n)=p(y_1)p(x_1|y_1)\\prod_{i=2}^n p(y_i|y_{i-1})p(x_i|y_i) \\end{aligned}上式基本上描述了HMM的结构信息，在实际计算时还需要如下参数 状态转移概率$A=[a_{ij}]_{N\\times N}$，其中a_{ij}=p(y_{t+1}=j|y_t=i)表示由状态$s_i$转移到状态$s_j$的概率。 输出观测概率$B=[b_{ij}]_{N\\times M}$，其中b_{ij}=p(x_t=j|y_t=i)表示在状态$s_i$下观测值为$o_j$的概率。 初始状态概率$\\pi=(\\pi_1,…,\\pi_N)$，其中\\pi_i=p(y_1=i)表示初始状态为$s_i$的概率。 指定了状态空间$Y$，观测空间$X$和上述三组参数，一个HMM就确定了，所以一个HMM可以表示成一个五元组$(N,M,A,B,\\pi)$，$N,M$分别表示状态值和观测值的可能取值范围。HMM也可以表示成$\\lambda=(A,B,\\pi)$。 下面考虑三个实际问题： 模型于观测序列匹配度给定模型$\\lambda=(A,B,\\pi)$，如何有效计算其产生观测序列$X=(x_1,x_2,…,x_T)$的概率$p(X|\\lambda)$？ 为解决这一问题，Baum提出了前向算法，具体如下：定义$\\theta_t(j)$为在$t$时刻，整体观测序列为$x_1,…,x_t$，此时状态为$s_j$的概率。其中我们有 \\begin{aligned} \\theta_1(i) = \\pi_ib_{ix_1} \\end{aligned}表示第一个观测值的概率，其递推式也很容易写出 \\begin{aligned} \\theta_{t+1}(i)=\\left[\\sum_{j=1}^N\\theta_t(j)a_{ji}\\right]b_{ix_{t+1}} \\end{aligned}有两部分构成，第一部分是由枚举$t$时刻的状态并跳转到$t+1$时刻，第二部分是$t+1$时刻的状态产生观测值的概率。 当$n=1$时，输出序列为$x_1$，此时计算概率$p(x_1|\\lambda)$也就是计算初始状态集合每个可能的状态产生观测值$x_1$的概率和，也就是 \\begin{aligned} p(x_1|\\lambda)=\\sum_{i=1}^N \\theta_1(i) \\end{aligned}当$n=2$时，输出序列为$x_1x_2$，所以有 \\begin{aligned} p(x_1,x_2|\\lambda) &= \\sum_{j=1}^N \\theta_2(j) \\end{aligned}后面的依此类推，前向算法的描述如下： 1 初始化：$\\theta_1(i)=\\pi_ib_{i1}, 1\\le i \\le N$2 $\\theta_{t+1}(j)=\\left[\\sum_{i=1}^N \\theta_t(i)a_{ij}\\right]b_{jx_{t+1}}$3 $p(x_1,…,x_T|\\lambda)=\\sum_{j=1}^N \\theta_T(j)$ 一共有$T$个时刻，每个时刻要考虑$N$个状态，每个状态又要考虑钱一个时刻的$N$个状态，所以时间复杂度为$O(N^2T)$。 推断隐藏序列由于有时候我们需要隐藏序列包含的信息，所以给出隐藏序列是有必要的（比如词性标注最终就需要给出词性序列）。问题的形式化表述即为 \\begin{aligned} \\arg\\max_{y_1,...,y_T} p(y_1,...,y_T|x_1,...,x_T,\\lambda) \\end{aligned}这个问题的解决方法是维特比（Viterbi）算法。 定义维特比变量$\\gamma_t(j)$：表示在时序$t$，观察序列为$x_1,…,x_t$，状态为$s_j$的最大概率，即 \\begin{aligned} \\gamma_t(j)=\\max p(y_1,...,y_t=j|x_1,...,x_t,\\lambda) \\end{aligned}直观来说，在时序$t+1$状态为$s_j$的最大概率应该是时序$t$时所有状态转换到时序$t+1$、观测值为$x_{t+1}$并且状态为$s_j$的最大值，即 \\begin{aligned} \\gamma_{t+1}(j)=\\max_k \\gamma_{t}(k)a_{kj}b_{jx_{t+1}} \\end{aligned}并且，为了记忆路径，定义路径变量$\\phi_t(j)$为该路径上的状态$s_j$的前一个状态，即从$t-1$时序到$t$的最优转移方式。 维特比算法的描述如下： 1 初始化：2 $\\quad \\gamma_1(j)=\\pi_i b_{ix_{1}},\\;\\phi_1(i)=0,1\\le i \\le N$3 归纳计算：4 $\\quad \\gamma_t(j)=\\max_k \\gamma_{t-1}(k)a_{kj}b_{jx_{t}}$5 $\\quad \\phi_t(i)=\\arg\\max_j \\gamma_{t-1}(j)a_{jk}b_{kx_{t}}$6 确定路径：7 $\\quad y_T=\\arg\\max_{y_j} \\gamma_{T}(j)$8 $\\quad for\\;t=T-1,…,1$9 $\\quad \\quad y_t=\\phi_{t+1}(y_{t+1})$ 模型训练HMM的学习就是给定观测序列$X=x_1,…,x_T$，试图找到最优的参数$\\lambda$使得$p(X|\\lambda)$最大。如果知道了状态序列，那么$\\pi,A,B$就都可以统计出来。但是状态序列其实是隐变量，求解此问题的方法是前向后向算法，也叫做Baum-Welch算法。 定义 \\begin{aligned} \\beta_t(i)=p(x_{t+1},...,x_T|y_t=i,\\lambda) \\end{aligned}表示当前$t$时刻状态为$s_i$，部分观测序列为$x_{t+1},…,x_T$的概率。与前向算法类似，$\\beta_t(i)$也可以有效地计算，公式如下 \\begin{aligned} \\beta_t(i)&=\\left[\\sum_{j=1}^N \\beta_{t+1}(j)a_{ij}\\right]b_{jx_{t+1}},\\; 1\\le t \\le T-1 \\\\ \\beta_T(i)&=1 \\end{aligned}进一步可以得到 \\begin{aligned} p(X,y_t=i|\\lambda)&=p(x_1,...,x_t,y_t=i|\\lambda)p(x_{t+1},...,x_T,y_t=i|\\lambda)=\\theta_t(i)\\beta_t(i) \\\\ p(X,y_t=i|\\lambda)&=\\sum_{i=1}^N \\theta_t(i)\\beta_t(i) \\end{aligned}![](http://ww2.sinaimg.cn/large/9bcfe727jw1fbacpj6v5zj20cc064jrl.jpg) 在前后向算法中，定义\\xi_t(i,j)=p(y_t=i,y_{t+1}=j|X,\\lambda)表示给定HMM和观测序列$X$，$t,t+1$时刻的状态分别是$s_i,s_j$的概率。如上图所示，对上式的推导为 \\begin{aligned} \\xi_t(i,j)&=\\frac{p(y_t=i,y_{t+1}=j,X|\\lambda)}{p(X|\\lambda)} \\\\ &= \\frac{\\theta_t(i)a_{ij}\\beta_{t+1}(j)b_{jx_{t+1}}} {\\sum_{i=1}^N \\sum_{j=1}^N \\theta_t(i)a_{ij}\\beta_{t+1}(j)b_{jx_{t+1}}} \\end{aligned}除此之外，再定义\\eta_t(i)=p(y_t=i|X,\\lambda)表示给定HMM和观测序列$X$，$t$时刻状态为$s_i$的概率，所以有 \\begin{aligned} \\eta_t(i) = \\frac{p(y_t=i,X|\\lambda)} {p(X|\\lambda)} = \\frac{\\theta_t(i)\\beta_t(i)}{\\sum_{i=1}^N \\theta_t(i)\\beta_t(i)} \\end{aligned}考虑$\\xi_t(i,j)$和$\\eta_t(i)$的定义，就能够得到（想想就能得到）\\eta_t(i)=\\sum_{i=1}^N \\xi_t(i,j)下面介绍前向后向算法的描述： 1 初始化：随机初始化参数$A,B,\\lambda$2 不满足停止条件时迭代计算：3 $\\quad \\beta_T(i)=1,1\\le i \\le N$4 $\\quad \\beta_t(i)=\\left[\\sum_{j=1}^N \\beta_{t+1}(j)a_{ij}\\right]b_{jx_{t+1}},\\; t \\in \\lbrace T-1,…,1 \\rbrace,1\\le i \\le N $5 $\\quad \\theta_{t}(i)=\\left[\\sum_{j=1}^N \\theta_{t-1}(j)a_{ji}\\right]b_{ix_{t}}$6 $\\quad$计算$\\xi_t(i,j),\\eta_t(i), 1\\le i,j \\le N,1 \\le t \\le T$7 $\\quad $更新参数：8 $\\quad \\pi=\\eta_1(i),1\\le i \\le N$9 $\\quad a_{ij}=\\frac{\\sum_{t=1}^{T-1}\\xi_t(i,j)}{\\sum_{t=1}^{T-1}\\eta_t(i)},1\\le i,j \\le N$10 $\\quad b_{jk}=\\frac{\\sum_{t=1,x_t=k}^T\\quad \\eta_t(j)} {\\sum_{t=1}^{T}\\eta_t(j)} ,1\\le j \\le N,1\\le k \\le M$11 输出HMM：$\\lambda=(A,B,\\pi)$ $o_t=k$表示$t$时刻的观测值为第$k$种观测值。停止条件可以是：参数$\\lambda=(A,B,\\pi)$收敛。","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"Support Vector Machine","slug":"Support-Vector-Machine","date":"2016-12-27T02:59:50.000Z","updated":"2018-12-16T14:08:06.432Z","comments":true,"path":"2016/12/27/Support-Vector-Machine/","link":"","permalink":"atlantic8.github.io/2016/12/27/Support-Vector-Machine/","excerpt":"","text":"支持向量机（SVM） 支持向量机是一种非常优秀的线性分类器。给定数据集$D=\\lbrace (x_1,y_1),(x_2,y_2),…,(x_m,y_m) \\rbrace ,y_i\\in \\lbrace -1,1 \\rbrace$，当$y_i=1$时，称$x_i$为正类；否则为负类。基本思想是在样本及空间内找到一个超平面将不同类别的样本分开。设超平面为 \\begin{aligned} \\omega^Tx+b=0 \\end{aligned}将特征空间划分两个部分，一部分是正类，一部分是负类，法向量指向的一侧为正类，反之为负类。相应的分类决策函数为$f(x)=sign(\\omega^Tx+b)$。 函数间隔定义超平面$(\\omega,b)$关于样本点$(x_i,y_i)$的函数间隔为 \\begin{aligned} \\hat{\\gamma_i}=y_i(\\omega^Tx_i+b) \\end{aligned}函数间隔的正负可以表示分类结果是否准确，其大小可以相对地表示样本点到超平面的远近，越远置信度越高。定义超平面$(\\omega,b)$关于数据集$D$的函数间隔为$(\\omega,b)$关于$D$中样本点$(x_i,y_i)$的函数间隔的最小值，即 \\begin{aligned} \\hat{\\gamma}=\\min_{i=1,...,m}\\hat{\\gamma_i} \\end{aligned}函数间隔可以表示分类的准确度和置信度。但是，函数间隔还存在一个明显问题，比如将$\\omega$和$b$都扩大2倍，超平面不变，但是函数间隔却扩大了2倍，解决方案是对函数间隔添加规范化约束。 几何间隔定义超平面$(\\omega,b)$关于分类正确的样本点$(x_i,y_i)$的几何间隔为 \\begin{aligned} \\gamma_i=\\frac{y_i( \\omega^Tx_i+b )}{\\Vert \\omega \\Vert} \\end{aligned}定义超平面$(\\omega,b)$关于数据集$D$的几何间隔为$(\\omega,b)$关于$D$中样本点$(x_i,y_i)$的几何间隔的最小值，即 \\begin{aligned} \\gamma=\\min_{i=1,...,m}\\gamma_i \\end{aligned}间隔最大化SVM学习的基本思想是求解能够正确划分训练数据集并且几何间隔最大的分离超平面，意味着以充分大的确信度对训练数据进行分类，以获得更好的泛化能力。所以问题就变成了 \\begin{aligned} & \\max_{\\omega,b}\\quad\\gamma \\\\ & s.t. \\quad \\frac{y_i( \\omega^Tx_i+b )}{\\Vert \\omega \\Vert} \\ge \\gamma,\\; i=1,2,...,m \\end{aligned}考虑到$\\gamma=\\frac{\\hat{\\gamma} }{\\Vert \\omega \\Vert}$，所以上式可以写成 \\begin{aligned} & \\max_{\\omega,b}\\quad\\frac{\\hat{\\gamma} }{\\Vert \\omega \\Vert} \\\\ & s.t. \\quad y_i( \\omega^Tx_i+b ) \\ge \\hat{\\gamma},\\; i=1,2,...,m \\end{aligned}前面提到将$(\\omega,b)$按比例缩放不会影响最终结果，所以可以取$\\hat{\\gamma}=1$，所以原问题可以转化为如下问题 \\begin{aligned} & \\max_{\\omega,b}\\quad\\frac{1 }{\\Vert \\omega \\Vert} \\\\ & s.t. \\quad y_i( \\omega^Tx_i+b ) \\ge 1,\\; i=1,2,...,m \\end{aligned}即 \\begin{aligned} &\\min_{\\omega,b} \\frac{1}{2}\\Vert \\omega \\Vert^2 \\\\ & s.t. \\quad y_i( \\omega^Tx_i+b ) \\ge 1,\\; i=1,2,...,m \\end{aligned}这就是SVM的基础形态，是一个凸二次规划问题。 拉格朗日对偶性考虑如下的优化问题 \\begin{aligned} \\min_{\\omega} f(\\omega) \\\\ \\quad \\quad s.t. \\quad g_i(\\omega) &\\le 0 \\\\ h_i(\\omega) &= 0 \\end{aligned}对应的拉格朗日函数如下，$\\alpha,\\beta$是拉格朗日乘子 \\begin{aligned} L(\\omega,\\alpha,\\beta)=f(\\omega)+\\sum_{i=1}^k\\alpha_ig_i(\\omega) + \\sum_{i=1}^l\\beta_ih_i(\\omega). \\end{aligned}考虑下面的优化问题 \\begin{aligned} \\theta_P(\\omega)=\\max_{\\alpha,\\beta:\\alpha_i\\ge 0} L(\\omega,\\alpha,\\beta) \\end{aligned}下标$P$是$primal$的意思，优化目标针对变量$\\alpha,\\beta$。给定$\\omega$，如果$\\omega$的任何一个分量违背了限制条件(比如$g_i(\\omega)&gt;0$或者$h_i(\\omega) \\neq 0$)，那么$\\theta_P(\\omega)$就是无穷大！反之，如果限制条件没有被打破，那么$\\theta_P(\\omega)=f(\\omega)$，所以 \\theta_P(\\omega)=\\begin{cases} f(\\omega) & 如果 \\omega满足限制条件 \\\\ \\infty & 其他 \\end{cases}下式成立 \\begin{aligned} \\min_{\\omega} \\theta_P(\\omega) = \\min_{\\omega} \\max_{\\alpha,\\beta:\\alpha_i\\ge 0} L(\\omega,\\alpha,\\beta) = p^{\\*} \\end{aligned} 下面考虑对偶问题，定义 \\begin{aligned} \\theta_D(\\alpha,\\beta) = \\min_{\\omega} L(\\omega,\\alpha,\\beta) \\end{aligned}这里下标$D$表示$dual$，优化目标针对变量$\\omega$。所以有 \\begin{aligned} \\max_{\\alpha,\\beta:\\alpha_i\\ge 0} \\theta_D(\\alpha,\\beta) = \\max_{\\alpha,\\beta:\\alpha_i\\ge 0} \\min_{\\omega} L(\\omega,\\alpha,\\beta) = d^{\\*} \\end{aligned} 对于上面的$p^{*}$和$d^{*}$，有如下的规律 \\begin{aligned} d^{\\*}=\\max_{\\alpha,\\beta:\\alpha_i\\ge 0} \\min_{\\omega} L(\\omega,\\alpha,\\beta) \\le \\min_{\\omega} \\max_{\\alpha,\\beta:\\alpha_i\\ge 0} L(\\omega,\\alpha,\\beta) = p^{\\*} \\end{aligned}上式中等号成立的条件是：函数$f$和$g_i$都是凸函数，$h_1,h_2,…,h_l$函数是同族函数。并且每个$g_i$函数都是严格合理的，即对每一个$i$，都存在一些$\\omega$满足$g_i(\\omega)小于0$。此外，存在$(\\alpha,\\beta,\\omega)$满足KKT条件，即 \\begin{aligned} \\frac{dL(\\alpha,\\beta,\\omega)}{d\\omega_i} &= 0,\\quad i=1,...,m \\\\ h_i(\\omega)&= 0,\\quad i=1,...,l \\\\ \\alpha_i g_i(\\omega) &= 0, \\quad i=1,...,k \\\\ g_i(\\omega) &\\le 0, \\quad i=1,...,k \\\\ \\alpha_i &\\ge 0 , \\quad i=1,...,k \\end{aligned} 对偶问题由最大化间隔得出的优化问题是一个凸二次规划问题，可以使用现成的工具完成。使用拉格朗日乘子法可得到其对偶问题，为其每项约束添加一个拉格朗日乘子$\\alpha_i \\ge 0$，拉格朗日目标函数为 \\begin{aligned} L(\\omega,b,\\alpha) = \\frac{1}{2}\\Vert \\omega \\Vert^2 + \\sum_{i=1}^m \\alpha_i(1-y_i(\\omega^Tx_i+b)) \\end{aligned}其中，$\\alpha=(\\alpha_1;\\alpha_2;…;\\alpha_m)$。上式分别对$\\omega,b$求偏导并令其为0可得 \\begin{aligned} \\omega = \\sum_{i=1}^m \\alpha_iy_ix_i \\\\ 0 = \\sum_{i=1}^m \\alpha_iy_i \\end{aligned}将上式代入$L(\\omega,b,\\alpha)$中，消去$\\omega,b$，则上式变成 \\begin{aligned} L(\\omega,b,\\alpha) = \\sum_{i=1}^m \\alpha_i - \\frac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^m \\alpha_i \\alpha_j y_i y_j x_i^T x_j \\end{aligned}由于满足KKT条件，所以原问题$f(\\omega)$的优化问题可以写成 \\begin{aligned} \\min_{\\omega,b} f(\\omega) &\\to \\min_{\\omega,b} \\max_{\\alpha} L(\\omega,b,\\alpha) \\\\ &\\to \\max_{\\alpha} \\min_{\\omega,b} L(\\omega,b,\\alpha) \\end{aligned}这里$ \\max_{\\alpha} L(\\omega,b,\\alpha)$的意义在于选择参数$\\alpha$使得$ L(\\omega,b,\\alpha)$最大，根据$ L(\\omega,b,\\alpha)$的公式，由于$1\\le y_i(\\omega^Tx_i+b)$，所以一旦出现$1 &lt; y_i(\\omega^Tx_i+b)$的情况，就应该有$\\alpha_i=0$，否则这一项就是负值，整体也就不是最小值了。所以，优化问题最终转化为 \\begin{aligned} \\max_{\\alpha} \\sum_{i=1}^m \\alpha_i - \\frac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^m \\alpha_i \\alpha_j y_i y_j x_i^T x_j \\\\ s.t. \\; \\sum_{i=1}^m\\alpha_iy_i=0,\\alpha_i \\ge 0,\\; i=1,...,m \\end{aligned} Sequential Minimal Optimization对偶问题依旧是二次规划问题，但问题的规模正比于训练样本数。SMO是高效算法之一，其思想是每次选取两个变量$\\alpha_i,\\alpha_j$并固定其他的$\\alpha_k$，不断执行迭代步骤。这种方法也称为坐标上升方法（coordinate ascent）。 令\\alpha_iy_i+\\alpha_jy_j=-\\sum_{k\\neq i,j}\\alpha_ky_k=c用这个式子消去优化目标函数中的$\\alpha_j$可以得到一个以$\\alpha_i$为单变量的二次规划问题，该问题有闭式解且简单易懂。解出之后，$\\alpha_i,\\alpha_j$就得到了更新。SMO选取$\\alpha_i,\\alpha_j$时，启发式地选择对应样本间隔最大的变量进行更新。 然后根据$\\omega = \\sum_{i=1}^m \\alpha_iy_ix_i$求出$\\omega$，对于$b$，可以使用任意一个支持向量的性质$y_s \\left(\\omega^Tx_s+b \\right)=1$来计算。当然更鲁棒的方法是使用所有的支持向量并对求出的$b$取均值。 软间隔支持向量机（Soft Margin SVM）基础型的SVM的假设所有样本在样本空间是线性可分的(硬间隔)，但是现实中的情况通常不满足这种特性。对应的软间隔允许某些样本不满足 \\begin{aligned} y_i(\\omega^Tx_i+b)\\ge 1 \\end{aligned}为了解决这个问题，可以对每个样本点引入一个松弛变量$\\xi_i\\ge 0$满足 \\begin{aligned} y_i(\\omega^Tx_i+b)+\\xi_i\\ge 1 \\end{aligned}同时，对每个松弛变量支付一个代价$\\xi_i$。训练时应该要保持不满足约束的样本尽量少，所以优化函数可以表示成 \\begin{aligned} &\\min_{\\omega,b,\\xi_i} \\frac{1}{2}\\Vert \\omega \\Vert^2 + C\\sum_{i=1}^m \\xi_i \\\\ &s.t. \\; y_i(\\omega^Tx_i+b) \\ge 1-\\xi_i \\\\ &\\quad \\xi_i \\ge 0,\\;i=1,...,m \\end{aligned}其中，$C&gt;0$是一个惩罚参数，调节损失函数两项的权重。这就是常用的软间隔支持向量机，通过拉格朗日乘子法，得到如下拉格朗日函数 \\begin{aligned} L(\\omega,b,\\alpha,\\xi,\\mu) = \\frac{1}{2}\\Vert \\omega \\Vert^2 + C\\sum_{i=1}^m \\xi_i + \\sum_{i=1}^m \\alpha_i(1-\\xi_i-y_i(\\omega^Tx_i+b)) - \\sum_{i=1}^m \\mu_i\\xi_i \\end{aligned}其中，$\\alpha_i,\\mu_i$就是拉格朗日乘子。令$L(\\omega,b,\\alpha,\\xi,\\mu)$对$\\omega,b,\\xi$的偏导数为0得到 \\begin{aligned} \\omega &= \\sum_{i=1}^m \\alpha_iy_ix_i \\\\ 0 &= \\sum_{i=1}^m \\alpha_iy_i \\\\ C &= \\alpha_i + \\mu_i \\end{aligned}由上式可知$0 \\le \\alpha_i \\le C$。将上式代入$L(\\omega,b,\\alpha,\\xi,\\mu)$中，并求解优化函数的对偶形式 \\begin{aligned} &\\max_{\\alpha} \\sum_{i=1}^m \\alpha_i - \\frac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^m \\alpha_i \\alpha_j y_i y_j x_i^T x_j \\\\ &s.t. \\sum_{i=1}^m\\alpha_iy_i=0 \\\\ &0 \\le \\alpha_i \\le C,\\; i=1,...,m \\end{aligned}对于软间隔支持向量机，其KKT条件是 \\begin{aligned} \\alpha_i y_i(\\omega^x_i+b)-1+\\xi_i &= 0, \\quad i=1,...,m \\\\ y_i(\\omega^x_i+b)-1+\\xi_i &\\le 0, \\quad i=1,...,m \\\\ \\alpha \\ge 0,\\mu_i &\\ge 0, \\quad i=1,...,m \\\\ \\xi_i \\ge 0, \\mu_i \\xi_i &= 0, \\quad i=1,...,m \\end{aligned}对于非支持向量，$\\alpha_i=0$。对支持向量，有$0 &lt; \\alpha_i \\le C$，即有$y_i(\\omega^x_i+b)=1-\\xi_i$，样本点$x_i$到间隔边界的距离为$\\frac{\\xi_i}{\\Vert \\omega \\Vert}$，软间隔的支持向量有以下几种情况 或者在间隔边界上（$\\alpha_i &lt; C,\\xi_i=0$） 或者在间隔边界与分离超平面之间（$\\alpha_i=C,0 &lt; \\xi_i &lt; 1$，此时分类也是正确的） 或者在分离超平面误分那一侧（$\\alpha_i=C,\\xi_i&gt;1$，分类错误，该样本是异常点） 上述优化问题依旧可以使用SMO算法，求出$\\omega$之后，$b$的求法如下。注意到满足$0&lt;\\alpha_i &lt; C$的样本是支持向量，即满足$y_i(\\omega^Tx_i+b)=1$，所以$b$就可解了。 非线性核支持向量机（Kernal SVM）核函数判定定理设$X$是输入空间，$k(\\cdot,\\cdot)$是定义在$X\\times X$的对称函数，则$k$是核函数当且仅当对于任意数据集$D=\\lbrace x_1,x_2,…,x_m \\rbrace$，核矩阵$K$总是半正定的，其中半正定是指对于每个非零的复向量$z$，$z^{*}Kz &gt; 0$，其中$z^{*}$是$z$的共轭转置。 常用的核函数有 \\begin{aligned} Linear\\; kernal &: \\quad k(x_i,x_j)= x_i^Tx_j \\\\ Multinomial\\; kernal &: \\quad k(x_i,x_j)= (x_i^Tx_j)^d \\\\ Gaussian\\; kernal &: \\quad k(x_i,x_j)= e^{-\\frac{\\Vert x_i-x_j \\Vert^2}{2\\sigma^2}} \\\\ Laplace\\; kernal &: \\quad k(x_i,x_j)= e^{-\\frac{\\Vert x_i-x_j \\Vert}{\\sigma}} \\\\ Sigmoid\\; kernal &: \\quad k(x_i,x_j)= tanh(\\beta x_i^Tx_j+\\theta),\\beta>0,0>\\theta \\end{aligned}另外核函数的线性组合、乘积也是核函数。并且对于任意函数$g(\\cdot)$，$k(x,z)=g(x)k_1(x,z)g(z)$也是核函数。 KSVM基础型的SVM的假设样本在样本空间是线性可分的，但是现实中的情况通常不满足这种特性。对于这种问题，一种可能的方法是将样本从原始空间映射到更高维的特征空间，使得其在线性可分。令$\\phi (x)$表示将$x$映射后的特征向量，于是特征空间中的超平面可以表示为f(x)=\\omega^T \\phi (x)+b优化的对偶问题变成 \\begin{aligned} \\max_{\\alpha} \\sum_{i=1}^m \\alpha_i - \\frac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^m \\alpha_i \\alpha_j y_i y_j \\phi (x_i)^T \\phi (x_j) \\\\ s.t. \\; \\sum_{i=1}^m\\alpha_iy_i=0,\\alpha_i \\ge 0,\\; i=1,...,m \\end{aligned}由于可能存在维度诅咒，计算$\\phi (x_i)^T \\phi (x_j)$将非常困难。这里引入核函数的概念 \\begin{aligned} k(x_i,x_j) = \\langle \\phi (x_i),\\phi (x_j) \\rangle = \\phi (x_i)^T \\phi (x_j) \\end{aligned}满足$x_i,x_j$在特征空间的内积等于它们在原始样本空间中通过函数$k(\\cdot)$计算的结果，核函数是避免维度诅咒的一种方法。 引用[1]. 统计学习方法. 李航著. 清华大学出版社[2]. 机器学习. 周志华.","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"Sparse Coding","slug":"Sparse-Coding","date":"2016-12-20T02:26:20.000Z","updated":"2018-12-16T14:08:06.413Z","comments":true,"path":"2016/12/20/Sparse-Coding/","link":"","permalink":"atlantic8.github.io/2016/12/20/Sparse-Coding/","excerpt":"","text":"字典学习字典学习是与稀疏性相关的学习方法，它被用来寻找一组“超完备”基向量来更高效地表示样本数据。稀疏性会降低计算和存储的开销，并且会提高模型的可解释性。 稀疏表示侧重于学习一个字典 给定数据集$\\lbrace x_1,x_2,…,x_m \\rbrace$，字典学习的简单形式如下 \\begin{aligned} \\min_{B,\\alpha_i} \\sum_{i=1}^m \\Vert x_i-B\\alpha_i \\Vert_2^2 + \\lambda \\sum_{i=1}^m \\Vert \\alpha_i \\Vert_1 \\end{aligned}其中$B\\in R^{d\\times k}$为字典矩阵，$k$称为字典的词汇量，$\\alpha_i \\in R^k$是样本$x_i$的稀疏表示。实际中，根据应用场景的要求，第二项中的$\\lambda \\sum_{i=1}^m \\Vert \\alpha_i \\Vert_1$也可以替换成别的代价函数。 奇异值分解简述SVD对任意矩阵奇异值分解M=U\\Sigma V^T其中，$\\Sigma$是对角矩阵，对角线上是矩阵的奇异值，$U$中的每一列是经过$M$转化后的标准正交基组成之一，而$V$表示了原始域的标准正交基，每一列是一个向量。 以后应该还有关于SVD的解释 训练方法上式的训练目标参数有$\\alpha_i,B$，可以用交替优化的方法。 1 为每个样本$x_i$找到相应的$\\alpha_i$，即 \\begin{aligned} \\min_{\\alpha_i} \\Vert x_i-B\\alpha_i \\Vert_2^2 + \\lambda \\Vert \\alpha_i \\Vert_1 \\end{aligned}这一步可以使用lasso的优化方法。 2 以$\\alpha_i$为初值来更新字典$B$，即 \\begin{aligned} \\min_{B} \\Vert X-BA \\Vert_F^2 \\end{aligned}其中，$X=(x_1,x_2,…,x_m)\\in R^{d\\times m},A=(\\alpha_1,\\alpha_2,…,\\alpha_m)\\in R^{k\\times m}$，矩阵的F范数是矩阵每个元素的平方和再开方。 上式的常用优化方法为KSVD，这是基于逐列更新的方法。令$b_i$表示字典$B$的第$i$列，$\\alpha^i$表示稀疏矩阵$A$的第$i$行($\\alpha_i$表示稀疏矩阵$A$的第$i$列)，$b_i\\alpha^i$其实是个矩阵。则上式可以重写成 \\begin{aligned} \\min_{B} \\Vert X-BA \\Vert_F^2 &= \\min_{b_i} \\left\\Vert X-\\sum_{j=1}^k b_ja^j \\right\\Vert_F^2 \\\\ &= \\min_{b_i} \\left\\Vert X-\\sum_{j=1,j\\not i}^k b_ja^j - b_i\\alpha^i \\right\\Vert_F^2 \\\\ &= \\min_{b_i} \\Vert E_i-b_i\\alpha^i \\Vert_F^2 \\end{aligned}更新字典第$i$列时，$E_i$是固定的，$E_i$表示没有$b_i$时表示的误差。所以最小化上式原则上就是对$E_i$进行奇异值分解(SVD)取得最大奇异值所对应的正交向量。对$E_i$进行奇异值分解$E_i=U\\Sigma V^T$，那么$b_i$是$U$中最大奇异值对应的正交向量，但此时$\\alpha^i$也需要更新，这就会破坏$\\alpha^i$的稀疏性质。 为了避免这种情况，KSVD做如下处理。注意到要保持稀疏性，我们不能将$\\alpha_i$原来为0的位置变成非零数。$b_i \\alpha^i$是一个矩阵，它的第$j$列是$b_i\\alpha_j^i$。如果原来$\\alpha_j^i=0$，那么$b_i\\alpha_j^i$就是全为0的列向量。这里，我们可以把$E_i$对应位置的列变成全0，这样奇异值分解后的结果就不会破坏$A$的稀疏性。然后，对$E_i$进行奇异值分解，更新$b_i$为$U$中最大奇异值对应的正交向量，更新$\\alpha^i$为$V$中最大奇异值对应的正交向量(列向量)乘以最大奇异值。 稀疏编码稀疏编码是字典学习的下一步，在学习到了字典$B$后，给定一个新的样本$x_k$，只需要通过优化 \\begin{aligned} \\min_{\\alpha_i} \\Vert x_k-B\\alpha_k \\Vert_2^2 + \\lambda \\Vert \\alpha_k \\Vert_1 \\end{aligned}来找到$\\alpha_k$，即求解出了基于字典$B$的关于$x_k$的稀疏表示。上式的优化方法即经典的Lasso优化问题，使用Proximal Gradient Descent方法。 比如说： ![](http://img.my.csdn.net/uploads/201304/09/1365483491_9524.jpg)","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"Manifold Learning","slug":"Manifold-Learning","date":"2016-12-18T03:50:16.000Z","updated":"2018-12-16T14:08:06.320Z","comments":true,"path":"2016/12/18/Manifold-Learning/","link":"","permalink":"atlantic8.github.io/2016/12/18/Manifold-Learning/","excerpt":"","text":"流形流形学习是一类借鉴了拓扑流行概念的概念降维方法 直观上来讲，一个流形好比是一个 d 维的空间 在一个 m 维的空间中 (m &gt; d) 被扭曲之后的结果 比如说一块布，可以把它看成一个二维平面，这是一个二维的欧氏空间，现在我们（在三维）中把它扭一扭，它就变成了一个流形（当然，不扭的时候，它也是一个流形，欧氏空间是流形的一种特殊情况），地球表面其实也只是一个二维流形。 流形的一个特点是：流形是在局部与欧式空间 同胚 的空间 即局部上具有欧式空间的特性，距离度量可以使用欧氏距离 所以，低维流形嵌入到高维空间中，数据样本在高维空间中的分布看上去会比较复杂，但在局部上具有欧式空间的特性。因此，可以容易地在局部建立降维映射关系，然后设法将局部关系映射到全局。此种降维方法可被用于数据可视化。 等度量映射（Isometric Mapping）Isomap的出发点是：低维嵌入流形上两点距离是“测地线距离”（地理上的概念，比如地球上两点的距离就不是欧氏距离）但是利用流形的局部与欧式空间同胚特性，我们就能在局部空间内找到每个点的近邻点，从而建立一个近邻连接图。所以，“测地线距离”就是图中的最短距离。最短路径算法可以使用Dijkstra算法或者Floyd算法。有了距离度量表示，就可以降维了，降维方法可以使用MDS算法（当然也可以使用其他方法） Isomap算法描述如下： 输入：样本集$D= \\lbrace x_1,x_2,…,x_m \\rbrace $; 近邻参数$k$; 低维空间维度$d^{‘}$ 1 $for\\quad i=1,…,m \\quad do$2 $\\quad$确定$x_i$的$k$近邻3 $\\quad x_i$与其$k$近邻的距离设置为其欧氏距离，与其他点的距离设置为无穷大4 $end \\quad for$5 调用最短距离路径算法计算任意两点之间的距离$dist(x_i,x_j)$6 将$dist(x_i,x_j)$作为MDS算法的输入，输出结果$Z$ 输出：样本集$D$在低维空间的投影$Z$ 局部线性嵌入（Locally Linear Embedding）Isomap 希望保持任意两点之间的测地线距离，保存的信息量大，但是计算量随着节点数量的增长爆炸增长（Dijkstra算法$O(n^2)$或者Floyd算法$O(n^3)$）。LLE 希望保持局部线性关系，信息量较小，但是对数据量较大的情形则比较有效。 LLE假设$x_i$能够通过其邻域内的样本$x_j,x_k,x_l$线性表出，即x_i=\\omega_{ij}x_j+\\omega_{ik}x_k+\\omega_{il}x_l所以，LLE需要先找出每个样本$x_i$的近邻下标集合$Q_i$，然后计算出基于$Q_i$中的样本对$x_i$进行线性重构的系数$\\omega_i$： \\begin{aligned} \\min_{\\omega_1,\\omega_2,...,\\omega_m} \\sum_{i=1}^m \\left\\Vert x_i-\\sum_{j \\in Q_i}\\omega_{ij}x_j \\right\\Vert^2 \\\\ s.t. \\quad \\sum_{j \\in Q_i}\\omega_{ij}=1 \\end{aligned}这里令$C_{jk}=(x_i-x_j)^T(x_i-x_k)$，$\\omega_{ij}$有闭式解 \\begin{aligned} \\omega_{ij}=\\frac{\\sum_{k\\in Q_i}C_{jk}^{-1}}{\\sum_{l,s\\in Q_i}C_{ls}^{-1}} \\end{aligned}因为LLE假设在低维空间中保持$\\omega_i$保持不变，令$Z=(z_1,z_2,…,z_m)\\in R^{d^{‘}\\times m},W_{ij}=\\omega_{ij}$.所以$x_i$的低维坐标$z_i$可以通过 \\begin{aligned} \\min_{z_1,z_2,...,z_m} \\sum_{i=1}^m \\left\\Vert z_i-\\sum_{j\\in Q_i}\\omega_{ij}z_j \\right\\Vert^2 \\\\ \\min_{z_1,z_2,...,z_m} \\sum_{i=1}^m \\left\\Vert z_i-W_iZ \\right\\Vert^2 \\end{aligned}求解，这里需要对$z_i$正规化以满足$\\sum_i z_i=0,\\frac{1}{m}\\sum_i z_iz_i^T=I$。可以令$M=(I-W)^T(I-W)$，那么优化函数可以写成\\min_Z tr(ZMZ^T) \\quad s.t \\; ZZ^T=I这里需要注意我们假设对$Z$正规化，才能满足$ZZ^T=I$。然后上面的优化函数可以通过特征值分解，取最小的$d^{‘}$个非零特征值对应的特征向量即为$Z^T$。 LLE算法描述 输入：样本集$D={x_1,x_2,…,x_m}$; 近邻参数$k$; 低维空间维度$d^{‘}$ 1 $for\\; i=1,…,m \\quad do$2 $\\quad$确定$x_i$的$k$近邻3 $\\quad$求$\\omega_{ij},\\; j\\in Q_i$, 不在$x_i$邻域内的系数为04 $end \\; for$5 求矩阵$M$5 对$M$进行特征值分解6 输出最小的$d^{‘}$个非零特征值对应的特征向量 输出：样本集$D$在低维空间的投影$Z$ 拉普拉斯特征映射(Laplacian Eigenmaps) 待更……","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"Multiple Dimensional Scaling","slug":"Multiple-Dimensional-Scaling","date":"2016-12-18T02:22:41.000Z","updated":"2018-12-16T14:08:06.360Z","comments":true,"path":"2016/12/18/Multiple-Dimensional-Scaling/","link":"","permalink":"atlantic8.github.io/2016/12/18/Multiple-Dimensional-Scaling/","excerpt":"","text":"Multiple Dimensional Scaling (MDS、多维缩放)是经典的聚类算法。 假设原始$d$维样本空间中有$m$个样本$x_1,x_2,…,x_m$，其距离矩阵为$D \\in R^{m\\times m}$，$dist_{ij}$为$x_i$到$x_j$的距离。MDS的出发点是获得样本在$d^{‘}$维空间内的表示$Z\\in R^{d^{‘} \\times m}$，新空间内样本的距离等于原始空间的距离，即\\Vert z_i-z_j \\Vert = dist_{ij}令$B=Z^TZ \\in R^{m\\times m}$，其中$B$为降维后的样本内积矩阵，$b_{ij}=z_i^Tz_j$，有 \\begin{aligned} dist_{ij}^2 &= \\Vert z_i \\Vert + \\Vert z_j \\Vert - 2z_i^Tz_j \\\\ &= b_{ii}+b_{jj}-2b_{ij} \\end{aligned}假设样本$Z$被中心化(normalization)，即$\\sum_{i=1}^m z_i=0$。于是有\\sum_{i=1}^mb_{ij}=\\sum_{j=1}^mb_{ij}=0。继而有 \\begin{aligned} \\sum_{i=1}^m dist_{ij}^2 = tr(B)+mb_{jj} \\\\ \\sum_{j=1}^m dist_{ij}^2 = tr(B)+mb_{ii} \\\\ \\sum_{i=1}^m \\sum_{j=1}^m dist_{ij}^2 = 2mtr(B) \\end{aligned}其中，$tr$表示矩阵的秩，$tr(B)=\\sum_{i=1}^m \\Vert z_i \\Vert^2$，联立上式可得b_{ij}=-\\frac{1}{2} \\left( dist_{ij}^2 - \\frac{1}{m}\\sum_{i=1}^m dist_{ij}^2 -\\frac{1}{m}\\sum_{j=1}^m dist_{ij}^2 + \\frac{1}{m^2}\\sum_{i=1}^m \\sum_{j=1}^m dist_{ij}^2 \\right)由此即可通过降维前后保持不变的距离矩阵$D$求取内积矩阵$B$。 那么，下面就需要求$Z$了。方法是对$B$做特征值分解，得到 \\begin{aligned} B=Z^TZ=V\\Lambda V^T \\end{aligned}其中，$\\Lambda=diag(\\lambda_1,…,\\lambda_{d})$为$d$个特征值构成的对角矩阵，$\\lambda_1 \\ge \\lambda_2 \\ge … \\ge \\lambda_d$。令$\\Lambda_{*}=diag(\\lambda_1,…,\\lambda_{d^{*}})$为对角矩阵，$\\Lambda_{*}$表示对应的特征向量矩阵，则Z=\\Lambda_{\\*}^{\\frac{1}{2}}V_{\\*}^T \\in R^{d^{\\*}\\times m}现实中，仅需要降维后的距离与原始空间内的距离尽可能接近，不必严格相等。此时可取$d^{*}$远小于$d$求解。 MDS算法描述如下： 输入：距离矩阵$D\\in R^{m\\times m}$，其元素$dist_{ij}$为样本$x_i$到$x_j$的距离；低维空间维度$d^{‘}$ 1 计算矩阵$B$2 对$B$做特征值分解3 取$\\Lambda$为$d^{‘}$个最大特征值所构成的对角矩阵，$V$为相应的特征向量矩阵 输出：$Z=\\Lambda^{\\frac{1}{2}}V^T$，其中$Z$的每列对应一个样本的低维坐标","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"Logistic Regression","slug":"Logistic-Regression","date":"2016-12-13T05:52:06.000Z","updated":"2018-12-16T14:08:06.303Z","comments":true,"path":"2016/12/13/Logistic-Regression/","link":"","permalink":"atlantic8.github.io/2016/12/13/Logistic-Regression/","excerpt":"","text":"Logistic RegressionLogistic Regression的思想源于广义线性模型y=g(\\omega^Tx+b)其中，函数$g()$称为联系函数。逻辑回归中，联系函数其实sigmoid函数: y=\\frac{1}{1+e^{-z}}其函数图如下： ![](http://ww2.sinaimg.cn/large/9bcfe727jw1fap4kz80uzj208w05xt8q.jpg) 令$z=\\omega^T x $，所以y=\\frac{1}{1+e^{-(\\omega^T x)}}其中，（通过扩展训练数据将bias部分加入，就省去了bias部分）上式可以写成ln\\frac{y}{1-y}=\\omega^T x如果把$y$当作正样本的后验概率$p(y=1|x)$，那么$1-y$就是负样本的后验概率$p(y=0|x)$。所以有： \\begin{aligned} p(y=1|x) = \\frac{e^{-(\\omega^T x)}}{1+e^{-(\\omega^T x)}} \\\\ p(y=0|x) = \\frac{1}{1+e^{-(\\omega^T x)}} \\end{aligned}我们通过极大似然法来估计$\\omega$，给定数据集${(x_i,y_i)}_{i=1}^m$，对数似然函数可以写成： \\begin{aligned} l(\\omega) &= ln\\prod_{i=1}^m \\left(\\frac{e^{-\\omega^T x_i}}{1+e^{-\\omega^T x_i}}\\right)^{y_i} \\cdot \\left(\\frac{1}{1+e^{-\\omega^T x_i}}\\right)^{1-y_i} \\\\ &= \\sum_{i=1}^m \\left( y_i ln \\frac{e^{-\\omega^T x_i}}{1+e^{-\\omega^T x_i}} + (1-y_i) ln \\frac{1}{1+e^{-\\omega^T x_i}} \\right) \\end{aligned}这里使用经典的方法，$l(\\omega)$对$\\omega$求导，闭式解不好表示，所以可以使用梯度上升的方法表示，其中 \\begin{aligned} \\frac{dl(\\omega)}{d\\omega} &= \\sum_{i=1}^m \\left( y_ix_i-\\frac{x_i e^{-\\omega^T x_i}}{1+e^{-\\omega^T x_i}} \\right) \\\\ \\omega &= \\omega+\\frac{dl(\\omega)}{d\\omega} \\end{aligned}将批量梯度下降转换成随机梯度下降有 \\begin{aligned} & for\\quad i\\; \\in \\; \\{1,2,...,m\\} \\\\ & \\quad\\quad\\omega = \\omega+\\alpha \\cdot \\left(y_i-\\frac{e^{-\\omega^T x_i}}{1+e^{-\\omega^T x_i}} \\right) \\cdot x_i \\end{aligned}Generalized Linear Models上面提到，广义线性模型的形式如下&lt;/b&gt;y=g(\\omega^Tx+b)联系线性回归、logistic回归。广义线性模型的训练，如果满足条件，其随机梯度下降的训练方法如下： \\begin{aligned} & for\\quad i\\; \\in \\; \\{1,2,...,m\\} \\\\ & \\quad\\quad\\omega = \\omega+\\alpha \\cdot \\left(y_i-h_{\\theta}(x_i) \\right) \\cdot x_i \\end{aligned}其中，$h_{\\theta}(x) = g(\\theta^Tx)$即是目标模型的形式.","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"Expection Maximization","slug":"Expection-Maximization","date":"2016-12-09T14:58:01.000Z","updated":"2018-12-16T14:08:06.226Z","comments":true,"path":"2016/12/09/Expection-Maximization/","link":"","permalink":"atlantic8.github.io/2016/12/09/Expection-Maximization/","excerpt":"","text":"EM算法极大似然估计从极大似然法的角度引入EM算法，先考虑这样的一个问题。 给定训练数据，假设训练数据满足高斯分布$f(x|\\mu,\\sigma^2)$，求这个分布的参数. 这便是典型的极大似然估计问题，对数似然函数为l(\\mu,\\sigma^2|X)=\\sum_iln(f(x_i|\\mu,\\sigma^2))上面的式子分别对$\\mu$和$\\sigma$求偏导，并设置其偏导数为0，那么$\\mu$和$\\sigma$的解可以直接计算。 包含隐含变量的极大似然估计假设还有一个条件：数据X有两个类别，$\\lambda_1,\\lambda_2$分别表示$f(x|\\mu_1,\\sigma_1^2)$和$f(x|\\mu_2,\\sigma_2^2)$在总体中的比率。因此总体分布就可以是$g(x|\\lambda_1,\\lambda_2,\\mu_1,\\mu_2,\\sigma_1^2,\\sigma_2^2)$，即两个分布的混合。所以有g(x|\\lambda_1,\\lambda_2,\\mu_1,\\mu_2,\\sigma_1^2,\\sigma_2^2)=\\lambda_1f(x|\\mu_1,\\sigma_1^2)+\\lambda_2f(x|\\mu_2,\\sigma_2^2) \\quad s.t.: \\quad \\lambda_1+\\lambda_2=1极大似然估计的求解方法如下，似然公式为l()=log(P(X|\\lambda_1,\\lambda_2,\\mu_1,\\mu_2,\\sigma_1^2,\\sigma_2^2))=log\\left(\\sum_ig(x_i|\\lambda_1,\\lambda_2,\\mu_1,\\mu_2,\\sigma_1^2,\\sigma_2^2) \\right)上面式子是先求和在取对数，求偏导的方法就不行了！ Jensen不等式如果一个函数满足：对于任意的$x$都有$f^{‘’}(x) \\ge 0$，那么$f(x)$是凸函数(如果输入$x$是向量，那么对应于其hessian矩阵(半)正定)，如果等号可以去掉即可称之为严格凸函数。Jensen不等式的表述如下：假设$f$是凸函数，X是一个随机变量，那么有：E[f(X)] \\ge f(E[X])对立面的表述是，如果函数$f$是凹(concave)函数($f^{‘’}(x) \\le 0$)，那么有E[f(X)] \\le f(E[X])当不等式中的等号成立时，$f(X)$是常数函数。 期望最大化现在抽象化问题，已知模型为$p(x|\\theta)$，$X=(x_1,x_2,…,x_n)$，求$\\theta$。这里需要引入隐含变量$Z=(z_1,z_2,…,z_m)$，所以有： \\begin{aligned} P(X|\\theta)=\\sum_zP(x_i|z,\\theta) \\cdot P(z|\\theta) \\end{aligned}定义似然函数为l(\\theta)=log(P(X|\\theta))=log\\sum_z(P(x_i|z,\\theta) \\cdot P(z|\\theta)) EM算法也是通过迭代方法求得$l(\\theta)$的极值，假设第$n$轮迭代计算出的$\\theta$为$\\theta_n$，只要下一轮的$\\theta$优于$\\theta_n$即可，推导如下： \\begin{aligned} l(\\theta)-l(\\theta_n) &= log(P(X|\\theta))-log(P(X|\\theta_n)) \\\\ &= log(\\sum_zP(x_i|z,\\theta) \\cdot P(z|\\theta))-log(P(X|\\theta_n)) \\\\ &= log(\\sum_z P(z|X,\\theta_n)\\cdot \\frac{P(x_i|z,\\theta) \\cdot P(z|\\theta)}{P(z|X,\\theta_n)})-log(P(X|\\theta_n)) \\\\ &\\ge \\sum_z P(z|X,\\theta_n) \\cdot log\\left( \\frac{P(x_i|z,\\theta) \\cdot P(z|\\theta)}{P(z|X,\\theta_n)} \\right) - \\sum_z P(z|X,\\theta_n) \\cdot log(P(X|\\theta_n)) \\\\ &= \\sum_z P(z|X,\\theta_n) \\cdot log\\left( \\frac{P(x_i|z,\\theta) \\cdot P(z|\\theta)}{P(z|X,\\theta_n) \\cdot P(X|\\theta_n)} \\right) \\\\ \\end{aligned}进而有 \\begin{aligned} l(\\theta) &\\ge l(\\theta_n)+\\sum_z P(z|X,\\theta_n) \\cdot log\\left( \\frac{P(x_i|z,\\theta) \\cdot P(z|\\theta)}{P(z|X,\\theta_n) \\cdot P(X|\\theta_n)} \\right) \\\\ Set : l(\\theta) &\\ge M(\\theta_n,\\theta) \\\\ PS : l(\\theta_n)&=M(\\theta_n,\\theta_n) \\end{aligned}所以，我们只要 \\begin{aligned} \\theta_{n+1} &= \\mathop{arg\\;max}_{\\theta} M(\\theta_n,\\theta) \\\\ &= \\mathop{arg\\;max}_{\\theta} \\sum_z P(z|X,\\theta_n) \\cdot log(P(X|z,\\theta) \\cdot P(z|\\theta)) \\\\ &= \\mathop{arg\\;max}_{\\theta} \\sum_z P(z|X,\\theta_n) \\cdot log(P(X,z|\\theta)) \\\\ &= \\mathop{arg\\;max}_{\\theta} E_{Z|X,\\theta_n}[log(P(X,z|\\theta)] \\\\ Set: F(\\theta)&=E_{Z|X,\\theta_n}[log(P(X,z|\\theta)] \\end{aligned}所以，EM算法的步骤如下： 随机初始化$\\theta_0$迭代直到收敛：E步：求条件期望$F(\\theta,\\theta_n)$M步：求$F(\\theta,\\theta_n)$的极值$\\theta_{n+1}$ 高斯混合模型高斯混合模型是EM算法在高斯分布上的应用。多元高斯分布函数的定义如下：p(x|\\mu,\\Sigma)=\\frac{1}{(2\\pi)^{n/2}|\\Sigma|^{1/2}} e^{-\\frac{(x-\\mu)^T \\Sigma^{-1} (x-\\mu) }{2}} 其中，$\\mu,\\Sigma$分别是均值和协方差矩阵。混合高斯模型的定义为： \\begin{aligned} p_M(x)&=\\sum_{i=1}^k \\alpha_i \\cdot p(x|\\mu_i,\\Sigma_i) \\\\ s.t.: \\sum_{i=1}^k \\alpha_i &= 1 \\end{aligned}为了方便性，定义$j$个样本由第$i$个高斯分布产生的概率： \\begin{aligned} p_M(z_j=i|x_j)&=\\gamma_{ji} \\\\ &= \\frac{P(z_j=i) \\cdot p_M(x_j|z_j=i)}{p_M(x_j)} \\\\ &= \\frac{\\alpha_i \\cdot p(x_j|\\mu_i,\\Sigma_i)}{\\sum_{l=1}^k \\alpha_l \\cdotp(x_j|\\mu_l,\\Sigma_l)} \\end{aligned}于是，给定样本集$D={x_1,…,x_m}$，用极大似然估计法，最大化似然对数： \\begin{aligned} l(D)=ln\\left( \\prod_{j=1}^m p_M(x_j) \\right)=\\sum_{j=1}^m ln\\left( \\sum_{i=1}^k \\alpha_i \\cdot p(x_j|\\mu_i,\\Sigma_i) \\right) \\end{aligned}上式中，分别由$l(D)$对$\\mu_i,\\Sigma_i,\\alpha_i$求偏导，由于$p_M(z_j=i|x_j)=\\gamma_{ji}$，所以令偏导数=0的结果如下： \\begin{aligned} \\mu_i &= \\frac{\\sum_{j=1}^m \\gamma_{ji} \\cdot x_j}{\\sum_{j=1}^m \\gamma_{ji}} \\\\ \\Sigma_i &= \\frac{\\sum_{j=1}^m \\gamma_{ji}(x_j-\\mu_i)(x_j-\\mu_i)^T}{\\sum_{j=1}^m \\gamma_{ji}} \\\\ \\end{aligned}对于混合系数$\\alpha_i$，除了考虑$l(D)$外，他还有一个限制$\\sum_{i=1}^k \\alpha_i=1$，所以这里可以使用拉格朗日乘子法：l(D)+\\lambda \\left( \\sum_{i=1}^k \\alpha_i-1 \\right)上式对$\\alpha_i$求导并设结果为0有(注意联系$\\gamma_{ji}的定义式$) \\begin{aligned} \\sum_{j=1}^m \\frac{p(x_j|\\mu_i,\\Sigma_i)}{\\sum_{l=1}^k \\alpha_l \\cdot p(x_j|\\mu_l,\\Sigma_l)} &= -\\lambda \\\\ multiply\\; \\alpha_i,\\; and\\;get\\; sum\\; with\\; respect\\; to\\; i \\\\ \\sum_{i=1}^k \\sum_{j=1}^m \\frac{\\alpha_i \\cdot p(x_j|\\mu_i,\\Sigma_i)}{\\sum_{l=1}^k \\alpha_l \\cdot p(x_j|\\mu_l,\\Sigma_l)} &= \\sum_{i=1}^k -\\lambda \\cdot \\alpha_i \\\\ hence: \\lambda &= -m \\\\ \\alpha_i &= \\frac{1}{m} \\sum_{j=1}^m \\gamma_{ji} \\end{aligned}所以，混合高斯的EM方法就是：先根据当前参数计算每个样本属于每个高斯成分的后验概率$\\gamma_{ji}$（E步）；然后根据上面的规则更新模型参数${(\\mu_i,\\Sigma_i,\\alpha_i)|1\\le i \\le k}$. 最后给出高斯混合聚类算法表述： 输入：样本集$D={x_1,…,x_m}$，高斯混合成分个数$k$; 1 初始化高斯混合分布的模型参数${(\\mu_i,\\Sigma_i,\\alpha_i)|1\\le i \\le k}$.2 迭代，直到满足停止条件3 $\\quad for\\; j=1,…m \\quad do$4 $\\quad \\quad$计算$p_M(z_j=i|x_j)=\\gamma_{ji},(1 \\le i \\le k)$5 $\\quad end\\; for$6 $\\quad for\\; i=1,…k \\quad do$7 $\\quad \\quad$更新模型参数$(\\mu_i,\\Sigma_i,\\alpha_i)$8 $C_i=\\emptyset,(1\\le i \\le k)$9 $for\\; j=1,…m \\quad do$10 $\\quad$根据最大后验概率规则确定每个$x_j$的簇$\\lambda_j$11 $\\quad C_{\\lambda_j}=C_{\\lambda_j}\\cup \\{x_j\\}$12 $end\\; for$ 输出：簇划分结果$C={C_1,..,C_k}$","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"DDoS的简单实现","slug":"DDoS的简单实现","date":"2016-12-06T02:52:57.000Z","updated":"2018-12-16T14:08:06.213Z","comments":true,"path":"2016/12/06/DDoS的简单实现/","link":"","permalink":"atlantic8.github.io/2016/12/06/DDoS的简单实现/","excerpt":"","text":"Scapy实现SYN泛洪攻击![](http://ww4.sinaimg.cn/large/9bcfe727jw1fagvyplc77j20b0052mxg.jpg) Scapy是一个可以让用户发送、侦听和解析并伪装网络报文的Python程序。这些功能可以用于制作侦测、扫描和攻击网络的工具。它的作用很多，简单如上图描述。 SYN泛洪攻击(SYN Flood)是一种比较常用的DoS方式之一。通过发送大量伪造的Tcp连接请求，使被攻击主机资源耗尽(通常是CPU满负荷或者内存不足) 的攻击方式。SYN泛洪攻击利用三次握手，客户端向服务器发送SYN报文之后就不再响应服务器回应的报文。由于服务器在处理TCP请求时，会在协议栈留一块缓冲区来存储握手的过程，当然如果超过一定的时间内没有接收到客户端的报文，本次连接在协议栈中存储的数据将会被丢弃。攻击者如果利用这段时间发送大量的连接请求，全部挂起在半连接状态。这样将不断消耗服务器资源，直到拒绝服务。 利用scapy构造一个SYN数据包的方法是： pkg = IP(src=&quot;202.121.0.12&quot;,dst=&quot;192.168.0.100&quot;)/TCP(sport=100,dport=80,flags=&quot;S&quot;) send(pkt) 其中，IP包中指定了源地址src和目的地址dst，其中src是我们伪造的地址，这是DoS攻击中保护攻击者的一种方式。flags的值我们设定为S,说明我们要发送的是SYN数据包，目标端口dport为80，发送端口sport为100。 Socket实现DDoS攻击总体采用CS模式，客户机连接服务器，服务器发送指令，然后客户机发起攻击，客户机使用伪装的IP攻击。事先规定攻击命令： #-H xxx.xxx.xxx.xxx -p xxxx -c &lt;start|stop&gt; ‘xxx.xxx.xxx.xxx’是目标地址， xxxx表示端口号，int型命令可以是start：开始攻击；stop：停止攻击 python中的socket使用客户端123456import socket#创建socket: AF_INET表示IPV4协议, SOCK_STREAM表示基于流的TCP协议s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)#建立连接, 指定服务器的IP和端口s.connect(('192.168.0,100', 7786)) 服务器1234567891011121314import socketcliList = []# 创建sockets = socket.socket(socket.AF_INET, socket.SOCK_STREAM)# 绑定地址和端口号s.bind(('0.0.0.0', 7786))：# 开始监听，指定最大连接数为10s.listen(10)while True: # 接受一个新的连接: sock, addr = s.accept() #将sock添加到列表中 cliList.append(sock) python多线程 &amp; 多进程12345t = Thread(target = func, args = (arg1, arg2))t.start()p = Process(target = func, args = (arg1, arg2))p.start() 客户机接受了服务器的命令后，启动一个进程发动攻击，一个客户端可以伪造不同的IP发送大量的SYN请求，大量客户端一起工作瘫痪目标。 具体的实现点击这里","categories":[],"tags":[{"name":"other","slug":"other","permalink":"atlantic8.github.io/tags/other/"}]},{"title":"Floyd Cycle Detection","slug":"Floyd-Cycle-Detection","date":"2016-12-01T01:06:54.000Z","updated":"2018-12-16T14:08:06.243Z","comments":true,"path":"2016/12/01/Floyd-Cycle-Detection/","link":"","permalink":"atlantic8.github.io/2016/12/01/Floyd-Cycle-Detection/","excerpt":"","text":"定义Floyd判圈算法(Floyd Cycle Detection Algorithm)，又称龟兔赛跑算法(Tortoise and Hare Algorithm)。该算法由美国科学家罗伯特·弗洛伊德发明，是一个可以在有限状态机、迭代函数或者链表上判断是否存在环，求出该环的起点与长度的算法。 如果有限状态机、迭代函数或者链表上存在环，那么在某个环上以不同速度前进的2个指针必定会在某个时刻相遇 如果从同一个起点(即使这个起点不在某个环上)同时开始以不同速度前进的2个指针最终相遇，那么可以判定存在一个环，且可以求出2者相遇处所在的环的起点与长度 算法描述假设已知某个起点节点为节点S。现设两个指针t和h，将它们均指向S 同时让t和h往前推进，但是二者的速度不同：t每前进1步，h前进2步 当h无法前进，即到达某个没有后继的节点时，就可以确定从S出发不会遇到环 当t与h再次相遇(在点M)时，就可以确定从S出发一定会进入某个环，设其为环C 令h仍均位于节点M，而令t返回起点节点S 让t和h往前推进，且保持二者的速度都为1 t和h相遇的地方即为环C的入口 相关问题Linked List Cycle Happy Number","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[]},{"title":"Happy Number","slug":"Happy-Number","date":"2016-12-01T01:04:43.000Z","updated":"2018-12-16T14:08:06.254Z","comments":true,"path":"2016/12/01/Happy-Number/","link":"","permalink":"atlantic8.github.io/2016/12/01/Happy-Number/","excerpt":"","text":"问题描述Write an algorithm to determine if a number is “happy”. A happy number is a number defined by the following process: Starting with any positive integer, replace the number by the sum of the squares of its digits, and repeat the process until the number equals 1 (where it will stay), or it loops endlessly in a cycle which does not include 1. Those numbers for which this process ends in 1 are happy numbers. Example: 19 is a happy number 12 + 92 = 82 82 + 22 = 68 62 + 82 = 100 12 + 02 + 02 = 1 解题思路可以使用hashset记录出现过的值，然后判断重复的是否是1本质上，这题可以使用Floyd Cycle Detection来解。其中 由一个数跳转到另一个数可以当作是链表寻找下一个节点 设置两个指针，每次分别前进1、2位 如果最后相交于1，那么输出true；否则输出no 123456789101112131415161718192021int digitSquareSum(int n) &#123; int sum = 0, tmp; while (n) &#123; tmp = n % 10; sum += tmp * tmp; n /= 10; &#125; return sum;&#125;bool isHappy(int n) &#123; int slow, fast; slow = fast = n; do &#123; slow = digitSquareSum(slow); fast = digitSquareSum(fast); fast = digitSquareSum(fast); &#125; while(slow != fast); if (slow == 1) return 1; else return 0;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Unique Binary Search Trees","slug":"Unique-Binary-Search-Trees","date":"2016-11-30T05:48:00.000Z","updated":"2018-12-16T14:08:06.442Z","comments":true,"path":"2016/11/30/Unique-Binary-Search-Trees/","link":"","permalink":"atlantic8.github.io/2016/11/30/Unique-Binary-Search-Trees/","excerpt":"","text":"Unique Binary Search Trees问题描述Given n, how many structurally unique BST’s (binary search trees) that store values 1…n? For example,Given n = 3, there are a total of 5 unique BST’s. 1 3 3 2 1 \\ / / / \\ \\ 3 2 1 1 3 2 / / \\ \\ 2 1 2 3 解题思路使用DP的思想解题定义两个函数： G(n)：n个数组成的序列能构成的BST的总数目 F(i,n), 1&lt;=i&lt;=n：1-n序列以第i个节点为根节点的BST的数目 G(n)由根节点分别为每个节点的BST组成。对每个F(i,n)，i是根，则左子树有i-1个节点，右子树有n-i个节点 显然，根据上面的定义有：G(n)=\\sum_{i=1}^nF(i,n) F(i,n)=G(i-1) \\times G(n-i)初始条件：G(0)=1, G(1)=1所以有：G(n)=\\sum_{i=1}^nG(i-1)\\times G(n-i) 代码如下：1234567891011public int numTrees(int n) &#123; int [] G = new int[n+1]; G[0] = G[1] = 1; for(int i=2; i&lt;=n; ++i) &#123; for(int j=1; j&lt;=i; ++j) &#123; G[i] += G[j-1] * G[i-j]; &#125; &#125; return G[n];&#125; Unique Binary Search Trees II问题描述Given an integer n, generate all structurally unique BST’s (binary search trees) that store values 1…n. For example,Given n = 3, there are a total of 5 unique BST’s. 1 3 3 2 1 \\ / / / \\ \\ 3 2 1 1 3 2 / / \\ \\ 2 1 2 3 解题思路与上一题的区别在于本题需要返回所有的BST，而不是仅仅计算结果。这题可以使用分治递归的思想，大致思想是： 对于1-n组成的节点，每个节点都可能是root 如果根结点是i，则分别求其左子树和右子树，然后所有左子树和右子树两两配对，加上根节点就是一棵树 1234567891011121314151617181920212223242526public List&lt;TreeNode&gt; generateTrees(int n) &#123; return generateSubtrees(1, n);&#125;private List&lt;TreeNode&gt; generateSubtrees(int s, int e) &#123; List&lt;TreeNode&gt; res = new LinkedList&lt;TreeNode&gt;(); if (s &gt; e) &#123; res.add(null); // empty tree return res; &#125; for (int i = s; i &lt;= e; ++i) &#123; List&lt;TreeNode&gt; leftSubtrees = generateSubtrees(s, i - 1); List&lt;TreeNode&gt; rightSubtrees = generateSubtrees(i + 1, e); for (TreeNode left : leftSubtrees) &#123; for (TreeNode right : rightSubtrees) &#123; TreeNode root = new TreeNode(i); root.left = left; root.right = right; res.add(root); &#125; &#125; &#125; return res;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"DP","slug":"DP","permalink":"atlantic8.github.io/tags/DP/"},{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Binary Tree","slug":"Binary-Tree","permalink":"atlantic8.github.io/tags/Binary-Tree/"}]},{"title":"Minimum Spanning Tree","slug":"Minimum-Spanning-Tree","date":"2016-11-27T02:30:03.000Z","updated":"2018-12-16T14:08:06.349Z","comments":true,"path":"2016/11/27/Minimum-Spanning-Tree/","link":"","permalink":"atlantic8.github.io/2016/11/27/Minimum-Spanning-Tree/","excerpt":"","text":"最小生成树（MST）算法是给定一个无向带权图（V, E），求解最小生成树。 普里姆算法 PrimPrim算法是逐渐加入点的算法 输入：一个加权连通图，其中顶点集合为V，边集合为E； 初始化：Vnew = {x}，其中x为集合V中的任一节点（起始点），Enew = {},为空； 重复下列操作，直到Vnew = V： 1. 在集合E中选取权值最小的边&lt;u, v&gt;，其中u为集合Vnew中的元素，而v不在Vnew集合当中，并且v∈V（如果存在有多条满足前述条件即具有相同权值的边，则可任意选取其中之一）； 2. 将v加入集合Vnew中，将&lt;u, v&gt;边加入集合Enew中； 输出：使用集合Vnew和Enew来描述所得到的最小生成树 1234567891011121314151617181920212223242526int Prim() &#123; int sum=0; // dis数组维护的是已经找过的点集 到 每一个点 的最小距离 // 每个点到第一个点的距离就是其直接距离 for(int i=1; i&lt;=n; i++) dis[i]=map[1][i]; vis[1]=1; for(int i=1; i&lt;n; i++) &#123; int min=INF; // 找到最近的点 for(int j=1; j&lt;=n; j++) if(!vis[j]&amp;&amp;dis[j]&lt;min) &#123; min=dis[j]; k=j; &#125; sum+=min; vis[k]=1; //标记访问 // 更新由于引入k点可能带来的距离变化 for(int j=1; j&lt;=n; j++) &#123; if(!vis[j]&amp;&amp;map[k][j]&lt;dis[j]) &#123; dis[j]=map[k][j]; &#125; &#125; &#125; return sum;&#125; 复杂度：$O(n^2)$, 其中$n$为点的个数，适用于边稠密的图。 克鲁斯卡尔算法 Kruskal并查集 Union-Find并查集是解决动态连通性一类问题的一种算法，主要思想与树的思想类似，利用根来确定连通性。并查集本质上由两个操作组成，分别是find和join，其中find用于查找最顶层的节点（root），join将两个连通子集合并起来。12345678910111213141516171819int pre[1000 ]; // 存储每一个节点的前继// 查找根节点int find(int x) &#123; int r=x; while ( pre[r ] != r ) r=pre[r ]; return r ;&#125;// 连接根节点void join(int x,int y) &#123; int fx = find(x); int fy = find(y); // 设置根之间的关系 if (fx != fy) pre[fx]=fy;&#125; Kruskal是逐渐加入边的算法 记Graph中有v个顶点，e个边 新建图Graphnew，Graphnew中拥有原图中相同的e个顶点，但没有边 将原图Graph中所有e个边按权值从小到大排序 循环：从权值最小的边开始遍历每条边 直至图Graph中所有的节点都在同一个连通分量(并查集思想)中 if 这条边连接的两个节点于图Graphnew中不在同一个连通分量中 添加这条边到图Graphnew中 123456789101112131415161718192021222324252627282930// 间接排序int cmp(const int i,const int j) &#123; return w[i]&lt;w[j];&#125;int find(int x) &#123; return p[x]==x ? x : p[x]=find(p[x]);&#125;int kruskal()&#123; int cou=0,x,y,i,ans=0; // 将每个点的前缀初始化为为自己 for(i=0;i&lt;n;i++) p[i]=i; for(i=0;i&lt;m;i++) r[i]=i; // 间接排序，排序后第i小的边保存在r[i]中 sort(r,r+m,cmp); // 从小到大取边 for(i=0;i&lt;m;i++) &#123; int e=r[i]; x=find(u[e]); y=find(v[e]); // 来自不同的连通分量就可以加入 if(x!=y) &#123; ans += w[e]; p[x]=y; cou++; &#125; &#125; if(cou&lt;n-1) ans=0; return ans;&#125; 复杂度：$O(elog_2^e)$，其中$e$为边的数量，适用于边稀疏的图。","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"Tree","slug":"Tree","permalink":"atlantic8.github.io/tags/Tree/"}]},{"title":"Tile Cover Problem","slug":"Tile-Cover-Problem","date":"2016-11-25T01:42:46.000Z","updated":"2018-12-16T14:08:06.435Z","comments":true,"path":"2016/11/25/Tile-Cover-Problem/","link":"","permalink":"atlantic8.github.io/2016/11/25/Tile-Cover-Problem/","excerpt":"","text":"题目描述POJ 2411编程之美用 1 x 2 的瓷砖覆盖 n x m 的地板，问共有多少种覆盖方式？ 解题思路这是个状态压缩DP问题，意思就是把状态用比特位的形式表示出来，然后使用DP求解 每个位置，有砖为1，无砖为0 由于转是1x2规格的，规定： 横着铺是连续两个都设成1 竖着铺时上面的设为0，下面的为1（因为上面的砖头对第二行有影响，如果上面的为0，那么下面的必须为1） 把每一行看作是一个二进制整数，这个整数就表示状态(有多少种01序列就有多少种状态) 因此每行都有很多状态，状态即为这一行01序列对应的值 DP[i][j]表示第i行状态为j时有多少种方法。 如果上一行的某个状态DP(i-1,k) 可以达到 DP(i, j) 那么两个状态是兼容的。 如果DP(i-1,k)和DP(i, j)兼容并且 DP(i-1, k)有S种铺设方案，那么DP(i, j)就可以从DP(i-1, k)这条路径中获得S个方案。 兼容性：兼容性指的是上一行和下一行的关系。Concretely，x和y兼容指的是x、y对应的二进制串对应的状态是兼容的。检测兼容性的方法是从左到右依次检测每一列是否兼容，具体检查内容包括：(假如现在铺设第i行x列) x x+1 i-1 i 0 如果第i行x列上的值(i,x)是0， 那么第 i-1行x列上一定是1 x x+1 i-1 i 1 如果(i,x)为1，那么 (i-1,x)为0，竖着铺的，下一步检测(i, x+1) (i-1,x)为1，下一步检测(i, x+2).因为(i,x)是横着铺，跨越两个格子。 第一行得兼容性 如果 (0,x) 是1，那么 (0,x+1) 也一定是1，然后测试到 (0,x+2) 如果(0,x)是0， 那么直接测试下一个(0,x+1) 因为是第一行，所以兼容只能获得一个方案 所以具体思路就是： 对每一行，遍历其所有可能得状态 检查其与上一行所有状态得兼容性，兼容则获取上一行状态所对应的方案数 第一行单独处理 最后一行结束后，返回DP[n-1][2^m-1]，因为最后一行必须全部为1 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182#include &lt;stdio.h&gt;#include &lt;memory.h&gt;#include &lt;math.h&gt;#include &lt;algorithm&gt;using namespace std;#define MAX_ROW 11#define MAX_STATUS 2048long long DP[MAX_ROW][MAX_STATUS];int g_Width, g_Height;// test the first linebool TestFirstLine(int nStatus) &#123; int i = 0; // 状态的每一个位 while( i &lt; g_Width) &#123; if(nStatus &amp; (0x1 &lt;&lt; i)) &#123; if( i == g_Width -1 || (nStatus &amp; (0x1 &lt;&lt; (i+1))) == 0) return false; i += 2; &#125; else &#123; i++; &#125; &#125; return true;&#125;// test if status (i, nStatusA) and (i-1, nStatusB) is compatable.bool CompatablityTest(int nStatusA, int nStatusB) &#123; int i = 0; while( i &lt; g_Width) &#123; if( (nStatusA &amp; (0x1 &lt;&lt; i)) == 0) &#123; if((nStatusB &amp; (0x1 &lt;&lt; i)) == 0) return false; i++; &#125; else &#123; if((nStatusB &amp; (0x1 &lt;&lt; i)) == 0 ) i++; else if( (i == g_Width - 1) || ! ( (nStatusA &amp; (0x1 &lt;&lt; (i+1))) &amp;&amp; (nStatusB &amp; (0x1 &lt;&lt; (i + 1)))) ) return false; else i += 2; &#125; &#125; return true;&#125;int main() &#123; int i,j; int k; while(scanf(\"%d%d\", &amp;g_Height, &amp;g_Width) != EOF ) &#123; if(g_Width == 0 &amp;&amp; g_Height == 0) break; if(g_Width &gt; g_Height) swap(g_Width, g_Height); int nAllStatus = 1 &lt;&lt; g_Width; memset(DP, 0, sizeof(DP)); for( j = 0; j &lt; nAllStatus; j++) &#123; if(TestFirstLine(j)) DP[0][j] = 1; &#125; for( i = 1; i &lt; g_Height; i++) &#123; // iterate all status for line i for( j = 0; j &lt; nAllStatus; j++) &#123; // iterate all status for line i-1 for( k = 0; k &lt; nAllStatus; k++) &#123; if(CompatablityTest(j, k)) DP[i][j] += DP[i-1][k]; &#125; &#125; &#125; printf(\"%lld\\n\", DP[g_Height-1][nAllStatus - 1]); &#125; return 0;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"DP","slug":"DP","permalink":"atlantic8.github.io/tags/DP/"},{"name":"POJ","slug":"POJ","permalink":"atlantic8.github.io/tags/POJ/"}]},{"title":"Flip Game","slug":"Flip-Game","date":"2016-11-24T13:55:34.000Z","updated":"2018-12-16T14:08:06.241Z","comments":true,"path":"2016/11/24/Flip-Game/","link":"","permalink":"atlantic8.github.io/2016/11/24/Flip-Game/","excerpt":"","text":"题目描述![](http://ww3.sinaimg.cn/large/9bcfe727jw1fa3jk4clc9g208w07wmx0.gif) 有一个4*4的方格，每个方格中放一粒棋子，这个棋子一面是白色，一面是黑色。游戏规则为每次任选16颗中的一颗，把选中的这颗以及它四周的棋子一并反过来，当所有的棋子都是同一个颜色朝上时，游戏就完成了。现在给定一个初始状态，要求输出能够完成游戏所需翻转的最小次数，如果初始状态已经达到要求输出0。如果不可能完成游戏，输出Impossible. 解题思想Queue1.如果用一个4*4的数组存储每一种状态，不但存储空间很大，而且在穷举状态时也不方便记录。因为每一颗棋子都只有两种状态，所以可以用二进制0和1表示每一个棋子的状态，则棋盘的状态就可以用一个16位的整数唯一标识。而翻转的操作也可以通过通过位操作来完成。显然当棋盘状态id为0(全白)或65535(全黑)时，游戏结束。 2.对于棋盘的每一个状态，都有十六种操作，首先要判断这十六种操作之后是否有完成的情况，如果没有，则再对这十六种操作的结果分别再进行上述操作，显然这里就要用到队列来存储了。而且在翻转的过程中有可能会回到之前的某种状态，而这种重复的状态是不应该再次入队的，所以维护isVis[i]数组来判断id==i的状态之前是否已经出现过，如果不是才将其入队。如果游戏无法完成，状态必定会形成循环，由于重复状态不会再次入队，所以最后的队列一定会是空队列。 3.由于0^1=1，1^1=0，所以翻转的操作可以通过异或操作来完成，而翻转的位置可以通过移位来确定。 DFS4x4得棋盘最多需要翻转16次就可以完成，因为同一位置上得两次翻转等于没有翻转。可以根据步数从0到16依次枚举，第一个符合条件的就是最小的步数，为了容易深搜，可以设定顺序为一行一行深搜，当一行搜完时从下一行开头搜。下面的代码也可以使用bit的思想压缩空间。123456789101112131415161718192021222324252627282930313233int DFS(int i, int j, int dp) &#123; // step表示当前尝试的步数上限 // dp表示在step步数上限的前提下，当前的步数 if(dp == step)&#123; flag=range(); return 0; &#125; if(flag||i==4) return 1; turn(i,j); //翻转当前位置 if(j&lt;3) DFS(i,j+1,dp+1); // 下一个列 else DFS(i+1,0,dp+1); // 下一行 turn(i,j); // 消除当前位置的翻转 if(j&lt;3) DFS(i,j+1,dp); // 当前位置不动的情况下，到下一列 else DFS(i+1,0,dp); // 当前位置不动的情况下，到下一行 return 0;&#125;/* 其余代码省略*/int main() &#123; // step表示步数0到16枚举 for(step=0; step&lt;=16; step++) &#123; flag=0; // 从(0,0)开始，开始第0步 dfs(0,0,0); // 如果找到了，输出即可。因为步数上限step是逐渐提高的 if(flag)break; &#125;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"POJ","slug":"POJ","permalink":"atlantic8.github.io/tags/POJ/"}]},{"title":"Principal-Component-Analysis","slug":"Principal-Component-Analysis","date":"2016-11-21T02:10:34.000Z","updated":"2018-12-16T14:08:06.386Z","comments":true,"path":"2016/11/21/Principal-Component-Analysis/","link":"","permalink":"atlantic8.github.io/2016/11/21/Principal-Component-Analysis/","excerpt":"","text":"主成分分析主成分分析是很常用降维方法之一。通过对原始数据进行投影而达到将其降维、划分的作用。 PCA的出发点有两个： 最近重构性：样本点到投影面的距离都足够近 最大可分性：样本点在投影面上的投影尽可能分开 预处理(均值和方差的正规化)求均值$\\hat{x}=\\frac{1}{m}\\sum_{i=1}^mx^{(i)}$ 将所有$x^{(i)}$替换成$x^{(i)}-\\hat{x}$. 求方差 $\\sigma_{j}^2=\\frac{1}{m}\\sum_i(x_j^{(i)})^2$ 将所有$x_j^{(i)}$替换成$x_j^{(i)}/\\sigma_j$. ![](http://ww2.sinaimg.cn/large/9bcfe727jw1f9zjud8hdxj20iv0h4dg5.jpg) 假设现在有两组二维空间的点，我们需要将他们投影到一维空间。也就是要找到一个单位投影向量$\\mu$，使投影后的点方差最大，分的最开，上图中，右下角的方法比右上角的差。点$x^{(i)}$投影过后到原点的距离是$\\mu^T x^{(i)}$，那么所有的投影过的数据的均值就是$\\frac{1}{m}\\sum_i \\mu^T x^{(i)}=\\frac{1}{m} \\mu^T \\sum_i x^{(i)}$，因为我们已经对原数据进行了正规化，所以投影过的数据均值是$0$. 因此，我们的目标函数就是最大化：\\frac{1}{m}\\sum_{i=1}^m (\\mu^T x^{(i)})^2=\\mu^T \\left( \\frac{1}{m}\\sum_{i=1}^mx^{(i)}(x^{(i)})^T \\right) \\mu \\quad .s.t. \\quad \\mu^T\\mu =1 上式中括号括起来的也就是原始数据的协方差矩阵$\\Sigma=\\frac{1}{m}\\sum_{i=1}^mx^{(i)}(x^{(i)})^T$，最大化这个公式也就是求解$\\Sigma$的特征向量(拉格朗日乘子法)。所以如果需要将原始空间的数据降到k维，那么只需要取$\\Sigma$前k大的特征值对应的特征向量作为投影向量即可。 PCA的算法描述如下： 输入：样本集D,和目标维度k 1. 对所有样本正规化 2. 计算样本的协方差矩阵 3. 对协方差矩阵做特征值分解 4. 降序排序特征值，取前k个特征值对应的特征向量组成投影矩阵 Robust主成分分析PCA假设数据的噪声是高斯的，对于大的噪声或者严重的离群点，PCA会被它影响，导致无法正常工作。而鲁棒PCA只假设噪声是稀疏的。所以，RPCA的出发点是将原数据分解成两个矩阵，一个是稀疏的（噪声点），另一个是低秩的（内部有一定的结构信息，造成各行或列间是线性相关的）。也就是：\\min_{A,E}rank(A)+\\lambda \\Vert E \\Vert_0 \\quad .s.t. \\; X=A+E 其中，$rank$是矩阵求秩的意思。但是上式有着非凸和非平滑等问题，可以转化成优化\\min_{A,E}\\Vert A \\Vert_{*}+\\lambda \\Vert E \\Vert_1 \\quad .s.t. \\; X=A+E求秩操作可以近似为求核范数，L0范数可以用L1范数逼近。求解出来上式，然后在对矩阵A运行PCA算法就可以得到对噪声有着比较好的鲁棒性的结果。","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"Norm Rule of Machine Learning","slug":"Norm-Rule-of-Machine-Learning","date":"2016-11-17T03:05:32.000Z","updated":"2018-12-16T14:08:06.364Z","comments":true,"path":"2016/11/17/Norm-Rule-of-Machine-Learning/","link":"","permalink":"atlantic8.github.io/2016/11/17/Norm-Rule-of-Machine-Learning/","excerpt":"","text":"L0范数是指向量中非0的元素的个数。 L1范数是指向量中各个元素绝对值之和，也称为“稀疏规则算子”（Lasso regularization） L2范数是指向量各元素的平方和然后求平方根 核范数是指矩阵奇异值的和 L0和L1范数L0和L1范数都有使得参数变得稀疏的作用，因为L0范数的求解困难（NP难），所以一般使用L1范数来逼近L0范数。稀疏的重要性在于： 特征选择 可解释性（减小多种特征带来的复杂性） L2范数L2范数也是使用颇为广泛的范数，再回归里使用L2范数的叫做“岭回归”condition number condition number是一个矩阵（或者它所描述的线性系统）的稳定性或者敏感度的度量 如果一个矩阵的condition number在1附近，那么它就是well-conditioned的 如果远大于1，那么它就是ill-conditioned的，如果一个系统是ill-conditioned的 比如：AX=b方程，稍微改动矩阵A的值，b就有很大变化，那么这个方程是ill-conditioned的 非奇异方阵的condition number定义为：k(A)=\\Vert A \\Vert \\times \\Vert A^{-1} \\Vert. L2范数的重要性在于 改善过拟合现象 处理 condition number不好的情况下矩阵求逆很困难的问题 关于2的解释因为目标函数如果是二次的，对于线性回归来说，那实际上是有解析解的，求导并令导数等于零即可得到最优解为: w=(X^TX)^{-1}X^Ty当样本X的数目比每个样本的维度还要小的时候，矩阵$X^TX$将会不是满秩的，也就是不可逆，所以$w$就没办法直接计算出来了，也可以说是有无穷多个解。这就是发生了过拟合。 但是如果加入了L2范数约束，就有：w=(X^TX+\\lambda I)^{-1}X^Ty 这样求逆就简单些了。 L1范数容易产生稀疏解的原因![](http://ww3.sinaimg.cn/large/9bcfe727jw1f9yxypfys9j20hb0a7q60.jpg) 核范数低秩矩阵：如果矩阵的秩远小于它的行数和列数，那么它就是低秩矩阵。核范数是指矩阵奇异值的和，可以用来近似低秩矩阵的秩。低秩的应用： 矩阵填充，矩阵各行(列)之间的线性相关求出丢失的元素 鲁棒PCA 背景建模 低秩纹理映射算法 近似梯度下降(Proximal Gradient Descent)近似梯度下降是解决L1优化问题的算法，优化问题的定义形式如下：\\min_x f(x)+\\lambda \\Vert x \\Vert_1其中$f(x)$是凸函数并且可微，而$\\lambda \\Vert x \\Vert_1$是凸函数但是不可微(non-differentiable)，所以不能按照岭回归那样求解。若$f(x)$可导，且$\\nabla f$满足L-Lipschitz条件，即存在常数$L&gt;0$使得\\Vert \\nabla f(x_1)-\\nabla f(x) \\Vert_2^2 \\le L \\Vert x_1-x \\Vert,\\; (\\forall x,x_1)在$x_k$附近将$f(x)$通过二阶泰勒展开式可以写成： \\begin{aligned} f(x) &\\simeq f(x_k)+\\nabla f(x_k)(x-x_k)+\\frac{ \\frac{\\nabla f(x)-\\nabla f(x_k)}{x-x_k} }{2} \\Vert x-x_k \\Vert^2 \\\\ &= f(x_k)+\\nabla f(x_k)(x-x_k)+\\frac{L}{2} \\Vert x-x_k \\Vert^2 \\\\ &= \\frac{L}{2} \\left\\Vert x-\\left( x_k-\\frac{1}{L}\\nabla f(x_k) \\right) \\right\\Vert_2^2 + \\varphi (x_k) \\end{aligned}其中，最后一步将关于$x$的项集中到一起，以及一个$\\varphi (x_k)$只包含$x_k$不包含$x$。$\\varphi (x_k)$可通过将最后一个式子拆开并和倒数第二个式子比较得到。这样，上式的最小值即为x_{k+1}=x_k-\\frac{1}{L}\\nabla f(x_k)这就是梯度下降的思想，梯度下降的每次迭代其实是在最小化原目标的一个二次近似函数。 将这种转化$f(x)$的思想应用到L1优化的目标函数上，可得每一步迭代其实是x_{k+1}=arg\\min_x \\frac{L}{2} \\left\\Vert x-\\left( x_k-\\frac{1}{L}\\nabla f(x_k) \\right) \\right\\Vert_2^2 + \\lambda \\Vert x \\Vert_1即在每一步对$f(x)$进行梯度下降的时候同时考虑优化L1范数。此时，可以先计算$z=x_k-\\frac{1}{L}\\nabla f(x_k)$，然后求解 \\begin{aligned} x_{k+1} = arg\\min_x \\frac{L}{2} \\Vert x-z \\Vert_2^2 + \\lambda \\Vert x \\Vert_1 \\end{aligned}这里考虑整个$x$就不合适了，考虑$x$的每个分量不会相互影响，即没有$x^ix^j$项。对于第$i$个分量$x^i$所以有x_{k+1}^i = arg\\min_x \\frac{L}{2} (x^i-z_i)^2+\\lambda \\vert x^i \\vert所以每个分量的更新方法为（高中知识，二次函数、分类讨论） x_{k+1}^i=\\begin{cases} z^i-\\frac{\\lambda}{L} & { \\frac{\\lambda}{L}","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"Binary Search Tree Iterator","slug":"Binary-Search-Tree-Iterator","date":"2016-11-16T14:34:46.000Z","updated":"2018-12-16T14:08:06.177Z","comments":true,"path":"2016/11/16/Binary-Search-Tree-Iterator/","link":"","permalink":"atlantic8.github.io/2016/11/16/Binary-Search-Tree-Iterator/","excerpt":"","text":"ProblemImplement an iterator over a binary search tree (BST). Your iterator will be initialized with the root node of a BST. Calling next() will return the next smallest number in the BST. Note: next() and hasNext() should run in average O(1) time and uses O(h) memory, where h is the height of the tree. Solution思路是使用栈。 给定根节点root，从root开始不断向左，将遇到的每个节点入栈 使用next函数时，栈顶top节点出栈，将top节点设置为root，执行步骤1 hasNext函数：查看栈是否为空即可 1234567891011121314151617181920212223242526class BSTIterator &#123; stack&lt;TreeNode *&gt; myStack;public: BSTIterator(TreeNode *root) &#123; pushAll(root); &#125; /** @return whether we have a next smallest number */ bool hasNext() &#123; return !myStack.empty(); &#125; /** @return the next smallest number */ int next() &#123; TreeNode *tmpNode = myStack.top(); myStack.pop(); pushAll(tmpNode-&gt;right); return tmpNode-&gt;val; &#125;private: // 从root开始不断向左，将遇到的每个节点入栈 void pushAll(TreeNode *node) &#123; for (; node != NULL; myStack.push(node), node = node-&gt;left); &#125;&#125;;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Binary Tree","slug":"Binary-Tree","permalink":"atlantic8.github.io/tags/Binary-Tree/"}]},{"title":"Gibbs Sampling","slug":"Gibbs-Sampling","date":"2016-11-16T07:39:21.000Z","updated":"2018-12-16T14:08:06.249Z","comments":true,"path":"2016/11/16/Gibbs-Sampling/","link":"","permalink":"atlantic8.github.io/2016/11/16/Gibbs-Sampling/","excerpt":"","text":"蒙特卡洛数值积分如果我们要求f(x)的积分$ \\int_a^b f(x) \\,dx $，而f(x)的形式比较复杂积分不好求，则可以通过数值解法来求近似的结果。常用的方法是蒙特卡洛积分:\\int_a^b \\frac{f(x)}{q(x)}q(x) \\,dx这样把q(x)看做是x在区间内的概率分布，而把前面的分数部门看做一个函数，然后在q(x)下抽取n个样本，当n足够大时，可以用采用均值来近似:\\frac{1}{n}\\sum_{i}\\frac{f(x_i)}{q(x_i)}因此只要q(x)比较容易采到数据样本就行了。随机模拟方法的核心就是如何对一个概率分布得到样本，即抽样（sampling）. Box-Muller 变换如果随机变量 $U_1,U_2$ 独立且$U_1,U_2 ∼ Uniform[0,1]$，如果有：Z_0=\\sqrt{-2lnU_1}cos(2\\pi U_2) Z_1=\\sqrt{-2lnU_1}sin(2\\pi U_2) 则 $Z_0,Z_1$ 独立且服从标准正态分布。 Monte Carlo principleX 表示随机变量，服从概率分布 p(x), 那么要计算 f(x) 的期望，只需要我们不停从 p(x) 中抽样$x_i$，然后对这些$f(x_i)$取平均即可近似f(x)的期望:E(f)=\\frac{1}{N}\\sum_{i=1}^Nf(x^i)其中$E(f)$即为f的期望。 ![](http://ww4.sinaimg.cn/large/9bcfe727jw1f9u6nr4wtmj20cx08ht98.jpg) 接受-拒绝抽样（Acceptance-Rejection sampling)有时候，p(x)是很难直接采样的的。既然 p(x) 太复杂在程序中没法直接采样，那么我设定一个程序可抽样的分布 q(x) 比如高斯分布，然后按照一定的方法拒绝某些样本，达到接近 p(x) 分布的目的，其中q(x)叫做 proposal distribution。具体操作如下，设定一个方便抽样的函数 q(x)，以及一个常量 k，使得 p(x) 总在 kq(x) 的下方。 x 轴方向：从 q(x) 分布抽样得到 a。(如果是高斯，就用之前说过的 tricky and faster 的算法更快） y 轴方向：从均匀分布（0, kq(a)) 中抽样得到 u。 如果刚好落到灰色区域： u &gt; p(a), 拒绝， 否则接受这次抽样 重复以上过程 在高维的情况下，Rejection Sampling 会出现两个问题，第一是合适的 q 分布比较难以找到，第二是很难确定一个合理的 k 值。这两个问题会导致拒绝率很高，无用计算增加。 ![](http://ww2.sinaimg.cn/large/9bcfe727jw1f9u6s3wo7hj20fa07vdgd.jpg) 马尔科夫稳态马氏链即马尔可夫链。社会学家经常把人按其经济状况分成3类：下层(lower-class)、中层(middle-class)、上层(upper-class)，我们用1,2,3 分别代表这三个阶层。社会学家们发现决定一个人的收入阶层的最重要的因素就是其父母的收入阶层。如果一个人的收入属于下层类别，那么他的孩子属于下层收入的概率是 0.65, 属于中层收入的概率是 0.28, 属于上层收入的概率是 0.07。事实上，从父代到子代，收入阶层的变化的转移概率如下： ![](http://ww3.sinaimg.cn/large/9bcfe727jw1f9u6zizzbaj20ch06hq2y.jpg) 经过迭代，三种阶层的状态converge to [0.286, 0.489, 0.225] 马氏链定理 ![](http://ww1.sinaimg.cn/large/9bcfe727jw1f9u72rq6c8j20fa0btwfv.jpg) Markov Chain Monte Carlo (MCMC)由于马氏链能收敛到平稳分布， 于是一个很的漂亮想法是：如果我们能构造一个转移矩阵为P的马氏链，使得该马氏链的平稳分布恰好是p(x), 那么我们从任何一个初始状态$x_0$出发沿着马氏链转移, 得到一个转移序列 $x_0,x_1,x_2,⋯x_n,x_{n+1}⋯$,， 如果马氏链在第n步已经收敛了，于是我们就得到了 π(x) 的样本$x_n,x_{n+1}⋯$。这是Metropolis算法的基本思想。MCMC 算法是 Metropolis 算法的一个改进变种，马氏链的收敛性质主要由转移矩阵P 决定, 所以基于马氏链做采样的关键问题是如何构造转移矩阵P,使得平稳分布恰好是我们要的分布p(x)。 ![](http://ww2.sinaimg.cn/large/9bcfe727jw1f9u7negt9mj20fa0f7tcc.jpg) 假设我们已经有一个转移矩阵Q(对应元素为q(i,j)), 用于采样概率分布p(x)的算法如下： ![](http://ww1.sinaimg.cn/large/9bcfe727jw1f9u7psj1wdj20fa06nmxc.jpg) ![](http://ww2.sinaimg.cn/large/9bcfe727jw1f9u7qj49bbj20fa0fk42d.jpg) ![](http://ww3.sinaimg.cn/large/9bcfe727jw1f9u7r9o55vj20fa07emxe.jpg) MCMC —— Gibbs Sampling算法![](http://ww1.sinaimg.cn/large/9bcfe727jw1f9u7s3xbp5j20fa0ddmzx.jpg) ![](http://ww1.sinaimg.cn/large/9bcfe727jw1f9u7sldz89j20ad08qgls.jpg) ![](http://ww4.sinaimg.cn/large/9bcfe727jw1f9u7tgi99tj20fa082q4m.jpg) ![](http://ww2.sinaimg.cn/large/9bcfe727jw1f9u7ueeigyj20fa0f1wj6.jpg) ![](http://ww3.sinaimg.cn/large/9bcfe727jw1f9u7uy86ffj20fa08oaa7.jpg) 以上算法收敛后，得到的就是概率分布$p(x_1,x_2,⋯,x_n)$的样本。","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"random algorithm","slug":"random-algorithm","permalink":"atlantic8.github.io/tags/random-algorithm/"}]},{"title":"3Sum Closest","slug":"3Sum-Closest","date":"2016-11-09T02:21:26.000Z","updated":"2018-12-16T14:08:06.170Z","comments":true,"path":"2016/11/09/3Sum-Closest/","link":"","permalink":"atlantic8.github.io/2016/11/09/3Sum-Closest/","excerpt":"","text":"ProblemGiven an array S of n integers, find three integers in S such that the sum is closest to a given number, target. Return the sum of the three integers. You may assume that each input would have exactly one solution. For example, given array S = {-1 2 1 -4}, and target = 1. The sum that is closest to the target is 2. (-1 + 2 + 1 = 2) Solution最简单的莫过于O(n^3)的遍历算法了。这里介绍一个O(n^2)的方法： 设置first,second和third三个下标。将数组先排序 第一层循环固定住first，将second放在first+1，将third放在最后 计算当前和curSum 如果curSum等于目标值target，直接返回 如果curSum比记录值更好，更新记录值 然后更改second或third。如果curSum大于target，则third—，否则second++ 当second和third相遇，内层循环结束。first++迭代 由于second和third这样移动的复杂度为O(n)，所以整体的复杂度为O(n^2). 1234567891011121314151617181920212223int threeSumClosest(vector&lt;int&gt;&amp; nums, int target) &#123; if(nums.size() &lt; 3) return 0; int closest = nums[0]+nums[1]+nums[2]; sort(nums.begin(), nums.end()); for(int first = 0 ; first &lt; nums.size()-2 ; ++first) &#123; if(first &gt; 0 &amp;&amp; nums[first] == nums[first-1]) continue; int second = first+1; int third = nums.size()-1; while(second &lt; third) &#123; int curSum = nums[first]+nums[second]+nums[third]; if(curSum == target) return curSum; if(abs(target-curSum)&lt;abs(target-closest)) &#123; closest = curSum; &#125; if(curSum &gt; target) &#123; --third; &#125; else &#123; ++second; &#125; &#125; &#125; return closest;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Find Minimum in Rotated Sorted Array","slug":"Find-Minimum-in-Rotated-Sorted-Array","date":"2016-11-09T01:27:53.000Z","updated":"2018-12-16T14:08:06.231Z","comments":true,"path":"2016/11/09/Find-Minimum-in-Rotated-Sorted-Array/","link":"","permalink":"atlantic8.github.io/2016/11/09/Find-Minimum-in-Rotated-Sorted-Array/","excerpt":"","text":"ProblemSuppose a sorted array is rotated at some pivot unknown to you beforehand. (i.e., 0 1 2 4 5 6 7 might become 4 5 6 7 0 1 2). Find the minimum element. You may assume no duplicate exists in the array. Solution将数组旋转，则会将小元素转到数组后面。这是一个经典的二叉搜索问题，考虑如下：对于位于下标[start, end]范围内的元素，如果有 a[start] &lt; a[end]: 那么从start到end范围内的元素是有序的，第一个元素便是其最小值 否则，看mid = start+(end-start)/2 如果a[start] &lt; a[mid]，那么旋转位置在(mid, end)之间，这时设置 start = mid+1 否则，旋转位置在(start, mid)之间, 这时设置 end = mid 12345678910111213141516int findMin(vector&lt;int&gt; &amp;num) &#123; int start=0,end=num.size()-1; while (start&lt;end) &#123; if (num[start] &lt; num[end]) return num[start]; int mid = start+(end-start)/2; if (num[mid] &gt; num[start]) &#123; start = mid+1; &#125; else &#123; end = mid; &#125; &#125; return num[start];&#125; Extension重复元素如果存在元素重复现象怎么办。即有可能出现没法判断应该向左还是向右的情况，所以简单的做法是将end-1。 1234567891011121314151617181920212223class Solution &#123;public: int findMin(vector&lt;int&gt; &amp;num) &#123; int lo = 0; int hi = num.size() - 1; int mid = 0; while(lo &lt; hi) &#123; mid = lo + (hi - lo) / 2; if (num[mid] &gt; num[hi]) &#123; lo = mid + 1; &#125; else if (num[mid] &lt; num[hi]) &#123; hi = mid; &#125; else &#123; // when num[mid] and num[hi] are same hi--; &#125; &#125; return num[lo]; &#125;&#125;; 二叉搜索的标准写法1234567891011121314int binary_search(int *a, int left, int right, int target) &#123; // 循环结束判断 while (left &lt;= right) &#123; int mid = left + (right-left)/2; if (a[mid] == target) return mid; // 如果left=2, right=3,并且a[2]&lt;target是将陷入死循环 if (a[mid] &lt; target) left = mid+1; else right = mid-1; &#125;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Binary Search","slug":"Binary-Search","permalink":"atlantic8.github.io/tags/Binary-Search/"}]},{"title":"Split Array Largest Sum","slug":"Split-Array-Largest-Sum","date":"2016-10-02T12:26:17.000Z","updated":"2018-12-16T14:08:06.415Z","comments":true,"path":"2016/10/02/Split-Array-Largest-Sum/","link":"","permalink":"atlantic8.github.io/2016/10/02/Split-Array-Largest-Sum/","excerpt":"","text":"ProblemGiven an array which consists of non-negative integers and an integer m, you can split the array into m non-empty continuous subarrays. Write an algorithm to minimize the largest sum among these m subarrays. Note:Given m satisfies the following constraint: 1 ≤ m ≤ length(nums) ≤ 14,000. Examples: Input: nums = [1,2,3,4,5] m = 2 Output: 9 Explanation:There are four ways to split nums into two subarrays.The best way is to split it into [1,2,3] and [4,5],where the largest sum among the two subarrays is only 9. Solution普通的递归方法会超时！！！ 首先确定任意合法的m值，对应结果的范围[left ~ right]其中left = max(nums[]), right = sum(nums[]). 这里考虑使用二分查找法，如果left = right，那么返回left就好给定一个可能的结果mid = left+(right-left)/2.，验证是否合法 判断一个x是否合法的方法如下： 顺序扫描nums[]，计算块和不大于（尽可能接近）mid的个数c 如果c &gt; m，那么mid应该变大，相应的c变小；反之，c &lt;= m，说明mid应该变小，相应c变大 如果合法：mid应该变小，即 right = mid；否则，mid应该变大，即 left = mid + 1； 1234567891011121314151617181920212223242526272829303132class Solution &#123;public: // check if nums can be divided into m subsets s.t each subset's summation &lt;= sum bool canSplit(vector&lt;int&gt;&amp; nums, int m, long sum) &#123; int c = 1; long s = 0; for (auto&amp; num : nums) &#123; s += num; if (s &gt; sum) &#123; s = num; // first element ++c; // a new subset &#125; &#125; // c&lt;=m indicates nums can be divided into m subsets s.t each subset's summation &lt;= sum return c &lt;= m; &#125; int splitArray(vector&lt;int&gt;&amp; nums, int m) &#123; long left = 0, right = 0; for (auto&amp; num : nums) &#123; left = max(left, (long)num); right += num; &#125; while (left &lt; right) &#123; if (left == right) return left; // answer found long mid = left + (right-left)/2; if (canSplit(nums, m, mid)) right = mid; // be smaller. else left = mid+1; // be bigger &#125; return left; &#125;&#125;;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Binary Search","slug":"Binary-Search","permalink":"atlantic8.github.io/tags/Binary-Search/"}]},{"title":"Trapping Rain Water","slug":"Trapping-Rain-Water","date":"2016-10-02T08:25:51.000Z","updated":"2018-12-16T14:08:06.439Z","comments":true,"path":"2016/10/02/Trapping-Rain-Water/","link":"","permalink":"atlantic8.github.io/2016/10/02/Trapping-Rain-Water/","excerpt":"","text":"一维情况Given n non-negative integers representing an elevation map where the width of each bar is 1, compute how much water it is able to trap after raining. For example Given [0,1,0,2,1,0,1,3,2,1,2,1], return 6. The above elevation map is represented by array [0,1,0,2,1,0,1,3,2,1,2,1]. In this case, 6 units of rain water (blue section) are being trapped. Thanks Marcos for contributing this image! 解决方案 双指针，分别指向数组两端，主要是由两边到中间的思想 维护左边最高、右边最高的值 如果: a[left] &lt; a[right]，先处理left-side [ 否则，right-side。这样保证未被处理的一边总有大于另一边最大值的元素。] 假如a[left] &gt;= maxleft, 那么: maxleft = a[left] 否则：ret += maxleft-a[left]. 因为右边总有比maxleft大的，否则，不可能处理left这边的数。 1234567891011121314151617181920212223class Solution &#123;public: int trap(int A[], int n) &#123; int left=0; int right=n-1; int res=0; int maxleft=0, maxright=0; while(left&lt;=right)&#123; // 先处理小的一方，保证对面方总有更大的数 if(A[left]&lt;=A[right])&#123; // 更新最大值 if(A[left]&gt;=maxleft) maxleft=A[left]; // 因为另一边总有大于maxleft的值，所以，此时可盛水maxleft-A[left] else res+=maxleft-A[left]; left++; &#125; else &#123; // 同左边 if(A[right]&gt;=maxright) maxright= A[right]; else res+=maxright-A[right]; right--; &#125; &#125; return res; &#125;&#125;; 二维状况Given an m x n matrix of positive integers representing the height of each unit cell in a 2D elevation map, compute the volume of water it is able to trap after raining. Note:Both m and n are less than 110. The height of each unit cell is greater than 0 and is less than 20,000. Example: Given the following 3x6 height map: [ [1,4,3,1,3,2], [3,2,1,3,2,4], [2,3,3,2,3,1] ] Return 4. The above image represents the elevation map [[1,4,3,1,3,2],[3,2,1,3,2,4],[2,3,3,2,3,1]] 解决方案从四周开始，由外向内的方法 从边界开始，挑选最矮的已经访问过的cell，检查它的邻居(没有被访问过的) 如果邻居比当前的矮，收集邻居能手机的水量（邻居不必当前矮则无法收集），并填充能收集水的邻居（更新其高度） 把所有的邻居加入到队列 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class Solution &#123; public class Cell &#123; int row; int col; int height; public Cell(int row, int col, int height) &#123; this.row = row; this.col = col; this.height = height; &#125; &#125; public int trapRainWater(int[][] heights) &#123; if (heights == null || heights.length == 0 || heights[0].length == 0) return 0; PriorityQueue&lt;Cell&gt; queue = new PriorityQueue&lt;&gt;(1, new Comparator&lt;Cell&gt;()&#123; public int compare(Cell a, Cell b) &#123; return a.height - b.height; &#125; &#125;); int m = heights.length; int n = heights[0].length; boolean[][] visited = new boolean[m][n]; // Initially, add all the Cells which are on borders to the queue. for (int i = 0; i &lt; m; i++) &#123; visited[i][0] = true; visited[i][n - 1] = true; queue.offer(new Cell(i, 0, heights[i][0])); queue.offer(new Cell(i, n - 1, heights[i][n - 1])); &#125; for (int i = 0; i &lt; n; i++) &#123; visited[0][i] = true; visited[m - 1][i] = true; queue.offer(new Cell(0, i, heights[0][i])); queue.offer(new Cell(m - 1, i, heights[m - 1][i])); &#125; // from the borders, pick the shortest cell visited and check its neighbors: // if the neighbor is shorter, collect the water it can trap and update its height as its height plus the water trapped // add all its neighbors to the queue. int[][] dirs = new int[][]&#123;&#123;-1, 0&#125;, &#123;1, 0&#125;, &#123;0, -1&#125;, &#123;0, 1&#125;&#125;; int res = 0; while (!queue.isEmpty()) &#123; Cell cell = queue.poll(); for (int[] dir : dirs) &#123; int row = cell.row + dir[0]; int col = cell.col + dir[1]; if (row &gt;= 0 &amp;&amp; row &lt; m &amp;&amp; col &gt;= 0 &amp;&amp; col &lt; n &amp;&amp; !visited[row][col]) &#123; visited[row][col] = true; res += Math.max(0, cell.height - heights[row][col]); queue.offer(new Cell(row, col, Math.max(heights[row][col], cell.height))); &#125; &#125; &#125; return res; &#125;&#125; Dijkstra构建一个图，每个cell都是一个节点，再加上一个dummy节点表示外部区域。如果cell(i, j)与cell(i’, j’)相邻，那么，创建一个由cell(i, j)到cell(i’, j’)的有向边，边的权值为height(i, j)边上cell与dummy节点有一条权值为0的边。设定每条路径的权值为：该路径上最大的权值。所以对每一个cell(i,j)，它能盛的水就是cell(i, j)到dummy节点的最短路径的权值dist(i, j)如果：dist(i, j) &lt;= height(i, j)，那么cell(i, j)不能盛水。 我们可能需要计算dist(i, j) 对于每个(i, j)对，即多个cell，只有一个终点dummy节点。所以将每条边的方向逆转，那么只需要使用一次Dijkstra算法就可以计算dummy节点到每个cell的最短路径，继而计算出每个cell能盛水的量（最短路径的权值）。 假设cell由r行、c列，那么时间复杂度：O(rclog(rc)) = O(rcmax(log r, log c))，空间复杂度为：O(rc). 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class Solution &#123; int[] dx = &#123;0, 0, 1, -1&#125;; int[] dy = &#123;1, -1, 0, 0&#125;; List&lt;int[]&gt;[] g; int start; private int[] dijkstra() &#123; int[] dist = new int[g.length]; Arrays.fill(dist, Integer.MAX_VALUE / 2); dist[start] = 0; TreeSet&lt;int[]&gt; tree = new TreeSet&lt;&gt;((u, v) -&gt; u[1] == v[1] ? u[0] - v[0] : u[1] - v[1]); tree.add(new int[]&#123;start, 0&#125;); while (!tree.isEmpty()) &#123; int u = tree.first()[0], d = tree.pollFirst()[1]; for (int[] e : g[u]) &#123; int v = e[0], w = e[1]; if (Math.max(d, w) &lt; dist[v]) &#123; tree.remove(new int[]&#123;v, dist[v]&#125;); dist[v] = Math.max(d, w); tree.add(new int[]&#123;v, dist[v]&#125;); &#125; &#125; &#125; return dist; &#125; public int trapRainWater(int[][] a) &#123; if (a == null || a.length == 0 || a[0].length == 0) return 0; int r = a.length, c = a[0].length; start = r * c; g = new List[r * c + 1]; for (int i = 0; i &lt; g.length; i++) g[i] = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; r; i++) for (int j = 0; j &lt; c; j++) &#123; if (i == 0 || i == r - 1 || j == 0 || j == c - 1) g[start].add(new int[]&#123;i * c + j, 0&#125;); for (int k = 0; k &lt; 4; k++) &#123; int x = i + dx[k], y = j + dy[k]; if (x &gt;= 0 &amp;&amp; x &lt; r &amp;&amp; y &gt;= 0 &amp;&amp; y &lt; c) g[i * c + j].add(new int[]&#123;x * c + y, a[i][j]&#125;); &#125; &#125; int ans = 0; int[] dist = dijkstra(); for (int i = 0; i &lt; r; i++) for (int j = 0; j &lt; c; j++) &#123; int cb = dist[i * c + j]; if (cb &gt; a[i][j]) ans += cb - a[i][j]; &#125; return ans; &#125;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Factorial","slug":"Factorial","date":"2016-09-27T15:19:41.000Z","updated":"2018-12-16T14:08:06.229Z","comments":true,"path":"2016/09/27/Factorial/","link":"","permalink":"atlantic8.github.io/2016/09/27/Factorial/","excerpt":"","text":"问题 POJ 1401给一个数n， 求出n！ 有多少个后导零 解决方案因为n!中的5因子比2多，所以只需要找5的个数就好。 令f(x)表示正整数x末尾所含有的“0”的个数，则有： 当0 &lt; n &lt; 5时，f(n!) = 0; 当n &gt;= 5时，f(n!) = k + f(k!), 其中 k = n / 5（取整） 12345678int countZero(int N) &#123; int ret = 0; while (N) &#123; ret += N/5; N /= 5; &#125; return ret;&#125; 如果是要求n!中k因子的个数，那么有： f(n) = x + f(x), where x = n / k.","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"Math","slug":"Math","permalink":"atlantic8.github.io/tags/Math/"}]},{"title":"Wildcard Matching","slug":"Wildcard-Matching","date":"2016-09-24T14:59:35.000Z","updated":"2018-12-16T14:08:06.448Z","comments":true,"path":"2016/09/24/Wildcard-Matching/","link":"","permalink":"atlantic8.github.io/2016/09/24/Wildcard-Matching/","excerpt":"","text":"ProblemImplement wildcard pattern matching with support for ‘?’ and ‘*’. ‘?’ Matches any single character.‘*’ Matches any sequence of characters (including the empty sequence). The matching should cover the entire input string (not partial). The function prototype should be:bool isMatch(const char s, const char p) Some examples: isMatch(&quot;aa&quot;,&quot;a&quot;) → false isMatch(&quot;aa&quot;,&quot;aa&quot;) → true isMatch(&quot;aaa&quot;,&quot;aa&quot;) → false isMatch(&quot;aa&quot;, &quot;*&quot;) → true isMatch(&quot;aa&quot;, &quot;a*&quot;) → true isMatch(&quot;ab&quot;, &quot;?*&quot;) → true isMatch(&quot;aab&quot;, &quot;c*a*b&quot;) → false SolutionC++的DP方法超时（好像java可以）。线性时间算法的基本思想是维护两个指针p1、p2，分别指向s和p，分以下几种情况： p[p2] == ‘?’ 说明匹配，那么 ++p1，++p2 p[p2] == ‘*’ 这也是一种匹配，但是可能的情况很多，用start保存此星号的位置，用matched保存与当前星号匹配的s的位置，p2++，p1不移动，先把与星号匹配的设为空，因为如果后面不匹配的话，还会回来给星号匹配字符 否则，当前已经不能匹配了，找到上一个星号位置 上一个星号存在，则p回退到上一个星号后一位，把matched对应的字符串匹配给星号，s回退到matched下一位，matched++，p2=star+1，p1=++matched 否则，没有可能的匹配了，返回 false 最后，如果p2还没到结尾，如果p2及其后面都是’*’，那么匹配成功，否则失败 1234567891011bool isMatch(string s, string p) &#123; int star=-1, s1=0, p1=0, matched=0; while (s1 &lt; s.length()) &#123; if (p[p1]=='?' || s[s1]==p[p1]) &#123;++s1, ++p1;&#125; else if (p[p1] == '*') &#123;star = p1++; matched = s1;&#125; else if (star&gt;=0) &#123;p1 = star+1; s1 = ++matched;&#125; else return false; &#125; while (p1&lt;p.length() &amp;&amp; p[p1]=='*') ++p1; return p1==p.length();&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Greedy","slug":"Greedy","permalink":"atlantic8.github.io/tags/Greedy/"}]},{"title":"Segment Tree","slug":"Segment-Tree","date":"2016-09-24T01:15:15.000Z","updated":"2018-12-16T14:08:06.402Z","comments":true,"path":"2016/09/24/Segment-Tree/","link":"","permalink":"atlantic8.github.io/2016/09/24/Segment-Tree/","excerpt":"","text":"线段树线段树（英语：Segment Tree）是一种二叉搜索树，它将一个区间划分成一些单元区间，每个单元区间对应线段树中的一个叶结点。 对于线段树中的每一个非叶子节点[a,b]，它的左子树表示的区间为[a,(a+b)/2]，右子树表示的区间为[(a+b)/2+1,b]。因此线段树是平衡二叉树。叶节点数目为N，即整个线段区间的长度。 给定整个线段区间，建立一棵线段树的时间复杂度是O(N)。单点修改的时间复杂度是O(logN) 。单点查询的时间复杂度是O(1)。如果允许惰性赋值而加上延迟标记的话，许多的区间修改的时间复杂度也会是 O(log N)，但是单点查询的时间复杂度会变成O(log N)。 线段树的每个节点上往往都增加了一些其他的域。在这些域中保存了某种动态维护的信息，视不同情况而定。这些域使得线段树具有极大的灵活性，可以适应不同的需求。 动态结构struct node{ node* left; node* right; …… } 动态结构的方法在Range Sum Query中。 静态数组型结构：maxn是最大区间数，而节点数要开4倍多 struct node{ int left; int right; …… }Tree[maxn*4+5] 使用静态数组结构（从1开始计数），left、right表示其左右孩子在数组中对应的位置，如果当前节点的位置时i，那么左孩子2i，右孩子2i+1。 构造方法：主要思想是递归构造，如果当前节点记录的区间只有一个值，则直接赋值，否则递归构造左右子树，最后回溯的时候给当前节点赋值1234567891011121314151617181920/*node： 当前节点在静态数组segTree中的位置begin：题目给定数组的下标起始位置end： 题目给定数组的下标终止位置*/void build(int node, int begin, int end) &#123; if (begin == end) segTree[node] = array[begin]; /* 只有一个元素,节点记录该单元素 */ else &#123; /* 递归构造左右子树 */ build(2*node, begin, (begin+end)/2); build(2*node+1, (begin+end)/2+1, end); /* 回溯时得到当前node节点的线段信息 */ if (segTree[2 * node] &lt;= segTree[2 * node + 1]) segTree[node] = segTree[2 * node]; else segTree[node] = segTree[2 * node + 1]; &#125;&#125; 区间查询：123456789101112131415161718192021222324252627/*node：当前查询节点begin,end：当前节点存储的区间，即当前结点的范围left,right：此次query所要查询的区间*/int query(int node, int begin, int end, int left, int right) &#123; int p1, p2; /* 查询区间和要求的区间没有交集 */ if (left &gt; end || right &lt; begin) return -1; // 查询范围和当前结点的范围重合 if (begin == left &amp;&amp; end == right) return segTree[node]; // 分别查询当前结点的左右孩子 p1 = query(2 * node, begin, (begin + end) / 2, left, right); p2 = query(2 * node + 1, (begin + end) / 2 + 1, end, left, right); /* return the expect value */ if (p1 == -1) return p2; if (p2 == -1) return p1; return p1 + p2;&#125; 单节点更新：1234567891011121314151617181920/*node：当前节点的下标left,right：当前节点的表示范围ind,add：将原数组中ind位置元素增加add*/void Updata(int node, int left, int right, int ind, int add) &#123; // 当前是叶节点了，直接更新 if( begin == end ) &#123; segTree[node] += add; return ; &#125; int m = ( left + right ) &gt;&gt; 1; if(ind &lt;= m) Updata(node * 2,left, m, ind, add); else Updata(node * 2 + 1, m + 1, right, ind, add); /*回溯更新父节点*/ segTree[node] = segTree[node * 2] + segTree[node * 2 + 1];&#125; Range Sum Query - MutableGiven an integer array nums, find the sum of the elements between indices i and j (i ≤ j), inclusive. The update(i, val) function modifies nums by updating the element at index i to val.Example:Given nums = [1, 3, 5] sumRange(0, 2) -&gt; 9update(1, 2)sumRange(0, 2) -&gt; 8Note: The array is only modifiable by the update function. You may assume the number of calls to update and sumRange function is distributed evenly. 使用直接的方法处理，在有大量的查询(O(N)复杂度)和更新时时间复杂度过高。使用线段树处理的话，查询和修改的复杂度均为O(logN). 本题中，每个节点包含左右孩子节点指示自己的范围，还包含一个表示以该节点为根的子树的所有元素的和。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class NumArray &#123; SegmentTreeNode root = null; // 线段树的节点，包含左右孩子，和其全部孩子值的和 class SegmentTreeNode &#123; int sum; int start, end; public SegmentTreeNode left, right; public SegmentTreeNode(int start, int end) &#123; this.start = start; this.end = end; this.left = null; this.right = null; this.sum = 0; &#125; &#125; // 将数据index位置的值转换成value，树中只需要更改sum值就好 public void Update(SegmentTreeNode root, int index, int value) &#123; // 到叶节点时，直接修改sum值 if (root.start == root.end) root.sum = value; else &#123; // 非叶节点，要考虑修改树的中间结点 int mid = root.start + (root.end - root.start) / 2; if (index &lt;= mid) // 如果需要修改的节点在左子树，右子树不需要修改 Update(root.left, index, value); else // 只修改右子树 Update(root.right, index, value); // 修改根节点的sum值 root.sum = root.left.sum + root.right.sum; &#125; &#125; // 返回从索引start到end的值的和 public int SumRange(SegmentTreeNode root, int start, int end) &#123; // root对应的范围正好是查询的范围 if (root.start == start &amp;&amp; root.end == end) return root.sum; int mid = root.start + (root.end - root.start) / 2; // 查询范围在左子树上 if (end &lt;= mid) return SumRange(root.left, start, end); // 查询范围在右子树上 else if (start &gt; mid) return SumRange(root.right, start, end); // 查询范围在左、右子树上 return SumRange(root.left, start, mid) + SumRange(root.right, mid + 1, end); &#125; public SegmentTreeNode ConstructSegmentTree(int[] nums, int start, int end) &#123; if (start &gt; end) return null; SegmentTreeNode ret = new SegmentTreeNode(start, end); if (start == end) &#123; ret.sum = nums[start]; &#125; else &#123; int mid = start + (end - start) / 2; ret.left = ConstructSegmentTree(nums, start, mid); ret.right = ConstructSegmentTree(nums, mid + 1, end); ret.sum = ret.left.sum + ret.right.sum; &#125; return ret; &#125; public NumArray(int[] nums) &#123; root = ConstructSegmentTree(nums, 0, nums.length - 1); &#125; void update(int i, int val) &#123; Update(root, i, val); &#125; public int sumRange(int i, int j) &#123; return SumRange(root, i, j); &#125;&#125; 线段(可能重合)的总长度思路是在线段可能出现的范围内建立线段树，节点上设置一个表示此节点是否被覆盖的属性cover，cover=1表示该结点所对应的区间被完全覆盖，cover=0表示该结点所对应的区间未被完全覆盖。如下图的线段树，添加线段[1,2][3,5][4,6]","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Binary Tree","slug":"Binary-Tree","permalink":"atlantic8.github.io/tags/Binary-Tree/"}]},{"title":"Binary Indexed Tree","slug":"Binary-Indexed-Tree","date":"2016-09-23T12:43:51.000Z","updated":"2018-12-16T14:08:06.175Z","comments":true,"path":"2016/09/23/Binary-Indexed-Tree/","link":"","permalink":"atlantic8.github.io/2016/09/23/Binary-Indexed-Tree/","excerpt":"","text":"定义树状数组(Binary Indexed Tree, BIT)用来求区间元素和，求一次区间元素和的时间效率为O(logn)树状数组是一个可以很高效的进行区间统计的数据结构。在思想上类似于线段树，比线段树节省空间，编程复杂度比线段树低，但适用范围比线段树小。 问题定义： 有n个元素的数组。可能的操作为 1.改变数组下标k的元素 2.查询下标 i~j 的元素和 用树状数组，对操作1和2的时间复杂度都为O(logn)。 算法内容利用树状数组求前i个元素的和S[i]对给定序列：A[1]~A[8]，构建一个树状数组，如上图，其中，C[]是树状数组，S[k]表示从1-k的元素和。分析C[]的组成如下： C[1]=A[1]; C[2]=A[1]+A[2]; C[3]=A[3]; C[4]=A[1]+A[2]+A[3]+A[4]; C[5]=A[5]; C[6]=A[5]+A[6]; C[7]=A[7]; C[8]= A[1]+A[2]+A[3]+A[4]+A[5]+A[6]+A[7]+A[8]; 将数组下标转换成二进制，可得： 1 --&gt; 00000001 2 --&gt; 00000010 3 --&gt; 00000011 4 --&gt; 00000100 5 --&gt; 00000101 6 --&gt; 00000110 7 --&gt; 00000111 8 --&gt; 00001000 结论：下标i的二进制中的从右往左数有连续的x个“0”，那么C[i]为序列A[]中的第i-2^x+1到第i个元素的和，即： C[i] = A[i-2^x+1] + … + A[i], 其中x为i的二进制中的从右往左数有连续“0”的个数 对于每个i，求x的方法是：2^x = i &amp; (-i) 证明：设A’为A的二进制反码，i的二进制表示成A1B，其中A不管，B为全0序列。那么-i=A’0B’+1。由于B为全0序列，那么B’就是全1序列，所以-i=A’1B，所以：i&amp;(-i)= A1B&amp; A’1B=1B，即2^x的值。 所以，S[i]的方法是：123456789//返回前i个元素和int Sum(int i) &#123; int s=0; while (i &gt; 0) &#123; s += C[i]; i -= i &amp; (-i); &#125; return s;&#125; 更新C[]如果A[i]被改变了，那么所有包含A[i]的C[]都要更改，比如，A[3]被改变了，C[3], C[4], C[8]都得修改。如果A[i]被改变了，那么C[i]必须要更改，并且假设C[k]是C[i]的直接父亲，那么C[k]包含的元素是C[i]包含的元素的2倍，所以： k = i + 2^x（x是i的元素数）。 所以更新的方法是：1234567// A[i]的改变值为valuevoid Update(int i,int value) &#123; while(i&lt;=n) &#123; C[i] += value; i += i &amp; (-i); &#125;&#125; 二维树状数组BIT可用为二维数据结果。假设你有一个带有点的平面(有非负的坐标)。合理的操作有三种： 1.在(x , y)设置点 2.从(x , y)移除点 3.在矩形(0 , 0), (x , y)计算点数 - 其中(0 , 0)为左下角，(x , y)为右上角，而边是平行于x轴和y轴。 对于1操作，在（x,y）处设置点，即Update(x,y,1)，因为x，y坐标是离散的，所以我们分别对x,y进行更新即可，函数如下12345678910void Update(int x,int y,int val) &#123; while(x&lt;=n) &#123; int y1 = y; while (y1 &lt;= n) &#123; C[x][y1] += val; y1 += y1 &amp; (-y1); &#125; x += x &amp; (-x); &#125;&#125; 根据Update可以推得：GetSum函数为：123456789101112int GetSum(int x,int y) &#123; int sum=0; while (x &gt; 0) &#123; int y1 = y; while (y1 &gt; 0) &#123; sum += C[x][y1]; y1 -= y1 &amp; (-y1); &#125; x -= x &amp; (-x); &#125; return sum;&#125; 应用POJ 2352 Stars给定星星的坐标（y递增，若y相等，x递增），每个星星都有一个等级，规定它的等级就是在它左下方的星星的个数。输入所有星星后，依次输出等级为0到n-1的星星的个数。 解法： 因为数据按y排序（y相等按x排序），所以对第i个星星，之前的星星没有y值大于当前y值的，如果之前的星星k的x值小于当前x值，那么星星k就是对星星i的等级贡献1。并且，星星i后面的星星不可能贡献星星i的等级。 所以，计算一个星星的等级就应该在这个星星没正式加入之前，计算之前哪些星星在它左下角，y值严格非递减就不用考虑了，只计数x坐标小于等于当前的个数，可以令A[i]的值是已经加入星星中x坐标为i的星星的数量，i的等级即为 Sum(i); 每次加入一个星星，加入星星i之前，计算星星i的贡献，即出现在星星i左下角的星星个数，也即数组A[]中小于等于i的元素和。 12345678910111213141516171819202122232425262728293031323334#include&lt;stdio.h&gt;#include&lt;string.h&gt;#define n 32001int c[n+5], total[n+5];int Lowbit(int t) &#123; return t&amp;(t^(t-1));&#125;int Sum(int end) &#123; int sum = 0; while(end &gt; 0) &#123; sum += c[end]; end -= Lowbit(end); &#125; return sum;&#125;void add(int li, int val) &#123; while(li&lt;=n) &#123; c[li] += val; li += Lowbit(li); &#125;&#125;int main() &#123; int i, j, x, y, nn; scanf(\"%d\", &amp;nn); memset(c, 0, sizeof(c)); memset(total, 0, sizeof(total)); for(i=1; i&lt;=nn; i++) &#123; scanf(\"%d%d\", &amp;x, &amp;y); //由于坐标x可能为0，因此输入坐标要+1，不然会超时0&amp;(-0)=0; add(x+1, 1); total[Sum(x+1)-1]++; &#125; for(i=0; i&lt;nn; i++) printf(\"%d\\n\", total[i]);&#125; 本题用线段树也可以做，用静态数组结构，开始时就把所有的元素当成0，加入节点，就是一种更新操作。在把A[]抽象出来后，每次加入一个点时，计算Sum，然后更新节点。 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstring&gt;using namespace std;int sum[200000];struct node &#123; int x,y;&#125; p[20000];void push_up(int root) &#123; sum[root]=sum[root*2]+sum[root*2+1];&#125;void update(int root,int l,int r,int p,int v) &#123; int mid=(l+r)/2; if(l==r) &#123; sum[root]++; return; &#125; if(p&lt;=mid)update(root*2,l,mid,p,v); else update(root*2+1,mid+1,r,p,v); push_up(root);&#125;int q_sum(int root,int l,int r,int ql,int qr) &#123; if(ql&gt;r||qr&lt;l)return 0; if(ql&lt;=l&amp;&amp;r&lt;=qr)return sum[root]; int mid=(l+r)/2; return q_sum(root*2,l,mid,ql,qr)+q_sum(root*2+1,mid+1,r,ql,qr);&#125;int main() &#123; int n,i,j,m=32000; int _hash[20000]; scanf(\"%d\",&amp;n); memset(_hash,0,sizeof(_hash)); for(i=0; i&lt;n; i++) &#123; scanf(\"%d%d\",&amp;p[i].x,&amp;p[i].y); _hash[q_sum(1,0,m,0,p[i].x)]++; update(1,0,m,p[i].x,1); &#125; for(i=0; i&lt;n; i++) printf(\"%d\\n\",_hash[i]); return 0;&#125; 二维树状数组问题描述： 一个由数字构成的大矩阵，能进行两种操作 1) 对矩阵里的某个数加上一个整数（可正可负） 2) 查询某个子矩阵里所有数字的和,要求对每次查询，输出结果 一维扩展到二维的情况：(lowbit(x)=x&amp;(-x)) C[x][y] = ∑ a[i][j], 其中 x-lowbit(x) + 1 &lt;= i &lt;= x y-lowbit(y) + 1 &lt;= j &lt;= y 在这样的定义下有： Sun(1,1)=C[1][1]; Sun(1,2)=C[1][2]; Sun(1,3)=C[1][3]+C[1][2];... Sun(2,1)=C[2][1]; Sun(2,2)=C[2][2]; Sun(2,3)=C[2][3]+C[2][2];... Sun(3,1)=C[3][1]+C[2][1]; Sun(3,2)=C[3][2]+C[2][2]; 求和Sum：123456789int Sum(int i, int j)&#123; int result = 0; for (int x = i; x &gt; 0; x -= lowbit(x)) &#123; for(int y = j; y &gt; 0; y -= lowbit(y)) &#123; result += C[x][y]; &#125; &#125; return result;&#125; 更新update12345678private void Modify(int i, int j, int delta)&#123; A[i][j]+=delta; for(int x = i; x&lt; A.length; x += lowbit(x)) &#123; for(int y = j; y &lt;A[i].length; y += lowbit(y)) &#123; C[x][y] += delta; &#125; &#125;&#125; POJ 2155给定MxN矩阵，每个元素取值{0, 1}，合法的操作如下： 将左上角坐标为(x1, y1)，右下角坐标为(x2, y2)的矩形区域内的所有元素反转（0-&gt;1, 1-&gt;0） 查询A[i][j]的值 在树状数组中存储该节点的变换次数，因为数值只是0或1，所以奇数次的效果是一样的，偶数次的效果也是一样的。如下图所示： 反转[(x1, y1), (x2, y2)]等价于： 分别反转 [(x1, y1), (n,n)], [(x2+1, y2+1), (n,n)], [(x1, y2+1), (n,n)], [(x1+1, y2), (n,n)] 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;iostream&gt;using namespace std;const int MAX = 1010;int c[MAX][MAX];int n;int Lowbit(int x) &#123; return x &amp; (-x);&#125;// 是将以(n,n)为右下角，(x,y)为左上角的矩形区域反转// 需要把所有包含(x, y)的c数组元素更新void Updata(int x,int y) &#123; int i,k; for(i=x; i&lt;=n; i+=Lowbit(i)) for(k=y; k&lt;=n; k+=Lowbit(k)) c[i][k]++;&#125;// 包含点(x, y)的所有区间的总反转次数// 因为反转都是左上-&gt;右下，所以包含点(x, y)的区间端点不会在(x, y)右、下角int Get(int x,int y) &#123; int i,k,sum = 0; for(i=x; i&gt;0; i-=Lowbit(i)) for(k=y; k&gt;0; k-=Lowbit(k)) sum += c[i][k]; return sum;&#125;int main() &#123; int ncases,m; int x1,y1,x2,y2; char ch[2]; scanf(\"%d\",&amp;ncases); while( ncases-- ) &#123; memset(c,0,sizeof(c)); scanf(\"%d%d\",&amp;n,&amp;m); while( m-- ) &#123; scanf(\"%s\",ch); if( ch[0] == 'C' ) &#123; scanf(\"%d%d%d%d\",&amp;x1,&amp;y1,&amp;x2,&amp;y2); x1++; y1++; x2++; y2++; Updata(x2,y2); Updata(x1-1,y1-1); Updata(x1-1,y2); Updata(x2,y1-1); &#125; else &#123; scanf(\"%d%d\",&amp;x1,&amp;y1); printf(\"%d/n\",Get(x1,y1)%2); &#125; &#125; printf(\"/n\"); &#125;return 0;&#125;","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Binary Tree","slug":"Binary-Tree","permalink":"atlantic8.github.io/tags/Binary-Tree/"}]},{"title":"Water and Jug Problem","slug":"Water-and-Jug-Problem","date":"2016-09-22T06:58:18.000Z","updated":"2018-12-16T14:08:06.445Z","comments":true,"path":"2016/09/22/Water-and-Jug-Problem/","link":"","permalink":"atlantic8.github.io/2016/09/22/Water-and-Jug-Problem/","excerpt":"","text":"ProblemYou are given two jugs with capacities x and y litres. There is an infinite amount of water supply available. You need to determine whether it is possible to measure exactly z litres using these two jugs. If z liters of water is measurable, you must have z liters of water contained within one or both buckets by the end. Operations allowed: Fill any of the jugs completely with water. Empty any of the jugs. Pour water from one jug into another till the other jug is completely full or the first jug itself is empty. Example 1: (From the famous &quot;Die Hard&quot; example) Input: x = 3, y = 5, z = 4 Output: True Example 2: Input: x = 2, y = 6, z = 5 Output: False Solution贝祖等式（Bézout’s identity / 定理）：对任何整數 a、 b和它们的最大公约数 d，关于未知数 x 和 y 的线性方程（称为贝祖等式）： ax + by = m 有整数解时当且仅当m是d的倍数。 所以，只要x、y的最大公约数d能整除m，并且x+y&lt;=m，那么存在a、b满足 ax + by = m 12345678910111213141516public boolean canMeasureWater(int x, int y, int z) &#123; if(x + y &lt; z) return false; // 出现x=0或者y=0、x + y == z if( x == z || y == z || x + y == z ) return true; // 利用贝祖定理，求最大公约数 return z%GCD(x, y) == 0;&#125;public int GCD(int a, int b)&#123; while(b != 0 )&#123; int temp = b; b = a%b; a = temp; &#125; return a;&#125;","categories":[],"tags":[]},{"title":"STL Heap","slug":"Cpp-commonly-Used-Data-Structures-and-Methods","date":"2016-09-19T13:50:49.000Z","updated":"2018-12-16T14:08:06.210Z","comments":true,"path":"2016/09/19/Cpp-commonly-Used-Data-Structures-and-Methods/","link":"","permalink":"atlantic8.github.io/2016/09/19/Cpp-commonly-Used-Data-Structures-and-Methods/","excerpt":"","text":"堆make_heap123456void make_heap (RandomAccessIterator first, RandomAccessIterator last, Compare comp );make_heap (v.begin(),v.end()); 重新组织[first, last)，使之成为一个堆（默认为大顶堆）。 is_heap123456bool is_heap (RandomAccessIterator first, RandomAccessIterator last, Compare comp);is_heap(foo.begin(), foo.end()); 检查[first, last)范围内的元素是否满足堆的定义 is_heap_until123456RandomAccessIterator is_heap_until (RandomAccessIterator first, RandomAccessIterator last, Compare comp);auto last = std::is_heap_until (foo.begin(),foo.end()); 返回[first, last)范围内第一个不满足heap定义的迭代器。 pop_heap &amp; push_heap12345678void pop_heap (RandomAccessIterator first, RandomAccessIterator last, Compare comp);pop_heap (v.begin(), v.end());v.pop_back(); pop, push完了之后，重新调整，pop默认最大值。 sort_heap12void sort_heap (RandomAccessIterator first, RandomAccessIterator last, Compare comp); 排序，heap的属性可能会丢失 排序12#include &lt;algorithm&gt; |function|explanation|function|explanation| |:———:|:————-:|:———:|:————-:| |sort|对给定区间所有元素进行排序|stable_sort|对给定区间所有元素进行稳定排序| |partial_sort|对给定区间所有元素部分排序|partial_sort_copy|对给定区间复制并排序| |nth_element|找出给定区间的某个位置对应的元素|is_sorted|判断一个区间是否已经排好序| |partition|使得符合某个条件的元素放在前面|stable_partition|相对稳定的使得符合某个条件的元素放在前面| sort1234void sort (RandomAccessIterator first, RandomAccessIterator last, Compare comp);sort (myvector.begin(), myvector.end()); 将[first, last)范围内元素排序，排序方式由comp决定，comp是自定义函数，可以使用lambda表达式替代。 1234567891011121314151617181920212223242526272829303132333435363738/* lambda表达式形式如下capture：指定了在可见域范围内 lambda 表达式的代码内可见得外部变量的列表，可能取值如下： [] 不截取任何变量 [&amp;] 截取外部作用域中所有变量，并作为引用在函数体中使用 [=] 截取外部作用域中所有变量，并拷贝一份在函数体中使用 [=, &amp;foo] 截取外部作用域中所有变量，并拷贝一份在函数体中使用，但是对foo变量使用引用 [bar] 截取bar变量并且拷贝一份在函数体重使用，同时不截取其他变量 [x, &amp;y] x按值传递，y按引用传递 [this] 截取当前类中的this指针。如果已经使用了&amp;或者=就默认添加此选项params： 指定 lambda 表达式的参数ret: 返回类型body: 函数体*/[ capture ] ( params ) -&gt; ret &#123; body &#125;sort (envelopes.begin(), envelopes.end(), [](const pair&lt;int, int&gt; &amp;a, const pair&lt;int, int&gt; &amp;b)&#123; if (a.first == b.first) return a.second &gt; b.second; return a.first &lt; b.first;&#125;); stable_sort12void stable_sort ( RandomAccessIterator first, RandomAccessIterator last, Compare comp ); 函数用法与sort一致，它的排序结果是稳定的。 partial_sort12void partial_sort (RandomAccessIterator first, RandomAccessIterator middle, RandomAccessIterator last, Compare comp); 对[first, middle)范围的元素进行排序。 partial_sort_copy12void partial_sort_copy (InputIterator first,InputIterator last,RandomAccessIterator result_first,RandomAccessIterator result_last, Compare comp); 对[first, last)范围的元素进行排序，并将排序结果复制到[result_first, result_last) is_sorted12bool is_sorted (ForwardIterator first, ForwardIterator last, Compare comp); 判断[first, last)范围的元素是否有序。 nth_element12void nth_element (RandomAccessIterator first, RandomAccessIterator nth, RandomAccessIterator last, Compare comp); 重新组织[first, last)范围的元素，使第n大元素处于第n位置，并且比这个元素小的元素都排在这个元素之前，比这个元素大的元素都排在这个元素之后，但不能保证他们是有序的 partition12BidirectionalIterator partition (BidirectionalIterator first, BidirectionalIterator last, UnaryPredicate pred); 将区间[first,last)中的元素重新排列，满足判断条件pred的元素会被放在区间的前段，不满足pred的元素会被放在区间的后段。该算法不能保证元素的初始相对位置，返回指向第二类第一个元素的迭代器。 用法： 123456789101112131415161718192021222324252627282930313233343536bool IsOdd (int i) &#123; //用语判断奇数 return (i%2) == 1; //奇数返回true，偶数返回0&#125;int main(void)&#123; std::vector&lt;int&gt; ivec; for (int i=1; i&lt;10; ++i) ivec.push_back(i); // 1 2 3 4 5 6 7 8 9 auto bound = partition (ivec.begin(), ivec.end(), IsOdd); std::cout &lt;&lt; \"odd elements:\"; for (auto it=ivec.begin(); it!=bound; ++it) std::cout &lt;&lt; ' ' &lt;&lt; *it; //输出1,9,3,7,5 std::cout &lt;&lt; \"even elements:\"; for (auto it=bound; it!=ivec.end(); ++it) std::cout &lt;&lt; ' ' &lt;&lt; *it; //输出6,4,8,2 return 0;&#125; stable_partitionpartition的稳定版本。 sort_heap12void sort_heap (RandomAccessIterator first, RandomAccessIterator last, Compare comp); 用法和上面的函数一致。 lower_bound &amp; upper_bound1234ForwardIter lower_bound(ForwardIter first, ForwardIter last, const _Tp&amp; val);ForwardIter upper_bound(ForwardIter first, ForwardIter last, const _Tp&amp; val); lower_bound返回一个非递减序列[first, last)中的第一个大于等于值val的位置. upper_bound返回一个非递减序列[first, last)中第一个大于val的位置 这两个函数都是用二分查找方法实现的，复杂度为O(logn) 集合setset作为一个容器也是用来存储同一数据类型的数据类型，并且能从一个数据集合中取出数据，在set中每个元素的值都唯一，而且元素的值是有序的。set中数元素的值不能直接被改变。C++ STL中标准关联容器set, multiset, map, multimap内部采用RB树(插入元素迭代器不会失效，删除元素时除了被删除的那个以外的迭代器不会失效)。 其包含的方法包括 begin(), end(), rbegin(), rend() clear(), empty(), find(), insert(key_value) inset(first,second);将迭代器first到second之间的元素插入到set中，返回值是void size(), max_size() equal_range()，返回一对迭代器，分别表示第一个大于或等于给定关键值的元素迭代器 以及 第一个大于给定关键值的元素的迭代器，这个返回值是一个pair类型，如果这一对定位器中哪个返回失败，就会等于end()的值。 erase(iterator) ，删除迭代器iterator指向的值 erase(first,second)，删除迭代器first和second之间的值 erase(key_value)，删除键值key_value的值 lower_bound(key):返回第一个大于等于key的迭代器指针 upper_bound(key):返回第一个大于key的迭代器指针 链表listc++中的list容器是双向链表。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#include &lt; list &gt; list&lt;int&gt; new_list;assign(iter1, iter2) 将两个迭代器之间的元素赋值给当前listback() 返回最后一个元素begin() 返回指向第一个元素的迭代器clear() 删除所有元素empty() 如果list是空的则返回trueend() 返回末尾的迭代器erase() 删除一个元素 front() 返回第一个元素 get_allocator() 返回list的配置器 insert(const_iterator position, const value_type&amp; val) 插入一个元素到list中 max_size() 返回list能容纳的最大元素数量 merge(list&amp; x, Compare comp) 合并当前list和xpop_back() 删除最后一个元素 pop_front() 删除第一个元素 push_back() 在list的末尾添加一个元素 push_front() 在list的头部添加一个元素 rbegin() 返回指向第一个元素的逆向迭代器 remove(const value_type&amp; val) 从list删除元素元素valremove_if(Predicate pred) 按指定条件删除所有满足条件的元素 rend() 指向list末尾的逆向迭代器 resize(size_type n, const value_type&amp; val) 改变list的大小，val是增加空间用的填充值reverse() 把list的元素倒转 size() 返回list中的元素个数 sort(Compare comp) 给list排序，复杂度大约是NlogN，可以用归并splice() 合并两个list swap(list&amp; x) 交换当前list和xunique() 删除list中重复的元素 遍历使用迭代器 forward_listforward_list是单向链表 dequedeque容器类与vector类似，支持随机访问和快速插入删除，它在容器中某一位置上的操作所花费的是线性时间。与vector不同的是，deque还支持从开始端插入数据：push_front()。其余类似vector操作方法的使用。 随机访问方便，即支持[ ] 操作符和vector.at() ，但性能没有vector 好； 可以在内部进行插入和删除操作，但性能不及list ； 可以在两端进行push 、pop ； 相对于verctor 占用更多的内存。 priority_queue将任意类型的序列容器转换为一个优先级队列，一般使用vector作为底层存储方式。 只能访问第一个元素，不能遍历整个priority_queue。 模板声明带有三个参数，priority_queue&lt;Type, Container, Functional&gt; 其中Type 为数据类型， Container 为保存数据的容器，Functional 为元素比较方式。 Container 必须是用数组实现的容器，比如 vector, deque 但不能用list. STL里面容器默认用的是 vector. 比较方式默认用 operator &lt; 缺省时优先队列就是大顶堆，队头元素优先级最大。 12345678910111213141516#include &lt;queue&gt;priority_queue &lt;Elem&gt; c; // 创建一个空的queuec.top(); // 返回队列头部数据c.push(elem); // 在队列尾部增加elem数据c.pop(); // 队列头部数据出队c.empty();c.size();","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"Cpp","slug":"Cpp","permalink":"atlantic8.github.io/tags/Cpp/"},{"name":"STL","slug":"STL","permalink":"atlantic8.github.io/tags/STL/"}]},{"title":"First Missing Positive","slug":"First-Missing-Positive","date":"2016-09-14T01:18:18.000Z","updated":"2018-12-16T14:08:06.238Z","comments":true,"path":"2016/09/14/First-Missing-Positive/","link":"","permalink":"atlantic8.github.io/2016/09/14/First-Missing-Positive/","excerpt":"","text":"ProblemGiven an unsorted integer array, find the first missing positive integer. For example, Given [1,2,0] return 3, and [3,4,-1,1] return 2. Your algorithm should run in O(n) time and uses constant space. Solution解题思路 把每个数放在它应该的位置，比如找到4，就把4和num[3]兑换 小于1的数忽略，因为题目说是正数 大于数组长度的数也不可能是，因为它前面至少有n个数，至少有一个缺失 第一遍扫面把数放在正确的地方，第二遍，把num[i]!=i+1的最小序号输出 1234567891011121314class Solution&#123;public: int firstMissingPositive(int A[], int n) &#123; // 将数放在正确的地方 for(int i = 0; i &lt; n; ++ i) while(A[i] &gt; 0 &amp;&amp; A[i] &lt;= n &amp;&amp; A[A[i] - 1] != A[i]) swap(A[i], A[A[i] - 1]); // 找到缺失的数 for(int i = 0; i &lt; n; ++ i) if(A[i] != i + 1) return i + 1; return n + 1; &#125;&#125;;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Copy List with Random Pointer","slug":"Copy-List-with-Random-Pointer","date":"2016-09-12T15:40:24.000Z","updated":"2018-12-16T14:08:06.189Z","comments":true,"path":"2016/09/12/Copy-List-with-Random-Pointer/","link":"","permalink":"atlantic8.github.io/2016/09/12/Copy-List-with-Random-Pointer/","excerpt":"","text":"Copy List with Random PointerA linked list is given such that each node contains an additional random pointer which could point to any node in the list or null. Return a deep copy of the list.节点的数据结构如下： class RandomListNode { int label; RandomListNode next, random; RandomListNode(int x) { this.label = x;} }; Solution本题的naive思想如下： 在原来list上，每个节点后面插入一个拷贝这个节点的节点 从第一个节点开始，若：nodei-&gt;random = nodek, 那么设置nodei-&gt;next.random = nodek-&gt;next即可 还原原来的list，提取复制的list 1234567891011121314151617181920212223242526272829303132333435363738394041424344public RandomListNode copyRandomList(RandomListNode head) &#123; RandomListNode iter = head, next; // 在原链表上每个节点后一位创建copy while (iter != null) &#123; next = iter.next; RandomListNode copy = new RandomListNode(iter.label); iter.next = copy; copy.next = next; iter = next; &#125; // random指针设置 iter = head; while (iter != null) &#123; if (iter.random != null) &#123; iter.next.random = iter.random.next; &#125; iter = iter.next.next; &#125; // 还原原来的list，提取复制的list iter = head; RandomListNode pseudoHead = new RandomListNode(0); RandomListNode copy, copyIter = pseudoHead; while (iter != null) &#123; // extract the copy copy = iter.next; copyIter.next = copy; copyIter = copy; // restore the original list next = iter.next.next; iter.next = next; iter = next; &#125; return pseudoHead.next;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Reservoir Sampling","slug":"Reservoir-Sampling","date":"2016-09-12T10:59:35.000Z","updated":"2018-12-16T14:08:06.400Z","comments":true,"path":"2016/09/12/Reservoir-Sampling/","link":"","permalink":"atlantic8.github.io/2016/09/12/Reservoir-Sampling/","excerpt":"","text":"算法介绍Reservoir Sampling（水塘抽样）是一系列的随机算法，其目的在于从包含n个项目的集合S中选取k个样本，其中n为一很大或未知的数量，尤其适用于不能把所有n个项目都存放到主内存的情况。算法思路如下： 从S中抽取首k项放入「水塘」中 对于每一个S[j]项（j ≥ k）： 随机产生一个范围从0到j的整數r 若 r &lt; k 则把水塘中的第r项换成S[j]项 相关问题可否在一未知大小的集合中，随机取出一元素？第一次直接以第一行作为取出行 choice第二次以二分之一概率决定是否用第二行替换 choice第三次以三分之一的概率决定是否以第三行替换 choice以此类推。Generally，在取第n个数据的时候，我们生成一个0到1的随机数p，如果p小于1/n，保留第n个数。大于1/n，继续保留前面的数。直到数据流结束，返回此数，算法结束。 证明思路：最后一个数留下的概率是1/N，第一个数留下的概率是1x1/2x2/3x…x(N-1)/N = 1/N，其他元素证明类似，所以每个数被选中的概率是一样的，即这种方法是等概率的。 在一个长度很大但未知的链表中，如何最高效地取出k个元素？道理同上，在取第n个数据的时候，我们生成一个0到1的随机数p如果p小于k/n，替换池中任意一个为第n个数大于k/n，继续保留前面的数直到数据流结束，返回此k个数但是为了保证计算机计算分数额准确性，一般是生成一个0到n的随机数，跟k相比，小于k就替换第k项。 Random Pick Index Given an array of integers with possible duplicates, randomly output the index of a given target number. You can assume that the given target number must exist in the array. Note:The array size can be very large. Solution that uses too much extra space will not pass the judge. Example: int[] nums = new int[] {1,2,3,3,3}; Solution solution = new Solution(nums); // pick(3) should return either index 2, 3, or 4 randomly. Each index should have equal probability of returning. solution.pick(3); // pick(1) should return 0. Since in the array only nums[0] is equal to 1. solution.pick(1); 解体思想：用简单的map思路来做会超出空间限制，水塘抽样是比较好的方法 扫描每一个元素，不是当前要求的忽略 遇到第k个目标元素，以1/k的概率替换ret值 直到扫描完整个字符串 1234567891011121314vector&lt;int&gt; data;void Solution(vector&lt;int&gt; nums) &#123; srand((int)time(NULL)); // 设置时间种子，放在pick里面会导致之间间隔太短而使得随机数不随机 data = nums;&#125;int pick(int target) &#123; int ret = 0, n = 1; for (int i=0; i&lt;data.size(); i++) &#123; if (data.at(i) != target) continue; else if (rand()%n++ == 0) ret = i; // 以以1/k的概率使用第k个target值 &#125; return ret;&#125;","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"random algorithm","slug":"random-algorithm","permalink":"atlantic8.github.io/tags/random-algorithm/"}]},{"title":"KMP","slug":"KMP","date":"2016-09-12T03:05:21.000Z","updated":"2018-12-16T14:08:06.286Z","comments":true,"path":"2016/09/12/KMP/","link":"","permalink":"atlantic8.github.io/2016/09/12/KMP/","excerpt":"","text":"KMP算法是是一种在线性时间内对字符串进行匹配的经典算法.待匹配的字符串是s，模式串为p 匹配原理 算法的出发点很直接，如上图所示，当匹配过程中出现不匹配时，不是简单地将模式串向右移动一位再从头匹配。而是利用匹配中的信息，比如上图，应该直接将模式串移动4位，到达下图的位置： 那么算法如何确定应该移动几位呢？这样的信息其实隐藏在模式串p中。我们把这些信息放在数组中，称之为next数组。（后面再讨论next数组的求法） 例子中模式串p的next数组位 A B C D A B D 0 0 0 0 1 2 0 所以当第k位匹配失败时，模式串向前移动的位数满足： 移动位数 = 已匹配的字符数 - next[k-1] next数组next数组就是”前缀”和”后缀”的最长的共有元素的长度next[i]表示的是p的子串p[0,i]的”前缀”和”后缀”的最长的共有元素的长度next数组的计算方式依旧采用滑动匹配的方式，并且在计算next[j]时需要使用已经计算过的next值 首先p的第一个字符的最大相同前后缀长度为0 设next[q-1]=k，对于第q个 如果：p[q]==p[k]，那么，next[q] = ++k，break; 否则：因为此时p[q]和p[k]已经不匹配了，所以我们需要将匹配串右移next[k-1]=j位，此时p[0,j-1]和p[q-j,q-1]已经匹配上了，所以此时要看p[j]==p[q]?，所以回到第2步； 实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include&lt;stdio.h&gt;#include&lt;string.h&gt;void makeNext(const char P[],int next[]) &#123; int q,k; int m = strlen(P); next[0] = 0; for (q = 1,k = 0; q &lt; m; ++q) &#123; // k=0时，无论P[q]和P[k]是否匹配，next[q]都next[k-1]值无关 // 不匹配时，根据next[k-1]=j右移，并且看P[q]和P[j]的匹配情况 while(k &gt; 0 &amp;&amp; P[q] != P[k]) k = next[k-1]; if (P[q] == P[k]) &#123; // next值增长一 k++; &#125; next[q] = k; &#125;&#125;int kmp(const char T[],const char P[],int next[]) &#123; int n,m; int i,q; // i指示T的索引，q指示P的索引 n = strlen(T); m = strlen(P); makeNext(P,next); for (i = 0,q = 0; i &lt; n; ++i) &#123; // 这里的原理和上面一致 while(q &gt; 0 &amp;&amp; P[q] != T[i]) q = next[q-1]; if (P[q] == T[i]) &#123; q++; &#125; if (q == m) &#123; // 找到一个匹配 printf(\"Pattern occurs with shift:%d\\n\",(i-m+1)); // count++; // 计算模式串出现的次数 q = next[q-1]; // 找到一个匹配后，寻找下一个匹配，移动p &#125; &#125;&#125;int main() &#123; int i; int next[20]=&#123;0&#125;; char T[] = \"ababxbababcadfdsss\"; char P[] = \"abcdabd\"; printf(\"%s\\n\",T); printf(\"%s\\n\",P ); // makeNext(P,next); kmp(T,P,next); for (i = 0; i &lt; strlen(P); ++i) &#123; printf(\"%d \",next[i]); &#125; printf(\"\\n\"); return 0;&#125;","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"String","slug":"String","permalink":"atlantic8.github.io/tags/String/"}]},{"title":"Word Search","slug":"Word-Search","date":"2016-09-11T02:23:58.000Z","updated":"2018-12-16T14:08:06.455Z","comments":true,"path":"2016/09/11/Word-Search/","link":"","permalink":"atlantic8.github.io/2016/09/11/Word-Search/","excerpt":"","text":"Word SearchGiven a 2D board and a word, find if the word exists in the grid. The word can be constructed from letters of sequentially adjacent cell, where “adjacent” cells are those horizontally or vertically neighboring. The same letter cell may not be used more than once. For example, Given board = [ [&#39;A&#39;,&#39;B&#39;,&#39;C&#39;,&#39;E&#39;], [&#39;S&#39;,&#39;F&#39;,&#39;C&#39;,&#39;S&#39;], [&#39;A&#39;,&#39;D&#39;,&#39;E&#39;,&#39;E&#39;] ] word = &quot;ABCCED&quot;, -&gt; returns true, word = &quot;SEE&quot;, -&gt; returns true, word = &quot;ABCB&quot;, -&gt; returns false. 解题思路 典型的DFS题 每到一个点，将其做标记（可以通过异或操作减少空间浪费），然后继续递归，递归完成后，把这个点的值还原 Word Search在上一题的基础上，给定一个单词集合words，找到words中的能由board构建的全部单词。对每个单词，假设board的每个格子只能用1次。 For example, Given words = [&quot;oath&quot;,&quot;pea&quot;,&quot;eat&quot;,&quot;rain&quot;] and board = [ [&#39;o&#39;,&#39;a&#39;,&#39;a&#39;,&#39;n&#39;], [&#39;e&#39;,&#39;t&#39;,&#39;a&#39;,&#39;e&#39;], [&#39;i&#39;,&#39;h&#39;,&#39;k&#39;,&#39;r&#39;], [&#39;i&#39;,&#39;f&#39;,&#39;l&#39;,&#39;v&#39;] ] Return [&quot;eat&quot;,&quot;oath&quot;]. 解题思路 还是要用dfs的思想 关于words的形式，trie树显然是最natural的 trie树节点包含26个指针，指向其可能存在的子节点，还包含一个string属性，此属性只在根节点上有用，表示以这个根结点结尾的word 对board的每一个节点，调用dfs算法，dfs算法根据trie树经行搜索。遇到根结点的话，将对应的结果存储 结果对重复的word并不计算，所以要考虑去重 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public List&lt;String&gt; findWords(char[][] board, String[] words) &#123; List&lt;String&gt; res = new ArrayList&lt;&gt;(); TrieNode root = buildTrie(words); for(int i = 0; i &lt; board.length; i++) &#123; for(int j = 0; j &lt; board[0].length; j++) &#123; dfs(board, i, j, root, res); &#125; &#125; return res;&#125;public void dfs(char[][] board, int i, int j, TrieNode p, List&lt;String&gt; res) &#123; char c = board[i][j]; if(c == '#' || p.next[c - 'a'] == null) return; p = p.next[c - 'a']; if (p.word != null) &#123; // 叶节点 res.add(p.word); p.word = null; // 记录这个单词一次就够了，以后不需要记录它 &#125; board[i][j] = '#'; if(i &gt; 0) dfs(board, i - 1, j ,p, res); if(j &gt; 0) dfs(board, i, j - 1, p, res); if(i &lt; board.length - 1) dfs(board, i + 1, j, p, res); if(j &lt; board[0].length - 1) dfs(board, i, j + 1, p, res); board[i][j] = c;&#125;public TrieNode buildTrie(String[] words) &#123; TrieNode root = new TrieNode(); for(String w : words) &#123; TrieNode p = root; for(char c : w.toCharArray()) &#123; int i = c - 'a'; if(p.next[i] == null) p.next[i] = new TrieNode(); p = p.next[i]; &#125; p.word = w; // 叶节点的word属性值为这个单词 &#125; return root;&#125;// trie树的定义class TrieNode &#123; TrieNode[] next = new TrieNode[26]; String word;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"DFS","slug":"DFS","permalink":"atlantic8.github.io/tags/DFS/"}]},{"title":"Word Break","slug":"Word-Break","date":"2016-09-11T02:00:56.000Z","updated":"2018-12-16T14:08:06.451Z","comments":true,"path":"2016/09/11/Word-Break/","link":"","permalink":"atlantic8.github.io/2016/09/11/Word-Break/","excerpt":"","text":"Word Break给定一些单词集合dic，问给定字符串s是否可以拆分成这些单词。思路如下： 使用DP思想，f[i]表示s.substring(0,i)是否可以拆分 f[i] |= (f[k] &amp;&amp; s.substring(k,i) in dic)对于所有的k in [0,i] Word Break II在上题的基础上，要求给出所有可能的拆分，单词之间用空格隔开 For example, given s = &quot;catsanddog&quot;, dict = [&quot;cat&quot;, &quot;cats&quot;, &quot;and&quot;, &quot;sand&quot;, &quot;dog&quot;]. A solution is [&quot;cats and dog&quot;, &quot;cat sand dog&quot;]. 解题思路： 由于需要给出所有的结果，上面的DP就不行了 解法是使用递归求解，对于已经处理过的子串，要用哈希表保存其结果，再次遇到可以直接使用代码如下： 12345678910111213141516171819202122public class Solution &#123; HashMap&lt;String, List&lt;String&gt; &gt;map = new HashMap&lt;String, List&lt;String&gt; &gt;(); public List&lt;String&gt; wordBreak(String s, Set&lt;String&gt; dict) &#123; if (map.containsKey(s) == true) // 已经处理过的子串 return map.get(s); List&lt;String&gt; ret = new ArrayList&lt;String&gt;(); for (int i=1; i&lt;=s.length(); i++) &#123; String tmp1 = s.substring(0, i), tmp2 = s.substring(i); if (dict.contains(tmp1) == true) &#123; // 第一段是word的话 if (tmp2.length() == 0) ret.add(tmp1); else &#123; List&lt;String&gt; l = wordBreak(tmp2, dict); // 获取第二段的组成方式 for (String str:l) ret.add(tmp1+\" \"+str); //拼接 &#125; &#125; // 否则进入下一次循环 &#125; map.put(s, ret); return ret; &#125;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"DP","slug":"DP","permalink":"atlantic8.github.io/tags/DP/"},{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Backtracking","slug":"Backtracking","permalink":"atlantic8.github.io/tags/Backtracking/"}]},{"title":"Subsets","slug":"Subsets","date":"2016-09-10T08:28:50.000Z","updated":"2018-12-16T14:08:06.418Z","comments":true,"path":"2016/09/10/Subsets/","link":"","permalink":"atlantic8.github.io/2016/09/10/Subsets/","excerpt":"","text":"ProblemGiven a set of distinct integers, nums, return all possible subsets. Note: The solution set must not contain duplicate subsets. &lt;无重复假设&gt; For example,If nums = [1,2,3], a solution is: [ [3], [1], [2], [1,2,3], [1,3], [2,3], [1,2], [] ] Solution递归的做法很明显，不赘述了。这里介绍使用bit思想的方法 一个长度为n的无重复数组，其子集的个数为2^n个，每一个元素可能出现或者不出现。 所以我们从0到2^n-1，逐个递增。对每个数，按位位移然后&amp;1就可以得到每一位的值，然后根据每一位是0还是1确定对应的数组元素是否加入。这种方法的优势在于不用递归调用栈。代码略！ 下面的代码是这样的思想 先生成2^n个空的集合 每一个元素都会在2^(n-1)个子集中出现 第一个元素每隔一个集合出现一次，第二个元素每4个元素出现连续2次，第三个元素每8个元素出现连续4次 所以第j个集合中，第i个元素是否出现可以由 j &gt;&gt; i &amp; 1 决定 下面是例子[1,2,3] [], [], [], [], [], [], [], [] [], [1], [], [1], [], [1], [], [1] [], [1], [2], [1, 2], [], [1], [2], [1, 2] [], [1], [2], [1, 2], [3], [1, 3], [2, 3], [1, 2, 3] 1234567891011121314class Solution &#123;public: vector&lt;vector&lt;int&gt; &gt; subsets(vector&lt;int&gt; &amp;S) &#123; sort (S.begin(), S.end()); int elem_num = S.size(); int subset_num = pow (2, elem_num); vector&lt;vector&lt;int&gt; &gt; subset_set (subset_num, vector&lt;int&gt;()); for (int i = 0; i &lt; elem_num; i++) for (int j = 0; j &lt; subset_num; j++) if ((j &gt;&gt; i) &amp; 1) subset_set[j].push_back (S[i]); return subset_set; &#125;&#125; 数组允许重复的情况在数组允许重复时，使用递归做的话，可以先排序，然后在遇到num[i] == num[i-1]时，直接跳过去就好 12345678910111213141516171819202122public class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; subsetsWithDup(int[] nums) &#123; Arrays.sort(nums); List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); List&lt;Integer&gt; each = new ArrayList&lt;&gt;(); helper(res, each, 0, nums); return res; &#125; public void helper(List&lt;List&lt;Integer&gt;&gt; res, List&lt;Integer&gt; each, int pos, int[] n) &#123; if (pos &lt;= n.length) &#123; res.add(each); &#125; int i = pos; while (i &lt; n.length) &#123; each.add(n[i]); helper(res, new ArrayList&lt;&gt;(each), i + 1, n); each.remove(each.size() - 1); while (i+1 &lt; n.length &amp;&amp; n[i] == n[i + 1]) i++; &#125; return; &#125;&#125; 迭代算法 采用逐个插入元素的思想，对每一个新元素，将其插入到每个已存在的子集中 如果当前元素是重复元素，那么只能把它插入到上一次插入位置的后面 比如说1,2,3,3，在插入最后一个3时，不能在[1],[2],[]这些集合中插入，因为第一个3插入时已经找到了这些子集，只能在第一个包含3的集合开始，所以需要插入第二个3的集合有[3],[1,3],[2,3],[1,2,3]。如果有3个3也是一样，第三个3只能插进包含2个3的子集。 1234567891011121314151617vector&lt;vector&lt;int&gt; &gt; subsetsWithDup(vector&lt;int&gt; &amp;S) &#123; sort(S.begin(), S.end()); // 包含空集的集合 vector&lt;vector&lt;int&gt;&gt; ret = &#123;&#123;&#125;&#125;; int size = 0, startIndex = 0; for (int i = 0; i &lt; S.size(); i++) &#123; // startIndex从上一次开始插入的地方开始，不是重复元素则从0开始 startIndex = i &gt;= 1 &amp;&amp; S[i] == S[i - 1] ? size : 0; size = ret.size(); for (int j = startIndex; j &lt; size; j++) &#123; vector&lt;int&gt; temp = ret[j]; temp.push_back(S[i]); ret.push_back(temp); &#125; &#125; return ret;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"bit","slug":"bit","permalink":"atlantic8.github.io/tags/bit/"}]},{"title":"Repeated DNA Sequences","slug":"Repeated-DNA-Sequences","date":"2016-09-10T08:03:17.000Z","updated":"2018-12-16T14:08:06.397Z","comments":true,"path":"2016/09/10/Repeated-DNA-Sequences/","link":"","permalink":"atlantic8.github.io/2016/09/10/Repeated-DNA-Sequences/","excerpt":"","text":"ProblemAll DNA is composed of a series of nucleotides abbreviated as A, C, G, and T, for example: “ACGAATTCCG”. When studying DNA, it is sometimes useful to identify repeated sequences within the DNA. Write a function to find all the 10-letter-long sequences (substrings) that occur more than once in a DNA molecule. For example, Given s = &quot;AAAAACCCCCAAAAACCCCCCAAAAAGGGTTT&quot;, Return: [&quot;AAAAACCCCC&quot;, &quot;CCCCCAAAAA&quot;]. Solution滑动窗口和哈希表的思想很明显，不过直接将子串作为key放入哈希表中会超出内存限制所以，关键是要减少内存使用量，一个可行的办法如下： 由于A,C,G,T这四个字母的二进制值的最后三位是不一样的，所以他们&amp;111的值也是不同的，也就是说三位二进制就能区分出这四个字母 因为window的长度是10，所以表示长度为10的子串需要30位的长度，int型长度是32位(前两位需要设置为0，可以&amp;3fffffff达到效果)，满足条件 随着窗口移动，左边的退出，右边的加入，我们使用的int数可以每次向左移动三位 123456789101112131415161718192021public class Solution &#123; public List&lt;String&gt; findRepeatedDnaSequences(String s) &#123; List&lt;String&gt; ret = new ArrayList&lt;String&gt;(); int res=0; HashMap&lt;Integer,Integer&gt; map = new HashMap&lt;Integer,Integer&gt;(); for (int i=0; i&lt;s.length(); i++) &#123; // 3 bits can indicates one letter. so we total need 30 bits to represent a 10-letter string // while int is 32 bits long, so, &amp;0x3FFFFFFF helps set the first 2 bits to 0. // res&lt;&lt;3 : move the header. // s.charAt(i)&amp;7 : add a new letter. res = res &lt;&lt; 3 &amp; 0x3FFFFFFF | (s.charAt(i) &amp; 7); //get rid of the header and add the tailer. if (map.containsKey(res)==true) &#123; if (map.get(res) == 1) ret.add(s.substring(i-9, i+1)); map.put(res, map.get(res)+1); &#125; else map.put(res, 1); &#125; return ret; &#125;&#125; 更加节省空间的方法也有，区分四个数其实只需要2bit。先看下ACGT的二进制后三位 A : 001 C : 011 G : 111 T : 100 所以，对于一个字母先&amp;100，再&amp;010即可区分这四个数。（区分较难也没关系，可以写个函数搞定）","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Sliding window","slug":"Sliding-window","permalink":"atlantic8.github.io/tags/Sliding-window/"}]},{"title":"Next Right Pointers in Each Node","slug":"Next-Right-Pointers-in-Each-Node","date":"2016-09-10T07:04:17.000Z","updated":"2018-12-16T14:08:06.362Z","comments":true,"path":"2016/09/10/Next-Right-Pointers-in-Each-Node/","link":"","permalink":"atlantic8.github.io/2016/09/10/Next-Right-Pointers-in-Each-Node/","excerpt":"","text":"Problem 1Given a binary tree struct TreeLinkNode { TreeLinkNode *left; TreeLinkNode *right; TreeLinkNode *next; } Populate each next pointer to point to its next right node. If there is no next right node, the next pointer should be set to NULL. Initially, all next pointers are set to NULL. Note: You may only use constant extra space.You may assume that it is a perfect binary tree (ie, all leaves are at the same level, and every parent has two children).For example,Given the following perfect binary tree, 1 / \\ 2 3 / \\ / \\ 4 5 6 7 After calling your function, the tree should look like: 1 -&gt; NULL / \\ 2 -&gt; 3 -&gt; NULL / \\ / \\ 4-&gt;5-&gt;6-&gt;7 -&gt; NULL Solution 1 将一个节点的左孩子链接到右孩子比较简单 根不同的节点无法直接连接在一起，这时需要借用上一层的信息，如果不同根节点的孩子需要连在一起，那么他们的根节点一定是连接起来的 所以只要有上一层的连接关系，就可以将下一层连接完成 设置pre和cur两个指针，指示父层 pre从跟开始，每次经过最左边的节点，cur从pre开始向右移动 每到一个新的cur，先设置cur.left.next = cur.right 如果cur有next节点，则需要设置cur.right.next = cur.next.left 一层循环完成，pre = pre.left，直到树叶 1234567891011121314void connect(TreeLinkNode *root) &#123; if (root == NULL) return; TreeLinkNode *pre = root; TreeLinkNode *cur = NULL; while(pre-&gt;left) &#123; cur = pre; while(cur) &#123; cur-&gt;left-&gt;next = cur-&gt;right; if(cur-&gt;next) cur-&gt;right-&gt;next = cur-&gt;next-&gt;left; cur = cur-&gt;next; &#125; pre = pre-&gt;left; &#125;&#125; Problem 2把第一题中的perfect binary tree变成一般的二叉树，要求O(1)空间复杂度比如： 1 / \\ 2 3 / \\ \\ 4 5 7 操作完成后： 1 -&gt; NULL / \\ 2 -&gt; 3 -&gt; NULL / \\ \\ 4-&gt; 5 -&gt; 7 -&gt; NULL Solution 2还是要利用父层的节点关系来帮助子层之间的连接，把父层和子层当成两个相关的list来处理在二叉树为一般二叉树时，我们就需要考虑节点是否有左孩子，右孩子我们引入三个指针now指示当前层最左节点。head和tail，分别表示子层上最左边的节点和当前最右的节点 1 从根节点开始，设置head = tail = null 2 如果now.left为空，跳过，否则： 如果tail为空：head = tail = now.left. 表示当找到这一层的头 否则：tail = tail.next = now.left. 把now.left接到tail上，tail移一位 3 对now.right的处理和now.left一样 4 处理完now的子树，将now向右移，now = now.left 5 如果now = null，那么此时这一层已经结束，now下移一层到下一层最左边，即now = head，此时要把head和tail都设置为null 6 否则，进入下一循环 1234567891011121314151617181920void connect(TreeLinkNode *root) &#123; TreeLinkNode *now, *tail, *head; now = root; head = tail = NULL; while(now) &#123; if (now-&gt;left) if (tail) tail = tail-&gt;next =now-&gt;left; else head = tail = now-&gt;left; if (now-&gt;right) if (tail) tail = tail-&gt;next =now-&gt;right; else head = tail = now-&gt;right; if(!(now = now-&gt;next)) // now没有后继，跳到下一行最左边的节点 &#123; now = head; head = tail=NULL; // head和tail设置为null &#125; &#125;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Binary Tree","slug":"Binary-Tree","permalink":"atlantic8.github.io/tags/Binary-Tree/"}]},{"title":"Permutation","slug":"Permutation","date":"2016-09-10T06:01:06.000Z","updated":"2018-12-16T14:08:06.380Z","comments":true,"path":"2016/09/10/Permutation/","link":"","permalink":"atlantic8.github.io/2016/09/10/Permutation/","excerpt":"","text":"生成全排列举例来说，要生成[1,2,3,4,5]的全排列可以按如下方式继续：1,x,x,x,x 2,x,x,x 3,x,x,x 4,x,x,x 5,x,x,x2,x,x,x,x3,x,x,x,x4,x,x,x,x5,x,x,x,x 所以可以使用递归的方式进行，设置一个pos表示当前递归到达数组的深度然后:for i=pos; i=n，则将一个排列结果存储，return 1234567891011121314151617181920212223242526272829public class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; permute(int[] num) &#123; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;List&lt;Integer&gt;&gt;(); permute(num,0,result); return result; &#125; public void permute(int[] num, int begin, List&lt;List&lt;Integer&gt;&gt; result)&#123; if(begin&gt;=num.length)&#123; List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); for(int i=0;i&lt;num.length;i++)&#123; list.add(num[i]); &#125; result.add(list); return; &#125; for(int i=begin;i&lt;num.length;i++)&#123; swap(begin,i,num); permute(num,begin+1,result); swap(begin,i,num); &#125; &#125; public void swap (int x, int y,int[] num)&#123; int temp = num[x]; num[x]=num[y]; num[y]=temp; &#125;&#125; 下一个排列寻找下一排列的方法如下： 从后向前搜索，找到第一个num[i]&lt;num[i+1]，此时，[i+1, n-1]序号的元素非递增 如果i+1=n-1的话，直接将num逆序即可 从[i+1, n-1]前向遍历，找到第一个小于num[i]的数num[k]，将num[i]与num[k]互换，注意此时[i+1, n-1]序号的元素还是非递增 将[i+1, n-1]序号的元素逆序 第k个排列还拿[1,2,3,4,5]的全排列举例：以1开头的排列有4!个，以2开头的排列有4!个所以思路很明显 12345678910111213141516171819202122232425262728293031public class Solution &#123; public String getPermutation(int n, int k) &#123; int pos = 0; List&lt;Integer&gt; numbers = new ArrayList&lt;&gt;(); int[] factorial = new int[n+1]; StringBuilder sb = new StringBuilder(); // create an array of factorial lookup int sum = 1; factorial[0] = 1; for(int i=1; i&lt;=n; i++)&#123; sum *= i; factorial[i] = sum; &#125; // factorial[] = &#123;1, 1, 2, 6, 24, ... n!&#125; // create a list of numbers to get indices for(int i=1; i&lt;=n; i++)&#123; numbers.add(i); &#125; // numbers = &#123;1, 2, 3, 4&#125; k--; for(int i = 1; i &lt;= n; i++)&#123; int index = k/factorial[n-i]; sb.append(String.valueOf(numbers.get(index))); numbers.remove(index); k-=index*factorial[n-i]; &#125; return String.valueOf(sb); &#125;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Permutation","slug":"Permutation","permalink":"atlantic8.github.io/tags/Permutation/"}]},{"title":"Maximum Gap","slug":"Maximum-Gap","date":"2016-09-10T01:34:02.000Z","updated":"2018-12-16T14:08:06.337Z","comments":true,"path":"2016/09/10/Maximum-Gap/","link":"","permalink":"atlantic8.github.io/2016/09/10/Maximum-Gap/","excerpt":"","text":"ProblemGiven an unsorted array, find the maximum difference between the successive elements in its sorted form. Try to solve it in linear time/space. Return 0 if the array contains less than 2 elements. You may assume all elements in the array are non-negative integers and fit in the 32-bit signed integer range. Solution解题思路：由于需要在O(n)的时间复杂度完成，一般的比较排序都不行了，这里考虑使用Bucket sort方法，主要的思想是将元素分配到bucket中 扫描一遍数组，得到最大、最小值max、min 创建n-1个bucket，从min到max，长度向上取整 将数组中除min、max之外的n-2个元素放入n-1个bucket中，所以必然有一个为空 每个bucket维护一个最大最小值，其他值忽略，因为最大间距必然出现在bucket之间 注意也要考虑min和max与临近数的gap 如果设置n+1个bucket的话，就可以把min、max也加入，而寻找最大gap时就不需要单独考虑min、max了 12345678910111213141516171819202122232425262728293031323334353637public class Solution &#123; public int maximumGap(int[] num) &#123; if (num.length &lt; 2) return 0; int N=num.length,bucketSize=0,bucketNum=0,minElement=Integer.MAX_VALUE,maxElement=0; // 确定最值 for (int i=0; i&lt;N; i++) &#123; minElement = Math.min(minElement, num[i]); maxElement = Math.max(maxElement, num[i]); &#125; bucketSize = (int)Math.ceil(((double)(maxElement-minElement))/(N-1)); // bucket的大小 bucketNum = (int)Math.ceil(((double)(maxElement-minElement))/bucketSize); // bucket数量 int[] bucketMax = new int[bucketNum+1],bucketMin = new int[bucketNum+1]; for (int i=0; i&lt;=bucketNum; i++) &#123; bucketMax[i]=Integer.MIN_VALUE; bucketMin[i]=Integer.MAX_VALUE; &#125; for (int i=0; i&lt;N; i++) &#123; //put elements in buckets if (num[i]==minElement || num[i]==maxElement) // 不加入最值 continue; int bucketId = (int) Math.ceil(((double)(num[i]-minElement))/bucketSize); // 计算bucket编号 bucketMax[bucketId] = Math.max(num[i], bucketMax[bucketId]); bucketMin[bucketId] = Math.min(num[i], bucketMin[bucketId]); &#125; int maxGap=0, temp=minElement; // temp设置为最小值，可以捕捉最小值和第二小值之间的gap // 在bucket之间寻找最大gap for (int i=1; i&lt;=bucketNum; i++) &#123; if (bucketMin[i]==Integer.MAX_VALUE) continue; if (maxGap &lt; bucketMin[i]-temp) &#123; maxGap = bucketMin[i]-temp; &#125; temp = bucketMax[i]; &#125; maxGap = Math.max(maxGap, maxElement-temp); 捕捉最大和第二大值之间的gap return maxGap; &#125;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Sort","slug":"Sort","permalink":"atlantic8.github.io/tags/Sort/"}]},{"title":"Longest Palindromic Substring","slug":"Longest-Palindromic-Substring","date":"2016-09-09T12:21:53.000Z","updated":"2018-12-16T14:08:06.307Z","comments":true,"path":"2016/09/09/Longest-Palindromic-Substring/","link":"","permalink":"atlantic8.github.io/2016/09/09/Longest-Palindromic-Substring/","excerpt":"","text":"ProblemGiven a string S, find the longest palindromic substring in S. You may assume that the maximum length of S is 1000, and there exists one unique longest palindromic substring. Solution本题的解法不止一种。 DP解法 维护一个二维数组，p[i][j]表示子串substring(i,j+1)是否为回文 p[i][j] = s[i]==s[j] ? p[i+1][j-1] : false; 时间复杂度O(n^2) 具体代码就不贴了 扩展式解法 循环扫描每一位 以当前为基准，向左右扩展寻找回文子串，要注意的是奇数、偶数长度子串的不同 最坏情况的时间复杂度O(n*len)，len为最长回文子串的长度 123456789101112131415161718192021222324public class Solution &#123;private int lo, maxLen;public String longestPalindrome(String s) &#123; int len = s.length(); if (len &lt; 2) return s; for (int i = 0; i &lt; len-1; i++) &#123; extendPalindrome(s, i, i); //assume odd length extendPalindrome(s, i, i+1); //assume even length &#125; return s.substring(lo, lo + maxLen);&#125;private void extendPalindrome(String s, int j, int k) &#123; while (j &gt;= 0 &amp;&amp; k &lt; s.length() &amp;&amp; s.charAt(j) == s.charAt(k)) &#123; j--; k++; &#125; if (maxLen &lt; k - j - 1) &#123; lo = j + 1; maxLen = k - j - 1; &#125;&#125;&#125; Manacher算法Manacher算法是上面解法思想的延伸，主要除去了一些不必要的比较。 首先用一个非常巧妙的方式，将所有可能的奇数/偶数长度的回文子串都转换成了奇数长度：在每个字符的两边都插入一个特殊的符号。比如 abba 变成 #a#b#b#a#， aba变成 #a#b#a#。 为了进一步减少编码的复杂度，可以在字符串的开始加入另一个特殊字符，这样就不用特殊处理越界问题，比如$#a#b#a# 以字符串12212321为例，经过上一步，变成了 S[] = “$#1#2#2#1#2#3#2#1#”; 然后用一个数组 P[i] 来记录以字符S[i]为中心的最长回文子串向左/右扩张的长度（包括S[i]），比如S和P的对应关系： 123S # 1 # 2 # 2 # 1 # 2 # 3 # 2 # 1 #P 1 2 1 2 5 2 1 4 1 2 1 6 1 2 1 2 1P[i]-1正好是原字符串中回文串的总长度 下面计算P[i]，该算法增加两个辅助变量id和mx，其中id表示最大回文子串中心的位置，mx则为id+P[id]，也就是最大回文子串的边界。 这个算法的关键点就在这里了： 当 mx - i &gt; P[j] 的时候，以S[j]为中心的回文子串包含在以S[id]为中心的回文子串中，由于 i 和 j 对称，以S[i]为中心的回文子串必然包含在以S[id]为中心的回文子串中，所以必有 P[i] = P[j]，见下图。 当 P[j] &gt; mx - i 的时候，以S[j]为中心的回文子串不完全包含于以S[id]为中心的回文子串中，但是基于对称性可知，下图中两个绿框所包围的部分是相同的，也就是说以S[i]为中心的回文子串，其向右至少会扩张到mx的位置，也就是说 P[i] &gt;= mx - i。至于mx之后的部分是否对称，就只能一个一个匹配了。 对于 mx &lt;= i 的情况，无法对 P[i]做更多的假设，只能P[i] = 1，然后再去匹配了 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;iostream&gt;#include &lt;string&gt;#include&lt;algorithm&gt;using namespace std;// 将字符串处理，比如abcd变成：$#a#b#c#d#.// 这样可以将奇数长度的回文和偶数长度回文一起处理。string preProcess(string &amp; str) &#123; string ret=\"$#\"; for (int i=0; i&lt;str.length(); i++) &#123; ret += str[i]; ret += \"#\"; &#125; return ret;&#125;int p[2000009]=&#123;0&#125;;void getMaxLength(string str) &#123; // mostFar记录了i之前回文到达的最右坐标 // id是与之对应的中心坐标。 p记录的是以i为中心的回文半价，单个字母为1. int id=0, mostFar=0, maxL=0; p[0] = 0; for (int i=1; i&lt;str.length(); i++) &#123; if (mostFar &gt; i) &#123; int j=2*id-i; // j and i are symmetric by id. if (p[j] &lt; mostFar-i) // extension needed p[i] = p[j]; else p[i] = mostFar-i; // extension needed &#125; else p[i] = 1; // extension while ((i+p[i]&lt;str.length()) &amp;&amp; (i-p[i]&gt;=0) &amp;&amp; str.at(i+p[i]) == str.at(i-p[i])) ++p[i]; if (p[i]+i &gt; mostFar) &#123; // update mostFar and id. mostFar = (p[i]+i); id = i; &#125; &#125; for (int i=0; i&lt;str.length(); i++) maxL = max(maxL, p[i]); cout&lt;&lt;maxL-1&lt;&lt;endl;&#125;int main() &#123; int n=0; cin&gt;&gt;n; string str=\"\"; for (int i=0; i&lt;n; i++) &#123; cin&gt;&gt;str; if (str.length() &lt; 2) cout&lt;&lt;str.length()&lt;&lt;endl; else &#123; str = preProcess(str); getMaxLength(str); &#125; &#125; return 0;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"DP","slug":"DP","permalink":"atlantic8.github.io/tags/DP/"},{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Largest Rectangle in Histogram","slug":"Largest-Rectangle-in-Histogram","date":"2016-09-08T02:20:14.000Z","updated":"2018-12-16T14:08:06.290Z","comments":true,"path":"2016/09/08/Largest-Rectangle-in-Histogram/","link":"","permalink":"atlantic8.github.io/2016/09/08/Largest-Rectangle-in-Histogram/","excerpt":"","text":"ProblemGiven n non-negative integers representing the histogram’s bar height where the width of each bar is 1, find the area of largest rectangle in the histogram. ![](http://ww4.sinaimg.cn/mw690/9bcfe727jw1f7lz38exq2j205805oaab.jpg) Above is a histogram where width of each bar is 1, given height = [2,1,5,6,2,3].The largest rectangle is shown in the shaded area, which has area = 10 unit. For example,Given heights = [2,1,5,6,2,3],return 10. Solution解题思路是：每到一个柱子i，计算以柱子i为最矮柱子的矩形面积，所以需要知道i左侧第一个小于h[i]的序号left，和i右侧第一个小于h[i]的序号right。做法是从左向右遍历，维护一个栈，每个柱子都会入栈一次。当一个比栈顶柱子更小的柱子出现时，栈顶柱子出栈，此时计算以这个出栈的柱子为最矮柱子的矩形面积。此时，当前循环的序号为right，栈里之前的元素是left，算法具体思路如下： 创建空的栈 从第一个柱子开始——&gt;最后一个柱子 如果栈为空或者h[i]大于栈顶的柱子高度，则将i入栈 如果h[i]小于栈顶的柱子高度，持续从栈顶移除元素直到栈顶对应的柱子的值大于h[i]为止。设被移除的柱子为h[tp]，将h[tp]当作最矮的柱子并计算对应的面积，此时，left为栈中tp之前的元素，right是当前的i 如果栈不为空，那么逐个移除其元素，并且按上面的步骤计算对应的面积 因为每个柱子仅入栈、出栈一次，所以算法的复杂度为O(n)。12345678910111213141516171819202122class Solution &#123;public: int largestRectangleArea(vector&lt;int&gt; &amp;height) &#123; vector&lt;int&gt; s; int ret = 0; height.push_back(0); for (int i=0; i&lt;height.size(); i++) &#123; while (s.size()&gt;0 &amp;&amp; height[s.back()]&gt;=height[i]) &#123; int h = height[s.back()], sid=0; s.pop_back(); if (s.size() == 0) sid = 0; else sid = s.back()+1; if (ret &lt; h*(i-sid)) ret = h*(i-sid); &#125; s.push_back(i); &#125; return ret; &#125;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Simulated Annealing","slug":"Simulated-Annealing","date":"2016-09-08T02:17:20.000Z","updated":"2018-12-16T14:08:06.404Z","comments":true,"path":"2016/09/08/Simulated-Annealing/","link":"","permalink":"atlantic8.github.io/2016/09/08/Simulated-Annealing/","excerpt":"","text":"爬山算法爬山算法是一种简单的贪心搜索算法，该算法每次从当前解的临近解空间中选择一个最优解作为当前解，直到达到一个局部最优解。爬山算法实现很简单，其主要缺点是会陷入局部最优解，而不一定能搜索到全局最优解。 模拟退火(Simulated Annealing)爬山法是完完全全的贪心法，每次都鼠目寸光的选择一个当前最优解，因此只能搜索到局部的最优值。模拟退火其实也是一种贪心算法，但是它的搜索过程引入了随机因素。模拟退火算法以一定的概率来接受一个比当前解要差的解，因此有可能会跳出这个局部的最优解，达到全局的最优解。以图1为例，模拟退火算法在搜索到局部最优解A后，会以一定的概率接受到E的移动。也许经过几次这样的不是局部最优的移动后会到达D点，于是就跳出了局部最大值A。 模拟退火算法描述： 若移动后得到更优解，则总是接受该移动 若移动后的解比当前解要差，则以一定的概率接受移动，而且这个概率随着时间推移逐渐降低（逐渐降低才能趋向稳定） 这里的“一定的概率”的计算参考了金属冶炼的退火过程，这也是模拟退火算法名称的由来。根据热力学的原理，在温度为T时，出现能量差为dE的降温的概率为P(dE)，表示为： P(dE) = exp( dE/(kT) ) 其中k是一个常数，exp表示自然指数，且dE小于0。这条公式说白了就是：温度越高，出现一次能量差为dE的降温的概率就越大；温度越低，则出现降温的概率就越小。又由于dE总是小于0（否则就不叫退火了），因此dE/kT 小于0 ，所以P(dE)的函数取值范围是(0,1).随着温度T的降低，P(dE)会逐渐降低。我们将一次向较差解的移动看做一次温度跳变过程，我们以概率P(dE)来接受这样的移动。 伪代码12345678910111213141516171819202122* J(y)：在状态y时的评价函数值* Y(i)：表示当前状态* Y(i+1)：表示新的状态* r： 用于控制降温的快慢* T： 系统的温度，系统初始应该要处于一个高温的状态* T_min ：温度的下限，若温度T达到T_min，则停止搜索while( T &gt; T_min ) &#123; dE = J( Y(i+1) ) - J( Y(i) ) ; if ( dE &gt;=0 ) //表达移动后得到更优解，则总是接受移动 Y(i+1) = Y(i) ; //接受从Y(i)到Y(i+1)的移动 else &#123; // 函数exp( dE/T )的取值范围是(0,1) ，dE/T越大，则exp( dE/T )也 if ( exp( dE/T ) &gt; random( 0 , 1 ) ) Y(i+1) = Y(i) ; //接受从Y(i)到Y(i+1)的移动 &#125; T = r * T ; //降温退火 ，0 &lt; r &lt; 1 。r越大，降温越慢；r越小，降温越快 /* * 若r过大，则搜索到全局最优解的可能会较高，但搜索的过程也就较长。若r过小，则搜索的过程会很快，但最终可能会达到一个局部最优值 */ i++ ;&#125; 使用模拟退火算法解决旅行商问题旅行商问题 ( TSP , Traveling Salesman Problem ) ：有N个城市，要求从其中某个问题出发，唯一遍历所有城市，再回到出发的城市，求最短的路线。旅行商问题属于所谓的NP完全问题，精确的解决TSP只能通过穷举所有的路径组合，其时间复杂度是O(N!) 。使用模拟退火算法可以比较快的求出TSP的一条近似最优路径。（使用遗传算法也是可以的，我将在下一篇文章中介绍）模拟退火解决TSP的思路： 产生一条新的遍历路径P(i+1)，计算路径P(i+1)的长度L( P(i+1) ) 若L(P(i+1)) &lt; L(P(i))，则接受P(i+1)为新的路径，否则以模拟退火的那个概率接受P(i+1) ，然后降温 重复步骤1，2直到满足退出条件 产生新的遍历路径的方法有很多，下面列举其中3种： 随机选择2个节点，交换路径中的这2个节点的顺序。 随机选择2个节点，将路径中这2个节点间的节点顺序逆转。 随机选择3个节点m，n，k，然后将节点m与n间的节点移位到节点k后面。","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"random algorithm","slug":"random-algorithm","permalink":"atlantic8.github.io/tags/random-algorithm/"}]},{"title":"Insert Interval","slug":"Insert-Interval","date":"2016-09-07T14:20:10.000Z","updated":"2018-12-16T14:08:06.270Z","comments":true,"path":"2016/09/07/Insert-Interval/","link":"","permalink":"atlantic8.github.io/2016/09/07/Insert-Interval/","excerpt":"","text":"ProblemGiven a set of non-overlapping intervals, insert a new interval into the intervals (merge if necessary).You may assume that the intervals were initially sorted according to their start times. Example 1:Given intervals [1,3],[6,9], insert and merge [2,5] in as [1,5],[6,9]. Example 2:Given [1,2],[3,5],[6,7],[8,10],[12,16], insert and merge [4,9] in as [1,2],[3,10],[12,16]. This is because the new interval [4,9] overlaps with [3,5],[6,7],[8,10]. Solution题的意思比较直观，简洁的代码是最棒的 12345678910111213public List&lt;Interval&gt; insert(List&lt;Interval&gt; intervals, Interval newInterval) &#123; int i=0; // 把能合并的区间之前的区间skip while (i&lt;intervals.size() &amp;&amp; intervals.get(i).end&lt;newInterval.start) i++; // 把能合并的区间删除 while (i&lt;intervals.size() &amp;&amp; intervals.get(i).start&lt;=newInterval.end) &#123; newInterval = new Interval(Math.min(intervals.get(i).start, newInterval.start), Math.max(intervals.get(i).end, newInterval.end)); intervals.remove(i); &#125; // 添加合并完的集合 intervals.add(i,newInterval); return intervals;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Container With Most Water","slug":"Container-With-Most-Water","date":"2016-09-07T13:43:54.000Z","updated":"2018-12-16T14:08:06.184Z","comments":true,"path":"2016/09/07/Container-With-Most-Water/","link":"","permalink":"atlantic8.github.io/2016/09/07/Container-With-Most-Water/","excerpt":"","text":"ProblemGiven n non-negative integers a1, a2, …, an, where each represents a point at coordinate (i, ai).n vertical lines are drawn such that the two endpoints of line i is at (i, ai) and (i, 0).Find two lines, which together with x-axis forms a container, such that the container contains the most water. Solution思路如下：假如已经计算了i和j之间的最大值 假如: height[i]&lt;height[j]，因为对所有的k属于[i+1, j-1]，必然有m[i][j] 大于 m[i][k]，所以++i 反之：—j 1234567891011121314class Solution &#123;public: int maxArea(vector&lt;int&gt; &amp;height) &#123; int i=0, j=height.size()-1, maxArea=0; while (i &lt; j) &#123; maxArea = max(maxArea, (j-i)*min(height[i],height[j])); if (height[i] &lt;= height[j]) ++i; else --j; &#125; return maxArea; &#125;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Greedy","slug":"Greedy","permalink":"atlantic8.github.io/tags/Greedy/"}]},{"title":"Binary Tree Traverse","slug":"Binary-Tree-Traverse","date":"2016-09-07T12:27:27.000Z","updated":"2018-12-16T14:08:06.179Z","comments":true,"path":"2016/09/07/Binary-Tree-Traverse/","link":"","permalink":"atlantic8.github.io/2016/09/07/Binary-Tree-Traverse/","excerpt":"","text":"updated 前序遍历根据前序遍历访问的顺序，优先访问根结点，然后再分别访问左孩子和右孩子。即对于任一结点，其可看做是根结点，因此可以直接访问，访问完之后，若其左孩子不为空，按相同规则访问它的左子树；当访问其左子树时，再访问它的右子树。因此其处理过程如下：首先将根节点入栈，然后对于任一结点P： 弹出节点P，访问P 分别将节点P的右、左孩子入栈（如果有的话） 123456789101112void preOrder(TreeNode *root) &#123; //非递归前序遍历 stack&lt;TreeNode*&gt; s; TreeNode *p=root; s.push(p); while(!s.empty()) &#123; p = s.top(); s.pop(); visit(p); if (p-&gt;right) s.push(p-&gt;right); if (p-&gt;left) s.push(p-&gt;left); &#125;&#125; 中序遍历顺序：左、中、右 对于任一结点P， 不断找当前结点的左边的子孙，将不是NULL的节点入栈 否则，弹出一个节点，并访问它，将其右子树入栈 直到P为NULL并且栈为空则遍历结束 123456789101112131415void inOrder(TreeNode *root) &#123; //非递归中序遍历 stack&lt;TreeNode*&gt; s; TreeNode *p=root; while (p!=NULL || !s.empty()) &#123; if (p != NULL) &#123; s.push(p); p = p-&gt;left; &#125; else &#123; p = s.top(); s.pop(); visit(p); p = p-&gt;right; &#125; &#125;&#125; 后序遍历顺序：左、右、中一个有用的规则是：先遍历到的点总是后访问的 123456789101112131415void postOrder(TreeNode *root) &#123; //非递归后序遍历 stack&lt;TreeNode*&gt; sTraverse, sVisit; sTraverse.push(root); while(!s.empty()) &#123; TreeNode * p = sTraverse.top(); sTraverse.pop(); sVisit.push(p); if (p-&gt;left) sTraverse.push(p-&gt;left); if (p-&gt;right) sTraverse.push(p-&gt;right); &#125; while (!sVisit.empty()) &#123; visit(sVisit.top()); sVisit.pop(); &#125;&#125;","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"Binary Tree","slug":"Binary-Tree","permalink":"atlantic8.github.io/tags/Binary-Tree/"}]},{"title":"Palindrome Partitioning II","slug":"Palindrome-Partitioning-II","date":"2016-09-06T13:50:52.000Z","updated":"2018-12-16T14:08:06.371Z","comments":true,"path":"2016/09/06/Palindrome-Partitioning-II/","link":"","permalink":"atlantic8.github.io/2016/09/06/Palindrome-Partitioning-II/","excerpt":"","text":"ProblemGiven a string s, partition s such that every substring of the partition is a palindrome. Return the minimum cuts needed for a palindrome partitioning of s. For example, given s = “aab”,Return 1 since the palindrome partitioning [“aa”,”b”] could be produced using 1 cut. Solution这题明显是DP题，因为满足最优子结构性质。刚开始，我使用了如下的表达式1num[i,j] = min(num[i,k]+num[k+1,j]) 但是超时了，在例子很大的时候TLE，其复杂度达到: O(n^3) 下面介绍通过的代码思想： 用num[i]数组记录字符串s的[0~i-1]子串需要的最小切割次数 每到一个i，向两侧延伸寻找最长的回文子串，需要分别考虑回文子串的长度为奇数、偶数 比如考虑在i时的奇数长度回文子串，长度/2=k，则num[i+k]=min(num[i-k-1]+1, num[i+k]) 123456789101112131415public class Solution &#123; public int minCut(String s) &#123; int[] num = new int[s.length()+1]; for (int i = 0; i &lt;= s.length(); i++) num[i] = i-1; for (int i = 0; i &lt; s.length(); i++) &#123; // 奇数回文子串 for (int j=0; i-j&gt;=0 &amp;&amp; i+j&lt;s.length() &amp;&amp; s.charAt(i-j)==s.charAt(i+j); j++) num[i+j+1] = Math.min(num[i+j+1], num[i-j]+1); // 偶数回文子串 for (int j=0; i-j&gt;=0 &amp;&amp; i+j+1&lt;s.length() &amp;&amp; s.charAt(i-j)==s.charAt(i+j+1); j++) num[i+j+2] = Math.min(num[i+j+2], num[i-j]+1); &#125; return num[s.length()]; &#125;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"DP","slug":"DP","permalink":"atlantic8.github.io/tags/DP/"},{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Patching Array","slug":"Patching-Array","date":"2016-09-05T08:47:55.000Z","updated":"2018-12-16T14:08:06.376Z","comments":true,"path":"2016/09/05/Patching-Array/","link":"","permalink":"atlantic8.github.io/2016/09/05/Patching-Array/","excerpt":"","text":"ProblemGiven a sorted positive integer array nums and an integer n, add/patch elements to the array such that any number in range [1, n] inclusive can be formed by the sum of some elements in the array. Return the minimum number of patches required. Example 1:nums = [1, 3], n = 6Return 1. Combinations of nums are [1], [3], [1,3], which form possible sums of: 1, 3, 4.Now if we add/patch 2 to nums, the combinations are: [1], [2], [3], [1,3], [2,3], [1,2,3].Possible sums are 1, 2, 3, 4, 5, 6, which now covers the range [1, 6].So we only need 1 patch. Example 2:nums = [1, 5, 10], n = 20Return 2.The two patches can be [2, 4]. Example 3:nums = [1, 2, 2], n = 5Return 0. Solution思路如下：设absent为当前缺失的最小的数，ind为nums的索引，count计数需要添加的数 如果存在一个nums[ind]小于absent，那么absent=nums[ind]+absent。这是因为[1,absent)都可以获得，现在又多了一个nums[ind]，所以当前可以得到的范围是[1,absent+nums[ind])，即absent=nums[ind]+absent 否则，我们需要引入absent，因为不引入它就没有办法继续，引入absent后，因为[1,absent-1]也是可以得到的，所以当前可以得到的集合是[1,absent+absent-1]，所以新的absent=2*absent 还需要注意的是数的表示范围，由于有一个例子n=2147483647，已经超出了int的表示范围，所以absent必须是long型的 1234567891011121314public class Solution &#123; public int minPatches(int[] nums, int n) &#123; long count = 0, absent = 1, ind = 0; while (absent &lt;= n) &#123; if (ind &lt; nums.length &amp;&amp; nums[(int) ind] &lt;= absent) &#123; absent += nums[(int) ind++]; &#125; else &#123; ++count; absent += absent; &#125; &#125; return (int) count; &#125;&#125;","categories":[],"tags":[]},{"title":"Linked List Cycle","slug":"Linked-List-Cycle","date":"2016-09-04T07:41:13.000Z","updated":"2018-12-16T14:08:06.298Z","comments":true,"path":"2016/09/04/Linked-List-Cycle/","link":"","permalink":"atlantic8.github.io/2016/09/04/Linked-List-Cycle/","excerpt":"","text":"Problem 1Description Given a linked list, determine if it has a cycle in it. Note: Solve it using O(1) space Solution 1决定一个list是否有环的方法是： 使用一个慢指针slow每次移动1步 使用一个快指针fast每次移动2步 如果快指针和慢指针在迭代一定次数后相遇，则存在回路 否则，如果fast.next=null或者slow.next=null，说明不存在回路 1234567891011public boolean hasCycle(ListNode head) &#123; if(head==null) return false; ListNode walker = head; ListNode runner = head; while(runner.next!=null &amp;&amp; runner.next.next!=null) &#123; walker = walker.next; runner = runner.next.next; if (walker==runner) return true; &#125; return false;&#125; Problem 2Description Given a linked list, return the node where the cycle begins. If there is no cycle, return null. Note: Do not modify the linked list. Solve it using O(1) space Solution 2确认一个list是否有回路的方法如上。确定回路入口的方法如下： 不妨假设list头到loop入口的距离是 l1 loop入口到两个指针相遇点的距离是 l2 loop的长度位 c，n表示fast指针绕loop的圈数 指针相遇时，slow指针走过的距离是：l1 + l2 + m x c，fast指针走过的距离是：l1 + l2 + n x c 因为fast指针的路程是slow指针的两倍， 所以：l1 + l2 + n x c = 2 x (l1 + l2 + m x c) l1 = (c-l2) + (n-2 x m-1)c，而c-l2是相遇点到loop入口的距离 所以分别从list头和指针相遇点出发、每次移动步长均为1的两个指针会在loop入口回合 12345678910111213141516171819202122public class Solution &#123; public ListNode detectCycle(ListNode head) &#123; ListNode slow = head; ListNode fast = head; while (fast!=null &amp;&amp; fast.next!=null)&#123; fast = fast.next.next; slow = slow.next; // 找到快指针和慢指针的汇合点，说明loop存在 if (fast == slow)&#123; ListNode slow2 = head; // 分别从链表头和汇合点出发的指针，在loop入口处相遇 while (slow2 != slow)&#123; slow = slow.next; slow2 = slow2.next; &#125; return slow; &#125; &#125; return null; &#125;&#125; 相似问题：Find the Duplicate Number","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Find the Duplicate Number","slug":"Find-the-Duplicate-Number","date":"2016-09-04T07:28:10.000Z","updated":"2018-12-16T14:08:06.234Z","comments":true,"path":"2016/09/04/Find-the-Duplicate-Number/","link":"","permalink":"atlantic8.github.io/2016/09/04/Find-the-Duplicate-Number/","excerpt":"","text":"ProblemDescription Given an array nums containing n + 1 integers where each integer is between 1 and n (inclusive), prove that at least one duplicate number must exist. Assume that there is only one duplicate number, find the duplicate one. Note: You must not modify the array (assume the array is read only). You must use only constant, O(1) extra space. Your runtime complexity should be less than O(n2). There is only one duplicate number in the array, but it could be repeated more than once. Solution 题中给定的是数组，由于长度位n+1的数组只有1-n的整数，所以可以把数组看成静态链表，数组下标是节点值，对应的值指示下一节点的值 我们所要求的重复元素其实就是：不同的下标对应相同的值，在静态链表中也就是loop的入口节点的值 由于必然存在重复，所以这个静态链表肯定存在loop，查找loop入口节点的值方法和Linked List Cycle II一致 123456789101112131415public class Solution &#123; public int findDuplicate(int[] nums) &#123; int slow=nums[0], fast=nums[nums[0]]; while (fast != slow) &#123; slow=nums[slow]; fast=nums[nums[fast]]; &#125; fast = 0; while (fast != slow) &#123; slow=nums[slow]; fast=nums[fast]; &#125; return fast; &#125;&#125; 相关问题：Linked List Cycle II","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Majority Element","slug":"Majority-Element","date":"2016-09-04T07:27:02.000Z","updated":"2018-12-16T14:08:06.316Z","comments":true,"path":"2016/09/04/Majority-Element/","link":"","permalink":"atlantic8.github.io/2016/09/04/Majority-Element/","excerpt":"","text":"ProblemGiven an integer array of size n, find all elements that appear more than ⌊n/3⌋(这是向下取整符号) times. The algorithm should run in linear time and in O(1) space. Solution这是主元素法的扩展，原主元素问题是： 设T[0:n-1]是n个元素的数组。对任一元素x，设S(x)={i|T[i]=x}。当|S(x)|&gt;n/2时，称x为T的主元素。设计一个线性时间算法，确定T[0:n-1]是否有一个主元素。 解法为：如果每次删除两个不同的数字（不管是否包含主元素的数字），那么在剩下的数字中，主元素的出现的次数仍然超过总数的一半。可以通过不断的重复这个过程，转化为更小的问题，从而得到答案。 1234567891011121314151617181920master(A): n ← length[A] count ← 1 seed ← A[0] 找候选主元素，即数目最多的那个元素 for i ← 1 to n – 1 do if A[i] = seed then count ← count + 1 else if count &gt; 0 then count ← count – 1 else seed ← A[i] 查找候选主元素是否是主元素 count ← 0 for i ← 0 to n – 1 do if A[i] = seed then count ← count + 1 if count &gt; n/2 then return seed and count else return null 在此基础上，本题的解题思路： 题目要求寻找个数大于⌊n/3⌋的元素，那么长度为n的数组中最多只有两个这样的元素。 使用两个标记，寻找出现次数最大和次大的元素 判断这两个元素是否满足：个数大于⌊n/3⌋ 123456789101112131415161718192021222324public Class Solution &#123; public List&lt;Integer&gt; majorityElement(int[] nums) &#123; List&lt;Integer&gt; ret = new ArrayList&lt;Integer&gt;(); if (nums.length == 0) return ret; int cand1=0,cand2=0,count1=0,count2=0; for (int i=0; i&lt;nums.length; i++) &#123; // if elseif可以防止cand1,cand2相同 if (nums[i] == cand1) ++count1; else if (nums[i] == cand2) ++count2; else if (count1 == 0) &#123; cand1 = nums[i]; count1 = 1; &#125; else if (count2 == 0) &#123; cand2 = nums[i]; count2 = 1; &#125; else &#123; --count1; --count2; &#125; &#125; count1=0; count2=0; // 判断候选元素数目是否满足条件 for (int i=0; i &lt; nums.length; i++) &#123; if (nums[i] == cand1) ++count1; else if (nums[i] == cand2) ++count2; &#125; if (count1 &gt; nums.length/3) ret.add(cand1); if (count2 &gt; nums.length/3) ret.add(cand2); return ret; &#125;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Count Primes","slug":"Count-Primes","date":"2016-09-04T07:24:44.000Z","updated":"2018-12-16T14:08:06.195Z","comments":true,"path":"2016/09/04/Count-Primes/","link":"","permalink":"atlantic8.github.io/2016/09/04/Count-Primes/","excerpt":"","text":"ProblemDescription: Count the number of prime numbers less than a non-negative number, n. Solution埃拉托斯特尼筛法本题使用埃拉托斯特尼筛法解，此方法用于找出一定范围内的所有质数，也是最有效的方法之一 原理：从2开始，将每个质数的倍数标记成合数，倍数的实现可以借助于等差数列，不断剔除合数即可 方法：找出sqrt(n)以内的质数、并将相应的合数去掉即可。 说明：大于sqrt(n)的合数可以被消除，因为假设一个合数sqrt(n)小于z=a*b，那么，min(a,b)小于sqrt(n)，所以算法在遇到min(a,b)的时候就已经将z标记为合数了 埃拉托斯特尼筛法的伪代码如下12345678910Input: an integer n &gt; 1Let A be an array of Boolean values, indexed by integers 2 to n,initially all set to true.for i = 2, 3, 4, ..., not exceeding √n: if A[i] is true: for j = i2, i2+i, i2+2i, i2+3i, ..., not exceeding n : A[j] := falseOutput: all i such that A[i] is true. 具体实现过程中，java使用BitSet类可以节约空间。 BitSet BitSet类实现了大小可动态改变, 取值为true或false的位集合(每位长度位1bit)。用于表示一组布尔标志，默认情况下，set 中所有位的初始值都是 false。 使用方法 1234567891011121314151617181920// 构造函数public BitSet();public BitSet(int nbits);// 方法public void set(int pos); //位置pos的字位设置为truepublic void set(int bitIndex, boolean value); //将指定索引处的位设置为指定的值public void clear(int pos); //位置pos的字位设置为falsepublic void clear(); //将此 BitSet 中的所有位设置为 falsepublic int cardinality(); //返回此 BitSet 中设置为 true 的位数public boolean get(int pos); //返回位置是pos的字位值public void and(BitSet other); //other同该字位集进行与操作，结果作为该字位集的新值public void or(BitSet other); //other同该字位集进行或操作，结果作为该字位集的新值public void xor(BitSet other); //other同该字位集进行异或操作，结果作为该字位集的新值public void andNot(BitSet set); //清除此 BitSet 中所有的位,set-用来屏蔽此 BitSet 的 BitSetpublic int size(); //返回此 BitSet 表示位值时实际使用空间的位数public int length(); //返回此 BitSet 的“逻辑大小”：BitSet 中最高设置位的索引加 1public int hashCode(); //返回该集合Hash 码， 这个码同集合中的字位值有关public boolean equals(Object other); //如果other中的字位同集合中的字位相同，返回truepublic Object clone(); //克隆此 BitSet，生成一个与之相等的新 BitSetpublic String toString(); //返回此位 set 的字符串表示形式","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"prime","slug":"prime","permalink":"atlantic8.github.io/tags/prime/"}]},{"title":"Super Ugly Number","slug":"Super-Ugly-Number","date":"2016-09-04T02:09:59.000Z","updated":"2018-12-16T14:08:06.425Z","comments":true,"path":"2016/09/04/Super-Ugly-Number/","link":"","permalink":"atlantic8.github.io/2016/09/04/Super-Ugly-Number/","excerpt":"","text":"ProblemWrite a program to find the nth super ugly number. Super ugly numbers are positive numbers whose all prime factors are in the given prime list primes of size k. For example, [1, 2, 4, 7, 8, 13, 14, 16, 19, 26, 28, 32] is the sequence of the first 12 super ugly numbers given primes = [2, 7, 13, 19] of size 4. Note:(1) 1 is a super ugly number for any given primes.(2) The given numbers in primes are in ascending order.(3) 0 &lt; k ≤ 100, 0 &lt; n ≤ 106, 0 &lt; primes[i] &lt; 1000. Solution 维护一个长度为n的数组，存储ugly数 使用一个数组idx，长度与primes一致，用以记录每个primes元素已经和哪一位的ugly相乘过，相乘过就移动之 去重，需要扫描idx，对应primes[j]*un[idx[j]]&lt;=un[i]的都要去掉 12345678910111213141516public class Solution &#123; public int nthSuperUglyNumber(int n, int[] primes) &#123; int[] pos = new int[primes.length], un = new int[n]; un[0] = 1; for (int i=1; i&lt;n; i++) &#123; un[i] = Integer.MAX_VALUE; // 找当下最小的数 for (int j=0; j&lt;primes.length; j++) un[i] = Math.min(primes[j]*un[pos[j]], un[i]); // 去重 for (int j=0; j&lt;primes.length; j++) while (primes[j]*un[pos[j]] &lt;= un[i]) pos[j]++; &#125; return un[n-1]; &#125;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Maximal Rectangle","slug":"Maximal-Rectangle","date":"2016-09-03T10:54:38.000Z","updated":"2018-12-16T14:08:06.329Z","comments":true,"path":"2016/09/03/Maximal-Rectangle/","link":"","permalink":"atlantic8.github.io/2016/09/03/Maximal-Rectangle/","excerpt":"","text":"ProblemGiven a 2D binary matrix filled with 0’s and 1’s, find the largest rectangle containing only 1’s and return its area. For example, given the following matrix: 1 0 1 0 01 0 1 1 11 1 1 1 11 0 0 1 0 Return 6. Solution本题是DP题，为了能对所有情形考虑，每一列对应一个height值，表示从当前行开始一直向上的最大高度所以具体的做法是： 每到一个位置，计算以这个位置所在列为最高的矩形面积 逐行处理，遇到0忽略，遇到1时，计算其height值 有了height，还要知道width才能计算数量，width的计算需要借助left、right和left_most、right_most 每一行的left、right到下一行才有用，因为要使用当前位置向上延伸的最高高度，所以在向两边延伸时需要上一行两边的情况 对于left，从左向右扫描，遇到0时left=0，否则left=max(left_last_row, 本行最近的0的下一位置序号)。（这里遇到0设置left=0是为了不影响下一行） 对于right，从右向左扫描，遇到0时right=行长度-1，否则，left=min(right_last_row, 本行最近的0的上一位置序号) 扫描这一行，多次计算(right-left+1)*height，并及时更新最大值 实现过程中，left、right和height可以分别用一维数组存储，详细见代码 123456789101112131415161718192021222324252627282930public class Solution &#123; public int maximalRectangle(char[][] matrix) &#123; int m=0, n=0, ret=0; if ((m=matrix.length)==0 || (n=matrix[0].length)==0) return 0; int[] height=new int[n], left=new int[n], right=new int[n]; for (int j=0; j&lt;n; j++) right[j] = n-1; for (int i=0; i&lt;m; i++) &#123; // left_most是当前点左侧最近0点的下一位 // right_most是当前点右侧最近0点的前一个 // 这两个变量可以确定以当前点为中心，连续为1的长度 int left_most = 0, right_most = n-1; // 要想使用上一行的left值，本行的left_most必须小于等于上一行对应位的left值 for (int j=0; j&lt;n; j++) &#123; if (matrix[i][j]=='0') &#123;left_most=Math.max(left_most, j+1); left[j] = 0;&#125; else left[j] = Math.max(left[j], left_most); &#125; for (int j=n-1; j&gt;=0; j--) &#123; if (matrix[i][j]=='1') right[j] = Math.min(right[j], right_most); else &#123;right_most = Math.min(right_most, j-1); right[j] = n-1;&#125; &#125; // 更新height值，并计算以本行中每个点为底，最高的矩形的面积 for (int j=0; j&lt;n; j++) &#123; if (matrix[i][j]=='0') height[j] = 0; else height[j] += 1; ret = Math.max(ret, (right[j]-left[j]+1)*height[j]); &#125; &#125; return ret; &#125;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"DP","slug":"DP","permalink":"atlantic8.github.io/tags/DP/"},{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Minimum Height Trees","slug":"Minimum-Height-Trees","date":"2016-09-03T06:29:46.000Z","updated":"2018-12-16T14:08:06.346Z","comments":true,"path":"2016/09/03/Minimum-Height-Trees/","link":"","permalink":"atlantic8.github.io/2016/09/03/Minimum-Height-Trees/","excerpt":"","text":"ProblemFor a undirected graph with tree characteristics, we can choose any node as the root. The result graph is then a rooted tree. Among all possible rooted trees, those with minimum height are called minimum height trees (MHTs). Given such a graph, write a function to find all the MHTs and return a list of their root labels. FormatThe graph contains n nodes which are labeled from 0 to n - 1. You will be given the number n and a list of undirected edges (each edge is a pair of labels). You can assume that no duplicate edges will appear in edges. Since all edges are undirected, [0, 1] is the same as [1, 0] and thus will not appear together in edges. Example 1: Given n = 4, edges = [[1, 0], [1, 2], [1, 3]] 0 | 1 / \\ 2 3 return [1] Example 2: Given n = 6, edges = [[0, 3], [1, 3], [2, 3], [4, 3], [5, 4]] 0 1 2 \\ | / 3 | 4 | 5 return [3, 4] Solution解体思想是，维护图的每个度为1的节点为叶节点集合，loop： 每层循环，对每一个叶节点，从叶节点集合中去掉当前页节点，并去除该叶节点上的边(指向此叶节点的边也得去掉) 对于，每个去掉的叶节点，如果与其相连的节点也成为了叶节点，将其加入叶节点集合 每次删除一个叶节点，将节点总数-1 当节点总数&lt;=2时，退出循环，此时叶节点集合即为所求 12345678910111213141516171819202122232425262728public class Solution &#123; public List&lt;Integer&gt; findMinHeightTrees(int n, int[][] edges) &#123; if (n == 1) return Collections.singletonList(0); HashMap&lt;Integer, Set&lt;Integer&gt;&gt; map = new HashMap&lt;&gt;(); // 建立邻接表 for (int[] edge : edges) &#123; map.computeIfAbsent(edge[0], k-&gt;new HashSet&lt;Integer&gt;()).add(edge[1]); map.computeIfAbsent(edge[1], k-&gt;new HashSet&lt;Integer&gt;()).add(edge[0]); &#125; // 叶节点集合 List&lt;Integer&gt; leafs = new LinkedList&lt;&gt;(); for (Integer key : map.keySet()) if (map.get(key).size() == 1) leafs.add(key); while (n &gt; 2) &#123; n -= leafs.size(); List&lt;Integer&gt; new_leafs = new LinkedList&lt;&gt;(); for (Integer leaf : leafs) &#123; // 删除指向此叶节点的边 int box = map.get(leaf).iterator().next(); map.get(box).remove(leaf); // 新的叶节点出现 if (map.get(box).size() == 1) new_leafs.add(box); &#125; leafs = new_leafs; &#125; return leafs; &#125;&#125;","categories":[],"tags":[]},{"title":"Increasing Triplet Subsequence","slug":"Increasing-Triplet-Subsequence","date":"2016-09-02T01:18:26.000Z","updated":"2018-12-16T14:08:06.267Z","comments":true,"path":"2016/09/02/Increasing-Triplet-Subsequence/","link":"","permalink":"atlantic8.github.io/2016/09/02/Increasing-Triplet-Subsequence/","excerpt":"","text":"ProblemGiven an unsorted array return whether an increasing subsequence of length 3 exists or not in the array. Formally the function should:Return true if there exists i, j, ksuch that arr[i] &lt; arr[j] &lt; arr[k] given 0 ≤ i &lt; j &lt; k ≤ n-1 else return false.Your algorithm should run in O(n) time complexity and O(1) space complexity. Examples:Given [1, 2, 3, 4, 5],return true. Given [5, 4, 3, 2, 1],return false. Solution 解题思路是维护两个变量，min和mid min表示当前遇到的最小的数 mid表示在当前情况下，所有长度为2的递增序列第二个数的最小值（表示前面有一个比mid还小的数且没有一个小于mid的数能取代mid的位置） 当出现一个比min大的数时： 如果这个数比mid大，则返回true 如果这个数比mid小，则更新mid为当前值 代码如下：123456789public boolean increasingTriplet(int[] nums) &#123; int min = Integer.MAX_VALUE, secondMin = Integer.MAX_VALUE; for(int num : nums)&#123; if(num &lt;= min) min = num; else if(num &lt; secondMin) secondMin = num; else if(num &gt; secondMin) return true; &#125; return false;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"}]},{"title":"Design Twitter","slug":"Design-Twitter","date":"2016-09-01T11:10:24.000Z","updated":"2018-12-16T14:08:06.219Z","comments":true,"path":"2016/09/01/Design-Twitter/","link":"","permalink":"atlantic8.github.io/2016/09/01/Design-Twitter/","excerpt":"","text":"ProblemDesign a simplified version of Twitter where users can post tweets, follow/unfollow another user and is able to see the 10 most recent tweets in the user’s news feed. Your design should support the following methods: postTweet(userId, tweetId): Compose a new tweet. getNewsFeed(userId): Retrieve the 10 most recent tweet ids in the user’s news feed. Each item in the news feed must be posted by users who the user followed or by the user herself. Tweets must be ordered from most recent to least recent. follow(followerId, followeeId): Follower follows a followee. unfollow(followerId, followeeId): Follower unfollows a followee. Example123456789101112131415161718192021222324Twitter twitter = new Twitter();// User 1 posts a new tweet (id = 5).twitter.postTweet(1, 5);// User 1's news feed should return a list with 1 tweet id -&gt; [5].twitter.getNewsFeed(1);// User 1 follows user 2.twitter.follow(1, 2);// User 2 posts a new tweet (id = 6).twitter.postTweet(2, 6);// User 1's news feed should return a list with 2 tweet ids -&gt; [6, 5].// Tweet id 6 should precede tweet id 5 because it is posted after tweet id 5.twitter.getNewsFeed(1);// User 1 unfollows user 2.twitter.unfollow(1, 2);// User 1's news feed should return a list with 1 tweet id -&gt; [5],// since user 1 is no longer following user 2.twitter.getNewsFeed(1); Solution解题思路：如果将所有用户的tweet放在一个队列里，在getNewsFeed时遍历查找会超时 每个用户维护一个follow集合，集合中元素时该用户关注的用户ID 每个用户维护一个自己的tweet列表，列表元素包含时间和tweet ID，列表按时间排好序 getNewsFeed时，采用merge k sorted array的思想，将用户自己和关注的用户的tweet列表放入一个堆中 每次弹出第一个元素对应时间最近的列表，取出第一个元素，然后再将其加入进堆中（如果该列表还有元素） 取出的元素达到要求或者堆为空时退出 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class Twitter &#123; HashMap&lt;Integer, Set&lt;Integer&gt;&gt; cmap; HashMap&lt;Integer, List&lt;int[]&gt;&gt; tw; int count; /** Initialize your data structure here. */ public Twitter() &#123; cmap = new HashMap&lt;&gt;(); tw = new HashMap&lt;&gt;(); count = 0; &#125; /** Compose a new tweet. */ public void postTweet(int userId, int tweetId) &#123; int[] tmp = &#123;count++, tweetId&#125;; tw.computeIfAbsent(userId, k-&gt;new LinkedList&lt;&gt;()).add(0,tmp); System.out.println(count); &#125; /** Retrieve the 10 most recent tweet ids in the user's news feed. Each item in the news feed must be posted by users who the user followed or by the user herself. Tweets must be ordered from most recent to least recent. */ public List&lt;Integer&gt; getNewsFeed(int userId) &#123; int n = 0; Set&lt;Integer&gt; tmp = cmap.containsKey(userId)?cmap.get(userId):new HashSet&lt;Integer&gt;(); List&lt;Integer&gt; ret = new LinkedList&lt;&gt;(); PriorityQueue&lt;List&lt;int[]&gt; &gt; pq = new PriorityQueue&lt;&gt;(new Comparator&lt;List&lt;int[]&gt;&gt;()&#123; @Override public int compare(List&lt;int[]&gt; o1, List&lt;int[]&gt; o2) &#123; // TODO Auto-generated method stub return o2.get(0)[0] - o1.get(0)[0]; &#125;&#125;); if (tw.containsKey(userId) &amp;&amp; tw.get(userId).size()&gt;0) pq.offer(tw.get(userId)); for (Integer it : tmp) &#123; if (!tw.containsKey(it) || tw.get(it).size()==0) continue; pq.offer(tw.get(it)); &#125; while (pq.size()&gt;0 &amp;&amp; n++&lt;10) &#123; List&lt;int[]&gt; list = pq.poll(); ret.add(list.get(0)[1]); if (list.size()&gt;1) pq.offer(list.subList(1, list.size())); &#125; return ret; &#125; /** Follower follows a followee. If the operation is invalid, it should be a no-op. */ public void follow(int followerId, int followeeId) &#123; if (followerId == followeeId) return; cmap.computeIfAbsent(followerId, k -&gt; new HashSet&lt;Integer&gt;()).add(followeeId); &#125; /** Follower unfollows a followee. If the operation is invalid, it should be a no-op. */ public void unfollow(int followerId, int followeeId) &#123; if (followerId==followeeId || !cmap.containsKey(followerId)) return; Set&lt;Integer&gt; tmp = cmap.get(followerId); if (!tmp.contains(followeeId)) return; tmp.remove(followeeId); &#125;&#125; 实现过程中，tweet集合不使用java自带的List，改用自定义类和索引标识可以进一步加速程序。","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[]},{"title":"Median of Two Sorted Arrays","slug":"Median-of-Two-Sorted-Arrays","date":"2016-09-01T03:01:10.000Z","updated":"2018-12-16T14:08:06.342Z","comments":true,"path":"2016/09/01/Median-of-Two-Sorted-Arrays/","link":"","permalink":"atlantic8.github.io/2016/09/01/Median-of-Two-Sorted-Arrays/","excerpt":"","text":"ProblemThere are two sorted arrays nums1 and nums2 of size m and n respectively. Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)). Example 1:nums1 = [1, 3]nums2 = [2] The median is 2.0Example 2:nums1 = [1, 2]nums2 = [3, 4] The median is (2 + 3)/2 = 2.5 Solution基本思路是分别将A、B分别切割，两个左边的部分合并，两个右侧的部分合并，如下所示：123 left_part | right_partA[0], A[1], ..., A[i-1] | A[i], A[i+1], ..., A[m-1]B[0], B[1], ..., B[j-1] | B[j], B[j+1], ..., B[n-1] 如果12len(left_part) == len(right_part)max(left_part) &lt;= min(right_part) 第一个条件可以通过设定j的值满足，设置j=(m+n+1)/2，使得左边部分的数量不小于右边数量，所以整体为奇数时，左边部分的最大值即为median。第二个条件需要验证，然后根据相应的情况移动A的切割选取范围。那么12median=[max(left_part) + min(right_part)]/2 m+n是偶数median=[] 寻找A数组的分割位置可以使用binary search整个算法的时间复杂度为O(log(min(m,n)))代码如下：12345678910111213141516171819202122232425262728293031def median(A, B): m, n = len(A), len(B) if m &gt; n: A, B, m, n = B, A, n, m if n == 0: raise ValueError # 设置half_len=(m + n + 1) / 2, 保证左边部分总是不小于右边 imin, imax, half_len = 0, m, (m + n + 1) / 2 while imin &lt;= imax: i = (imin + imax) / 2 j = half_len - i if j &gt; 0 and i &lt; m and B[j-1] &gt; A[i]: # i 太小 imin = i + 1 elif i &gt; 0 and j &lt; n and A[i-1] &gt; B[j]: # i 太大 imax = i - 1 else: # i 刚刚好 if i == 0: max_of_left = B[j-1] elif j == 0: max_of_left = A[i-1] else: max_of_left = max(A[i-1], B[j-1]) # 考虑整体是奇数的情况 if (m + n) % 2 == 1: return max_of_left if i == m: min_of_right = B[j] elif j == n: min_of_right = A[i] else: min_of_right = min(A[i], B[j]) # 考虑整体是偶数的情况 return (max_of_left + min_of_right) / 2.0","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Divide & Conquer","slug":"Divide-Conquer","permalink":"atlantic8.github.io/tags/Divide-Conquer/"}]},{"title":"Perfect Rectangle","slug":"Perfect-Rectangle","date":"2016-08-30T11:50:39.000Z","updated":"2018-12-16T14:08:06.378Z","comments":true,"path":"2016/08/30/Perfect-Rectangle/","link":"","permalink":"atlantic8.github.io/2016/08/30/Perfect-Rectangle/","excerpt":"","text":"ProblemGiven N axis-aligned rectangles where N &gt; 0, determine if they all together form an exact cover of a rectangular region. Each rectangle is represented as a bottom-left point and a top-right point. For example, a unit square is represented as [1,1,2,2]. (coordinate of bottom-left point is (1, 1) and top-right point is (2, 2)). Example ![](https://leetcode.com/static/images/problemset/rectangle_perfect.gif) rectangles = [ [1,1,3,3], [3,1,4,2], [3,2,4,4], [1,3,2,4], [2,3,3,4]]Return true. All 5 rectangles together form an exact cover of a rectangular region. Solution可以拼凑成矩形的情形应当满足一下条件： 大矩形面积 = sum(小矩形面积) 除了最外边的4个角(corner)，其他角都应该重复偶数次(2或者4次) 重复在同一个点的角(corner)应该方向不同(左下、左上、右下、右上) 解决思路： 使用哈希表维护边角()和其类型，类型分别取值1、2、4、8 这些类型其二进制都只有一个位是1。与运算结果不为0时表示出现重复(方块重叠发生)，否则做或运算并更新哈希表(保持这个值的存在) 单独考虑总体矩形的边角，最后哈希表里值为1、2、4、8的只能且必须有4个 1234567891011121314151617181920212223242526HashMap&lt;String, Integer&gt; mapp = new HashMap&lt;&gt;(); public boolean isRectangleCover(int[][] rectangles) &#123; if (rectangles.length==0 || rectangles[0].length==0) return false; int minx=Integer.MAX_VALUE,miny=Integer.MAX_VALUE,maxx=0,maxy=0,sum=0,count=0; for (int[] rect : rectangles) &#123; minx = Math.min(minx, rect[0]); miny = Math.min(miny, rect[1]); maxx = Math.max(maxx, rect[2]); maxy = Math.max(maxy, rect[3]); if (isRectangleCover_assist(rect[0]+\" \"+rect[1], 1)) return false; if (isRectangleCover_assist(rect[0]+\" \"+rect[3], 2)) return false; if (isRectangleCover_assist(rect[2]+\" \"+rect[1], 4)) return false; if (isRectangleCover_assist(rect[2]+\" \"+rect[3], 8)) return false; sum += (rect[2]-rect[0])*(rect[3]-rect[1]); &#125; for (Integer tmp : mapp.values()) // 只有整体矩形的四个边角才是这些值 if (tmp==1 || tmp==2 || tmp==4 || tmp==8) count += 1; return count==4 &amp;&amp; sum==(maxx-minx)*(maxy-miny); &#125; // 确定mapp中是否已经存在两个一样的pair public boolean isRectangleCover_assist(String key, int value) &#123; if (mapp.containsKey(key) &amp;&amp; (mapp.get(key)&amp;value)!=0) return true; mapp.put(key, mapp.containsKey(key)?mapp.get(key)|value:value); return false; &#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Geometry","slug":"Geometry","permalink":"atlantic8.github.io/tags/Geometry/"}]},{"title":"Longest Substring","slug":"Longest-Substring","date":"2016-08-27T02:55:20.000Z","updated":"2018-12-16T14:08:06.312Z","comments":true,"path":"2016/08/27/Longest-Substring/","link":"","permalink":"atlantic8.github.io/2016/08/27/Longest-Substring/","excerpt":"","text":"Longest SubstringProblem — Without Repeating CharactersGiven a string, find the length of the longest substring without repeating characters. Examples: Given “abcabcbb”, the answer is “abc”, which the length is 3. Given “bbbbb”, the answer is “b”, with the length of 1. Given “pwwkew”, the answer is “wke”, with the length of 3. Note that the answer must be a substring, “pwke” is a subsequence and not a substring. Solution 双指针思想，滑动窗口 没找到T包含所有字符时，end指针移动，找到时移动start指针 注意滑动窗口、双指针类的题目一般都是这么解的 12345678910int lengthOfLongestSubstring(string s) &#123; vector&lt;int&gt; map(128,0); int counter=0, begin=0, end=0, d=0; while(end&lt;s.size())&#123; if(map[s[end++]]++&gt;0) counter++; while(counter&gt;0) if(map[s[begin++]]--&gt;1) counter--; d=max(d, end-begin); //while valid, update d &#125; return d;&#125; Problem — At Most Two Distinct CharactersGiven a string, find the length of the longest substring T that contains at most 2 distinct characters. For example, Given s = “eceba”, T is “ece” which its length is 3. Solution 子串只能包含最多2个不同的字符，所以扫描的时候，count表示子串不同字符的数量 需要记录子串中每个字符出现的次数，第一次出现时count+1，第二次、三次等不需要 加入字符后，如果count&gt;2，需要从子串的头部删除元素，直到满足count&lt;=2为止 1234567891011121314int lengthOfLongestSubstringTwoDistinct(string s) &#123; vector&lt;int&gt; map(128, 0); int counter=0, begin=0, end=0, d=0; while(end&lt;s.size())&#123; // add a new character if(map[s[end++]]++==0) counter++; // at most 2 distinct characters, so, count &lt;= 2 // only when map[s[begin]]--==1, we get rid of s[begin] completely while(counter&gt;2) if(map[s[begin++]]--==1) counter--; // update d d=max(d, end-begin); &#125; return d;&#125; Problem — At Most k Distinct CharactersGiven a string s, find the length of the longest substring T that contains at most k distinct characters. ExampleFor example, Given s = “eceba”, k = 3, T is “eceb” which its length is 4 Solution思路同上一题，只需要将2变成k即可 1234567891011121314int lengthOfLongestSubstringKDistinct(string s, int k) &#123; vector&lt;int&gt; map(128, 0); int counter=0, begin=0, end=0, d=0; while(end&lt;s.size())&#123; // add a new character if(map[s[end++]]++==0) counter++; // at most k distinct characters, so, count &lt;= k // only when map[s[begin]]--==1, we get rid of s[begin] completely while(counter&gt;k) if(map[s[begin++]]--==1) counter--; // update d d=max(d, end-begin); &#125; return d;&#125; Generalization对于要求寻找特定要求的子串的问题，通用解法就是滑动窗口的思想，使用哈希表和双指针，可以有如下模板：12345678910111213141516171819202122232425int findSubstring(string s)&#123; vector&lt;int&gt; map(128,0); int counter; // check whether the substring is valid int begin=0, end=0; //two pointers, one point to tail and one head int d; //the length of substring for() &#123; /* initialize the hash map here */ &#125; while(end&lt;s.size())&#123; if(map[s[end++]]-- ?)&#123; /* modify counter here */ &#125; while(/* counter condition */)&#123; /* update d here if finding minimum*/ //increase begin to make it invalid/valid again if(map[s[begin++]]++ ?)&#123; /*modify counter here*/ &#125; &#125; /* update d here if finding maximum*/ &#125; return d;&#125; 原文地址，感谢作者","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"String","slug":"String","permalink":"atlantic8.github.io/tags/String/"},{"name":"Sliding window","slug":"Sliding-window","permalink":"atlantic8.github.io/tags/Sliding-window/"}]},{"title":"Minimum Window Substring","slug":"Minimum-Window-Substring","date":"2016-08-27T02:26:59.000Z","updated":"2018-12-16T14:08:06.352Z","comments":true,"path":"2016/08/27/Minimum-Window-Substring/","link":"","permalink":"atlantic8.github.io/2016/08/27/Minimum-Window-Substring/","excerpt":"","text":"ProblemGiven a string S and a string T, find the minimum window in S which will contain all the characters in T in complexity O(n). For example,S = “ADOBECODEBANC”T = “ABC”Minimum window is “BANC”. Note: If there is no such window in S that covers all characters in T, return the empty string “”. If there are multiple such windows, you are guaranteed that there will always be only one unique minimum window in S. Solution 使用滑动窗口、两个指针的思想，从前到后扫描 没找到T包含所有字符时，end指针移动，找到时移动start指针 注意滑动窗口、双指针类的题目一般都是这么解的 12345678910111213string minWindow(string s, string t) &#123; vector&lt;int&gt; map(128,0); for(auto c: t) map[c]++; int counter=t.size(), begin=0, end=0, d=INT_MAX, head=0; while (end&lt;s.size()) &#123; if(map[s[end++]]--&gt;0) counter--; //in t while(counter==0)&#123; //valid if(end-begin&lt;d) d=end-(head=begin); if(map[s[begin++]]++==0) counter++; //make it invalid &#125; &#125; return d==INT_MAX? \"\":s.substr(head, d);&#125; 别人写的精炼代码，拿来参考.","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"String","slug":"String","permalink":"atlantic8.github.io/tags/String/"},{"name":"Sliding window","slug":"Sliding-window","permalink":"atlantic8.github.io/tags/Sliding-window/"}]},{"title":"Substring with Concatenation of All Words","slug":"Substring-with-Concatenation-of-All-Words","date":"2016-08-27T02:04:46.000Z","updated":"2018-12-16T14:08:06.420Z","comments":true,"path":"2016/08/27/Substring-with-Concatenation-of-All-Words/","link":"","permalink":"atlantic8.github.io/2016/08/27/Substring-with-Concatenation-of-All-Words/","excerpt":"","text":"ProblemYou are given a string, s, and a list of words, words, that are all of the same length. Find all starting indices of substring(s) in s that is a concatenation of each word in words exactly once and without any intervening characters. For example, given:s: “barfoothefoobarman”words: [“foo”, “bar”] You should return the indices: [0,9].(order does not matter). Solution每个单词的长度一致，考虑滑动窗口的思想 使用滑动窗口的思想，双层循环 第一层确定要寻找的单词组合的开头下标 第二层循环试图寻找一个可能的组合，如果成功则记录开头下标；否则，退出第二层循环 程序采用复制哈希表的方式会超时 123456789101112131415161718192021222324public static List&lt;Integer&gt; findSubstring(String S, String[] L) &#123; List&lt;Integer&gt; res = new ArrayList&lt;Integer&gt;(); if (S == null || L == null || L.length == 0) return res; int len = L[0].length(); // length of each word Map&lt;String, Integer&gt; map = new HashMap&lt;String, Integer&gt;(); // map for L for (String w : L) map.put(w, map.containsKey(w) ? map.get(w) + 1 : 1); for (int i = 0; i &lt;= S.length() - len * L.length; i++) &#123; // possible start index Map&lt;String, Integer&gt; copy = new HashMap&lt;String, Integer&gt;(map); for (int j = 0; j &lt; L.length; j++) &#123; // checkc if match String str = S.substring(i + j*len, i + j*len + len); // next word if (copy.containsKey(str)) &#123; // is in remaining words int count = copy.get(str); if (count == 1) copy.remove(str); else copy.put(str, count - 1); if (copy.isEmpty()) &#123; // matches res.add(i); break; &#125; &#125; else break; // not in L &#125; &#125; return res;&#125; 这样的代码还有一种写法，也是使用双层循环。第一层循环为单个单词的长度，第二层以固定的步长进行匹配，不推荐这么写。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public List&lt;Integer&gt; findSubstring(String s, String[] words) &#123; List&lt;Integer&gt; ret = new LinkedList&lt;&gt;(); if (s.length() == 0 || words.length == 0) return ret; Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); for (String word : words) map.put(word, map.containsKey(word)?map.get(word)+1:1); int len = words[0].length(), start = 0, end = 0, count; Map&lt;String, Integer&gt; tmp_map = new HashMap&lt;&gt;(); for (int i = 0; i &lt; len; i++) &#123; tmp_map.clear(); start = i; end = i; count = 0; while (end + len &lt;= s.length()) &#123; String tmp_str = s.substring(end, end + len), tmp = null; if (map.containsKey(tmp_str)) &#123; // a word if (tmp_map.containsKey(tmp_str)) tmp_map.put(tmp_str, tmp_map.get(tmp_str)+1); else tmp_map.put(tmp_str, 1); count++; if (tmp_map.get(tmp_str) &gt; map.get(tmp_str)) &#123; while (start &lt;= end &amp;&amp; tmp_map.get(tmp_str) &gt; map.get(tmp_str)) &#123; tmp = s.substring(start, start + len); tmp_map.put(tmp, tmp_map.get(tmp) - 1); start += len; count--; &#125; &#125; if (count == words.length) &#123; --count; tmp = s.substring(start, start+len); tmp_map.put(tmp, map.get(tmp)-1); ret.add(start); start += len; &#125; end += len; &#125; else &#123; // not a word end += len; start = end; tmp_map.clear(); count = 0; &#125; &#125; &#125; return ret; &#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"String","slug":"String","permalink":"atlantic8.github.io/tags/String/"},{"name":"Sliding window","slug":"Sliding-window","permalink":"atlantic8.github.io/tags/Sliding-window/"}]},{"title":"Remove Duplicate Letters","slug":"Remove-Duplicate-Letters","date":"2016-08-25T01:45:42.000Z","updated":"2018-12-16T14:08:06.395Z","comments":true,"path":"2016/08/25/Remove-Duplicate-Letters/","link":"","permalink":"atlantic8.github.io/2016/08/25/Remove-Duplicate-Letters/","excerpt":"","text":"ProblemGiven a string which contains only lowercase letters, remove duplicate letters so that every letter appear once and only once. You must make sure your result is the smallest in lexicographical order among all possible results. Example:Given “bcabc”Return “abc” Given “cbacdcbc”Return “acdb” Solution给定字符串s，使用贪心算法一定能得到最优解。需要稍微注意点的是，遇到只出现了一次的字符串的情况 扫描一遍字符串，获取每个字符对应的出现次数 扫描一遍字符串，寻找找到最小的字符对应的下标。每扫描到一个字符，其出现次数要-1，如果减完1后是0，表示这个字符是唯一的，所以要在此停顿，处理前面出现的最小字符。(下一次字符出现次数会重新计数) 1234567891011121314public class Solution &#123; public String removeDuplicateLetters(String s) &#123; if (s.length() == 0) return \"\"; int[] map = new int[26]; for (int i=0; i&lt;s.length(); i++) map[s.charAt(i)-'a'] += 1; int pos = 0; for (int i=0; i&lt;s.length(); i++) &#123; if (s.charAt(i) &lt; s.charAt(pos)) pos = i; if (--map[s.charAt(i)-'a'] == 0) break; &#125; return s.charAt(pos)+removeDuplicateLetters(s.substring(pos+1).replaceAll(\"\"+s.charAt(pos), \"\")); &#125;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Greedy","slug":"Greedy","permalink":"atlantic8.github.io/tags/Greedy/"}]},{"title":"python数据规整_分组_聚合","slug":"python数据规整-分组-聚合","date":"2016-08-15T11:09:26.000Z","updated":"2018-12-16T14:08:06.501Z","comments":true,"path":"2016/08/15/python数据规整-分组-聚合/","link":"","permalink":"atlantic8.github.io/2016/08/15/python数据规整-分组-聚合/","excerpt":"","text":"数据合并DataFrame合并1234import pandas as pdfrom pandas import DataFrame,Seriesimport numpy as nppd.merge(***) merge方法merge函数的参数 param explanation param explanation left 左侧的DataFrame right 右侧的DataFrame how 连接方式，inner、outer、left、right，默认为inner on 指定连接的列名 left_on 左侧DataFrame用于连接的键名 right_on 右侧DataFrame用于连接的键名 left_index 将左侧的行索引用作其连接键 right_index 将右侧的行索引用作其连接键 sort 对合并后的数据在连接键上排序，默认为True suffixes 重叠列名后缀，用于重复列名区分 copy 默认为True，设置为False可以避免将数据复制到结果数据结构中 ———— ————- 123456789101112131415161718192021left1 = DataFrame(&#123;'key':['a','b','a','a','b','c'], 'value':range(6)&#125;)$-&gt; key value0 a 01 b 12 a 23 a 34 b 45 c 5right1 = DataFrame(&#123;'group_val':[2,5]&#125;,index=['a','b'])$-&gt; group_vala 2b 5pd.merge(left1, right1, left_on='key', right_index=True)$-&gt; key value group_val0 a 0 22 a 2 23 a 3 21 b 1 54 b 4 5 层次化索引应当以列表的形式指明用作合并键的多个列 join方法 join方法可以更为方便地实现按索引合并 可以合并多个带有相同或相似索引的DataFrame对象 123456# on指定调用者的连接键left.join(right, how='', on='')# 多个DataFrame合并another = DataFrame(....)left2.join([right2, another]) concat方法concat方法用于轴向连接、绑定、堆叠操作numpy有一个合并原始NumPy数组的concatenate的函数 123arr = np.arange(12).reshape((3,4))# axis=1水平连接，axis=0垂直连接np.concatenate([arr, arr], axis=1) 1234567891011121314151617181920212223s1 = Series([0,1], index=['a', 'b'])s2 = Series([2,3,4], index=['c','d', 'e'])s3 = Series([5,6], index=['f', 'g'])# 默认 axis=0pd.concat([s1, s2, s3])$-&gt; a 0 b 1 c 2 d 3 e 4 f 5 g 6 dtype: int64pd.concat([s1, s2, s3], axis=1)$-&gt; 0 1 2a 0.0 NaN NaNb 1.0 NaN NaNc NaN 2.0 NaNd NaN 3.0 NaNe NaN 4.0 NaNf NaN NaN 5.0g NaN NaN 6.0 concat函数的参数 param explanation param explanation objs 参与连接的pandas对象的列表或字典，必需参数 axis 指明连接轴向，默认为0，参考上面示例 join 连接方式，inner、outer，默认为outer join_axes 指明其他n-1条轴的索引，不执行并集、交集运算 keys 用于形成连接轴上的层次化索引 levels 指定层次化索引上各级别的索引 names 用于创建分层级别的索引，如果设置了keys和levels的话 verify_integrity 检查结果对象新轴上的重复对象 ignore_index 不保留连接轴上的索引，产生新索引range() ——- ———————- 重塑层次化索引 stack 将数据的列‘旋转’为行 unstack 将数据的行‘旋转’为列 1234567891011121314151617181920212223242526272829303132data = DataFrame(np.arange(6).reshape((2,3)), index=pd.Index(['Ohio','Colorado'],name='state'), columns=pd.Index(['one','two','three'],name='number'))$-&gt; datanumber one two threestateOhio 0 1 2Colorado 3 4 5result = data.stack()result$-&gt; state number Ohio one 0 two 1 three 2 Colorado one 3 two 4 three 5 dtype: int32result.unstack()$-&gt; number one two three state Ohio 0 1 2 Colorado 3 4 5# unstack(和stack一样)默认操作的是最内层地址，给函数传入层次级别的编号或者名称即可在不同级别操作。result.unstack(0)$-&gt; state Ohio Colorado number one 0 3 two 1 4 three 2 5result.unstack('state') # 效果同上 unstack操作可能会产生缺失值，而stack操作默认会过滤缺失值，可以设置参数dropna=False取消。 数据转换去重 DataFrame的duplicated()方法返回一个bool型Series实例，指示每一行是否是重复行 DataFrame的drop_duplicates()方法返回一个移除重复行的DataFrame drop_duplicates()默认保留第一个出现的值组合，设置take_last=True则保留最后一个 指定部分列进行重复项判断，drop_duplicates([‘a1’, ‘a2’]) 替换 Series中的replace函数可以进行替换操作 data.replace(a, b) data.replace([a1, a2], b) data.replace([a1, a2], [b1, b2]) 映射 Series的map方法接受一个函数，或者含有映射关系的字典对象，返回一个映射后的Series对象 data.map(str.lower) data.map(lambda x : str.lower(x)) 离散化与bin划分 cut函数 12345678910111213141516171819202122232425262728ages = [20,22,25,27,21,23,37,31,61,45,41,32]bins = [18, 25, 35, 60 ,100]# 将ages按照bins划分进行切割# 直接切割得到的区间是左开右闭的，设置right=False可以得到左闭右开区间# 设置参数labels=['a1','a2',...,'an']可以更改区间名称# 也可以不传入bins，直接传入整数n表示分成n个区间，函数会根据最值等间距划分cats = pd.cut(ages, bins)cats$-&gt; [(18, 25], (18, 25], (18, 25], (25, 35], (18, 25], ..., (25, 35], ( 60, 100], (35, 60], (35, 60], (25, 35]] Length: 12 Categories (4, object): [(18, 25] &lt; (25, 35] &lt; (35, 60] &lt; (60, 100] ]cats.codes #每个数据的标签$-&gt; array([0, 0, 0, 1, 0, 0, 2, 1, 3, 2, 2, 1], dtype=int8)cats.categories #区间信息$-&gt; Index([u'(18, 25]', u'(25, 35]', u'(35, 60]', u'(60, 100]'], dtype='object')# 简单统计pd.value_count(cats)$-&gt; (18, 25] 5 (35, 60] 3 (25, 35] 3 (60, 100] 1 dtype: int64 qcut函数根据样本分位数对样本进行划分，可以使得每个bin中的数据数量比较接近 123456789101112131415161718data = np.random.rand(1000)# 5分位数cats = pd.qcut(data, 5)pd.value_counts(cats)$-&gt; (0.813, 1] 200 (0.628, 0.813] 200 (0.421, 0.628] 200 (0.223, 0.421] 200 [0.000386, 0.223] 200# 自定义的分位数cats = pd.qcut(data, [0, 0.1, 0.5, 0.9, 1.0])pd.value_counts(cats)$-&gt; (0.539, 0.901] 400 (0.127, 0.539] 400 (0.901, 1] 100 [0.000386, 0.127] 100 dtype: int64 检测和过滤异常值123456789data = DataFrame(np.random.randn(1000,4))col = data[3]# 找出某一列中绝对值大于3的值col[np.abs(col) &gt; 3]# 找出data中全部大于3的值data[(np.abs(data) &gt; 3).any(1)]# 替换异常值data[np.abs(data) &gt; 3] = 1 排列和随机采样123np.random.permutation(5)# 整数采样，从[0,5)区间上采，样本空间为20np.random.randint(0,5,20) 计算指示变量、哑变量本节的作用是将分类变量转换为‘哑变量矩阵’（dummy matrix）或‘指示变量矩阵0-1’（indicator matrix）.如果DataFrame中的某一列有k个不同的值，则可以派生出一个k列矩阵或DataFrame12345678910data = DataFrame(&#123;'key':['a','b','a','c','d'],'value':range(5)&#125;)pd.get_dummies(data['key'])$-&gt; a b c d0 1.0 0.0 0.0 0.01 0.0 1.0 0.0 0.02 1.0 0.0 0.0 0.03 0.0 0.0 1.0 0.04 0.0 0.0 0.0 1.0# 为新生成的列名添加前缀pd.get_dummies(data['key'], prefix='new_') 字符串操作python内置的字符串库 strip() 修剪空白符、换行符 split(‘xx’) 字符串分割 a.join(list): 在字符串a后面接上列表list（或元组）里所有的元素 str.index(‘,’) 在字符串str中找到’,’的位置，如果找不到则抛出异常 str.find(‘,’) 在字符串str中找’,’，找到返回第一个位置，找不到返回-1 str.rfind(‘,’) 在字符串str中找’,’，找到返回最后一个位置，找不到返回-1 str.count(‘,’) 统计str中’,’的个数 str.replace(‘aa’,’a’) 替换 str.lower(), upper() 大小写转换 str.ljust(n), rjust(n) 用空白字符填充以满足最小长度n 正则表达式 正则表达式是用于处理字符串的强大工具，拥有自己独特的语法以及一个独立的处理引擎，效率上可能不如str自带的方法，但功能十分强大。得益于这一点，在提供了正则表达式的语言里，正则表达式的语法都是一样的，区别只在于不同的编程语言实现支持的语法数量不同。下图展示了使用正则表达式进行匹配的流程： ![](http://ww4.sinaimg.cn/mw690/9bcfe727jw1f6unc8s9fzj20d605w0ue.jpg) 下图列出了Python支持的正则表达式元字符和语法： ![](http://ww3.sinaimg.cn/mw690/9bcfe727jw1f6unc85kmxj20m71brniv.jpg) 正则表达式通常用于在文本中查找匹配的字符串。Python里数量词默认是贪婪的（在少数语言里也可能是默认非贪婪），总是尝试匹配尽可能多的字符；非贪婪的则相反，总是尝试匹配尽可能少的字符。例如：正则表达式”ab*”如果用于查找”abbbc”，将找到”abbb”。 与大多数编程语言相同，正则表达式里使用”\\”作为转义字符，这就可能造成反斜杠困扰。假如你需要匹配文本中的字符”\\”，那么使用编程语言表示的正则表达式里将需要4个反斜杠”\\\\\\\\”：前两个和后两个分别用于在编程语言里转义成反斜杠，转换成两个反斜杠后再在正则表达式里转义成一个反斜杠。Python里的原生字符串很好地解决了这个问题，这个例子中的正则表达式可以使用r”\\\\”表示。同样，匹配一个数字的”\\\\d”可以写成r”\\d”。 re模块。Python通过re模块提供对正则表达式的支持。使用re的一般步骤是先将正则表达式的字符串形式编译为Pattern实例，然后使用Pattern实例处理文本并获得匹配结果（一个Match实例），最后使用Match实例获得信息，进行其他的操作。 1import re compilere.compile(strPattern[, flag])用于将字符串形式的正则表达式编译为Pattern对象,第二个参数flag是匹配模式，取值可以使用按位或运算符’|’表示同时生效。flag的可选值有：re.I(re.IGNORECASE): 忽略大小写（括号内是完整写法，下同）M(MULTILINE): 多行模式，改变’^’和’$’的行为（参见上图）S(DOTALL): 点任意匹配模式，改变’.’的行为L(LOCALE): 使预定字符类 \\w \\W \\b \\B \\s \\S 取决于当前区域设定U(UNICODE): 使预定字符类 \\w \\W \\b \\B \\s \\S \\d \\D 取决于unicode定义的字符属性X(VERBOSE): 详细模式。这个模式下正则表达式可以是多行，忽略空白字符，并可以加入注释 matchmatch(string[, pos[, endpos]]) | re.match(pattern, string[, flags])这个方法将从string的pos下标处起尝试匹配pattern；如果pattern结束时仍可匹配，则返回一个Match对象；如果匹配过程中pattern无法匹配，或者匹配未结束就已到达endpos，则返回None。pos和endpos的默认值分别为0和len(string)；re.match()无法指定这两个参数，参数flags用于编译pattern时指定匹配模式。 注意：这个方法并不是完全匹配。当pattern结束时若string还有剩余字符，仍然视为成功。想要完全匹配，可以在表达式末尾加上边界匹配符’$’。 splitsplit(string[, maxsplit]) | re.split(pattern, string[, maxsplit])按照能够匹配的子串将string分割后返回列表。maxsplit用于指定最大分割次数，不指定将全部分割。 findallfindall(string[, pos[, endpos]]) | re.findall(pattern, string[, flags])搜索string，以列表形式返回全部能匹配的子串 finditerfinditer(string[, pos[, endpos]]) | re.finditer(pattern, string[, flags])搜索string，返回一个顺序访问每一个匹配结果（Match对象）的迭代器 subsub(repl, string[, count]) | re.sub(pattern, repl, string[, count])使用repl替换string中每一个匹配的子串后返回替换后的字符串。当repl是一个字符串时，可以使用\\id或\\g、\\g引用分组，但不能使用编号0。当repl是一个方法时，这个方法应当只接受一个参数（Match对象），并返回一个字符串用于替换（返回的字符串中不能再引用分组）。count用于指定最多替换次数，不指定时全部替换。 subnsubn(repl, string[, count]) |re.sub(pattern, repl, string[, count])返回 (sub(repl, string[, count]), 替换次数) 原文地址与示例 pandas中矢量化的字符串操作通过Series的str方法获取Series中值得字符串内容，函数示例 data.str.constins(‘hello’), 返回一个bool型的Series对象 data.str.findall(pattern,flags=re.IGNORECASE) matches = data.str.match(pattern, flags=re.IGNORECASE) matches.str.get(1) 矢量化元素获取 matches.str[1] 矢量化元素获取(效果和上一个一致),也支持分片操作 矢量化的字符串方法 method explanation method explanation cat 元素级的字符串连接操作，可指定分隔符 contains 返回各字符串是否包含指定模式的bool数组 count 模式出现的次数 endswith,startswith 各元素是否以指定的模式开头、结尾，返回bool数组 findall 计算各字符串的模式列表 get 获取各元素的第i个字符 join 根据指定的分隔符将各元素的字符串连接起来 len 计算各字符串的长度 lower,upper 大小写转换 match 根据给定模式，执行re.match() pad 在字符串左边/右边或两边添加空白符 center 相当于pad(side=’both’) repeat 重复操作，在字符串上就是多个相同的拼接 replace 替换指定模式 slice 对各个字符串进行子串分片操作 split 根据指定模式，对字符串切割 strip,rstrip,lstrip 去空白符，换行符 数据聚合1234567df$-&gt; data1 data2 key1 key20 2.128648 0.552487 a one1 2.040146 -0.974248 a two2 -1.442976 -0.404534 b one3 1.796789 -1.413561 b two4 0.429355 0.604959 a one GroupBy groupby用于DataFrame上，假定要按‘key’进行分组，并计算‘value’列的值，默认在axis=0上分组 grouped = df[‘value’].groupby(df[‘key’]) grouped是一个GroupBy对象，只包含一些有关分组建的中间数据 上面的等价语法为：df.groupby(df[‘key’])[‘value’]或者df.groupby(df[‘key’])[[‘value’]] grouped.mean() 使用GroupBy的方法进行计算 分组键可以不止一个，groupby(df[‘key1’,’key2’])，得到层次索引结果 分组键可是任意长度适当的数组，可以是字符串、数字或其他python对象，比如’key1’，也可以按照列的类型dtype进行分组: df.groupby(df.dtypes, axis=1) df.groupby(df[‘key’]).mean() 对df的所有数值列求值，非数值列自动忽略 df.groupby(df[‘key’]).size() 返回含有分组大小的Series grouped.describe()等方法也是可以用在这里的 分组迭代 GroupBy对象支持迭代，可以产生一组二元分组（由分组名和数据块组成） for name,group in df.groupby(df[‘key’]) 将返回df[‘key’]每一种可能的值以及其对应的df行集合 for (k1, k2),group in df.groupby(df[‘key1’, ‘key2’]) groupby对象字典化1234567891011121314151617181920212223grouped = df.groupby('key1')glist = list(grouped) # glist中包含的是(分组名, 数据块)组成的元组$-&gt; [('a', data1 data2 key1 key2 0 2.128648 0.552487 a one 1 2.040146 -0.974248 a two 4 0.429355 0.604959 a one), ('b', data1 data2 key1 key2 2 -1.442976 -0.404534 b one 3 1.796789 -1.413561 b two)]gdict = dict(glist) # 字典化$-&gt; &#123;'a': data1 data2 key1 key2 0 2.128648 0.552487 a one 1 2.040146 -0.974248 a two 4 0.429355 0.604959 a one, 'b': data1 data2 key1 key2 2 -1.442976 -0.404534 b one 3 1.796789 -1.413561 b two&#125;dict(list(df.groupby(df.dtypes, axis=1))) 分组通过字典或者Series进行分组比如说现在dataframe有列’a’,’b’,’c’,’d’,’e’，通过如下代码12345678mapping = &#123;'a':'red','b':'blue','c':'red','d':'red','e':'blue'&#125;# 将字典传给groupby函数，设置axis=1（这是合并列）by_column = df.groupby(mapping, axis=1)by_column.sum() # 对映射到相同名称的列求和，结果的列只有'red'和'blue'# Series也有同样的功能map_series(mapping)df.groupby(map_series, axis=1).sum() 通过函数进行分组比如说索引为字符串，若想按照字符串长度进行分组，则可以：12345df.groupby(len).sum()# 将函数跟数组、列表、字典等结合起来使用也可以key_list = ['one','one','one','two','two']df.groupby([len, key_list]).sum() # 得到一个层次化索引的结果 通过索引级别进行分组通过level关键字传入级别编号或名称，按照索引级别进行分组123456789columns = pd.MultiIndex.from_arrays([['US','US','US','JP','JP'],[1,3,5,1,3]], names=['country','tenor'])df = DataFrame(np.random.randn(4,5), columns=columns)df.groupby(level='country', axis=1).count()$-&gt;country JP US0 2 31 2 32 2 33 2 3 聚合方法自定义聚合函数，将其传入agg或者aggregate方法即可 经过优化的groupby方法，可以传入函数名字符串进行调用 method explanation method explanation count 分组中非NAN值的数量 sum 非NAN值的和 mean 非NAN值的均值 median 非NAN值的中值 std,var 无偏(分母n-1)标准差和方差 min,max 非NAN值的最值 prod 非NAN值的乘积 first,last 第一个、最后一个非NAN值 面向列的多函数应用12345678# 传入一个函数列表执行多个函数，每个函数的执行结果单成一列grouped['data3'].agg(['mean', 'std', my_function])# 传入由(name, function)元组组成的列表时，每个元组第一个元素成为结果DataFrame的列名，第二个元素是对应此列名上的函数grouped.agg([('data1','mean'), ('data2','std')])# 不同的列对应不同的函数，可传入字典grouped.agg(&#123;'data1':['min','max'], 'data2':[np.max, 'std']) 聚合结果索引变换python聚合返回结果时，向groupby函数传入: as_index=False 取消由分组键形成索引，而是将分组键变成列，把简单数字作为索引。对结果调用reset_index()也能得到这样的结果。 分组运算与转换transformtransform函数接收一个函数，并将这个函数应用到各个分组，然后将每个分组的结果放置在这个分组对应的每一个元素上，最后显示它。1234567891011121314151617181920212223242526people$-&gt; a b c d eJoe -0.338386 0.849100 -1.951048 -1.153923 -1.672975Steve -0.490588 0.408497 -0.692801 -0.100917 0.970808Wes -1.603786 NaN NaN -0.534380 0.847692Jim 0.309432 2.768331 -0.454094 -1.026735 -0.679794Travis -1.400938 -0.865599 -0.190541 -0.835916 0.315975key=['one','two','one','two','one']people.groupby(key).mean()$-&gt; a b c d eone -1.114370 -0.008250 -1.070794 -0.841406 -0.169769two -0.090578 1.588414 -0.573447 -0.563826 0.145507people.groupby(key).transform(np.mean)$-&gt; a b c d eJoe -1.114370 -0.008250 -1.070794 -0.841406 -0.169769Steve -0.090578 1.588414 -0.573447 -0.563826 0.145507Wes -1.114370 -0.008250 -1.070794 -0.841406 -0.169769Jim -0.090578 1.588414 -0.573447 -0.563826 0.145507Travis -1.114370 -0.008250 -1.070794 -0.841406 -0.169769# 传入自定义的函数也可以，需要注意的是自定义函数的输入参数是已经分好组的各个分组def my_function(arr): return arr-arr.mean() apply：拆分-应用-合并 apply 将待处理的对象拆成多个分段，然后对各分段调用传入的函数，最后尝试将各分段组合到一起 分段组合需要用到pandas.concat函数 apply 传入函数名，这里传入的函数需要包括：分好组的DataFrame分段，也可以包括一些其他的参数 1234567# 取列'tip_pct'排前五的记录def top(df, n=5, col='tip_pct'): return df.sort_index(by=col)[-n:]df.groupby('smoker').apply(top)# 禁止分组键df.groupby('smoker', group_keys=False).apply(top) 分位数和桶分析 pandas中面元划分、样本分位数划分的函数cut和qcut可以和groupby结合起来 函数cut和qcut返回的对象可以作为groupby函数的参数 123456def get_status(group): return &#123;'min':group.min, 'max':group.max, 'count':group.count&#125;factor = pd.cut(df.data1, 4) # labels=False，只获取分位数编号grouped = df.data2.groupby(factor)grouped.apply(get_status).unstack() 透视表与交叉表透视表 根据一个或多个键对数据进行聚合，并根据行和列上的分组键将数据分配到各个矩形区域中 DataFrame有个pivot_table函数 顶级函数：pandas.pivot_table pivot_table的参数 method explanation method explanation values 待聚合列的名称，默认为所有数值列 rows 用于分组的列名或其他分组键，出现在结果透视图的行 cols 用于分组的列名或其他分组键，出现在结果透视图的列 aggfunc 聚合函数或函数列表，默认为mean。可以是任何对groupby有效的函数 fill_value 用于替换结果表中的缺失值 margin 添加行列小计，默认为False 123456789# 第一个参数是表格内容，如果不设置，则默认为pivot_table中的默认聚合类型# 设置参数 rows，设置行内容和索引，# 设置参数 cols，设置列内容和索引tips.pivot_table(['tip_pct','size'], rows=['sex','day'], cols='smoker')# 设置：margins=True，添加分项小计，默认为平均值tips.pivot_table(['tip_pct','size'], rows=['sex','day'], cols='smoker', margins=True)# 要使用其他小计函数，可以使用：aggfunc参数tips.pivot_table(['tip_pct','size'], rows=['sex','day'], cols='smoker', margins=True,aggfunc='sum') 交叉表 交叉表是一种用于计算分组频率的特殊透视表 pandas.crosstab函数可以统计交叉表 1234# param1: 用于分组的列名或其他分组键，出现在结果透视图的行# param2: 用于分组的列名或其他分组键，出现在结果透视图的列# margins=True：行、列小计pd.crosstab(param1, param2, margins=True)","categories":[],"tags":[{"name":"python","slug":"python","permalink":"atlantic8.github.io/tags/python/"},{"name":"数据分析","slug":"数据分析","permalink":"atlantic8.github.io/tags/数据分析/"}]},{"title":"python时间序列分析","slug":"python时间序列分析","date":"2016-08-15T11:06:30.000Z","updated":"2018-12-16T14:08:06.505Z","comments":true,"path":"2016/08/15/python时间序列分析/","link":"","permalink":"atlantic8.github.io/2016/08/15/python时间序列分析/","excerpt":"","text":"基础工具基础工具类，datetime模块 type explanation date 以公历形式存储日历日期 time 以时、分、秒、毫秒形式存储时间 datetime 存储如期和时间 timedelta 两个datetime之间的差 datetime以毫秒形式存储日期和时间，datetime.timedelta表示两个datetime对象之间的时间差 可以给datetime加上、减去一个或者多个timedelta对象 1234567891011from datetime import datetime, timedeltanow = datetime.now()now.year, now.month, now.day$-&gt; datetime.datetime(2016, 8, 4, 15, 14, 36, 899000)# timedelta只有days和seconds这两个成员delta = datetime(2011,7,2)-datetime(2011,7,1,9)delta.days, delta.seconds$-&gt; (0, 54000)delta = datetime(2011,7,2)-2*timedelta(10) 字符串和datetime的相互转换datetime -&gt; string str方法 strftime方法 12345stamp = datetime(2011,8,1)str(stamp)$-&gt; '2011-08-01 00:00:00'stamp.strftime('%Y-%m-%d')$-&gt; '2011-08-01' string -&gt; datetime datetime.strptime dateutil的parser.parse方法，dateutil几乎可以理解所有人类能够理解的日期格式 123456value = '2011-1-25'# 返回一个datetime对象datetime.strptime(value, '%Y-%m-%d')from dateutil.parse import parseparse('2011-03-12') pandas中的时间数据处理 pandas处理成组的时间数据 可以处理空值和非法值，用NaT表示 可能会把一些不是日期的字符串变成日期 12datestr = ['2011-04-12','2015-11-09']pd.to_datetime(datestr) 时间序列基础12345678from datetime import datetimedates = [datetime(2012,1,1), datetime(2012,1,2)]# datetime对象放置在一个DatetimeIndex中，pandas会自动识别这个Series为时间序列数据ts = Series(np.random.randn(2), index=dates)# DatetimeIndex中的各个标量是pandas的TimeStamp对象ts.index[0]$-&gt; Timestamp('2012-01-01 00:00:00') 索引与子集12345678910111213# 可以传入被解释为日期的字符串来访问ts['2012-01-01']# 切片操作，可以传入‘年’或者‘年月’# periods决定date_range的长度longer_ts = Series(np.random.randn(1000), index=pd.date_range('1/1/2000',period=1000))# 也可以像列表切片那样，可以传入字符串日期，datetime或TimeStamp对象# 这样切片产生的是源数据的视图，与numpy数组的切片运算一致ts[datetime(2011,1,7):] # 2011-1-7起的所有数据ts['1/6/2011':'1/11/2011'] # 从[2011-1-6, 2011-1-11)的数据ts.truncate(after='1/1/2011') # 也有类似的效果 在Series与DataFrame中均适用，只要设置index即可 日期范围date_range pandas.date_range(start=s, end=e, period=p, freq=f, normalize=True) [s, e)：决定了初始时间和结束时间 p：周期值，决定日期长度 f：决定频率，默认为’D’,表示天。常用频率见下表，更详细的见书本314页 normalize：True表示产生规范化到午夜的时间戳 value explanation value explanation D 每日历日 B 每工作日 H 每小时 T or min 每分钟 S 每秒钟 L or ms 每毫秒 U 每微秒 M 每月最后一个日历日 BM 每月最后一个工作日 MS 每月第一个日历日 W-MON,W-TUE,.. 从指定的星期几开始起的每一周 BMS 每月第一个工作日 Q-JAN,Q-FEB,.. 从起始时间开始，每个季度最后一个月的最后一个工作日 WOM-1MON,WOM-2MON,..WOM-1FRI.. 产生每月第x个星期几 日期偏移量12345678910from pandas.tseries.offsets import Hour,Minutehour = Hour(4)# 也可以更加简洁地使用freq参数# freq = '1h30min'pd.date_range('1/1/2011', '1/2/2011', freq='4h')$-&gt; DatetimeIndex(['2011-01-01 00:00:00', '2011-01-01 04:00:00', '2011-01-01 08:00:00', '2011-01-01 12:00:00', '2011-01-01 16:00:00', '2011-01-01 20:00:00', '2011-01-02 00:00:00'], dtype='datetime64[ns]', freq='4H') 移动数据 Series和DataFrame都有一个shift方法用于移动数据 shift移动步长参数：正值后移，负值前移 shift也可以带有参数 freq，这种情况下，数据不变，索引移动(正值前移) 1234# 计算变化率ts / ts.shift(1) - 1ts.shift(2,freq='D') 日期偏移量可以做用在datetime或TimeStamp对象上 如果加的是锚点偏移量(如MonthEnd)，第一次会偏移到符合频率规则的下一日期 通过锚点偏移量的rollforward和rollback方法 12345678910111213from pandas.tseries.offsets import Day, MonthEndnow = datetime(2011,2,15)now + MonthEnd()$-&gt; Timestamp('2011-02-28 00:00:00')now + MonthEnd(2)$-&gt; Timestamp('2011-03-31 00:00:00')'offset = MonthEnd()offset.rollforward(now)$-&gt; Timestamp('2011-02-28 00:00:00')offset.rollback(now)$-&gt; Timestamp('2011-01-31 00:00:00') 时区处理时间序列、日期范围和时间戳都可以从naive型转化为本地化时区意识型，也可以从一个时区转化为另一个时区12345import pytz# 常用时区列表pytz.common_timezones# 获取时区对象tz = pytz.timezone('UTC') 默认情况下，pandas中的时区是naive的，其索引的tz字段为None所以在生成日期范围的时候可以加上一个时区信息,设置tz参数。也可以直接使用tz_localize方法12345678910111213pd.date_range('1/1/2001',period=10,tz='UTC')# 完成本地化操作ts_utc = ts.tz_localize('UTC')# 时区转化ts_utc.tz_convert('US/Eastern')# 时间戳转换stamp = pd.TimeStamp('2011-03-12 04:00')stamp_utc = stamp.tz_localize('UTC')stamp_eu = stamp.tz_convert('Europe/Moscow')stamp_moscow = pd.TimeStamp('2011-03-12 04:00', tz='Europe/Moscow') 合并两个时间序列数据，时区不同时，结果自动转化为UTC时间。 时期Period及其算术运算 时期Period表示的是时间区间，如数日、数月、数季、数年等，包含在pandas中 构造函数需要一个字符串或者整数，以及freq参数 pandas.period_range函数，pandas.PeriodIndex函数 123456789101112131415161718# 这个Period表示的是从2007-1-1到2007-12-31日之间的整段时间# 可以被看成一个被划分成多个月度时期的时间段中的游标p = pd.Period(2007,freq='A-DEC')# 与整数直接进行加、减法运算p + 5$-&gt; Period('2012', 'A-DEC')# Period对象之间的加、减法运算# freq不同时会抛出异常pd.Period('2014', freq='A-DEC') - p$-&gt; 7L# 创建时期范围pd.period_range('1/1/2000', '6/30/2000', freq='M')values = ['2001Q3', '2002Q2', '2003Q1']index = pd.PeriodIndex(values, freq='Q-DEC')index $-&gt; PeriodIndex(['2001Q3', '2002Q2', '2003Q1'], dtype='int64', freq='Q-DEC') 时期的频率转换Period和PeriodIndex对象都可以通过其asfreq方法被转换到其他频率123456789101112131415161718192021222324252627282930313233343536373839404142434445p = pd.Period('2007', freq='A-DEC')p.asfreq('M',how='start')$-&gt; Period('2007-01','M')p.asfreq('M',how='end')$-&gt; Period('2007-12','M')P.asfreq('B',how='start')$-&gt; Period('2007-01-01', 'B')# 高频率转化为低频率p = pd.Period('2007-08', 'M')p.asfreq('A-JUN')# 在频率A-JUN中，2007-08实际上是属于2008年$-&gt; Period('2008','A-JUN')# 按季度计算的时期频率# 频率为 Q-JAN,Q-FEB,Q-MAR,....Q-DEC, JAN starts from febp = pd.Period('2012Q4', freq='Q-JAN')# 2012年Q4是从2011-11-01到2012-01-31p.asfreq('D', 'start')$-&gt; Period('2011-11-01', 'D')p.asfreq('D','e')$-&gt; Period('2012-01-31', 'D')# TimeStamp和Period的相互转换# to_timestamp()和to_period('freq')方法ts = Series(np.random.randn(3), index=pd.date_range('1/1/2000',periods=3,freq='M'))ts $-&gt;2000-01-31 2.3754842000-02-29 0.7260242000-03-31 -0.328938Freq: M, dtype: float64pts = ts.to_period()pts $-&gt;2000-01 2.3754842000-02 0.7260242000-03 -0.328938Freq: M, dtype: float64pts.to_timestamp(how='end')$-&gt;2000-01-31 2.3754842000-02-29 0.7260242000-03-31 -0.328938Freq: M, dtype: float64 通过数组创建PeriodIndex固定频率的数据集通常会将时间信息分开存放在多个列中，将这些数据以及频率传入PeriodIndex中就可以将它们合并成一个DataFrame索引12# quarter表示季度pd.PeriodIndex(year=data.year, quarter=data.quarter, freq='Q-DEC') 重采样及频率转换 重采样指的是将时间序列从一个频率转换到另一个频率的处理过程 低频到高频称为升采样，反之为降采样 pandas对象都有一个resample方法 param explanation param explanation freq 表示重采样频率的字符串或DataOffset,’M’,’5min’,Second(15) how=’mean’ 产生聚合的函数名或数组函数，默认为mean，还有’first’,’last’,’ohlc’,’min’ axis=0 采样轴，默认为axis=0 fill_method=None 升采样时的插值方式，可取’ffill’或’bfill’ closed=’right’ 降采样中，时间段哪一端是闭合的 label=’right’ 降采样中聚合值的标签 loffset=None 面元标签的时间校正值，-1s(Second(-1))将时间调早1s limit=None 向前、向后填充时，允许填充的最大时期数 kind=None 聚合到时期或时间戳，默认聚合到时间序列的索引类型 convention=None 重采样时期，低频到高频所采用的约定(‘start’/‘end’)，默认为’end’ 降采样1234# 聚合到5min范围，聚合函数为'sum'求和ts.resample('5min', how='sum')ts.resample('5min', how='sum', closed='left', label='left', loffset='-1s') OHLC重采样 经常应用于金融数据的采样方法，计算各面元的四个值，分别是第一个值（open/开盘）、最后一个值（close/收盘）、最大值（high/最高）、最小值（low/最低） 传入how=’ohlc’即可得到含有这四种聚合值的DataFrame ts.resample(‘5min’, how=’ohlc’) 也可以通过groupby进行重采样 ts.groupby(lambda x: x.month).mean() ts.groupby(lambda x: x.weekday).mean() 升采样 升采样过程中，不需要聚合，需要插值 既不是降采样也不是升采样的采样，需要传入新的频率 frame.resample(‘W-MON’,fill_method=’ffill’) 123456789101112131415161718frame = DataFrame(np.random.randn(2,4),index=pd.date_range('1/1/2000',periods=2,freq='W-WED'),columns=['a','b','c','d'])frame$-&gt; a b c d2000-01-05 -0.550387 -1.294863 0.274911 0.3307412000-01-12 2.512896 -1.719330 0.090617 0.329635# 设置fill_method为ffill或者bfill，不设置时，引入缺失值# 如果设置limit值，则只填充limit行frame.resample('D', fill_method='ffill', limit=4)$-&gt; a b c d2000-01-05 -0.550387 -1.294863 0.274911 0.3307412000-01-06 -0.550387 -1.294863 0.274911 0.3307412000-01-07 -0.550387 -1.294863 0.274911 0.3307412000-01-08 -0.550387 -1.294863 0.274911 0.3307412000-01-09 -0.550387 -1.294863 0.274911 0.3307412000-01-10 NaN NaN NaN NaN2000-01-11 NaN NaN NaN NaN2000-01-12 2.512896 -1.719330 0.090617 0.329635 绘图中的移动窗口函数 移动窗口上计算的各种函数也是一类常见于时间序列的数组变换，称之为移动窗口函数 它们接受TimeSeries或DataFrame对象，以及一个窗口长度。它们是pandas的函数 移动窗口和指数加权函数 function explanation function explanation rolling_count 各窗口非NA观测值的数量 rolling_sum 窗口和 rolling_mean 窗口均值 rolling_median 窗口中位数 rolling_var,rolling_std 窗口无偏方差、标准差(n-1) rolling_skew,rolling_kurt 窗口三阶矩(偏度)、四阶矩(峰度) rolling_min,rolling_max 窗口的最值 rolling_quantile 窗口制定百分数、分位数位置的值 rolling_corr,rolling_cov 窗口的相关系数和协方差 rolling_apply 对窗口应用普通数组函数 ewma 指数加权移动平均 ewmvar,ewmstd 指数加权移动方差和标准差 ewmcorr,ewmcov 指数加权移动相关系数和协方差 这些函数均不考虑NA值，bottlenect则是NA友好的窗口移动函数集。123456# 窗口长度为250pd.rooling_mean(data['col1'], 250, min_periods=10).plot()# 将rolling_mean()函应用到所有列上,画出所有列对应的数据expanding = lambda x : rolling_mean(x, len(x), min_periods=1)pd.rolling_mean(data, 60).plot(logy=True) 指数加权函数 通过定义一个衰减因子，decay factor，使得近期的观测值拥有更大的权重 衰减因子定义可以使用：时间间隔span，兼容于窗口大小等于时间间隔的简单移动窗口函数 具有较强的适应性 12pd.ewma(data['col1'], span=60).plot()# ewmvar, ewmstd的使用同理 二元移动窗口函数 作用在两个个序列上的函数，比如相关性计算和协方差计算 1234pd.rolling_corr(series1, series2, 100, min_periods=100).plot()# 计算一个序列与DataFrame的各个列的相关关系时data = DataFrame(...)pd.rolling_corr(data, series, 100, min_periods=100).plot() 用户定义的移动窗口函数 使用rolling_apply()函数，需要自定义函数作为参数输入 自定义函数要求：能从数组的各个片段中产生单个值 1234# percentileofscore(x,y)可用于计算样本x中特定值y的百分等级from scipy.stats import percentileofscorescore_at_2percent = lambda x: percentileofscore(x, 0.02)pd.rolling_apply(data['col'], 200, score_at_2percent)","categories":[],"tags":[{"name":"python","slug":"python","permalink":"atlantic8.github.io/tags/python/"},{"name":"time_series_data","slug":"time-series-data","permalink":"atlantic8.github.io/tags/time-series-data/"}]},{"title":"NumPy进阶","slug":"NumPy进阶","date":"2016-08-15T11:03:52.000Z","updated":"2018-12-16T14:08:06.369Z","comments":true,"path":"2016/08/15/NumPy进阶/","link":"","permalink":"atlantic8.github.io/2016/08/15/NumPy进阶/","excerpt":"","text":"数组重塑1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import numpy as npfrom numpy.random import randn# reshape函数arr = np.arange(8)arr.reshape((4, 2)).sahpe$-&gt; (4, 2)arr.reshape((5,-1))# 扁平化函数# flatten函数返回数据副本，ravel则不是# 这些函数可以带有指示顺序的参数：&#123;'C':行有限, 'F':列优先&#125;arr = np.arange(15).reshape((5, 3))arr.ravel()$-&gt; array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])arr.flatten()$-&gt; array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])arr.ravel('F')$-&gt; array([ 0, 3, 6, 9, 12, 1, 4, 7, 10, 13, 2, 5, 8, 11, 14])# 拆分合并arr1 = np.array([[1,2,3],[4,5,6]])arr2 = np.array([[7,8,9],[10,11,12]])np.concatenate([arr1, arr2], axis=0)$-&gt; array([[ 1, 2, 3], [ 4, 5, 6], [ 7, 8, 9], [10, 11, 12]])np.concatenate([arr1, arr2], axis=1)$-&gt; array([[ 1, 2, 3, 7, 8, 9], [ 4, 5, 6, 10, 11, 12]])# vstack(垂直方向的连接), hstack(水平方向的连接)# 里面的圆括号也可以换成方括号np.vstack((arr1, arr2))$-&gt; array([[ 1, 2, 3], [ 4, 5, 6], [ 7, 8, 9], [10, 11, 12]])np.hstack([arr1, arr2])$-&gt; array([[ 1, 2, 3, 7, 8, 9], [ 4, 5, 6, 10, 11, 12]])# splitarr = randn(5, 2)first, second, third = np.split(arr,[1,3])first$-&gt; array([[-0.28435497, 0.71298716]])second$-&gt; array([[ 0.48442513, -0.84460369], [-0.38289692, -1.11166995]])third$-&gt; array([[-0.44724781, 0.52083756], [-0.39584687, 0.14325106]]) 数组连接函数 method explanation concatenate 沿一条轴连接一组数组 vstack,hstack 垂直、水平连接 row_stack 按行连接，相当于vstack column_stack 按列连接，相当于hstack dstack 以面向‘深度’的方式堆叠，沿轴2 split 沿指定轴的指定位置拆分 hsplit,vsplit,dsplit 分别沿轴0、1、2切分 元素重复操作tile and repeat函数tile沿指定轴向堆叠数组的副本1234567891011121314151617arr = np.arange(3)arr.repeat(3)$-&gt; array([0, 0, 0, 1, 1, 1, 2, 2, 2])arr.repeat([2,3,4])$-&gt; array([0, 0, 1, 1, 1, 2, 2, 2, 2])arr = np.arange(4).reshape((2,2))arr.repeat([2,3], axis=0)$-&gt; array([[0, 1], [0, 1], [2, 3], [2, 3], [2, 3]])np.tile(arr, 2)$-&gt; array([[0, 1, 0, 1], [2, 3, 2, 3]]) 广播12345678910111213141516171819202122232425262728293031323334353637383940414243np.arange(4) + 3$-&gt; array([3, 4, 5, 6])# 每一行减去均值时，直接减# 每一列减时需要维度变化arr = np.arange(12).reshape((3,4))# 参数为0计算每列的均值，1则计算每行的均值arr.mean(0)$-&gt; array([ 4., 5., 6., 7.])arr - arr.mean(0)$-&gt; array([[-4., -4., -4., -4.], [ 0., 0., 0., 0.], [ 4., 4., 4., 4.]])# arr - arr.mean(1)报错# 沿其他轴广播，较小数组的‘广播维’必须为1，所以需要reshape()，把n变成(n,1)arr - arr.mean(1).reshape((4,1))$-&gt; array([[-1.5, -0.5, 0.5, 1.5], [-1.5, -0.5, 0.5, 1.5], [-1.5, -0.5, 0.5, 1.5]])# 一般解决方法是：专门为广播添加一个新轴# 通过np.newaxis属性及全切片完成arr = randn(3,4,5)depth_mean = arr.mean(2)demean = arr - depth_mean[:,np.newaxis,:]demean.mean(2)# 结果基本为0$-&gt; array([[ 0.00000000e+00, -2.22044605e-17, 1.11022302e-17, 8.88178420e-17], [ -2.22044605e-17, -1.11022302e-17, -7.77156117e-17, 2.77555756e-17], [ 2.22044605e-17, -5.55111512e-18, -3.33066907e-17, -6.66133815e-17]])# 通过广播设置数组的值arr = randn(3,4)arr[:] = 5arr $-&gt;array([[ 5., 5., 5., 5.], [ 5., 5., 5., 5.], [ 5., 5., 5., 5.]]) ufunc高级应用ufunc方法 method explanation reduce(x) 通过连续执行原始运算的方式对值进行聚合 accumulate(x) 聚合值，保留所有局部聚合结果 reduceat(x,bin) 局部约简。约简数据的各个切片以产生聚合型数组 outer(x,y) 对x、y中的每个元素应用原始运算 自定义ufunc numpy.frompyfunc()函数接受一个python函数，以及两个分别表示输入输出参数数量的整数 numpy.vectorize()函数用法类似 这两个函数速度较慢 12345678910def add_elements(x, y): return x+y# add_elements函数接受两个参数，返回一个参数add_them = np.frompyfunc(add_elements, 2, 1)add_them(np.arange(6), np.arange(6))$-&gt; array([0, 2, 4, 6, 8, 10], dtype=object)add_them = np.vectorize(add_elements)add_them(np.arange(6), np.arange(6))$-&gt; array([ 0, 2, 4, 6, 8, 10]) 更多的排序 ndarray的排序是就地排序 numpy.sort产生一个排好序的副本 两个函数都可以接受axis参数，0：对列排序，1：对行排序 间接排序对多个键排序时，可以使用这两个函数123456789101112131415values = np.array([5,0,1,3,2])index = values.argsort()index$-&gt; array([1, 2, 4, 3, 0])values[index]$-&gt; array([0, 1, 2, 3, 5])first = np.array(['a','b','c','d','e'])last = np.array(['z','y','x','v','u'])# 键的应用是从后往前，先last，再firstsorter = np.lexsort((first, last))sorter $-&gt; array([4, 3, 2, 1, 0])zip(last[sorter], first[sorter])$-&gt; [('u', 'e'), ('v', 'd'), ('x', 'c'), ('y', 'b'), ('z', 'a')] 排序算法的kind参数 param speed stability space complexity worst complexity quicksort 1 no 0 O(n^2) mergesort 2 yes n/2 O(nlogn) heapsort 3 no 0 O(nlogn) numpy.searchsorted 有序数组中的查找，使用二分查找 存在待查找的元素，返回其序号，否则返回插入该元素后该元素的序号 123456789101112arr = np.array([1,2,4,5,6,8,9])arr.searchsorted(5)$-&gt; 3arr.searchsorted(7)$-&gt; 5arr = np.array([0,0,0,1,1,1])arr.searchsorted([0,1])$-&gt; array([0, 3])# 从右边数arr.searchsorted([0,1], side='right')$-&gt; array([3, 6]) NumPy的matrix类 np.matrix()接受参数：二维数组，构建一个矩阵对象 支持使用直接的 * 运算 X.I返回矩阵X的逆 可用X.asarray将其转化为正规的ndarray对象 输出输入内存映像文件 内存映像文件是一种将磁盘上的非常大的二进制文件当作文件中的数组进行处理的方式，实际上就是放在磁盘上的ndarray NumPy中的memmap对象允许将大文件分成小段进行读写 np.memmap()函数接受(文件路径,数据类型,文件模式,模式) 对memmap对象切片会返回磁盘上的数据视图，如果对这些视图赋值，数据会被存储在内存中，调用flush就可以写入磁盘 如果某个内存映像超出作用域，他就会被垃圾回收器回收，之前的修改都会被写入磁盘 123456mmap = memmap('mymmap', dtype='float64', mode='w+', shape=(10000,10000))section = mmap[:5]section[:] = randn(5,10000)mmap.flush()del mmap HDF5 PyTables和h5py用于处理高效、可压缩的HDF5格式的数据 PyTables提供了一些用于结构化数组的高级查询功能 性能加速 避免复制 使用广播 使用ufunc方法 使用连续内存 Cython加速 123arr_c = np.ones((1000,1000), order='C')arr_f = np.ones((1000,1000), order='F')# 对前者的操作要快于后者的操作，前者数据按照C语言的连续方式存储","categories":[],"tags":[{"name":"numpy","slug":"numpy","permalink":"atlantic8.github.io/tags/numpy/"},{"name":"python","slug":"python","permalink":"atlantic8.github.io/tags/python/"}]},{"title":"Count Complete Tree Nodes","slug":"Count-Complete-Tree-Nodes","date":"2016-07-19T08:21:35.000Z","updated":"2018-12-16T14:08:06.192Z","comments":true,"path":"2016/07/19/Count-Complete-Tree-Nodes/","link":"","permalink":"atlantic8.github.io/2016/07/19/Count-Complete-Tree-Nodes/","excerpt":"","text":"Problemcount the total number of Binary Complete Tree nodes Solution traverse tree skill is not acceptable. The height of a tree can be found by just going left. Let a single node tree have height 0. Find the height h of the whole tree. If the whole tree is empty, i.e., has height -1, there are 0 nodes. Otherwise check whether the height of the right subtree is just one less than that of the whole tree, meaning left and right subtree have the same height. If yes, then the last node on the last tree row is in the right subtree and the left subtree is a full tree of height h-1. So we take the 2^h-1 nodes of the left subtree plus the 1 root node plus recursively the number of nodes in the right subtree. If no, then the last node on the last tree row is in the left subtree and the right subtree is a full tree of height h-2. So we take the 2^(h-1)-1 nodes of the right subtree plus the 1 root node plus recursively the number of nodes in the left subtree. Since I halve the tree in every recursive step, I have O(log(n)) steps. Finding a height costs O(log(n)). So overall O(log(n)^2). recursive version:1234567891011class Solution &#123; int height(TreeNode root) &#123; return root == null ? -1 : 1 + height(root.left); &#125; public int countNodes(TreeNode root) &#123; int h = height(root); return h &lt; 0 ? 0 : height(root.right) == h-1 ? (1 &lt;&lt; h) + countNodes(root.right) : (1 &lt;&lt; h-1) + countNodes(root.left); &#125;&#125; iterative version:123456789101112131415class Solution &#123;public: int countNodes(TreeNode* root) &#123; if(!root) return 0; int num=1; TreeNode *curR(root-&gt;left), *curL(root-&gt;left); // curR is the rightmost edge, which has a height equal to or less than the leftmost edge while(curR) &#123; curL = curL-&gt;left; curR = curR-&gt;right; num = num&lt;&lt;1; &#125; return num + ( (!curL)?countNodes(root-&gt;right):countNodes(root-&gt;left) ); &#125;&#125;;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Binary Tree","slug":"Binary-Tree","permalink":"atlantic8.github.io/tags/Binary-Tree/"}]},{"title":"Combination Sum","slug":"Combination-Sum","date":"2016-07-19T07:20:12.000Z","updated":"2018-12-16T14:08:06.181Z","comments":true,"path":"2016/07/19/Combination-Sum/","link":"","permalink":"atlantic8.github.io/2016/07/19/Combination-Sum/","excerpt":"","text":"Problem 1 : Combination SumGiven a set of candidate numbers (C) and a target number (T), find all unique combinations in C where the candidate numbers sums to T.The same repeated number may be chosen from C unlimited number of times. Note: All numbers (including target) will be positive integers. The solution set must not contain duplicate combinations. For example, given candidate set [2, 3, 6, 7] and target 7,A solution set is:[ [7], [2, 2, 3] ] Solutionthe solution is: use recursive way , the function in the code following: recursive(vector","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Backtracking","slug":"Backtracking","permalink":"atlantic8.github.io/tags/Backtracking/"}]},{"title":"Binary Tree Maximum Path Sum","slug":"Binary-Tree-Maximum-Path-Sum","date":"2016-07-19T07:01:56.000Z","updated":"2018-12-16T14:08:06.178Z","comments":true,"path":"2016/07/19/Binary-Tree-Maximum-Path-Sum/","link":"","permalink":"atlantic8.github.io/2016/07/19/Binary-Tree-Maximum-Path-Sum/","excerpt":"","text":"ProblemGiven a binary tree, find the maximum path sum. For this problem, a path is defined as any sequence of nodes from some starting node to any node in the tree along the parent-child connections. The path does not need to go through the root. For example:Given the below binary tree, 1 / \\ 2 3 Return 6. Original AddressSolutionfunction getMaxRoot(r) compute max value edged with node ralso, r is the highest node. for example: 1 / \\ 2 3 getMaxRoot(1) returns 4.each path has a highest node.for a single node: maxPrice = max(maxPrice, getMaxRoot(r-&gt;left)+getMaxRoot(r-&gt;right)+r-&gt;val);12345678910111213141516171819class Solution &#123;public: int maxPrice;public: int maxPathSum(TreeNode *root) &#123; maxPrice=INT_MIN; getMaxRoot(root); return maxPrice; &#125; // compute the maximum value of the path with hightest and edge node r. int getMaxRoot(TreeNode *r) &#123; if (r == NULL) return 0; int leftM = max(0,getMaxRoot(r-&gt;left)); int rightM = max(0,getMaxRoot(r-&gt;right)); maxPrice = max(maxPrice, leftM+rightM+r-&gt;val); return max(leftM,rightM)+r-&gt;val; &#125;&#125;;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Binary Tree","slug":"Binary-Tree","permalink":"atlantic8.github.io/tags/Binary-Tree/"}]},{"title":"Best Time to Buy and Sell Stock","slug":"Best-Time-to-Buy-and-Sell-Stock","date":"2016-07-19T06:32:38.000Z","updated":"2018-12-16T14:08:06.174Z","comments":true,"path":"2016/07/19/Best-Time-to-Buy-and-Sell-Stock/","link":"","permalink":"atlantic8.github.io/2016/07/19/Best-Time-to-Buy-and-Sell-Stock/","excerpt":"","text":"Problem : Time to Buy and Sell Stock IISay you have an array for which the ith element is the price of a given stock on day i. Design an algorithm to find the maximum profit. You may complete as many transactions as you like (ie, buy one and sell one share of the stock multiple times). However, you may not engage in multiple transactions at the same time (ie, you must sell the stock before you buy again). Solution贪心算法：条件是假设一天内卖完了可以再买，1-2-3可以拆分成1-2和2-3.12345678public class Solution &#123;public int maxProfit(int[] prices) &#123; int total = 0; for (int i=0; i&lt; prices.length-1; i++) &#123; if (prices[i+1]&gt;prices[i]) total += prices[i+1]-prices[i]; &#125; return total;&#125; 如果不允许在一天内卖完了可以再买，贪心的算法是没有意义的，虽然答案是对的。这时，每一次需要找到local最小值和local最大值，然后把差值加到返回值上。123456789101112public int maxProfit(int[] prices) &#123; int profit = 0, i = 0; while (i &lt; prices.length) &#123; // 找到local最小值 while (i &lt; prices.length-1 &amp;&amp; prices[i+1] &lt;= prices[i]) i++; int min = prices[i++]; // 因为price[i+1]&gt;price[i]，所以将i++ // 找到local最大值 while (i &lt; prices.length-1 &amp;&amp; prices[i+1] &gt;= prices[i]) i++; profit += i &lt; prices.length ? prices[i++] - min : 0; &#125; return profit;&#125; Problem : Time to Buy and Sell Stock IIISay you have an array for which the ith element is the price of a given stock on day i. Design an algorithm to find the maximum profit. You may complete at most two transactions. Note:You may not engage in multiple transactions at the same time (ie, you must sell the stock before you buy again). Original AddressSolution依旧是DP问题，如果用a[i][j]表示从标号i到j单次最大的利润，代码如下：12345678910111213141516171819202122232425262728public int maxProfit(int[] prices) &#123; int n = prices.length; if (n &lt;= 1) return 0; int[][] minElement=new int[n][n], maxpay=new int[n][n]; for (int i=0; i&lt;n; i++) &#123; minElement[i][i] = prices[i]; maxpay[i][i] = 0; &#125; for (int len=1; len&lt;n; len++) &#123; for (int i=0; i+len&lt;n; i++) &#123; int j = i+len; if (prices[i]-minElement[i][j-1] &gt; maxpay[i][j-1]) maxpay[i][j] = prices[i]-minElement[i][j-1]; minElement[i][j] = Math.min(prices[j], minElement[i][j-1]); &#125; &#125; int div = 2, maxprofit = maxpay[0][n-1]; if (n &lt;= 3) return maxprofit; for (int i=div; i&lt;n-2; i++) &#123; int x1 = maxpay[0][i]; int x2 = maxpay[i][n-1]; if (x1+x2 &gt; maxprofit) maxprofit = x1+x2; &#125; return maxprofit;&#125; 但是，这样时间复杂度为O(n^2)。TLE！！！！！！！！！然后参考了别人的思路：——————————————-以f[k][i]表示第k个transaction后从开始到标号i-1得到的最大利润迭代方程要考虑两种情况： p[i]不比前一个售出点的price高，所以f[k][i]=f[k][i-1] p[i] 比前一个售出点的price高，所以f[k][i]=max{f[k-1][j]+p[i]-p[j]}=p[i]+max{f[k-1][j]-p[j]} (其中1&lt;j&lt;i-1) 所以，f[k][i] = max{f[k][i-1], max{f[k-1][j]+p[i]-p[j]} }问题来了，如果这么实现，复杂度又会达到O(n^2).注意到情况2中的“ max{f[k-1][j]-p[j]} ”，可以使用一个变量记录最大的f[k-1][j]-p[j]，然后每次更新它即可对于每个transaction循环，它的初始值为：tmp = maxpay[k-1][0]-p[0], 每到一个新的i，更新tmp=max{tmp, f[k-1][i]-p[i])。所以迭代方程就可以写成：f[k][i]=p[i]+tmp. 这样，时间复杂度就降到了O(n). &lt;/b&gt;本题也可以变形为至多执行k个transaction，只需要把代码中2,3改成k,k+1即可。12345678910111213141516171819202122232425public class Solution &#123; public int maxProfit(int[] prices) &#123; int n = prices.length; if (n &lt;= 1) return 0; // maxpay[t][i] indicates the max profit in t-th transaction int[][] maxpay=new int[3][n]; // initialize maxpay, when t=0, maxpay[t][i]=0 for (int j=0; j&lt;3; j++) for (int i=0; i&lt;n; i++) maxpay[j][i] = 0; for (int t=1; t&lt;3; t++) &#123; // for every t, initialize t int tmp = maxpay[t-1][0]-prices[0]; for (int i=1; i&lt;n; i++) &#123; //iteration formula //maxpay[t][i] = Math.max&#123; maxpay[t][i-1] , prices[i]+max&lt;j&gt;&#123;maxpay[t-1][j]-prices[j]&#125; &#125;; maxpay[t][i] = Math.max(maxpay[t][i-1], prices[i]+tmp); // make sure that tmp = max(tmp , maxpay[t-1][i]-prices[i]) tmp = Math.max(tmp, maxpay[t-1][i]-prices[i]); &#125; &#125; return maxpay[2][n-1]; &#125;&#125; Problem : Time to Buy and Sell Stock IVSay you have an array for which the ith element is the price of a given stock on day i. Design an algorithm to find the maximum profit. You may complete at most k transactions. Note:You may not engage in multiple transactions at the same time (ie, you must sell the stock before you buy again). Original AddressSolutionwe are allowed to perform at most k transactionswe can apply the algorithm above, but there is one thing to notice, when k is very large: k&gt;=n/2, that’s to say, we perform one transaction on each day. so, the problem becomes Best Time to Buy and Sell Stock II, greedy algorithm is ok, otherwise we get TLE. 12345678910111213141516171819202122232425public class Solution &#123; public int maxProfit(int k, int[] prices) &#123; int len = prices.length; if (k &gt;= len / 2) return quickSolve(prices); int[][] t = new int[k + 1][len]; for (int i = 1; i &lt;= k; i++) &#123; int tmpMax = -prices[0]; for (int j = 1; j &lt; len; j++) &#123; t[i][j] = Math.max(t[i][j - 1], prices[j] + tmpMax); tmpMax = Math.max(tmpMax, t[i - 1][j - 1] - prices[j]); &#125; &#125; return t[k][len - 1]; &#125; private int quickSolve(int[] prices) &#123; int len = prices.length, profit = 0; for (int i = 1; i &lt; len; i++) // as long as there is a price gap, we gain a profit. if (prices[i] &gt; prices[i - 1]) profit += prices[i] - prices[i - 1]; return profit; &#125;&#125; Problem : Best Time to Buy and Sell Stock with CooldownSay you have an array for which the ith element is the price of a given stock on day i. Design an algorithm to find the maximum profit. You may complete as many transactions as you like (ie, buy one and sell one share of the stock multiple times) with the following restrictions: You may not engage in multiple transactions at the same time (ie, you must sell the stock before you buy again).After you sell your stock, you cannot buy stock on next day. (ie, cooldown 1 day) Example: prices = [1, 2, 3, 0, 2] maxProfit = 3 transactions = [buy, sell, cooldown, buy, sell] Solution本题中，可能的操作有buy、sell、rest(啥也不干)。可以使用状态机来解题：由题可以绘制如下状态机：转移方程表示如下： s0[i] = max(s0[i - 1], s2[i - 1]); s1[i] = max(s1[i - 1], s0[i - 1] - prices[i]); s2[i] = s1[i - 1] + prices[i]; 由于s1状态是买完以后的状态，所以最值最大值肯定不在s1上出现，只要找到最大的s0和s2.关于初值设置： s0=0，因为如果以s0为开始，你没有任何股票 如果以s1为开始，通过buy第一天的股票获得，可以设置s1的初值为-price[0] 设置s2的初值为INT_MIN，当然设置为0也完全没有问题(没有股票卖也卖不到钱) 123456789101112131415161718class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices)&#123; if (prices.size() &lt;= 1) return 0; vector&lt;int&gt; s0(prices.size(), 0); vector&lt;int&gt; s1(prices.size(), 0); vector&lt;int&gt; s2(prices.size(), 0); s1[0] = -prices[0]; s0[0] = 0; s2[0] = INT_MIN; for (int i = 1; i &lt; prices.size(); i++) &#123; s0[i] = max(s0[i - 1], s2[i - 1]); s1[i] = max(s1[i - 1], s0[i - 1] - prices[i]); s2[i] = s1[i - 1] + prices[i]; &#125; return max(s0[prices.size() - 1], s2[prices.size() - 1]); &#125;&#125;; 空间复杂度为O(n)，可以降低到O(1). 12345678910111213class Solution &#123; int maxProfit(vector&lt;int&gt;&amp; prices) &#123; if (prices.size() &lt; 2) return 0; int s0 = 0, s1 = -prices[0], s2 = 0; for (int i = 1; i &lt; prices.size(); ++i) &#123; int last_s2 = s2; s2 = s1 + prices[i]; s1 = max(s0 - prices[i], s1); s0 = max(s0, last_s2); &#125; return max(s0, s2); &#125;&#125;","categories":[{"name":"OJ","slug":"OJ","permalink":"atlantic8.github.io/categories/OJ/"}],"tags":[{"name":"DP","slug":"DP","permalink":"atlantic8.github.io/tags/DP/"},{"name":"LeetCode","slug":"LeetCode","permalink":"atlantic8.github.io/tags/LeetCode/"},{"name":"Greedy","slug":"Greedy","permalink":"atlantic8.github.io/tags/Greedy/"},{"name":"State Machine","slug":"State-Machine","permalink":"atlantic8.github.io/tags/State-Machine/"}]},{"title":"python visualization","slug":"python-visualization","date":"2016-07-10T14:12:11.000Z","updated":"2018-12-16T14:08:06.493Z","comments":true,"path":"2016/07/10/python-visualization/","link":"","permalink":"atlantic8.github.io/2016/07/10/python-visualization/","excerpt":"","text":"matplotlibmatplotlib配置 修改文件，位于.matplotlib目录中 使用rc方法,可以定义的有’figure’,’axes’,’xtick’,’ytick’,’grid’,’legend’等123456plt.rc('figure', figsize=(10,10)) # 设置图像默认大小# 也可以font_option = &#123;'family':'monospace', 'weight':'bold', 'size':'small'&#125;plt.rc('font', **font_option) matplotlib使用12import matplotlib.pyplot as pltimport numpy as np 创建一个新的figure，所有图像都位于Figure对象中1fig = plt.figure(2) # 图像编号为2 无法通过空的Figure绘图，必须用add_subplot()创建subplot创建4个子图，2x21234ax1 = fig.add_subplot(2,2,1)ax2 = fig.add_subplot(2,2,2)ax3 = fig.add_subplot(2,2,3)fig.show() # 显示 分别对每个sub_figure画图1234ax1.plot(...)ax2.scatter(...)ax2.bar(...)fig.show() subplots，返回一个含有已创建subplot对象的numpy数组axes可以使用axes[][]的形式访问12345678fig, axes = plt.subplots(2,3)axes$-&gt; array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0A8B2EF0&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0AA5F5D0&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0AA9DD90&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0AAD1E70&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0AB1B810&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0697C130&gt;]], dtype=object) subplots_adjust间距控制wspace,hspace控制宽度和高度的百分比，可以用作subplot之间的距离1plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=None) pyplot.subplots的选项 parameter explaination nrows subplot的行数 ncols subplot的列数 sharex 所有子图使用相同x轴刻度（xlim的影响） sharey 所有子图使用相同y轴刻度（xlim的影响） subplot_kw 用于创建各subplot的关键字字典 **fig_kw 创建fig时的其他关键字，如plt.subplot(2,2,figsize=(8,6)) 设置x、y轴的刻度12345ticks = axe1.set_xticks([0,200,400,600,800])# 旋转45读，字体大小为9labels = axe1.set_xtickslabels(['one','two','three','four','five'],rotation=45,fontsize=9)# 将图例放在不错的位置，自动选择ax.legend(loc='best') 注解，显示在(x,y)位置123456ax.text(x, y, 'hello world', family='consola', fontsize=10)# annotate函数注解，既有箭头又有文字# xy是箭头位置，xytext是注解位置，结果如下图：ax.annotate('local max', xy=(2, 1), xytext=(3, 1.5), arrowprops=dict(facecolor='black', shrink=0.05), ) ![](http://matplotlib.org/_images/annotation_basic.png) 图形中放入块patch1234567rect = plt.Rectangle((0.2,0.75), 0.4, 0.15, color='r', alpha=0.3)circ = plt.Circle((0.7,0.2), 0.15, color='b', alpha=0.3)pgon = plt.Polygon([[0.15,0.15],[0.35,0.4],[0.2,0.6]], color='g', alpha=0.3)ax.add_patch(rect)ax.add_patch(circ)ax.add_patch(pgon) 图形属性和说明 attribute explaination color color=’g’ 颜色，可以指定’#555555’ linestyle linestyle=’—‘ 线性 marker marker=’o’ 标记 label label=’algorithm 1’ 图例 xlim,ylim x轴、y轴的范围 保存文件，参数设置如下表1plt.savefig() params introduction fname 文件名 dpi 分辨率（每英寸点数），默认为100 facecolor、edgecolor 背景色，默认为白色 format 设置文件格式，png、pdf等 bbox_inches 图标需要保存的部分。设为tight则尝试剪掉图标周围的空白部分 Pandas中的可视化方法普通的plot12345678import matplotlib.pyplot as pltimport matplotlibmatplotlib.style.use('ggplot')ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))ts = ts.cumsum()ts.plot()plt.show() ![](http://pandas.pydata.org/pandas-docs/stable/_images/series_plot_basic.png) On DataFrame, plot() is a convenience to plot all of the columns with labels1234567df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list('ABCD'))df = df.cumsum()df.plot()plt.show()# 其他关键字 subplots=True将不同列的图分别画在子图中# layout=(2, 3) 两行三列# sharex=False，sharey=False -&gt; 不共享x、y轴 ![](http://pandas.pydata.org/pandas-docs/stable/_images/frame_plot_basic.png) You can plot one column versus another using the x and y keywords in plot()1234df3 = pd.DataFrame(np.random.randn(1000, 2), columns=['B', 'C']).cumsum()df3['A'] = pd.Series(list(range(len(df))))df3.plot(x='A', y='B')plt.show() 使用第二个y轴使用secondary_y关键字123456df.A.plot()df.B.plot(secondary_y=True, style='g')# 或者 mark_right默认是Trueax = df.plot(secondary_y=['A', 'B'], mark_right=True)ax.set_ylabel('CD scale')ax.right_ax.set_ylabel('AB scale') ![](http://pandas.pydata.org/pandas-docs/stable/_images/frame_plot_secondary_y.png) Scales尺度使用logy、logx、loglog关键字123ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))ts = np.exp(ts.cumsum())ts.plot(logy=True) 其他plot，用kind指定 value function value function bar 直方图 hist 统计直方图 kde, density 密度图 box 盒须图 area 面积图 scatter 散点图 hexbin 六边形箱图 pie 饼图 barh 横向的直方图 12df.ix[5].plot(kind='bar')plt.show() ![](http://pandas.pydata.org/pandas-docs/stable/_images/bar_plot_ex.png) 其他用法1234df = pd.DataFrame()$-&gt; df.plot.area df.plot.box df.plot.hist df.plot.pie df.plot.bar df.plot.density df.plot.kde df.plot.scatter df.plot.barh df.plot.hexbin df.plot.line bar plot1234567df.ix[5].plot.bar()plt.show()df2 = pd.DataFrame(np.random.rand(10, 4), columns=['a', 'b', 'c', 'd'])df2.plot.bar()df2.plot.bar(stacked=True) # 堆叠式df2.plot.barh(stacked=True) # 横向 histogramHistogram can be drawn by using the DataFrame.plot.hist() and Series.plot.hist() methods123df4 = pd.DataFrame(&#123;'a': np.random.randn(1000) + 1, 'b': np.random.randn(1000),'c': np.random.randn(1000) - 1&#125;, columns=['a', 'b', 'c'])df4.plot.hist(stacked=True, bins=20) # 下图df4['a'].plot.hist(orientation='horizontal', cumulative=True) ![](http://pandas.pydata.org/pandas-docs/stable/_images/hist_new_stacked.png) Box盒须图Boxplot can be drawn calling Series.plot.box() and DataFrame.plot.box(), or DataFrame.boxplot() to visualize the distribution of values within each column123456df = pd.DataFrame(np.random.rand(10, 5), columns=['A', 'B', 'C', 'D', 'E'])# 设置不同区域的颜色color = dict(boxes='DarkGreen', whiskers='DarkOrange', medians='DarkBlue', caps='Gray')# sym keyword, vert表示是否横向显示# 另外还有positions=[1, 4, 5, 6, 8]参数指示盒图的位置df.plot.box(color=color, sym='r+', vert=False) ![](http://pandas.pydata.org/pandas-docs/stable/_images/box_new_colorize.png) Area面积图Series.plot.area() and DataFrame.plot.area() 123df = pd.DataFrame(np.random.rand(10, 4), columns=['a', 'b', 'c', 'd'])df.plot.area(stacked=True)# 如果stacked=False，图形不堆叠 ![](http://pandas.pydata.org/pandas-docs/stable/_images/area_plot_stacked.png) Scatter散点图using the DataFrame.plot.scatter() method12345678df = pd.DataFrame(np.random.rand(50, 4), columns=['a', 'b', 'c', 'd'])ax = df.plot.scatter(x='a', y='b', color='DarkBlue', label='Group 1')# 两种不同颜色的组，注意ax=axdf.plot.scatter(x='c', y='d', color='DarkGreen', label='Group 2', ax=ax)df.plot.scatter(x='a', y='b', c='c', s=50) # 下图# 用c的值确定bubble大小df.plot.scatter(x='a', y='b', s=df['c']*200) ![](http://pandas.pydata.org/pandas-docs/stable/_images/scatter_plot_colored.png) ![](http://pandas.pydata.org/pandas-docs/stable/_images/scatter_plot_bubble.png) Hexagonal Bin Plot六边形箱图数据过多，过于密集，无法显示出每一个数据，所以就显示数据密度相关参数use DataFrame.plot.hexbin()12345678df = pd.DataFrame(np.random.randn(1000, 2), columns=['a', 'b'])df['b'] = df['b'] + np.arange(1000)# gridsize决定网格能有多少个，默认值为100df.plot.hexbin(x='a', y='b', gridsize=25)# a和b作为二维坐标，C作为值，reduce_C_function是一个用于处理多个数据值的函数# reduce_C_function包括：mean, max, sum, std等，下面有图df.plot.hexbin(x='a', y='b', C='z', reduce_C_function=np.max, gridsize=25) ![](http://pandas.pydata.org/pandas-docs/stable/_images/hexbin_plot_agg.png) Pie饼图DataFrame.plot.pie() or Series.plot.pie()12345678910series = pd.Series(3 * np.random.rand(4), index=['a', 'b', 'c', 'd'], name='series')# Series的饼状图series.plot.pie(figsize=(6, 6))# 使用subplot，每一列都是一个饼图，subplots=True要有df = pd.DataFrame(3 * np.random.rand(4, 2), index=['a', 'b', 'c', 'd'], columns=['x', 'y'])df.plot.pie(subplots=True, figsize=(8, 4))# labels=['AA', 'BB', 'CC', 'DD'] 每个扇形的标签# colors=['r', 'g', 'b', 'c'] 每个扇形的颜色# autopct='%.2f' 显示比例、显示精度# fontsize=20 字体大小 Density plot12ser = pd.Series(np.random.randn(1000))ser.plot.kde() # 数量越多就越接近高斯分布 ![](http://pandas.pydata.org/pandas-docs/stable/_images/kde_plot.png) Scatter Matrix Plot123from pandas.tools.plotting import scatter_matrixdf = pd.DataFrame(np.random.randn(1000, 4), columns=['a', 'b', 'c', 'd'])scatter_matrix(df, alpha=0.2, figsize=(6, 6), diagonal='kde') ![](http://pandas.pydata.org/pandas-docs/stable/_images/scatter_matrix_kde.png) 多元数据可视化Andrews曲线可以应用于多元数据，将其绘制成使用样本属性作为傅里叶级数参数的大量曲线。123from pandas.tools.plotting import andrews_curvesdata = pd.read_csv('data/iris.data')andrews_curves(data, 'Name') # Name是类别属性，根据类别划分 iris.data中的数据 SepalLength SepalWidth PetalLength PetalWidth Name 5.1 3.5 1.4 0.2 Iris-setosa ![](http://pandas.pydata.org/pandas-docs/stable/_images/andrews_curves.png) Parallel Coordinates平行坐标系可以应用于多元数据,每个垂直的线都对应一个属性123from pandas.tools.plotting import parallel_coordinatesdata = pd.read_csv('data/iris.data')parallel_coordinates(data, 'Name') ![](http://pandas.pydata.org/pandas-docs/stable/_images/parallel_coordinates.png) 随机性检测Lag Plot用于检测数据集或者是时间序列数据是否是随机数据,显示data[t]和data[t+1]的关系。如果plot出的图形是无规则的，那么数据有极大的可能性是随机的。12345from pandas.tools.plotting import lag_plotdata = pd.Series(np.arange(1000)) # 有规则data = pd.Series(np.random.rand(1000)) # 无规则data = pd.Series(0.1 * np.random.rand(1000) + 0.9 * np.sin(np.linspace(-99 * np.pi, 99 * np.pi, num=1000))) # 有规则， 有图lag_plot(data) ![](http://pandas.pydata.org/pandas-docs/stable/_images/lag_plot.png) Autocorrelation Plot用于检测时序数据的随机性，通过计算不同的时间延迟（步长）下数据的自相关系数如果这个序列是随机的，那么对于所有的延迟，其自相关系数都应该接近于0。否则，必然存在至少一个延迟对应的自相关系数远大于/小于0123from pandas.tools.plotting import autocorrelation_plotdata = pd.Series(0.7 * np.random.rand(1000) + 0.3 * np.sin(np.linspace(-9 * np.pi, 9 * np.pi, num=1000)))autocorrelation_plot(data) ![](http://pandas.pydata.org/pandas-docs/stable/_images/autocorrelation_plot.png) 其中，中间黑线的0值线，向外的实线和虚线分别是95%、99%置信带，有颜色的线是不同延迟对应的自相关系数。 Bootstrap Plot可视化地评估统计信息的不确定性，比如说均值、中值、中距等方法：从数据集中随机选取特定长度的子集并计算其相应的统计信息，重复特定次数123from pandas.tools.plotting import bootstrap_plotdata = pd.Series(np.random.rand(1000))bootstrap_plot(data, size=50, samples=500, color='grey') ![](http://pandas.pydata.org/pandas-docs/stable/_images/bootstrap_plot.png) Colormaps123456789from matplotlib import cm# df.plot(colormap='cubehelix')# df.plot(colormap=cm.cubehelix)# colormap='Greens'# colormap='gist_rainbow'# colormap='winter'dd = pd.DataFrame(np.random.randn(10, 10)).applymap(abs)dd = dd.cumsum()dd.plot.bar(colormap='Greens') Plotting Tables关键字table=True，table关键字也可以使用DataFrame或者Series作为值1234fig, ax = plt.subplots(1, 1)df = pd.DataFrame(np.random.rand(5, 3), columns=['a', 'b', 'c'])ax.get_xaxis().set_visible(False) # Hide Ticksdf.plot(table=True, ax=ax)","categories":[],"tags":[{"name":"python","slug":"python","permalink":"atlantic8.github.io/tags/python/"},{"name":"visualization","slug":"visualization","permalink":"atlantic8.github.io/tags/visualization/"}]},{"title":"python数据加载、存储与文件格式","slug":"python数据加载、存储与文件格式","date":"2016-06-23T07:37:19.000Z","updated":"2018-12-16T14:08:06.497Z","comments":true,"path":"2016/06/23/python数据加载、存储与文件格式/","link":"","permalink":"atlantic8.github.io/2016/06/23/python数据加载、存储与文件格式/","excerpt":"","text":"csv 输入函数 说明 read_csv 从文件、URL、文件对象中加载带分隔符(,)的数据 read_table 从文件、URL、文件对象中加载带分隔符(默认为制表符:\\t)的数据 read_fwf 读取顶宽列格式数据(没有分隔符) read_clipboard 读取剪贴板数据，read_table的剪贴板版 from_csv Series的方法，直接读出Series实例 一些上述函数扩展用法123456789101112131415161718192021222324252627282930313233343536import pandas as pdfrom pandas import DataFrame,Series# 指定分隔符，也可用delimiter，读取前10行数据pd.read_table('filename', sep=',',nrows=10)# 读取特定大小的文件块(byte)pd.read_table('filename', chunksize=1000)# 读入DataFrame时，指定列名pd.read_csv('filename', header=None)pd.read_csv('filename', names=['a','b','c','d'])# 指定列为索引，列d设为索引pd.read_csv('filename', names=['a','b','c','d'], index_col='d')# 层次化索引的话，可以index_col指定多个列名pd.read_csv('filename', names=['a','b','c','d'], index_col=['c','d'])# 跳过文件的某些行pd.read_csv('filename', skiprows=[1,3,6])# 需要忽略的行数，从尾部算起pd.read_csv('filename', skip_footer=10)# 读文件缺失值处理，将文件中某些值设置为nanpd.read_csv('filename', na_values=['NULL'])# 将文件中满足box条件的值设置为nanbox = &#123;'col1':['foo','NA'], 'col3':['two']&#125;pd.read_csv('filename', na_values=['NULL'])# 写文件缺失值处理，将nan写成na_reppd.read_csv('filename', na_rep='NULL')# 日期解析,解析所有列，也可以指定，默认为False;# 冲突型日期，看成国际标准格式，28/6/2016, 默认为Falsepd.read_csv('filename', parse_dates=True, dayfirst=True)# 设置编码，数据解析后仅有一列返回Seriespd.read_csv('filename', encoding='utf-8', squeeze=True) 输出函数 说明 to_csv 把数据写入到文件、输出流中，分隔符为(,)，Series也有这个方法 12345678# 直接打印data.to_csv(sys.stdout)# 输出到文件，并且将nan用'NULL'替换data.to_csv('filename', na_rep='NULL')# 列名和index也可以禁用data.to_csv('filename', index=False, header=False)# 通过指定cols可以显示特定的列data.to_csv('filename', index=False, cols=['a','b']) 手工处理分隔符格式对于任何单字符分隔符文件，可以直接使用python内置的csv模块，将任意已打开的文件或文件对象传递给csv.reader:123456import csvf = open('filename')reader = csv.reader(f)# 对reader迭代会为每行产生一个元组for line in reader: print(line) csv文件的形式多样只需定义csv.Dialect的一个子类即可定义出新格式123456class my_dialect(csv.Dialect): lineterminator = '\\n' delimiter = ';' quotechar = '\"'reader = csv.reader(f, dialect=my_dialect()) csv.Dialect的属性还包括： 属性 说明 delimiter 分隔字段的单字符字符串，默认为’,’ lineterminator 写操作的行终结符，默认为’\\r\\n’。读操作忽略，它能认出跨平台结束符 quotechar 用于带有特殊字符的字段的引用符号 quoting 引用约定。包括csv.QUOTE_ALL(引用所有字段)，csv.QUOTE_MINIMAL(只引用带有特殊字符的字段)，csv.QUOTE_NONNUMERIC(只引用非数值属性),csv.QUOTE_NON(不引用) skipinitialspace 忽略分隔符后面的空白符，默认为False doublequote 处理字段内的引用符号，如果为True则双写 escapechar 用于对分隔符进行转义的字符串，默认禁用 要手工输出分隔符文件，使用csv.writer1234with open('filename', 'w') as f:writer = csv.writer(f, dialect=my_dialect)writer.writerow(('one','two','three'))writer.writerow(('1','2','3')) JSON123456789101112131415161718obj = \"\"\"&#123;\"name\":\"wes\", \"place\":[\"usa\",\"russia\",\"china\"], \"pet\": null, \"siblings\": [&#123;\"name\":\"scott\",\"age\":25, \"pet\":\"Zuko\"&#125;,&#123;\"name\":\"katie\",\"age\":33, \"pet\":\"Cisco\"&#125;]&#125;\"\"\"import json# 将json字符串转换成python形式result = json.loads(obj)$-&gt; &#123;u'name': u'wes', u'pet': None, u'place': [u'usa', u'russia', u'china'], u'siblings': [&#123;u'age': 25, u'name': u'scott', u'pet': u'Zuko'&#125;, &#123;u'age': 33, u'name': u'katie', u'pet': u'Cisco'&#125;]&#125;# 将python字符串转换成json形式asjson = json.dumps(result) pandas团队正致力于开发原生的高效json导出(to_json)和解码(from_json)功能，待续……… XML和HTML解析使用lxml.html处理HTML内容 123456789101112from lxml.html import parsefrom urllib2 import urlopenparsed = parse(urlopen('http://finance.yahoo.com/xxxx/xxx/xxx///xxxx'))doc = parsed.getroot()# 通过doc可以获得特定类型的所有html标签(tag)，比如table等links = doc.findall('.//a') # 链接links[0].get('href')$-&gt; 'http://baidu.com'links[0].text_content()$-&gt; '百度一下' 处理表格，’.//table’表格的每一行都是 ‘.//tr’表格的第一行是标题行，th表示单元格余下的行是数据行，td表示单元格123456789101112131415161718from pandas.io.parsers import TextParser# 下面的是解析函数,解析一行数据def _unpack(row, kind='td'): elts = row.findall('.//%s' % kind) return [val.text_content() for val in elts]# 解析整个表格，返回一个DataFrame对象def parse_table(table): rows = table.findall('.//tr') header = _unpack(row[0], kind='th') data = [_unpack(r) for r in rows[1:]] # TextParser将数值型的列进行类型转化 return TextParser(data, names=header).get_chunk()# 定位所有的表格tables = doc.findall('.//table')tab = tables[0]parse_table(tab) 使用lxml.objectify处理XML内容root.INDICATOR用于返回一个用于产生各个XML元素的生成器。123456789101112131415161718from lxml import objectifyparsed = objectify.parse(open('hello.xml'))root = parsed.getroot()root.get('href')$-&gt; 'http://baidu.com'root.text$-&gt; '百度一下'data = []for elt in root.INDICATOR: el_data = &#123;&#125; for child in elt.getchildren(): el_data[child.tag] = child.pyval data.append(el_data)# 转化成DataFrameperf = DataFrame(data) 二进制数据和Excel文件pandas对象有一个将数据以pickle序列化形式保存到磁盘上的方法：save1234# 写入磁盘frame.save('filename')# 读入内存frame = pd.load('filename') 使用xlrd包和openpyxl包(需要安装)读写xls或者xlsx文件1234# 创建ExcelFile示例xls_file = pd.ExcelFile('data.xls')# 存放在某个工作表中的数据可以通过parse读取到DataFrame中table = xls_file.parse('sheet1') 使用数据库关系型数据库12345678910111213141516171819202122232425import sqlite3# create tablequery = \"\"\"create table test(a varchar(20), b integer);\"\"\"con = sqlite3.connect(':memory:')con.execute(query)con.commit()# insertdata = [('tom',20),('jerry',15)]stmt = \"insert into test values(?,?)\"con.executemany(stmt, data)con.commit# query, select返回元组列表(大部分python SQL驱动器都这样)cursor = con.execute('select * from test')rows = cursor.fetchall()print(rows)# 由于这样产生DataFrame的方法比较复杂，所以有现成的方法import pandas.io.sql as sqlsql.read_frame('select * from test', con) 非关系型数据库非关系型数据库有多种方式，有些是字典键值对形式存在，另一些是基于文档的，这里不再赘述。","categories":[],"tags":[{"name":"python","slug":"python","permalink":"atlantic8.github.io/tags/python/"},{"name":"文件","slug":"文件","permalink":"atlantic8.github.io/tags/文件/"},{"name":"pandas","slug":"pandas","permalink":"atlantic8.github.io/tags/pandas/"}]},{"title":"NumPy基础","slug":"NumPy基础","date":"2016-06-23T07:32:40.000Z","updated":"2018-12-16T14:08:06.367Z","comments":true,"path":"2016/06/23/NumPy基础/","link":"","permalink":"atlantic8.github.io/2016/06/23/NumPy基础/","excerpt":"","text":"12import numpy as npfrom numpy.random import randn ndarray：一种对维数组对象创建方法 函数 说明 array 将输入数据(列表、元组、数组或其他序列类型)转换为ndarray，可以指定dtype asarray 将输入转换为ndarray，如果输入本身就是ndarray，则不进行复制 arange 同range，只是返回的是ndarray ones,ones_like 前者根据指定形状和dtype创建一个全1数组。 后者以另一个数组为参照，copy其形状和dtype zeros,zeros_like 前者根据指定形状和dtype创建一个全0数组。 后者以另一个数组为参照，copy其形状和dtype empty,empty_like 只分配内存，不填充任何值 eye,identity 单位矩阵 NumPy的精度dtype集合，实际使用应该加上np.前缀 dtype dtype int8, uint8 int16,uint16 int32, uint32 int64,uint64 float16, float32 float64,float128 complex64 complex128 complex256 bool 1234567891011# constructarr1 = np.array([1,2,3,4,5])arr1.ndim$-&gt; 1 # 一维数组arr1.shape$-&gt; (1,5) # 1x5的数组arr1.dtype$-&gt; dtype('int64')# type convert，这里一定会常见一个新的数组，无论目标转换类型与原数组类型是否一致float_arr = arr1.astype(np.float64) 索引与切片索引切片方法与list的对应方法相似，不同点在于：数组切片也是原始数组的视图，这意味着数据不会被复制，因此视图上的任何更改都会直接地反映到源数组上。而list不然，请具体看下面的例子。1234567891011121314a = [1,2,3,4,5,6]b = a[2:5]b[1] = 100print(a)$-&gt; [1, 2, 3, 4, 5, 6]arr = np.array([1,2,3,4,5,6])br = arr[2:5]br[1] = 99arr$-&gt; array([ 1, 2, 3, 99, 5, 6])# 如果需要ndarray的切片的副本而非视图，可以显示地复制new_arr = arr[2:5].copy() 多维数组的切片123456789101112131415161718192021222324arr2d = np.array([[1,2,3],[4,5,6],[7,8,9]])arr2d[1][1]$-&gt; 1arr2d[1,1]$-&gt; 1# 沿着第0轴(第一个轴)切片arr2d[:2]$-&gt; array([[1, 2, 3], [4, 5, 6]])arr2d[:2,1:]$-&gt; array([[2, 3], [5, 6]])arr2d[:,:1]$-&gt; array([[1], [4], [7]])# bool索引与赋值arr&lt;4$-&gt; array([ True, True, True, False, False, False], dtype=bool)arr[arr&lt;4] = 4arr$-&gt; array([ 4, 4, 4, 99, 5, 6]) 花式索引(fancy indexing),花式索引总是将数据复制到新数组中，切片得到的是视图。123456789101112131415161718192021222324252627282930313233arr = np.empty((8,4))for i in range(8): arr[i] = iarr$-&gt; array([[ 0., 0., 0., 0.], [ 1., 1., 1., 1.], [ 2., 2., 2., 2.], [ 3., 3., 3., 3.], [ 4., 4., 4., 4.], [ 5., 5., 5., 5.], [ 6., 6., 6., 6.], [ 7., 7., 7., 7.]])# 以特定顺序选取行子集，传入一个制定顺序的证书列表或者ndarrayarr[[4,2,6]] # 打印第5、3、7行$-&gt; array([[ 4., 4., 4., 4.], [ 2., 2., 2., 2.], [ 6., 6., 6., 6.]])# 如果使用负数将从末尾计数arr[[-2,-1,4]] # 倒数第二行、第一行和正数第5行$-&gt; array([[ 6., 6., 6., 6.], [ 7., 7., 7., 7.], [ 4., 4., 4., 4.]])arr = np.arange(32).reshape((8,4))arr[[1,5,7,2],[0,3,1,2]]$-&gt; array([ 4, 23, 29, 10])# 上面操作结果没有返回一个指示对应行列值得矩阵，方法如下：arr[np.ix_([1,5,7,2],[0,3,1,2])]$-&gt; array([[ 4, 7, 5, 6], [20, 23, 21, 22], [28, 31, 29, 30], [ 8, 11, 9, 10]]) 数组轴对换和转置数组不仅有transpose方法(返回数据源视图，不复制)，还有T属性，二维的情况很容易理解，下面是高纬轴对换的例子。123456789101112131415161718192021222324252627arr = np.arange(16).reshape((2,2,4))arr$-&gt; array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7]], [[ 8, 9, 10, 11], [12, 13, 14, 15]]])arr.transpose((1,0,2))$-&gt; array([[[ 0, 1, 2, 3], [ 8, 9, 10, 11]], [[ 4, 5, 6, 7], [12, 13, 14, 15]]])# swapaxes,返回数据源视图，不复制arr = np.arange(16).reshape((2,2,4))arr.swapaxes(1,2)Out[53]:array([[[ 0, 4], [ 1, 5], [ 2, 6], [ 3, 7]], [[ 8, 12], [ 9, 13], [10, 14], [11, 15]]]) 通用函数，元素级数组函数 一元函数 说明 一元函数 说明 abs,fabs 求绝对值，实数用fabs更快 sqrt 计算各元素平方根,相当于arr**0.5 square 计算各元素平方,相当于arr**2 exp 计算e的元素次方 log,log10,log2,log1p 对数运算，最后一个是log(1+x) sign 指示符号，(1,0,-1) ceil 向上取整 floor 向下取整 rint 四舍五入到最近的整数，保留dtype modf 将数组的整数和小数部分以两个独立数组的形式返回 isnan 返回哪些是NaN的bool数组 isfinite,isinf 返回哪些是有穷的/无穷的bool数组 cos,cosh,sin,sinh,tan,tanh 普通型和双曲型三角函数 logical_not 计算各元素not x的真值，相当于-arr arccos,arccosh,arcsin,arcsinh,arctan,arctanh 反三角函数 二元函数 说明 二元函数 说明 add 数值中对应元素相加 substract 第一个数组元素减去第二个数组元素 multiply 数组元素相乘 divide,floor_divide 除法，向下圆整除法 power 第一个数组元素为底，第二个数组元素为顶计算乘方 maximum,fmax 最大值，fmax忽略nan minimum,fmin fmin忽略nan mod 求模 copysign 将第二个数组元素的符号赋给第一个数组的元素 greater,greater_equal,less,less_equal 比较运算，产生bool数组 equal,not_equal 比较运算，产生bool数组 logical_and,logical_or,logical_xor 元素级真值逻辑运算 123456789101112arr = np.arange(10)np.sqrt(arr)x = randn(8)y = randn(8)np.maximum(x,y)arr = randn(8)*5np.modf(arr)$-&gt; (array([[-0.06742411, -0.37438428, 0.7491406 , 0.63876896, -0.73629364, 0.60505606, -0.38540241, 0.78968936]]), array([[-1., -1., 0., 0., -1., 1., -1., 0.]])) 数据处理和统计12345678910111213141516171819202122232425points = np.arange(-5,5,0.01) # 1000个间隔相等的点xs,ys = np.meshgrid(points, points)z = np.sqrt(xs**2+ys**2)xarr = np.array([1.1,1.2,1.3,1.4,1.5])yarr = np.array([2.1,2.2,2.3,2.4,2.5])cond = np.array([True,False,True,True,False])# 根据cond的情况选取xarr或者yarrresult = [(x if c else x) for x,y,c in xarr,yarr,cond]# 上述方法对大数组处理速度较慢，且无法用于多维数组# np.where函数通常用于：根据一个数组产生另一个数组result = np.where(cond, xarr, yarr)arr = randn(4,4)arr$-&gt; array([[ 1.52182545, 0.87451946, 1.04261881, -1.0087171 ], [-0.17748091, -0.11488603, -0.29951479, 0.67766543], [-0.21761354, -0.83476571, 1.69775644, 1.45229995], [ 0.1791336 , 1.55750933, 0.23509194, 0.39716205]])np.where(arr&gt;0, 2, -2) # 把大于0的都换成2，小于0的换成-2$-&gt; array([[ 2, 2, 2, -2], [-2, -2, -2, 2], [-2, -2, 2, 2], [ 2, 2, 2, 2]]) 基本数组统计方法既是数组示例的方法，也是顶级方法。这类函数可以接受一个axis参数，表示轴向方向 方法 说明 sum 求和，对于bool值数组，sum计算True的个数 mean 均值，长度为0的均值为NaN std,var 标准差和方差，自由度可调，默认为n min,max 最小值，最大值 argmin,argmax 最小、最大元素的索引 cumsum 所有元素累计和 cumprod 所有元素累计积 12345678910arr.mean(axis=1)arr = np.arange(9).reshape((3,3))arr.cumsum(axis=0) # 列和$-&gt; array([[ 0, 1, 2], [ 3, 5, 7], [ 9, 12, 15]])arr.cumprod(1) #行积$-&gt; array([[ 0, 0, 0], [ 3, 12, 60], [ 6, 42, 336]]) 用于bool数组的方法12345(arr&gt;0).sum() #计算正值数量bools = np.array([False, True, True, False])# any用于检测数组中是否有True， all检查是否都是Truebools.any() -&gt; Truebools.all() -&gt; False 排序顶级方法np.sort返回排序完的副本，就地排序则会修改数组本身12345678910111213arr = randn(8)arr.sort()np.array(arr)$-&gt; array([[ 0.4811325 ], [ 1.49888281], [ 0.71035914], [-1.24322946], [ 0.90270716], [ 1.29337938], [-0.29419419], [ 0.71318192]])arr = randn(5,3)arr.sort(axis=0) 数组集合运算 | 函数 | 说明 || unique(x) | 计算x中的唯一元素，返回排序好的结果 || intersect1d(x,y) | 计算x和y中的公共元素(交集)，返回排序好的结果 || union1d(x,y) | 计算x和y中的并集，返回排序好的结果 || in1d(x,y) | 返回表示x的元素是否在y中的bool数组 || setdiff1d(x,y) | 差集，在x中，不在y中 || setxor1d(x,y) | 对称差，找出只出现在一个数组中的元素 | 线性代数基础 函数 说明 函数 说明 diag 给定矩阵，以一维数组的方式返回对角线元素；给定一维数组，返回以此数组为对角线的方阵 dot 矩阵乘法 trace 矩阵的迹 det 行列式的值 eig 方阵的特征值和特征向量 inv 方阵的逆 pinv 矩阵的Moore-Penrose伪逆 qr 计算矩阵的QR分解 svd 奇异值分解 solve 计算线性方程组Ax=b，A是方阵 lstsq 计算Ax=b的最小二乘解 1234567from numpy.linalg import inv,qrx = np.arange(6).reshape((3,2))y = np.arange(6).reshape((2,3))x.dot(y) # 等同于np.dot(x,y)q,r = pr(arr) 随机数生成numpy.random中的部分函数 函数 说明 函数 说明 seed 确定随机数生成器种子 permutation 序列的随机排列或一个随机排列的范围 shuffle 对一个序列就地随机排列 rand 产生均匀分布的样本值 randint 给定上下限的随机整数选取 randn 产生正态分布样本值(mean=0,std=1) binomial 产生二项分布样本值 normal 产生正态分布样本值 beta 产生Beta分布样本值 chisqaure 产生卡方分布样本值 gama 产生Gamma分布样本值 uniform 产生[0,1]均匀分布样本值","categories":[],"tags":[{"name":"numpy","slug":"numpy","permalink":"atlantic8.github.io/tags/numpy/"},{"name":"python","slug":"python","permalink":"atlantic8.github.io/tags/python/"}]},{"title":"简单git使用方法","slug":"简单git使用方法","date":"2016-06-08T01:34:40.000Z","updated":"2018-12-16T14:08:06.513Z","comments":true,"path":"2016/06/08/简单git使用方法/","link":"","permalink":"atlantic8.github.io/2016/06/08/简单git使用方法/","excerpt":"","text":"查看当前远程库12345678$-&gt; git remote$-&gt; git remote -vBITDM https://github.com/BITDM/bitdm.github.io.git (fetch)BITDM https://github.com/BITDM/bitdm.github.io.git (push)bitdm https://github.com/BITDM/bitdm.github.io (fetch)bitdm https://github.com/BITDM/bitdm.github.io (push)origin https://github.com/Atlantic8/bitdm.github.io.git (fetch)origin https://github.com/Atlantic8/bitdm.github.io.git (push) 添加远程库1$-&gt; git remote add emacs git://github.com/lishuo/emacs 从远程库抓取数据1$-&gt;git fetch [remote-name] 添加远程源，upstream可以是别的名字12345678$-&gt; git remote add upstream https://github.com/BITDM/bitdm.github.io.git$-&gt; git remote -vBITDM https://github.com/BITDM/bitdm.github.io.git (fetch)BITDM https://github.com/BITDM/bitdm.github.io.git (push)origin https://github.com/Atlantic8/bitdm.github.io.git (fetch)origin https://github.com/Atlantic8/bitdm.github.io.git (push)upstream https://github.com/BITDM/bitdm.github.io.git (fetch)upstream https://github.com/BITDM/bitdm.github.io.git (push) 用远程源来更新自己的项目12$-&gt; git fetch upstream$-&gt; git merge upstream/master 推送数据到远程仓库1$-&gt; git push [remote-name] [branch-name] 远程仓库的删除和重命名12$-&gt; git remote rm [remote-name] $-&gt; git remotw rename form-name to-name 把本地文件夹放到github上作为repository12345678首先在网页上创建github仓库进入目标文件夹git init # initialize an empty repositorygit remote add origin http://xxxxxx.git # add remote repository addressgit add --all # 添加所有文件git commit -m &apos;add&apos; # 提交/注释git push origin master # 提交完成 修改本地文件，同步到仓库1234567891011121314# 先添加文件git add test.txtgit commit -m &quot;add test.txt&quot;# 删除文件，如果要在版本库中删除，使用git rm，并且commitrm test.txtgit status # 查看状态git push origin master # 推送到远程库# 修改文件的话，先自行修改git status # 显示修改git add 想要提交的文件名git commit -m &quot;注释的一些信息&quot;# 如果在这一步出错的话：git reset --hard HEAD 回滚到add之前的状态git push # 完成","categories":[],"tags":[{"name":"git","slug":"git","permalink":"atlantic8.github.io/tags/git/"},{"name":"github","slug":"github","permalink":"atlantic8.github.io/tags/github/"}]},{"title":"pandas初步","slug":"pandas初步","date":"2016-05-17T14:34:11.000Z","updated":"2018-12-16T14:08:06.490Z","comments":true,"path":"2016/05/17/pandas初步/","link":"","permalink":"atlantic8.github.io/2016/05/17/pandas初步/","excerpt":"","text":"SeriesSeries类似于一维数组对象，由一组数据和其对应的标签组成，仅由一组数据即可产生简单的Series：123456789101112131415161718192021222324252627282930313233343536373839from pandas import Series, DataFrameimport pandas as pdobj = Series([4,7,-5,3])obj.index$-&gt; RangeIndex(start=0, stop=4, step=1)obj.values$-&gt; array([ 4, 7, -5, 3], dtype=int64)obj2 = Series([4,7,-5,3], index=['a','b','c','d'])# a 4, b 7, c -5, d 3obj2['a']$-&gt; 4obj2[['a','b']]$-&gt; &#123;'a':4, 'b':7&#125;obj2[obj2 &gt; 3]$-&gt; &#123;'a':4, 'b':7&#125;#也可以将Series看成一个字典， index是key， values是value'b' in obj2$-&gt; true#可以通过字典建立Seriesobj3 = Series(&#123;'a':4, 'b':7, 'c':-5, 'd':3&#125;)sdata = &#123;'Ohio':35000,'Texas':71000,'Oregon':16000,'Utah':5000&#125;states=['California','Ohio','Oregon','Texas']obj4=Series(sdata,index=states)$-&gt; California NaN Ohio 35000.0 Oregon 16000.0 Texas 71000.0obj4.isnull()$-&gt; California True Ohio False Oregon False Texas False#Series对象有一个name属性obj4.name = 'population' DataFrame表格型数据，有行索引和列索引12345678910data = &#123;'state':['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'], 'year':[200,2001,2002,2001,2002], 'pop':[1.5,1.7,3.6,2.4,2.9]&#125;frame = DataFrame(data)$-&gt; pop state year 0 1.5 Ohio 200 1 1.7 Ohio 2001 2 3.6 Ohio 2002 3 2.4 Nevada 2001 4 2.9 Nevada 2002 指定列名，列会按照columns制定的顺序排列1DataFrame(data, columns=['year', 'state', 'pop']) 指定index，如果index元素不在columns中，产生一列 NaN 值12345678910DataFrame(data, columns=['year','state','pop'], index=['year','state','pop','A'])# 获取DataFrame的一个列，成为一个Series# 相同的index，name属性就是对应的列名frame['year'] &amp; frame.year# 获取列名，删除一列frame.columns$-&gt; Index([u'pop', u'state', u'year'], dtype='object')del frame.year 嵌套字典构造DataFrame，外层的key作为列属性，里层的key作为行属性12345678910111213141516171819pop = &#123;'Nvidia':&#123;2001:2.4, 2002:2.9&#125;, 'AMD':&#123;2000:1.5,2001:1.7,2002:3.6&#125;&#125;frame3 = DataFrame(pop)，加上index=[],重新设置index值$-&gt; AMD Nvidia 2000 1.5 NaN 2001 1.7 2.4 2002 3.6 2.9frame3.T$-&gt; 2000 2001 2002 AMD 1.5 1.7 3.6 Nvidia NaN 2.4 2.9# 设置行、列属性的name,设置完了也会打印出来frame3.index.name = 'year'frame3.columns.name = 'state'# 显示DataFrame中的数据，ndarray形式frame3.values$-&gt; array([[ 1.5, nan], [ 1.7, 2.4], [ 3.6, 2.9]]) DataFrame构造器 data type explain 二维ndarray 数据矩阵，还可以传入行标和列标 由数组、列表或元组组成的字典 每个序列会变成DataFrame的一列，所有序列长度必须相同 NumPy的结构化/记录数据 类似于由数组组成的字典 由Series组成的字典 每个Series组成一列。没有显示指定index的话，各Series的index会被合并成结果的行index 由字典组成的字典 各内层字典组成一列，键合并成行index 字典或Series的列表 各项成为DataFrame的一行，字典键或Series索引的并集将成为列index 由列表或元组组成的列表 类似于ndarray 另一个DataFrame 原来DataFrame的索引会被保留，除非显示指定 NumPy的MaskedArray 类似于ndarray，只是掩码值在结果DataFrame会变成NaN/缺失值 索引对象1234obj = Series(range(3), index=['a','b','c'])index = obj.indexindex[1] = 'x'$-&gt; TypeError: Index does not support mutable operations 重新索引,如果某个索引值当前不存在，引入缺失值1234567# 重新索引列indexobj = Series([1,2,3], index=['a','b','c'])obj2 = obj.reindex(['a','b','c','d'], fill_value=0)# 重新索引行/列indexobj2 = obj.reindex(['a','b','c','d'], fill_value=0, columns=['x','y','z'])# 也可以使用frame.ix[['a','b','c','d'], ['x','y','z']] 处理时间序列数据时，可能需要一些插值处理，method选项ffill | pad : 前向填充(搬运)bfill | backfill : 后向填充(搬运)123456789obj3=Series(['blue','red','yellow'], index=[0,2,3])obj3.reindex(range(6), method='ffill')$-&gt; 0 blue 1 blue 2 red 3 yellow 4 yellow 5 yellow dtype: object 丢弃指定轴上的项12345obj = Series([1,2,3], index=['a','b','c'])obj.drop('c')$-&gt; a 1 b 2 dtype: int64 索引、选取和过滤123456789101112131415161718192021222324obj = Series(np.arange(4.), index=['a','b','c','d'])obj[0]$-&gt; 0.0obj['b':'d']$-&gt; b 1.0 c 2.0 d 3.0 dtype: float64# b c d 对应的都设置为5obj['b':'d'] = 5data = DataFrame(np.arange(16).reshape((4,4)), columns=['a','b','c','d'], index=['A','B','C','D'])data &gt; 5$-&gt; upper a b c d A False False False False B False False True True C True True True True D True True True Truedata[data &lt; 5] = 0$-&gt; upper a b c d A 0 0 0 0 B 0 5 6 7 C 8 9 10 11 D 12 13 14 15 DataFrame的索引选项 data type explain obj[val] 选取DataFrame的单个列或一组列 obj.ix[val] 选取DataFrame的单个行或一组行 obj.ix[:,val] 选取单个列或列子集 obj.ix[val1,val2] 同时选取行和列 reindex方法 匹配一个或多个轴到新索引 xs方法 根据标签选取当行或单列，返回一个Series icol,irow方法 根据整数选取当行或单列，返回一个Series get_value 根据行列标签获取对应值 set_value 根据行列标签设置对应值 算术运算和数据对齐Series对象可以叠加，对应index相加，没有对应index相加的是 NaNDataFrame对象也可以相加，行和列都相加为了不得到NaN，可以使用add函数，设置fill_value12345df1.add(df2, fill_value=0)# other operantsdf1.sub(df2, fill_value=0)df1.div(df2, fill_value=0)df1.mul(df2, fill_value=0) 函数应用和映射NumPy的ufunc也可以用于操作pandas对象123frame = DataFrame(np.random.randn(4,3),columns=list('bde'),index=list('xyzw'))# 绝对值np.abs(frame) DataFrame的apply方法12345678910frame = DataFrame(np.random.randn(4,3),columns=list('bde'),index=list('xyzw'))f = lambda x: x.max()-x.min()frame.apply(f)# 除标量外，传递给apply的函数还可以返回多个值组成的Seriesdef f(x): return Series([x.min(), x.max()], index=['min', 'max'])frame.apply(f)$-&gt; b d e min -0.983954 -0.578884 -0.916169 max 1.111333 0.982841 0.663686 排序和排名12345678910111213141516171819obj = Series(range(4), index=['a','d',b','c'])obj.sort_index() # order by index$-&gt; a 0.0 b 1.0 c 2.0 d 3.0 dtype: float64obj.order() # 按值排序, NaN都放最后$-&gt; a 0.0 b 1.0 c 2.0 d 3.0 dtype: float64# DataFrame对象也可以排序frame.sort_index(axis=0)frame = DataFrame(&#123;'a':[1,2,3], 'b':[4,5,6]&#125;)# 按照a和b排序，降序frame.sort_index(by=['a','b'],ascending=False) 重复值轴索引123obj = Series(range(5), index=['a','a','b','b','c'])obj.index.is_unique$-&gt; False 汇总和计算描述统计1234567891011121314151617181920212223242526df = DataFrame([[1.4,np.nan],[7.1,-4.5],[np.nan,np.nan],[0.75,-1.3]],index=['a','b','c','d'],columns=['one','two'])# ax=1时按行求和，ax=0时按列求和# skipna=True会忽略NaN(默认)df.sum(axis=ax, skipna=False)# idxmin/idxmax返回间接统计索引df.idxmax()$-&gt; one b two d dtype: objectdf.cumsum()$-&gt; one two a 1.40 NaN b 8.50 -4.5 c NaN NaN d 9.25 -5.8df.describe() # 一次性产生多个汇总统计$-&gt; one two count 3.000000 2.000000 mean 3.083333 -2.900000 std 3.493685 2.262742 min 0.750000 -4.500000 25% NaN NaN 50% NaN NaN 75% NaN NaN max 7.100000 -1.300000 method explain count 非NaN值的数量 describe 汇总统计 min,max 最大、最小值 argmin,argmax 最小、最大值的索引位置 idxmin,idxmax 最小、最大值的索引 quantile 计算样本的分位数 sum,mean,median 总和、均值、中位数 mad 根据平均值计算平均绝对离差 var,std 样本方差、标准差 skew 样本值的偏度(三阶矩) kurt 样本值的峰度(四阶矩) cumsum 样本累计和 cummin,cummax 样本累计最小、最大值 cumprod 样本累计积 diff 计算一阶差分(时间序列数据) pct_change 计算百分数变化 相关系数和协方差12345678910111213141516# 列表之间的相关系数、协方差frame.col1.corr(frame.col2)frame.col1.cov(frame.col2)# DataFrame的相关系数、协方差，是指各个列之间的相关系数、协方差frame.corr()$-&gt; b d e b 1.000000 -0.911353 0.324945 d -0.911353 1.000000 -0.252583 e 0.324945 -0.252583 1.000000frame.cov()$-&gt; b d e b 0.591176 -0.292541 0.347585 d -0.292541 0.174294 -0.146703 e 0.347585 -0.146703 1.935457# x可以是Series或者是DataFrameframe.corrwith(x) 唯一值、值计数和成员资格12345678910111213141516171819202122232425262728obj = Series(['a','b','c','b','a','c','d','b'])obj.unique()$-&gt; array(['a', 'b', 'c', 'd'], dtype=object)obj.value_counts()$-&gt; b 3 c 2 a 2 d 1 dtype: int64pd.value_counts(obj.values, sort=False)# Series中的所有元素是否在参数中mask = obj.isin(['b','c'])$-&gt; 0 False 1 True 2 True 3 True 4 False 5 True 6 False 7 True dtype: boolobj[mask]$-&gt; 1 b 2 c 3 b 5 c 7 b dtype: object 缺失数据处理 method explain dropna 根据标签值中是否存在缺失数据对轴标签进行过滤，可通过阈值调节容忍度 fillna 用指定值或插值方法填充缺失数据 isnull 布尔值列表，True表示缺失值/NA notnull 与isnull相反 12345678910from numpy import nan as NAdata = Series([1,NA,3.5,NA,7])# 舍弃包含NA的行或列，加上how='all'后舍弃全是NA的行或列# 默认是行，设置axis=1变成列！data.dropna() data.dropna(how='all')data.[data.notnull()]# 替换NA，返回新对象# 设置inplace=True对现有对象就地修改data.fillna(0) 层次化索引1234567891011data = Series(np.random.randn(10),index=[['a','a','a','b','b','b','c','c','d','d'],[1,2,3,1,2,3,1,2,2,3]])$-&gt; a 1 0.506070 2 -2.293016 3 1.391751 b 1 -1.218733 2 0.390983 3 1.462456 c 1 0.162262 2 -0.091724 d 2 0.321799 3 0.203933 取值方法123456789101112131415161718192021222324data['b']data['b':'c']data[:,2] # 二层取值# unstack可以将这种数据重新安装到DataFrame中# stack是unstack的逆操作data.unstack()$-&gt; 1 2 3 a 0.506070 -2.293016 1.391751 b -1.218733 0.390983 1.462456 c 0.162262 -0.091724 NaN d NaN 0.321799 0.203933# DataFrame可以使用分层索引frame = DataFrame(np.arange(12).reshape((4,3)),index=[['a','a','b','b'],[1,2,1,2]],columns=[['Ohis','Ohis','Colorado'],['Green','Red','Green']])frame.index.names=['key1','key2']frame.columns.names=['state','color']$-&gt; state Ohis Colorado color Green Red Green key1 key2 a 1 0 1 2 2 3 4 5 b 1 6 7 8 2 9 10 11 重排分级顺序12345678frame.swaplevel('key1','key2')$-&gt; state Ohis Colorado color Green Red Green key2 key1 1 a 0 1 2 2 a 3 4 5 1 b 6 7 8 2 b 9 10 11 根据级别汇总统计1234567891011121314# 如果对列计数，需要设置axis=1frame.sum(level='key2')$-&gt; state Ohis Colorado color Green Red Green key2 1 6 8 10 2 12 14 16frame.sum(level='color',axis=1)$-&gt; color Green Red key1 key2 a 1 2 1 2 8 4 b 1 14 7 2 20 10","categories":[],"tags":[{"name":"python","slug":"python","permalink":"atlantic8.github.io/tags/python/"},{"name":"pandas","slug":"pandas","permalink":"atlantic8.github.io/tags/pandas/"}]},{"title":"mean shift","slug":"mean-shift","date":"2016-05-11T13:07:55.000Z","updated":"2018-12-16T14:08:06.486Z","comments":true,"path":"2016/05/11/mean-shift/","link":"","permalink":"atlantic8.github.io/2016/05/11/mean-shift/","excerpt":"","text":"基本Mean Shift给定d维空间$R^d$的n个样本点 ,i=1,…,n,在空间中任选一点x，那么Mean Shift向量的基本形式定义为: ![](http://pic002.cnblogs.com/images/2012/358029/2012051213564761.jpg) 其中，$S_k$是在一个半径为h的高维球区域中的点集合。 基于核函数的Mean Shift![](http://pic002.cnblogs.com/images/2012/358029/2012051215383189.jpg)解释一下K()核函数，h为半径，$\\frac{C_{k,d}}{nh^d}$ 为单位密度，要使得上式f得到最大，最容易想到的就是对上式进行求导，的确meanshift就是对上式进行求导.。 Mean Shift Clustering伪代码123456789// e is a predefined threshold value.for data in dataset: x = data; do : calculate mean shift of x: ms; error = f(ms-x); while (error &lt; e); dict&#123;data&#125; = x;dict&#123;x&#125;=dict&#123;y&#125; -&gt; x,y in same cluster","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"atlantic8.github.io/categories/Algorithm/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"atlantic8.github.io/tags/machine-learning/"}]},{"title":"IPython使用方法","slug":"IPython使用方法","date":"2016-05-11T13:05:36.000Z","updated":"2018-12-16T14:08:06.264Z","comments":true,"path":"2016/05/11/IPython使用方法/","link":"","permalink":"atlantic8.github.io/2016/05/11/IPython使用方法/","excerpt":"","text":"IPython的部分功能整理Tab自动完成内容补全，与linux中的功能相似 内省显示对象通用信息1234b = [1, 2, 3, 4, 5]b?b??np.*load*? #列出NumPy命名空间中所有包含load的函数 b也可以是函数对象，如果函数对象后面跟两个？，就可以显示函数代码。 %run执行脚本文件12#执行my_work.py中的python代码%run my_work.py 绝对路径和相对路径都可以使用 命令行中剪贴代码12345678%paste#粘贴代码，一次性粘贴完%cpaste#粘贴代码#可以多次粘贴#结束时输入--即可#-- 代码性能分析python主要的性能分析工具是cProfile模块12345678#执行script.py并输出各函数的执行时间python -m cProfile script.py#按照cumulative time排序python -m cProfile -s cumulative script.py%run -p -s cumulative script.py#IPython接口, %prun用于分析语句而不是模块%prun -l 7 -s cumulative func() 对于逐行分析代码性能，可以使用line_profiler库，具体参见&lt;利用python进行数据分析&gt;74页。 魔术命令以%为前缀的命令叫做魔术命令 command explaination %quickref 显示IPython快速参考 %magic 显示所有魔术命令的详细文档 %debug 从最新的异常跟踪底部进入交互式调试器 %hist 打印命令的输入(也可是输出)历史 %pdb 在异常发生后自动进入调试器 %paste 执行剪贴板中的python代码 %cpaste 打开特殊提示符以便手工粘贴待执行的python代码 %reset 删除交互式命名空间中全部变量/名称 %page object 通过分页器打印输出object %run script.py 执行script.py中的代码 %prun statement 通过cProfile执行statement，并打印分析器结果 %time statement 报告statement的执行时间 %timeit statement 多次执行statement输出平均时间 %who %who_ls %whos 显示交互式空间中定义的变量/信息级别/冗余度 %xdel variable 删除变量varibale，并尝试清除其在IPython中对象上的一切引用 与操作系统相关的魔术命令 command explaination !cmd 在系统shell中执行cmd output=!cmd args 执行cmd，并将stdout存放在output中 %alias alias_name cmd 为系统shell命令定义别名 %bookmark 使用IPython的目录书签系统 %cd directory 将directory设置为当前目录 %pwd 返回系统当前工作目录 %pushd directory 将当前目录入栈，转向目标目录 %popd 弹出栈顶目录，并转向该目录 %dirs 返回一个含有当前目录栈的列表 %dhist 打印目录访问历史 %env 以dict形式返回系统环境变量","categories":[],"tags":[{"name":"IPython","slug":"IPython","permalink":"atlantic8.github.io/tags/IPython/"}]},{"title":"matplotlib绘图基本方法","slug":"matplotlib绘图基本方法","date":"2016-05-10T01:30:37.000Z","updated":"2018-12-16T14:08:06.483Z","comments":true,"path":"2016/05/10/matplotlib绘图基本方法/","link":"","permalink":"atlantic8.github.io/2016/05/10/matplotlib绘图基本方法/","excerpt":"","text":"设置中文编码1# -*- coding: utf-8 -*- 头文件1234import numpy as npimport matplotlib.pyplot as pltimport pylabfrom matplotlib.legend import Legend 直方图(histogram)12345678910111213141516171819202122232425#N：表示横坐标点个数#m：对比方案个数def getHistogram(data, my_title): color = ['gray','green','blue','magenta'] N = 6 fs = 20 # font size ind = np.arange(N) # the x locations for the groups width = 0.2 # the width of the bars, 1/(m+1) pylab.grid(True) # pylab.title(my_title, fontsize = fs) pylab.ylim((-25,15)) #plt.ylim((0,7.5)) pylab.bar(ind-2*width, data[0], width, color=color[0],label='MBE3',edgecolor=color[0]) pylab.bar(ind-1*width, data[1], width, color=color[1],label='PRIVATUS',edgecolor=color[1]) pylab.bar(ind+0*width, data[2], width, color=color[2],label='OPPEMS',edgecolor=color[2]) pylab.bar(ind+1*width, data[3], width, color=color[3],label='DPMRRS',edgecolor=color[3]) # add some text for labels, title and axes ticks pylab.xlabel(r'$\\epsilon$', fontsize = fs) #pylab.ylabel('mutual information', fontsize = fs) pylab.ylabel('extra cost/$', fontsize = fs) pylab.xticks(ind, ('0.15', '0.25', '0.35', '0.45', '0.55','0.65'), fontsize = fs) pylab.yticks(fontsize = fs) pylab.legend(ncol = 4, loc = 'upper left') pylab.show() 折线图(plot)12345678910111213def getLine(data,my_title): plt.grid(True) fs = 20 X = [100, 200, 300, 400, 500] plt.xlabel('number of invalid noises', fontsize = fs) plt.ylabel('extra cost/$', fontsize = fs) # plt.ylabel('mutual information', fontsize = fs) plt.xlim((0,600)) plt.xticks(fontsize = fs) plt.yticks(fontsize = fs) # plt.title(my_title, fontsize = fs) plt.plot(X, data, 'ro-',linewidth=4) plt.show() 散点图(dot)1234567891011121314151617def plotDots(data): plt.grid(True) fs = 20 X = range(96) plt.xlabel('time', fontsize = fs) # plt.ylabel('price/($/kwh)', fontsize = fs) plt.ylabel('mutual information', fontsize = fs) plt.xlim((-4,100)) plt.ylim((0,0.03)) plt.xticks([]) plt.yticks([]) # plt.title(my_title, fontsize = fs) plt.plot(X, data, 'go',label='price') plt.plot(X,y1, 'b--',label='$p_l$') plt.plot(X,y2, 'k--',label='$p_h$') # plt.legend(fontsize = fs, ncol=3) plt.show() 饼图(pie)1234567#sum(data)=1def plotPie(data): plt.title('pie chart') labels = ['China', 'Japan', 'America'] # labeldistance&gt;1, label就在饼图外面 plt.pie(x, labels=labels, autopct='%1.1f%%',labeldistance=1.2) plt.show()","categories":[],"tags":[{"name":"python","slug":"python","permalink":"atlantic8.github.io/tags/python/"}]},{"title":"java-matlab2014a混合编程","slug":"java-matlab2014a混合编程","date":"2016-05-05T07:16:47.000Z","updated":"2018-12-16T14:08:06.475Z","comments":true,"path":"2016/05/05/java-matlab2014a混合编程/","link":"","permalink":"atlantic8.github.io/2016/05/05/java-matlab2014a混合编程/","excerpt":"","text":"第一步 编写需要调用的matlab函数，可以多个文件一起编译 在matlab的shell框中输入deploytool，回车 在弹出的菜单中选中library compiler(这个根据实际情况自己决定) 左上角选中java package。点击稍右侧的+号添加文件 修改Library Name和类名 Runtime downloaded from web和runtime included in package视情况决定 点击右上角的Package按钮开始编译 第二步 首先需要将Matlab\\R2014a\\toolbox\\javabuilder\\jar中的javabuilder.jar放入java工程文件夹内(最好这么做) 将编译完成的xxx.jar包放入java工程文件夹内(最好这么做) 在eclipse的Package Explore中右键工程名 Build path -&gt; configure build path，然后点击Add External JARs添加上面的2个jar包 第三步 首先导入jar包 12import com.mathworks.toolbox.javabuilder.*;import xxx.Class1; 使用函数时 123456Class1 class = new Class1();Object[] result = t = new Object[2]; //这里必须用数组形式，至少在matlab2014a里是这样的result = class.functionName(2, argument1, srgument2, argument3); //2表示返回结果的个数为2MWNumericArray temp = (MWNumericArray)result[0]; //第一个结果是数组 double[][] recv = (double[][]) temp.toDoubleArray(); //还有toInt/FloatArray以及toString等用法int box = Integer.valueOf(result[0].toString()); //第二个结果是一个int型整数.","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"atlantic8.github.io/tags/Java/"},{"name":"Matlab","slug":"Matlab","permalink":"atlantic8.github.io/tags/Matlab/"}]},{"title":"java序列化","slug":"java序列化","date":"2016-05-05T07:10:53.000Z","updated":"2018-12-16T14:08:06.478Z","comments":true,"path":"2016/05/05/java序列化/","link":"","permalink":"atlantic8.github.io/2016/05/05/java序列化/","excerpt":"","text":"一. 描述 在网络通信和数据存储方面很有用 对于需要序列化的类，应该在其实现时在类头部加上implements Serializable 二. 示例 序列化 12345678910111213public byte[] functionName (ClassType sample) &#123; try &#123; ByteArrayOutputStream baos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(baos); oos.writeObject(sample); byte[] bytes = baos.toByteArray(); System.out.println(\"...serialization complete.\"); return bytes; &#125; catch (Exception e) &#123; System.out.println(\"...serialization failed.\"); &#125; return null;&#125; 反序列化 12345678910public ClassType deserializeCFC(byte[] bytes) &#123; try &#123; ByteArrayInputStream bais = new ByteArrayInputStream(bytes); ObjectInputStream ois = new ObjectInputStream(bais); return (ClassType) ois.readObject(); &#125; catch (Exception e) &#123; System.out.println(\"...deserialization failed.\"); &#125; return null;&#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"atlantic8.github.io/tags/Java/"}]},{"title":"cpp-string","slug":"cpp-string","date":"2016-05-05T06:54:06.000Z","updated":"2018-12-16T14:08:06.462Z","comments":true,"path":"2016/05/05/cpp-string/","link":"","permalink":"atlantic8.github.io/2016/05/05/cpp-string/","excerpt":"","text":"toupper, tolower地球人都知道 C++ 的 string 没有 toupper ，好在这不是个大问题，因为我们有 STL 算法：12345string s(\"heLLo\");transform(s.begin(), s.end(), s.begin(), toupper);cout &lt;&lt; s &lt;&lt; endl;transform(s.begin(), s.end(), s.begin(), tolower);cout &lt;&lt; s &lt;&lt; endl; 当然，我知道很多人希望的是 s.to_upper() ，但是对于一个这么通用的 basic_string 来说，的确没办法把这些专有的方法放进来。如果你用 boost stringalgo ，那当然不在话下，你也就不需要读这篇文章了。 trim我们还知道 string 没有 trim ，不过自力更生也不困难，比 toupper 来的还要简单：12345string s(\" hello \");s.erase(0, s.find_first_not_of(\" /n\"));cout &lt;&lt; s &lt;&lt; endl;s.erase(s.find_last_not_of(' ') + 1);cout &lt;&lt; s &lt;&lt; endl; 注意由于 find_first_not_of 和 find_last_not_of 都可以接受字符串，这个时候它们寻找该字符串中所有字符的 absence ，所以你可以一次 trim 掉多种字符。 erasestring 本身的 erase 还是不错的，但是只能 erase 连续字符，如果要拿掉一个字符串里面所有的某个字符呢？用 STL 的 erase + remove_if 就可以了，注意光 remove_if 是不行的。12string s(\" hello, world. say bye \");s.erase(remove_if(s.begin(),s.end(), bind2nd(equal_to&lt;char&gt;(), ' ')), s.end()); 上面的这段会拿掉所有的空格，于是得到 hello,world.saybye。 replacestring 本身提供了 replace ，不过并不是面向字符串的，譬如我们最常用的把一个 substr 换成另一个 substr 的操作，就要做一点小组合：1234string s(\"hello, world\");string sub(\"ello, \");s.replace(s.find(sub), sub.size(), \"appy \");cout &lt;&lt; s &lt;&lt; endl; 输出为 happy world。注意原来的那个 substr 和替换的 substr 并不一定要一样长。 startwith, endwith这两个可真常用，不过如果你仔细看看 string 的接口，就会发现其实没必要专门提供这两个方法，已经有的接口可以干得很好：1234567string s(\"hello, world\");string head(\"hello\");string tail(\"ld\");bool startwith = s.compare(0, head.size(), head) == 0;cout &lt;&lt; boolalpha &lt;&lt; startwith &lt;&lt; endl;bool endwith = s.compare(s.size() - tail.size(), tail.size(), tail) == 0;cout &lt;&lt; boolalpha &lt;&lt; endwith &lt;&lt; endl; 当然了，没有1s.startwith(\"hello\") 这样方便。 toint, todouble, tobool…这也是老生常谈了，无论是 C 的方法还是 C++ 的方法都可以，各有特色：1234567891011121314151617181920string s(\"123\");int i = atoi(s.c_str());cout &lt;&lt; i &lt;&lt; endl; int ii;stringstream(s) &gt;&gt; ii;cout &lt;&lt; ii &lt;&lt; endl; string sd(\"12.3\");double d = atof(sd.c_str());cout &lt;&lt; d &lt;&lt; endl; double dd;stringstream(sd) &gt;&gt; dd;cout &lt;&lt; dd &lt;&lt; endl; string sb(\"true\");bool b;stringstream(sb) &gt;&gt; boolalpha &gt;&gt; b;cout &lt;&lt; boolalpha &lt;&lt; b &lt;&lt; endl; C 的方法很简洁，而且赋值与转换在一句里面完成，而 C++ 的方法很通用。 split这可是件麻烦事，我们最希望的是这样一个接口： ‘’’s.split(vect, ‘,’)’’’ 。用 STL 算法来做有一定难度，我们可以从简单的开始，如果分隔符是空格、tab 和回车之类，那么这样就够了：123456string s(\"hello world, bye.\");vector&lt;string&gt; vect;vect.assign( istream_iterator&lt;string&gt;(stringstream(s)), istream_iterator&lt;string&gt;()); 不过要注意，如果 s 很大，那么会有效率上的隐忧，因为 stringstream 会 copy 一份 string 给自己用。 concat把一个装有 string 的容器里面所有的 string 连接起来，怎么做？希望你不要说是 hand code 循环，这样做不是更好？ 123456vector&lt;string&gt; vect;vect.push_back(\"hello\");vect.push_back(\", \");vect.push_back(\"world\"); cout &lt;&lt; accumulate(vect.begin(), vect.end(), string(\"\")); 不过在效率上比较有优化余地。 reverse其实我比较怀疑有什么人需要真的去 reverse 一个 string ，不过做这件事情的确是很容易：1std::reverse(s.begin(), s.end()); 上面是原地反转的方法，如果需要反转到别的 string 里面，一样简单：1s1.assign(s.rbegin(), s.rend()); 效率也相当理想。 解析文件扩展名字数多点的写法：123std::string filename(\"hello.exe\");std::string::size_type pos = filename.rfind('.');std::string ext = filename.substr(pos == std::string::npos ? filename.length() : pos + 1); 不过两行，合并成一行呢？也不是不可以：1std::string ext = filename.substr(filename.rfind('.') == std::string::npos ? filename.length() : filename.rfind('.') + 1); 我们知道，rfind 执行了两次。不过第一，你可以希望编译器把它优化掉，其次，扩展名一般都很短，即便多执行一次，区别应该是相当微小。","categories":[],"tags":[{"name":"Cpp","slug":"Cpp","permalink":"atlantic8.github.io/tags/Cpp/"}]},{"title":"cpp-unordered_map","slug":"cpp-unordered-map","date":"2016-05-04T14:42:11.000Z","updated":"2018-12-16T14:08:06.466Z","comments":true,"path":"2016/05/04/cpp-unordered-map/","link":"","permalink":"atlantic8.github.io/2016/05/04/cpp-unordered-map/","excerpt":"","text":"unordered_map的基本用法如下：1234567unordered_map&lt;string, int&gt; map ;map[\"zhangsan\"]=3;map[\"lisi\"]=9;int x = map[\"lisi\"]; //9unordered_map&lt;string, int&gt;::iterator it;for (it=map.begin(); it!=map.end(); it++) cout&lt;&lt;it-&gt;first&lt;&lt;\" \"&lt;&lt;it-&gt;second&lt;&lt;endl; 关于支持复杂类型key，unordered_map支持string类型，但是自定义类型不行。下面给出通过重载使得unordered_map支持自定义类型的例子：123456789101112131415161718192021222324252627282930struct ReadingPair //作为key的类型&#123; double real, modified; ReadingPair() &#123; this-&gt;real = 0; this-&gt;modified = 0; &#125; // 判断两个示例是否相等的函数 bool operator== (const struct ReadingPair&amp; other) const &#123; if (real != other.real || modified != other.modified) return false; return true; &#125;&#125;;另外还需要一个hash函数，重载操作符(),计算key的哈希值。一个比较直观的方法是特化（specialize）std::hash模板。namespace std &#123; template &lt;&gt; struct hash&lt;ReadingPair&gt; &#123; std::size_t operator()(const ReadingPair&amp; k) const &#123; // Compute individual hash values for first, // second and third and combine them using XOR // and bit shifting: using std::hash; //重要 return ((hash&lt;double&gt;()(k.real) ^ (hash&lt;double&gt;()(k.modified) &lt;&lt; 1)) &gt;&gt; 1); &#125; &#125;;&#125;由于unordered_map不需要排序，所以不需要重载&lt;符号。","categories":[],"tags":[{"name":"Cpp","slug":"Cpp","permalink":"atlantic8.github.io/tags/Cpp/"}]}]}